{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 02.02.2024\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 19.02.2024\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 25.02.2024\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ASUS/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', kernel = 'rbf'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        X_fit = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            self.dec = PCA(self.new_dim)\n",
    "            X_fit = self.dec.fit_transform(X_fit)\n",
    "        \n",
    "        indices = np.random.randint(0, X_fit.shape[0], size=(1000000, 2))\n",
    "        X_pairs = X_fit[indices]\n",
    "        sigma = np.sqrt(np.median(np.sum(np.square(X_pairs[:, 0] - X_pairs[:, 1]), axis = 1)))\n",
    "\n",
    "        self.w = np.random.normal(0, (1 / sigma), [X_fit.shape[1], self.n_features])\n",
    "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        phi = np.cos(X_fit @ self.w + self.b)\n",
    "\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(max_iter = 100000)\n",
    "        if self.classifier == 'svm':\n",
    "            self.model = SVC(kernel = self.kernel, max_iter = 100000)\n",
    "        if self.classifier == 'linreg':\n",
    "            self.model = LinearRegression()\n",
    "        self.model.fit(phi, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        phi = np.cos(X_pred @ self.w + self.b)\n",
    "\n",
    "        return self.model.predict_proba(phi)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        phi = np.cos(X_pred @ self.w + self.b)\n",
    "        return self.model.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "rff = RFFPipeline()\n",
    "rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "print(\"accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ASUS/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8824\n",
      "CPU times: user 7min 43s, sys: 7.15 s, total: 7min 51s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVC_linear = RFFPipeline(classifier='svm', kernel = 'linear')\n",
    "SVC_linear.fit(x_train, y_train)\n",
    "y_pred = SVC_linear.predict(x_test)\n",
    "print(\"accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8677\n",
      "CPU times: user 8min 8s, sys: 5.4 s, total: 8min 13s\n",
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVC_kernel = RFFPipeline(classifier='svm', kernel = 'rbf')\n",
    "SVC_kernel.fit(x_train, y_train)\n",
    "y_pred = SVC_kernel.predict(x_test)\n",
    "print(\"accuracy:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8382\n",
      "CPU times: user 19min, sys: 815 ms, total: 19min 1s\n",
      "Wall time: 19min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_classifier = LinearSVC(max_iter=10000, dual = 'auto')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8828\n",
      "CPU times: user 5min 33s, sys: 779 ms, total: 5min 34s\n",
      "Wall time: 5min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_classifier = SVC(max_iter=10000, kernel = 'rbf')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "y_pred = svm_classifier.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный svm работает подольше и дает сравнительно хуже качество. Ядровой svm работает быстрее и дает качество лучше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Попробуем CatBoost с какой-то сеткой параметров*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = PCA(50)\n",
    "x_train_pca = dec.fit_transform(x_train)\n",
    "x_test_pca = dec.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.2887424\ttotal: 56.1ms\tremaining: 2.75s\n",
      "1:\tlearn: 2.2751298\ttotal: 96ms\tremaining: 2.3s\n",
      "2:\tlearn: 2.2622099\ttotal: 134ms\tremaining: 2.09s\n",
      "3:\tlearn: 2.2490670\ttotal: 173ms\tremaining: 1.98s\n",
      "4:\tlearn: 2.2363366\ttotal: 212ms\tremaining: 1.91s\n",
      "5:\tlearn: 2.2245693\ttotal: 250ms\tremaining: 1.83s\n",
      "6:\tlearn: 2.2127840\ttotal: 290ms\tremaining: 1.78s\n",
      "7:\tlearn: 2.2008081\ttotal: 331ms\tremaining: 1.74s\n",
      "8:\tlearn: 2.1901309\ttotal: 368ms\tremaining: 1.68s\n",
      "9:\tlearn: 2.1801158\ttotal: 405ms\tremaining: 1.62s\n",
      "10:\tlearn: 2.1693255\ttotal: 444ms\tremaining: 1.57s\n",
      "11:\tlearn: 2.1585238\ttotal: 484ms\tremaining: 1.53s\n",
      "12:\tlearn: 2.1485154\ttotal: 522ms\tremaining: 1.49s\n",
      "13:\tlearn: 2.1385680\ttotal: 561ms\tremaining: 1.44s\n",
      "14:\tlearn: 2.1285154\ttotal: 600ms\tremaining: 1.4s\n",
      "15:\tlearn: 2.1193603\ttotal: 639ms\tremaining: 1.36s\n",
      "16:\tlearn: 2.1090073\ttotal: 677ms\tremaining: 1.31s\n",
      "17:\tlearn: 2.0993106\ttotal: 718ms\tremaining: 1.28s\n",
      "18:\tlearn: 2.0902894\ttotal: 758ms\tremaining: 1.24s\n",
      "19:\tlearn: 2.0817092\ttotal: 795ms\tremaining: 1.19s\n",
      "20:\tlearn: 2.0723877\ttotal: 838ms\tremaining: 1.16s\n",
      "21:\tlearn: 2.0628424\ttotal: 877ms\tremaining: 1.12s\n",
      "22:\tlearn: 2.0536874\ttotal: 915ms\tremaining: 1.07s\n",
      "23:\tlearn: 2.0449460\ttotal: 953ms\tremaining: 1.03s\n",
      "24:\tlearn: 2.0361634\ttotal: 991ms\tremaining: 991ms\n",
      "25:\tlearn: 2.0278805\ttotal: 1.03s\tremaining: 951ms\n",
      "26:\tlearn: 2.0194461\ttotal: 1.07s\tremaining: 910ms\n",
      "27:\tlearn: 2.0113292\ttotal: 1.11s\tremaining: 871ms\n",
      "28:\tlearn: 2.0043285\ttotal: 1.15s\tremaining: 830ms\n",
      "29:\tlearn: 1.9972894\ttotal: 1.18s\tremaining: 789ms\n",
      "30:\tlearn: 1.9890015\ttotal: 1.23s\tremaining: 751ms\n",
      "31:\tlearn: 1.9814869\ttotal: 1.27s\tremaining: 713ms\n",
      "32:\tlearn: 1.9734434\ttotal: 1.31s\tremaining: 674ms\n",
      "33:\tlearn: 1.9657063\ttotal: 1.35s\tremaining: 635ms\n",
      "34:\tlearn: 1.9582717\ttotal: 1.39s\tremaining: 595ms\n",
      "35:\tlearn: 1.9516144\ttotal: 1.42s\tremaining: 554ms\n",
      "36:\tlearn: 1.9444247\ttotal: 1.46s\tremaining: 514ms\n",
      "37:\tlearn: 1.9380457\ttotal: 1.5s\tremaining: 474ms\n",
      "38:\tlearn: 1.9309670\ttotal: 1.54s\tremaining: 435ms\n",
      "39:\tlearn: 1.9238867\ttotal: 1.58s\tremaining: 395ms\n",
      "40:\tlearn: 1.9165813\ttotal: 1.62s\tremaining: 357ms\n",
      "41:\tlearn: 1.9095740\ttotal: 1.66s\tremaining: 317ms\n",
      "42:\tlearn: 1.9038248\ttotal: 1.7s\tremaining: 277ms\n",
      "43:\tlearn: 1.8973022\ttotal: 1.74s\tremaining: 237ms\n",
      "44:\tlearn: 1.8915187\ttotal: 1.78s\tremaining: 198ms\n",
      "45:\tlearn: 1.8850661\ttotal: 1.81s\tremaining: 158ms\n",
      "46:\tlearn: 1.8786885\ttotal: 1.85s\tremaining: 118ms\n",
      "47:\tlearn: 1.8731814\ttotal: 1.89s\tremaining: 78.7ms\n",
      "48:\tlearn: 1.8673253\ttotal: 1.93s\tremaining: 39.3ms\n",
      "49:\tlearn: 1.8623094\ttotal: 1.96s\tremaining: 0us\n",
      "0:\tlearn: 2.2883568\ttotal: 47ms\tremaining: 2.3s\n",
      "1:\tlearn: 2.2747754\ttotal: 84.8ms\tremaining: 2.04s\n",
      "2:\tlearn: 2.2619825\ttotal: 122ms\tremaining: 1.91s\n",
      "3:\tlearn: 2.2487982\ttotal: 161ms\tremaining: 1.85s\n",
      "4:\tlearn: 2.2360449\ttotal: 200ms\tremaining: 1.8s\n",
      "5:\tlearn: 2.2243268\ttotal: 238ms\tremaining: 1.75s\n",
      "6:\tlearn: 2.2125144\ttotal: 276ms\tremaining: 1.7s\n",
      "7:\tlearn: 2.2005244\ttotal: 316ms\tremaining: 1.66s\n",
      "8:\tlearn: 2.1899120\ttotal: 353ms\tremaining: 1.61s\n",
      "9:\tlearn: 2.1791836\ttotal: 389ms\tremaining: 1.56s\n",
      "10:\tlearn: 2.1685163\ttotal: 428ms\tremaining: 1.52s\n",
      "11:\tlearn: 2.1578298\ttotal: 468ms\tremaining: 1.48s\n",
      "12:\tlearn: 2.1476989\ttotal: 505ms\tremaining: 1.44s\n",
      "13:\tlearn: 2.1372152\ttotal: 543ms\tremaining: 1.4s\n",
      "14:\tlearn: 2.1272772\ttotal: 582ms\tremaining: 1.36s\n",
      "15:\tlearn: 2.1179040\ttotal: 620ms\tremaining: 1.32s\n",
      "16:\tlearn: 2.1077481\ttotal: 658ms\tremaining: 1.28s\n",
      "17:\tlearn: 2.0990454\ttotal: 695ms\tremaining: 1.24s\n",
      "18:\tlearn: 2.0900974\ttotal: 734ms\tremaining: 1.2s\n",
      "19:\tlearn: 2.0815990\ttotal: 773ms\tremaining: 1.16s\n",
      "20:\tlearn: 2.0720929\ttotal: 814ms\tremaining: 1.12s\n",
      "21:\tlearn: 2.0637206\ttotal: 852ms\tremaining: 1.08s\n",
      "22:\tlearn: 2.0545218\ttotal: 890ms\tremaining: 1.04s\n",
      "23:\tlearn: 2.0458339\ttotal: 929ms\tremaining: 1.01s\n",
      "24:\tlearn: 2.0369527\ttotal: 967ms\tremaining: 967ms\n",
      "25:\tlearn: 2.0287007\ttotal: 1s\tremaining: 928ms\n",
      "26:\tlearn: 2.0201690\ttotal: 1.04s\tremaining: 889ms\n",
      "27:\tlearn: 2.0120907\ttotal: 1.08s\tremaining: 851ms\n",
      "28:\tlearn: 2.0040010\ttotal: 1.12s\tremaining: 811ms\n",
      "29:\tlearn: 1.9970424\ttotal: 1.16s\tremaining: 771ms\n",
      "30:\tlearn: 1.9886463\ttotal: 1.2s\tremaining: 735ms\n",
      "31:\tlearn: 1.9812185\ttotal: 1.24s\tremaining: 696ms\n",
      "32:\tlearn: 1.9731577\ttotal: 1.28s\tremaining: 658ms\n",
      "33:\tlearn: 1.9654371\ttotal: 1.31s\tremaining: 619ms\n",
      "34:\tlearn: 1.9575341\ttotal: 1.35s\tremaining: 581ms\n",
      "35:\tlearn: 1.9509424\ttotal: 1.39s\tremaining: 541ms\n",
      "36:\tlearn: 1.9438229\ttotal: 1.43s\tremaining: 503ms\n",
      "37:\tlearn: 1.9371619\ttotal: 1.47s\tremaining: 464ms\n",
      "38:\tlearn: 1.9306511\ttotal: 1.5s\tremaining: 425ms\n",
      "39:\tlearn: 1.9235179\ttotal: 1.54s\tremaining: 386ms\n",
      "40:\tlearn: 1.9162616\ttotal: 1.58s\tremaining: 348ms\n",
      "41:\tlearn: 1.9100001\ttotal: 1.63s\tremaining: 310ms\n",
      "42:\tlearn: 1.9044832\ttotal: 1.67s\tremaining: 271ms\n",
      "43:\tlearn: 1.8976842\ttotal: 1.71s\tremaining: 233ms\n",
      "44:\tlearn: 1.8919704\ttotal: 1.74s\tremaining: 194ms\n",
      "45:\tlearn: 1.8855314\ttotal: 1.78s\tremaining: 155ms\n",
      "46:\tlearn: 1.8790615\ttotal: 1.82s\tremaining: 116ms\n",
      "47:\tlearn: 1.8736444\ttotal: 1.85s\tremaining: 77.3ms\n",
      "48:\tlearn: 1.8677758\ttotal: 1.89s\tremaining: 38.6ms\n",
      "49:\tlearn: 1.8627166\ttotal: 1.93s\tremaining: 0us\n",
      "0:\tlearn: 2.2883992\ttotal: 43.8ms\tremaining: 2.15s\n",
      "1:\tlearn: 2.2748302\ttotal: 81.3ms\tremaining: 1.95s\n",
      "2:\tlearn: 2.2620491\ttotal: 119ms\tremaining: 1.87s\n",
      "3:\tlearn: 2.2489606\ttotal: 159ms\tremaining: 1.83s\n",
      "4:\tlearn: 2.2362856\ttotal: 199ms\tremaining: 1.79s\n",
      "5:\tlearn: 2.2245520\ttotal: 237ms\tremaining: 1.74s\n",
      "6:\tlearn: 2.2127707\ttotal: 276ms\tremaining: 1.69s\n",
      "7:\tlearn: 2.2008380\ttotal: 315ms\tremaining: 1.65s\n",
      "8:\tlearn: 2.1902233\ttotal: 352ms\tremaining: 1.6s\n",
      "9:\tlearn: 2.1801882\ttotal: 388ms\tremaining: 1.55s\n",
      "10:\tlearn: 2.1693737\ttotal: 428ms\tremaining: 1.52s\n",
      "11:\tlearn: 2.1585790\ttotal: 467ms\tremaining: 1.48s\n",
      "12:\tlearn: 2.1486745\ttotal: 506ms\tremaining: 1.44s\n",
      "13:\tlearn: 2.1380172\ttotal: 544ms\tremaining: 1.4s\n",
      "14:\tlearn: 2.1279667\ttotal: 583ms\tremaining: 1.36s\n",
      "15:\tlearn: 2.1186466\ttotal: 621ms\tremaining: 1.32s\n",
      "16:\tlearn: 2.1083929\ttotal: 659ms\tremaining: 1.28s\n",
      "17:\tlearn: 2.0982911\ttotal: 699ms\tremaining: 1.24s\n",
      "18:\tlearn: 2.0885306\ttotal: 739ms\tremaining: 1.21s\n",
      "19:\tlearn: 2.0799321\ttotal: 777ms\tremaining: 1.17s\n",
      "20:\tlearn: 2.0709670\ttotal: 816ms\tremaining: 1.13s\n",
      "21:\tlearn: 2.0625071\ttotal: 854ms\tremaining: 1.09s\n",
      "22:\tlearn: 2.0535760\ttotal: 892ms\tremaining: 1.05s\n",
      "23:\tlearn: 2.0448276\ttotal: 930ms\tremaining: 1.01s\n",
      "24:\tlearn: 2.0362136\ttotal: 969ms\tremaining: 969ms\n",
      "25:\tlearn: 2.0280553\ttotal: 1.01s\tremaining: 930ms\n",
      "26:\tlearn: 2.0198525\ttotal: 1.04s\tremaining: 890ms\n",
      "27:\tlearn: 2.0118572\ttotal: 1.08s\tremaining: 852ms\n",
      "28:\tlearn: 2.0043603\ttotal: 1.12s\tremaining: 813ms\n",
      "29:\tlearn: 1.9966059\ttotal: 1.16s\tremaining: 772ms\n",
      "30:\tlearn: 1.9892091\ttotal: 1.2s\tremaining: 732ms\n",
      "31:\tlearn: 1.9822248\ttotal: 1.23s\tremaining: 693ms\n",
      "32:\tlearn: 1.9749547\ttotal: 1.27s\tremaining: 654ms\n",
      "33:\tlearn: 1.9677072\ttotal: 1.31s\tremaining: 615ms\n",
      "34:\tlearn: 1.9597330\ttotal: 1.35s\tremaining: 578ms\n",
      "35:\tlearn: 1.9531374\ttotal: 1.39s\tremaining: 539ms\n",
      "36:\tlearn: 1.9461781\ttotal: 1.42s\tremaining: 501ms\n",
      "37:\tlearn: 1.9384000\ttotal: 1.47s\tremaining: 463ms\n",
      "38:\tlearn: 1.9318234\ttotal: 1.5s\tremaining: 424ms\n",
      "39:\tlearn: 1.9246535\ttotal: 1.54s\tremaining: 385ms\n",
      "40:\tlearn: 1.9173613\ttotal: 1.58s\tremaining: 348ms\n",
      "41:\tlearn: 1.9110589\ttotal: 1.62s\tremaining: 309ms\n",
      "42:\tlearn: 1.9055872\ttotal: 1.66s\tremaining: 270ms\n",
      "43:\tlearn: 1.8990563\ttotal: 1.7s\tremaining: 232ms\n",
      "44:\tlearn: 1.8932895\ttotal: 1.74s\tremaining: 193ms\n",
      "45:\tlearn: 1.8865735\ttotal: 1.78s\tremaining: 155ms\n",
      "46:\tlearn: 1.8799433\ttotal: 1.81s\tremaining: 116ms\n",
      "47:\tlearn: 1.8730151\ttotal: 1.85s\tremaining: 77.3ms\n",
      "48:\tlearn: 1.8670554\ttotal: 1.89s\tremaining: 38.6ms\n",
      "49:\tlearn: 1.8618862\ttotal: 1.93s\tremaining: 0us\n",
      "0:\tlearn: 1.8941579\ttotal: 44ms\tremaining: 2.16s\n",
      "1:\tlearn: 1.5377570\ttotal: 83ms\tremaining: 1.99s\n",
      "2:\tlearn: 1.4084167\ttotal: 117ms\tremaining: 1.83s\n",
      "3:\tlearn: 1.3006020\ttotal: 150ms\tremaining: 1.72s\n",
      "4:\tlearn: 1.1835798\ttotal: 191ms\tremaining: 1.72s\n",
      "5:\tlearn: 1.1186851\ttotal: 232ms\tremaining: 1.7s\n",
      "6:\tlearn: 1.0589720\ttotal: 274ms\tremaining: 1.68s\n",
      "7:\tlearn: 1.0207498\ttotal: 318ms\tremaining: 1.67s\n",
      "8:\tlearn: 0.9716307\ttotal: 358ms\tremaining: 1.63s\n",
      "9:\tlearn: 0.9374245\ttotal: 398ms\tremaining: 1.59s\n",
      "10:\tlearn: 0.9005593\ttotal: 433ms\tremaining: 1.53s\n",
      "11:\tlearn: 0.8791850\ttotal: 466ms\tremaining: 1.48s\n",
      "12:\tlearn: 0.8600551\ttotal: 501ms\tremaining: 1.43s\n",
      "13:\tlearn: 0.8404446\ttotal: 548ms\tremaining: 1.41s\n",
      "14:\tlearn: 0.8211277\ttotal: 589ms\tremaining: 1.37s\n",
      "15:\tlearn: 0.8047691\ttotal: 636ms\tremaining: 1.35s\n",
      "16:\tlearn: 0.7877859\ttotal: 676ms\tremaining: 1.31s\n",
      "17:\tlearn: 0.7710834\ttotal: 709ms\tremaining: 1.26s\n",
      "18:\tlearn: 0.7594162\ttotal: 757ms\tremaining: 1.24s\n",
      "19:\tlearn: 0.7486702\ttotal: 790ms\tremaining: 1.19s\n",
      "20:\tlearn: 0.7343584\ttotal: 826ms\tremaining: 1.14s\n",
      "21:\tlearn: 0.7168879\ttotal: 865ms\tremaining: 1.1s\n",
      "22:\tlearn: 0.7066592\ttotal: 899ms\tremaining: 1.05s\n",
      "23:\tlearn: 0.6984217\ttotal: 940ms\tremaining: 1.02s\n",
      "24:\tlearn: 0.6904425\ttotal: 978ms\tremaining: 978ms\n",
      "25:\tlearn: 0.6793323\ttotal: 1.01s\tremaining: 932ms\n",
      "26:\tlearn: 0.6732710\ttotal: 1.05s\tremaining: 899ms\n",
      "27:\tlearn: 0.6660918\ttotal: 1.09s\tremaining: 856ms\n",
      "28:\tlearn: 0.6570792\ttotal: 1.14s\tremaining: 823ms\n",
      "29:\tlearn: 0.6499449\ttotal: 1.18s\tremaining: 787ms\n",
      "30:\tlearn: 0.6441819\ttotal: 1.22s\tremaining: 748ms\n",
      "31:\tlearn: 0.6312368\ttotal: 1.26s\tremaining: 710ms\n",
      "32:\tlearn: 0.6264899\ttotal: 1.3s\tremaining: 670ms\n",
      "33:\tlearn: 0.6213480\ttotal: 1.34s\tremaining: 631ms\n",
      "34:\tlearn: 0.6147848\ttotal: 1.38s\tremaining: 589ms\n",
      "35:\tlearn: 0.6097832\ttotal: 1.42s\tremaining: 552ms\n",
      "36:\tlearn: 0.6039471\ttotal: 1.46s\tremaining: 514ms\n",
      "37:\tlearn: 0.5989653\ttotal: 1.5s\tremaining: 473ms\n",
      "38:\tlearn: 0.5948862\ttotal: 1.54s\tremaining: 434ms\n",
      "39:\tlearn: 0.5905029\ttotal: 1.58s\tremaining: 396ms\n",
      "40:\tlearn: 0.5875785\ttotal: 1.63s\tremaining: 357ms\n",
      "41:\tlearn: 0.5835386\ttotal: 1.67s\tremaining: 317ms\n",
      "42:\tlearn: 0.5788865\ttotal: 1.71s\tremaining: 278ms\n",
      "43:\tlearn: 0.5778317\ttotal: 1.74s\tremaining: 237ms\n",
      "44:\tlearn: 0.5754053\ttotal: 1.77s\tremaining: 197ms\n",
      "45:\tlearn: 0.5720076\ttotal: 1.8s\tremaining: 157ms\n",
      "46:\tlearn: 0.5692409\ttotal: 1.84s\tremaining: 117ms\n",
      "47:\tlearn: 0.5669519\ttotal: 1.87s\tremaining: 78ms\n",
      "48:\tlearn: 0.5622592\ttotal: 1.91s\tremaining: 39ms\n",
      "49:\tlearn: 0.5531322\ttotal: 1.95s\tremaining: 0us\n",
      "0:\tlearn: 1.8834597\ttotal: 44.6ms\tremaining: 2.18s\n",
      "1:\tlearn: 1.5540128\ttotal: 84.3ms\tremaining: 2.02s\n",
      "2:\tlearn: 1.4013208\ttotal: 120ms\tremaining: 1.87s\n",
      "3:\tlearn: 1.2458418\ttotal: 153ms\tremaining: 1.76s\n",
      "4:\tlearn: 1.1365848\ttotal: 194ms\tremaining: 1.74s\n",
      "5:\tlearn: 1.0819374\ttotal: 229ms\tremaining: 1.68s\n",
      "6:\tlearn: 1.0267887\ttotal: 271ms\tremaining: 1.66s\n",
      "7:\tlearn: 0.9809151\ttotal: 315ms\tremaining: 1.65s\n",
      "8:\tlearn: 0.9480169\ttotal: 354ms\tremaining: 1.61s\n",
      "9:\tlearn: 0.9202955\ttotal: 396ms\tremaining: 1.58s\n",
      "10:\tlearn: 0.8922407\ttotal: 432ms\tremaining: 1.53s\n",
      "11:\tlearn: 0.8741179\ttotal: 465ms\tremaining: 1.47s\n",
      "12:\tlearn: 0.8519269\ttotal: 502ms\tremaining: 1.43s\n",
      "13:\tlearn: 0.8226432\ttotal: 540ms\tremaining: 1.39s\n",
      "14:\tlearn: 0.8048557\ttotal: 584ms\tremaining: 1.36s\n",
      "15:\tlearn: 0.7884799\ttotal: 630ms\tremaining: 1.34s\n",
      "16:\tlearn: 0.7761017\ttotal: 671ms\tremaining: 1.3s\n",
      "17:\tlearn: 0.7622796\ttotal: 706ms\tremaining: 1.25s\n",
      "18:\tlearn: 0.7489421\ttotal: 748ms\tremaining: 1.22s\n",
      "19:\tlearn: 0.7366134\ttotal: 792ms\tremaining: 1.19s\n",
      "20:\tlearn: 0.7260457\ttotal: 829ms\tremaining: 1.14s\n",
      "21:\tlearn: 0.7141922\ttotal: 867ms\tremaining: 1.1s\n",
      "22:\tlearn: 0.6986568\ttotal: 908ms\tremaining: 1.06s\n",
      "23:\tlearn: 0.6909831\ttotal: 951ms\tremaining: 1.03s\n",
      "24:\tlearn: 0.6840541\ttotal: 998ms\tremaining: 998ms\n",
      "25:\tlearn: 0.6782197\ttotal: 1.03s\tremaining: 951ms\n",
      "26:\tlearn: 0.6709491\ttotal: 1.07s\tremaining: 910ms\n",
      "27:\tlearn: 0.6644861\ttotal: 1.11s\tremaining: 870ms\n",
      "28:\tlearn: 0.6584056\ttotal: 1.14s\tremaining: 827ms\n",
      "29:\tlearn: 0.6518017\ttotal: 1.18s\tremaining: 790ms\n",
      "30:\tlearn: 0.6456094\ttotal: 1.23s\tremaining: 754ms\n",
      "31:\tlearn: 0.6376783\ttotal: 1.26s\tremaining: 712ms\n",
      "32:\tlearn: 0.6328615\ttotal: 1.3s\tremaining: 672ms\n",
      "33:\tlearn: 0.6290328\ttotal: 1.34s\tremaining: 632ms\n",
      "34:\tlearn: 0.6223129\ttotal: 1.38s\tremaining: 592ms\n",
      "35:\tlearn: 0.6157237\ttotal: 1.42s\tremaining: 551ms\n",
      "36:\tlearn: 0.6074052\ttotal: 1.46s\tremaining: 514ms\n",
      "37:\tlearn: 0.6018483\ttotal: 1.5s\tremaining: 475ms\n",
      "38:\tlearn: 0.5927888\ttotal: 1.55s\tremaining: 437ms\n",
      "39:\tlearn: 0.5888363\ttotal: 1.59s\tremaining: 397ms\n",
      "40:\tlearn: 0.5817276\ttotal: 1.63s\tremaining: 358ms\n",
      "41:\tlearn: 0.5767348\ttotal: 1.67s\tremaining: 318ms\n",
      "42:\tlearn: 0.5735479\ttotal: 1.71s\tremaining: 278ms\n",
      "43:\tlearn: 0.5694541\ttotal: 1.75s\tremaining: 239ms\n",
      "44:\tlearn: 0.5657482\ttotal: 1.8s\tremaining: 200ms\n",
      "45:\tlearn: 0.5639371\ttotal: 1.83s\tremaining: 159ms\n",
      "46:\tlearn: 0.5600321\ttotal: 1.86s\tremaining: 119ms\n",
      "47:\tlearn: 0.5584318\ttotal: 1.9s\tremaining: 79ms\n",
      "48:\tlearn: 0.5562943\ttotal: 1.93s\tremaining: 39.4ms\n",
      "49:\tlearn: 0.5536819\ttotal: 1.97s\tremaining: 0us\n",
      "0:\tlearn: 1.8848559\ttotal: 66ms\tremaining: 3.24s\n",
      "1:\tlearn: 1.5549957\ttotal: 108ms\tremaining: 2.6s\n",
      "2:\tlearn: 1.4022477\ttotal: 143ms\tremaining: 2.25s\n",
      "3:\tlearn: 1.2476357\ttotal: 176ms\tremaining: 2.02s\n",
      "4:\tlearn: 1.1361741\ttotal: 217ms\tremaining: 1.95s\n",
      "5:\tlearn: 1.0813948\ttotal: 251ms\tremaining: 1.84s\n",
      "6:\tlearn: 1.0469191\ttotal: 293ms\tremaining: 1.8s\n",
      "7:\tlearn: 0.9993784\ttotal: 350ms\tremaining: 1.84s\n",
      "8:\tlearn: 0.9548924\ttotal: 392ms\tremaining: 1.78s\n",
      "9:\tlearn: 0.9190057\ttotal: 435ms\tremaining: 1.74s\n",
      "10:\tlearn: 0.8963639\ttotal: 478ms\tremaining: 1.69s\n",
      "11:\tlearn: 0.8719764\ttotal: 521ms\tremaining: 1.65s\n",
      "12:\tlearn: 0.8515393\ttotal: 555ms\tremaining: 1.58s\n",
      "13:\tlearn: 0.8341757\ttotal: 601ms\tremaining: 1.54s\n",
      "14:\tlearn: 0.8183941\ttotal: 637ms\tremaining: 1.49s\n",
      "15:\tlearn: 0.7988227\ttotal: 682ms\tremaining: 1.45s\n",
      "16:\tlearn: 0.7800358\ttotal: 720ms\tremaining: 1.4s\n",
      "17:\tlearn: 0.7634180\ttotal: 765ms\tremaining: 1.36s\n",
      "18:\tlearn: 0.7519515\ttotal: 807ms\tremaining: 1.32s\n",
      "19:\tlearn: 0.7382603\ttotal: 843ms\tremaining: 1.26s\n",
      "20:\tlearn: 0.7237255\ttotal: 881ms\tremaining: 1.22s\n",
      "21:\tlearn: 0.7122259\ttotal: 914ms\tremaining: 1.16s\n",
      "22:\tlearn: 0.7008680\ttotal: 956ms\tremaining: 1.12s\n",
      "23:\tlearn: 0.6902221\ttotal: 990ms\tremaining: 1.07s\n",
      "24:\tlearn: 0.6826637\ttotal: 1.03s\tremaining: 1.03s\n",
      "25:\tlearn: 0.6774936\ttotal: 1.07s\tremaining: 984ms\n",
      "26:\tlearn: 0.6708397\ttotal: 1.1s\tremaining: 940ms\n",
      "27:\tlearn: 0.6593400\ttotal: 1.15s\tremaining: 900ms\n",
      "28:\tlearn: 0.6526211\ttotal: 1.19s\tremaining: 861ms\n",
      "29:\tlearn: 0.6441020\ttotal: 1.22s\tremaining: 816ms\n",
      "30:\tlearn: 0.6386812\ttotal: 1.26s\tremaining: 775ms\n",
      "31:\tlearn: 0.6324780\ttotal: 1.3s\tremaining: 733ms\n",
      "32:\tlearn: 0.6281617\ttotal: 1.34s\tremaining: 688ms\n",
      "33:\tlearn: 0.6234609\ttotal: 1.38s\tremaining: 648ms\n",
      "34:\tlearn: 0.6154425\ttotal: 1.42s\tremaining: 607ms\n",
      "35:\tlearn: 0.6088129\ttotal: 1.46s\tremaining: 567ms\n",
      "36:\tlearn: 0.6063166\ttotal: 1.49s\tremaining: 524ms\n",
      "37:\tlearn: 0.5978882\ttotal: 1.53s\tremaining: 483ms\n",
      "38:\tlearn: 0.5949962\ttotal: 1.56s\tremaining: 440ms\n",
      "39:\tlearn: 0.5855861\ttotal: 1.6s\tremaining: 401ms\n",
      "40:\tlearn: 0.5818000\ttotal: 1.65s\tremaining: 362ms\n",
      "41:\tlearn: 0.5799099\ttotal: 1.68s\tremaining: 320ms\n",
      "42:\tlearn: 0.5773687\ttotal: 1.71s\tremaining: 279ms\n",
      "43:\tlearn: 0.5727760\ttotal: 1.75s\tremaining: 239ms\n",
      "44:\tlearn: 0.5703810\ttotal: 1.79s\tremaining: 199ms\n",
      "45:\tlearn: 0.5663332\ttotal: 1.82s\tremaining: 158ms\n",
      "46:\tlearn: 0.5636925\ttotal: 1.85s\tremaining: 118ms\n",
      "47:\tlearn: 0.5609492\ttotal: 1.89s\tremaining: 78.8ms\n",
      "48:\tlearn: 0.5580420\ttotal: 1.92s\tremaining: 39.3ms\n",
      "49:\tlearn: 0.5531303\ttotal: 1.96s\tremaining: 0us\n",
      "0:\tlearn: 1.9155414\ttotal: 44.4ms\tremaining: 2.17s\n",
      "1:\tlearn: 1.4969725\ttotal: 86ms\tremaining: 2.06s\n",
      "2:\tlearn: 1.3707797\ttotal: 121ms\tremaining: 1.9s\n",
      "3:\tlearn: 1.2806549\ttotal: 154ms\tremaining: 1.77s\n",
      "4:\tlearn: 1.1714322\ttotal: 199ms\tremaining: 1.79s\n",
      "5:\tlearn: 1.0706660\ttotal: 244ms\tremaining: 1.79s\n",
      "6:\tlearn: 1.0035574\ttotal: 287ms\tremaining: 1.76s\n",
      "7:\tlearn: 0.9521157\ttotal: 327ms\tremaining: 1.72s\n",
      "8:\tlearn: 0.8996467\ttotal: 368ms\tremaining: 1.68s\n",
      "9:\tlearn: 0.8653891\ttotal: 412ms\tremaining: 1.65s\n",
      "10:\tlearn: 0.8391918\ttotal: 446ms\tremaining: 1.58s\n",
      "11:\tlearn: 0.8227849\ttotal: 480ms\tremaining: 1.52s\n",
      "12:\tlearn: 0.8074811\ttotal: 514ms\tremaining: 1.46s\n",
      "13:\tlearn: 0.7785301\ttotal: 547ms\tremaining: 1.41s\n",
      "14:\tlearn: 0.7680335\ttotal: 578ms\tremaining: 1.35s\n",
      "15:\tlearn: 0.7598727\ttotal: 610ms\tremaining: 1.3s\n",
      "16:\tlearn: 0.7401163\ttotal: 650ms\tremaining: 1.26s\n",
      "17:\tlearn: 0.7285407\ttotal: 683ms\tremaining: 1.21s\n",
      "18:\tlearn: 0.7135153\ttotal: 728ms\tremaining: 1.19s\n",
      "19:\tlearn: 0.6972458\ttotal: 764ms\tremaining: 1.15s\n",
      "20:\tlearn: 0.6878590\ttotal: 803ms\tremaining: 1.11s\n",
      "21:\tlearn: 0.6848515\ttotal: 836ms\tremaining: 1.06s\n",
      "22:\tlearn: 0.6778936\ttotal: 868ms\tremaining: 1.02s\n",
      "23:\tlearn: 2.4265578\ttotal: 902ms\tremaining: 978ms\n",
      "24:\tlearn: 9.3774052\ttotal: 938ms\tremaining: 938ms\n",
      "25:\tlearn: 8.9754260\ttotal: 983ms\tremaining: 907ms\n",
      "26:\tlearn: 8.4166506\ttotal: 1.02s\tremaining: 867ms\n",
      "27:\tlearn: 7.8815757\ttotal: 1.05s\tremaining: 827ms\n",
      "28:\tlearn: 7.5630135\ttotal: 1.09s\tremaining: 788ms\n",
      "29:\tlearn: 6.9269663\ttotal: 1.12s\tremaining: 749ms\n",
      "30:\tlearn: 6.2969779\ttotal: 1.16s\tremaining: 710ms\n",
      "31:\tlearn: 5.8928638\ttotal: 1.19s\tremaining: 672ms\n",
      "32:\tlearn: 5.8825887\ttotal: 1.23s\tremaining: 634ms\n",
      "33:\tlearn: 5.3967077\ttotal: 1.27s\tremaining: 596ms\n",
      "34:\tlearn: 4.7863558\ttotal: 1.3s\tremaining: 558ms\n",
      "35:\tlearn: 4.1879601\ttotal: 1.34s\tremaining: 520ms\n",
      "36:\tlearn: 5.2184059\ttotal: 1.37s\tremaining: 482ms\n",
      "37:\tlearn: 8.1246968\ttotal: 1.41s\tremaining: 444ms\n",
      "38:\tlearn: 8.1184749\ttotal: 1.44s\tremaining: 407ms\n",
      "39:\tlearn: 7.8103880\ttotal: 1.48s\tremaining: 369ms\n",
      "40:\tlearn: 7.5112801\ttotal: 1.51s\tremaining: 332ms\n",
      "41:\tlearn: 7.5002947\ttotal: 1.55s\tremaining: 295ms\n",
      "42:\tlearn: 7.2579037\ttotal: 1.58s\tremaining: 258ms\n",
      "43:\tlearn: 7.2512438\ttotal: 1.62s\tremaining: 221ms\n",
      "44:\tlearn: 6.9105668\ttotal: 1.66s\tremaining: 184ms\n",
      "45:\tlearn: 6.9017890\ttotal: 1.7s\tremaining: 148ms\n",
      "46:\tlearn: 6.5970290\ttotal: 1.73s\tremaining: 111ms\n",
      "47:\tlearn: 6.5927547\ttotal: 1.77s\tremaining: 73.7ms\n",
      "48:\tlearn: 6.5892724\ttotal: 1.8s\tremaining: 36.8ms\n",
      "49:\tlearn: 6.5871056\ttotal: 1.83s\tremaining: 0us\n",
      "0:\tlearn: 1.9728942\ttotal: 43.8ms\tremaining: 2.15s\n",
      "1:\tlearn: 1.5743907\ttotal: 83.4ms\tremaining: 2s\n",
      "2:\tlearn: 1.4035716\ttotal: 119ms\tremaining: 1.87s\n",
      "3:\tlearn: 1.2718791\ttotal: 152ms\tremaining: 1.75s\n",
      "4:\tlearn: 1.1924597\ttotal: 194ms\tremaining: 1.74s\n",
      "5:\tlearn: 1.0872659\ttotal: 240ms\tremaining: 1.76s\n",
      "6:\tlearn: 1.0338429\ttotal: 280ms\tremaining: 1.72s\n",
      "7:\tlearn: 0.9786056\ttotal: 320ms\tremaining: 1.68s\n",
      "8:\tlearn: 1.0188792\ttotal: 361ms\tremaining: 1.64s\n",
      "9:\tlearn: 0.9277885\ttotal: 396ms\tremaining: 1.58s\n",
      "10:\tlearn: 0.8929927\ttotal: 439ms\tremaining: 1.55s\n",
      "11:\tlearn: 0.8686064\ttotal: 484ms\tremaining: 1.53s\n",
      "12:\tlearn: 0.8459450\ttotal: 531ms\tremaining: 1.51s\n",
      "13:\tlearn: 0.8268179\ttotal: 575ms\tremaining: 1.48s\n",
      "14:\tlearn: 0.8048642\ttotal: 608ms\tremaining: 1.42s\n",
      "15:\tlearn: 0.7829528\ttotal: 649ms\tremaining: 1.38s\n",
      "16:\tlearn: 0.7732590\ttotal: 691ms\tremaining: 1.34s\n",
      "17:\tlearn: 0.7623329\ttotal: 726ms\tremaining: 1.29s\n",
      "18:\tlearn: 0.7458578\ttotal: 764ms\tremaining: 1.25s\n",
      "19:\tlearn: 0.7332818\ttotal: 802ms\tremaining: 1.2s\n",
      "20:\tlearn: 0.7233125\ttotal: 836ms\tremaining: 1.15s\n",
      "21:\tlearn: 0.7139192\ttotal: 876ms\tremaining: 1.11s\n",
      "22:\tlearn: 0.6976049\ttotal: 910ms\tremaining: 1.07s\n",
      "23:\tlearn: 0.6886449\ttotal: 946ms\tremaining: 1.02s\n",
      "24:\tlearn: 0.6778566\ttotal: 988ms\tremaining: 988ms\n",
      "25:\tlearn: 0.6679564\ttotal: 1.02s\tremaining: 942ms\n",
      "26:\tlearn: 0.6539480\ttotal: 1.07s\tremaining: 909ms\n",
      "27:\tlearn: 0.6469826\ttotal: 1.1s\tremaining: 866ms\n",
      "28:\tlearn: 0.6411270\ttotal: 1.13s\tremaining: 822ms\n",
      "29:\tlearn: 0.6352875\ttotal: 1.18s\tremaining: 786ms\n",
      "30:\tlearn: 0.6304245\ttotal: 1.21s\tremaining: 744ms\n",
      "31:\tlearn: 0.6251654\ttotal: 1.25s\tremaining: 705ms\n",
      "32:\tlearn: 0.6193801\ttotal: 1.29s\tremaining: 667ms\n",
      "33:\tlearn: 0.6128602\ttotal: 1.33s\tremaining: 627ms\n",
      "34:\tlearn: 0.6084042\ttotal: 1.37s\tremaining: 588ms\n",
      "35:\tlearn: 0.6060606\ttotal: 1.41s\tremaining: 548ms\n",
      "36:\tlearn: 0.6036634\ttotal: 1.45s\tremaining: 508ms\n",
      "37:\tlearn: 0.5969902\ttotal: 1.49s\tremaining: 469ms\n",
      "38:\tlearn: 0.5912307\ttotal: 1.52s\tremaining: 430ms\n",
      "39:\tlearn: 0.5884477\ttotal: 1.55s\tremaining: 389ms\n",
      "40:\tlearn: 0.5857831\ttotal: 1.59s\tremaining: 349ms\n",
      "41:\tlearn: 0.5802621\ttotal: 1.63s\tremaining: 311ms\n",
      "42:\tlearn: 0.5741529\ttotal: 1.68s\tremaining: 273ms\n",
      "43:\tlearn: 0.5723145\ttotal: 1.71s\tremaining: 233ms\n",
      "44:\tlearn: 0.5669041\ttotal: 1.74s\tremaining: 194ms\n",
      "45:\tlearn: 0.5659493\ttotal: 1.77s\tremaining: 154ms\n",
      "46:\tlearn: 0.5633825\ttotal: 1.81s\tremaining: 115ms\n",
      "47:\tlearn: 0.5606708\ttotal: 1.85s\tremaining: 77.2ms\n",
      "48:\tlearn: 0.5587442\ttotal: 1.9s\tremaining: 38.7ms\n",
      "49:\tlearn: 0.5559305\ttotal: 1.94s\tremaining: 0us\n",
      "0:\tlearn: 1.9740091\ttotal: 43.1ms\tremaining: 2.11s\n",
      "1:\tlearn: 1.5796705\ttotal: 83.1ms\tremaining: 1.99s\n",
      "2:\tlearn: 1.4104517\ttotal: 119ms\tremaining: 1.87s\n",
      "3:\tlearn: 1.2653408\ttotal: 152ms\tremaining: 1.75s\n",
      "4:\tlearn: 1.1855630\ttotal: 193ms\tremaining: 1.74s\n",
      "5:\tlearn: 1.0800257\ttotal: 235ms\tremaining: 1.73s\n",
      "6:\tlearn: 1.0240466\ttotal: 276ms\tremaining: 1.69s\n",
      "7:\tlearn: 0.9678568\ttotal: 316ms\tremaining: 1.66s\n",
      "8:\tlearn: 0.9332587\ttotal: 358ms\tremaining: 1.63s\n",
      "9:\tlearn: 0.9047029\ttotal: 400ms\tremaining: 1.6s\n",
      "10:\tlearn: 0.8776080\ttotal: 433ms\tremaining: 1.54s\n",
      "11:\tlearn: 0.8403938\ttotal: 477ms\tremaining: 1.51s\n",
      "12:\tlearn: 0.8200677\ttotal: 523ms\tremaining: 1.49s\n",
      "13:\tlearn: 0.7974067\ttotal: 566ms\tremaining: 1.45s\n",
      "14:\tlearn: 0.7796228\ttotal: 600ms\tremaining: 1.4s\n",
      "15:\tlearn: 0.7750726\ttotal: 638ms\tremaining: 1.35s\n",
      "16:\tlearn: 0.7436266\ttotal: 678ms\tremaining: 1.32s\n",
      "17:\tlearn: 0.7245391\ttotal: 725ms\tremaining: 1.29s\n",
      "18:\tlearn: 0.7139764\ttotal: 760ms\tremaining: 1.24s\n",
      "19:\tlearn: 0.7020607\ttotal: 807ms\tremaining: 1.21s\n",
      "20:\tlearn: 0.6932765\ttotal: 841ms\tremaining: 1.16s\n",
      "21:\tlearn: 0.6818193\ttotal: 888ms\tremaining: 1.13s\n",
      "22:\tlearn: 0.6673020\ttotal: 923ms\tremaining: 1.08s\n",
      "23:\tlearn: 0.6606854\ttotal: 955ms\tremaining: 1.03s\n",
      "24:\tlearn: 0.6510309\ttotal: 1s\tremaining: 1s\n",
      "25:\tlearn: 0.6468226\ttotal: 1.03s\tremaining: 954ms\n",
      "26:\tlearn: 0.6422220\ttotal: 1.06s\tremaining: 907ms\n",
      "27:\tlearn: 0.6346341\ttotal: 1.1s\tremaining: 862ms\n",
      "28:\tlearn: 0.6313354\ttotal: 1.13s\tremaining: 819ms\n",
      "29:\tlearn: 0.6231194\ttotal: 1.17s\tremaining: 782ms\n",
      "30:\tlearn: 0.6126287\ttotal: 1.21s\tremaining: 744ms\n",
      "31:\tlearn: 0.6072379\ttotal: 1.25s\tremaining: 705ms\n",
      "32:\tlearn: 0.6029206\ttotal: 1.29s\tremaining: 667ms\n",
      "33:\tlearn: 0.6001159\ttotal: 1.33s\tremaining: 625ms\n",
      "34:\tlearn: 0.5917683\ttotal: 1.37s\tremaining: 587ms\n",
      "35:\tlearn: 0.5894889\ttotal: 1.41s\tremaining: 548ms\n",
      "36:\tlearn: 0.5860175\ttotal: 1.45s\tremaining: 510ms\n",
      "37:\tlearn: 0.5807961\ttotal: 1.49s\tremaining: 471ms\n",
      "38:\tlearn: 0.5779734\ttotal: 1.53s\tremaining: 431ms\n",
      "39:\tlearn: 0.5737482\ttotal: 1.57s\tremaining: 393ms\n",
      "40:\tlearn: 0.5702743\ttotal: 1.61s\tremaining: 354ms\n",
      "41:\tlearn: 0.5689355\ttotal: 1.64s\tremaining: 313ms\n",
      "42:\tlearn: 0.5671406\ttotal: 1.68s\tremaining: 274ms\n",
      "43:\tlearn: 0.5639991\ttotal: 1.72s\tremaining: 234ms\n",
      "44:\tlearn: 0.5630879\ttotal: 1.75s\tremaining: 194ms\n",
      "45:\tlearn: 0.5588995\ttotal: 1.78s\tremaining: 155ms\n",
      "46:\tlearn: 0.5567358\ttotal: 1.81s\tremaining: 116ms\n",
      "47:\tlearn: 0.5539073\ttotal: 1.85s\tremaining: 77.3ms\n",
      "48:\tlearn: 0.5488129\ttotal: 1.9s\tremaining: 38.7ms\n",
      "49:\tlearn: 0.5475431\ttotal: 1.93s\tremaining: 0us\n",
      "0:\tlearn: 2.2887424\ttotal: 44.5ms\tremaining: 4.41s\n",
      "1:\tlearn: 2.2751298\ttotal: 83.3ms\tremaining: 4.08s\n",
      "2:\tlearn: 2.2622099\ttotal: 122ms\tremaining: 3.93s\n",
      "3:\tlearn: 2.2490670\ttotal: 161ms\tremaining: 3.85s\n",
      "4:\tlearn: 2.2363366\ttotal: 200ms\tremaining: 3.81s\n",
      "5:\tlearn: 2.2245693\ttotal: 239ms\tremaining: 3.74s\n",
      "6:\tlearn: 2.2127840\ttotal: 278ms\tremaining: 3.69s\n",
      "7:\tlearn: 2.2008081\ttotal: 318ms\tremaining: 3.66s\n",
      "8:\tlearn: 2.1901309\ttotal: 356ms\tremaining: 3.6s\n",
      "9:\tlearn: 2.1801158\ttotal: 394ms\tremaining: 3.55s\n",
      "10:\tlearn: 2.1693255\ttotal: 437ms\tremaining: 3.54s\n",
      "11:\tlearn: 2.1585238\ttotal: 480ms\tremaining: 3.52s\n",
      "12:\tlearn: 2.1485154\ttotal: 523ms\tremaining: 3.5s\n",
      "13:\tlearn: 2.1385680\ttotal: 565ms\tremaining: 3.47s\n",
      "14:\tlearn: 2.1285154\ttotal: 608ms\tremaining: 3.44s\n",
      "15:\tlearn: 2.1193603\ttotal: 651ms\tremaining: 3.42s\n",
      "16:\tlearn: 2.1090073\ttotal: 694ms\tremaining: 3.39s\n",
      "17:\tlearn: 2.0993106\ttotal: 742ms\tremaining: 3.38s\n",
      "18:\tlearn: 2.0902894\ttotal: 785ms\tremaining: 3.35s\n",
      "19:\tlearn: 2.0817092\ttotal: 828ms\tremaining: 3.31s\n",
      "20:\tlearn: 2.0723877\ttotal: 873ms\tremaining: 3.29s\n",
      "21:\tlearn: 2.0628424\ttotal: 918ms\tremaining: 3.25s\n",
      "22:\tlearn: 2.0536874\ttotal: 960ms\tremaining: 3.21s\n",
      "23:\tlearn: 2.0449460\ttotal: 1s\tremaining: 3.17s\n",
      "24:\tlearn: 2.0361634\ttotal: 1.05s\tremaining: 3.14s\n",
      "25:\tlearn: 2.0278805\ttotal: 1.09s\tremaining: 3.1s\n",
      "26:\tlearn: 2.0194461\ttotal: 1.14s\tremaining: 3.07s\n",
      "27:\tlearn: 2.0113292\ttotal: 1.18s\tremaining: 3.05s\n",
      "28:\tlearn: 2.0043285\ttotal: 1.23s\tremaining: 3.01s\n",
      "29:\tlearn: 1.9972894\ttotal: 1.27s\tremaining: 2.96s\n",
      "30:\tlearn: 1.9890015\ttotal: 1.32s\tremaining: 2.94s\n",
      "31:\tlearn: 1.9814869\ttotal: 1.36s\tremaining: 2.89s\n",
      "32:\tlearn: 1.9734434\ttotal: 1.4s\tremaining: 2.85s\n",
      "33:\tlearn: 1.9657063\ttotal: 1.44s\tremaining: 2.8s\n",
      "34:\tlearn: 1.9582717\ttotal: 1.48s\tremaining: 2.75s\n",
      "35:\tlearn: 1.9516144\ttotal: 1.52s\tremaining: 2.7s\n",
      "36:\tlearn: 1.9444247\ttotal: 1.56s\tremaining: 2.65s\n",
      "37:\tlearn: 1.9380457\ttotal: 1.6s\tremaining: 2.6s\n",
      "38:\tlearn: 1.9309670\ttotal: 1.64s\tremaining: 2.56s\n",
      "39:\tlearn: 1.9238867\ttotal: 1.68s\tremaining: 2.51s\n",
      "40:\tlearn: 1.9165813\ttotal: 1.72s\tremaining: 2.47s\n",
      "41:\tlearn: 1.9095740\ttotal: 1.76s\tremaining: 2.43s\n",
      "42:\tlearn: 1.9038248\ttotal: 1.79s\tremaining: 2.38s\n",
      "43:\tlearn: 1.8973022\ttotal: 1.83s\tremaining: 2.33s\n",
      "44:\tlearn: 1.8915187\ttotal: 1.87s\tremaining: 2.29s\n",
      "45:\tlearn: 1.8850661\ttotal: 1.91s\tremaining: 2.24s\n",
      "46:\tlearn: 1.8786885\ttotal: 1.94s\tremaining: 2.19s\n",
      "47:\tlearn: 1.8731814\ttotal: 1.98s\tremaining: 2.15s\n",
      "48:\tlearn: 1.8673253\ttotal: 2.02s\tremaining: 2.1s\n",
      "49:\tlearn: 1.8623094\ttotal: 2.06s\tremaining: 2.06s\n",
      "50:\tlearn: 1.8569124\ttotal: 2.1s\tremaining: 2.01s\n",
      "51:\tlearn: 1.8509751\ttotal: 2.13s\tremaining: 1.97s\n",
      "52:\tlearn: 1.8444884\ttotal: 2.17s\tremaining: 1.92s\n",
      "53:\tlearn: 1.8387943\ttotal: 2.21s\tremaining: 1.88s\n",
      "54:\tlearn: 1.8326855\ttotal: 2.25s\tremaining: 1.84s\n",
      "55:\tlearn: 1.8267279\ttotal: 2.29s\tremaining: 1.8s\n",
      "56:\tlearn: 1.8206892\ttotal: 2.33s\tremaining: 1.75s\n",
      "57:\tlearn: 1.8150449\ttotal: 2.36s\tremaining: 1.71s\n",
      "58:\tlearn: 1.8092092\ttotal: 2.4s\tremaining: 1.67s\n",
      "59:\tlearn: 1.8046725\ttotal: 2.44s\tremaining: 1.63s\n",
      "60:\tlearn: 1.7991361\ttotal: 2.48s\tremaining: 1.58s\n",
      "61:\tlearn: 1.7940032\ttotal: 2.51s\tremaining: 1.54s\n",
      "62:\tlearn: 1.7890862\ttotal: 2.55s\tremaining: 1.5s\n",
      "63:\tlearn: 1.7830559\ttotal: 2.59s\tremaining: 1.45s\n",
      "64:\tlearn: 1.7770346\ttotal: 2.63s\tremaining: 1.42s\n",
      "65:\tlearn: 1.7723723\ttotal: 2.66s\tremaining: 1.37s\n",
      "66:\tlearn: 1.7671987\ttotal: 2.7s\tremaining: 1.33s\n",
      "67:\tlearn: 1.7632785\ttotal: 2.74s\tremaining: 1.29s\n",
      "68:\tlearn: 1.7585778\ttotal: 2.78s\tremaining: 1.25s\n",
      "69:\tlearn: 1.7535022\ttotal: 2.81s\tremaining: 1.21s\n",
      "70:\tlearn: 1.7490805\ttotal: 2.85s\tremaining: 1.16s\n",
      "71:\tlearn: 1.7434536\ttotal: 2.89s\tremaining: 1.12s\n",
      "72:\tlearn: 1.7396763\ttotal: 2.92s\tremaining: 1.08s\n",
      "73:\tlearn: 1.7340763\ttotal: 2.96s\tremaining: 1.04s\n",
      "74:\tlearn: 1.7288672\ttotal: 3s\tremaining: 1s\n",
      "75:\tlearn: 1.7240401\ttotal: 3.04s\tremaining: 960ms\n",
      "76:\tlearn: 1.7189574\ttotal: 3.08s\tremaining: 919ms\n",
      "77:\tlearn: 1.7140687\ttotal: 3.11s\tremaining: 878ms\n",
      "78:\tlearn: 1.7092807\ttotal: 3.15s\tremaining: 838ms\n",
      "79:\tlearn: 1.7056039\ttotal: 3.19s\tremaining: 798ms\n",
      "80:\tlearn: 1.7013964\ttotal: 3.23s\tremaining: 758ms\n",
      "81:\tlearn: 1.6967745\ttotal: 3.27s\tremaining: 717ms\n",
      "82:\tlearn: 1.6922210\ttotal: 3.31s\tremaining: 678ms\n",
      "83:\tlearn: 1.6873883\ttotal: 3.35s\tremaining: 638ms\n",
      "84:\tlearn: 1.6826793\ttotal: 3.4s\tremaining: 599ms\n",
      "85:\tlearn: 1.6789364\ttotal: 3.45s\tremaining: 562ms\n",
      "86:\tlearn: 1.6753551\ttotal: 3.49s\tremaining: 521ms\n",
      "87:\tlearn: 1.6707249\ttotal: 3.53s\tremaining: 481ms\n",
      "88:\tlearn: 1.6660465\ttotal: 3.56s\tremaining: 440ms\n",
      "89:\tlearn: 1.6617257\ttotal: 3.6s\tremaining: 400ms\n",
      "90:\tlearn: 1.6576780\ttotal: 3.64s\tremaining: 360ms\n",
      "91:\tlearn: 1.6536925\ttotal: 3.67s\tremaining: 319ms\n",
      "92:\tlearn: 1.6495228\ttotal: 3.71s\tremaining: 279ms\n",
      "93:\tlearn: 1.6448501\ttotal: 3.75s\tremaining: 240ms\n",
      "94:\tlearn: 1.6417529\ttotal: 3.79s\tremaining: 199ms\n",
      "95:\tlearn: 1.6377168\ttotal: 3.83s\tremaining: 159ms\n",
      "96:\tlearn: 1.6346604\ttotal: 3.86s\tremaining: 119ms\n",
      "97:\tlearn: 1.6314673\ttotal: 3.9s\tremaining: 79.6ms\n",
      "98:\tlearn: 1.6276022\ttotal: 3.93s\tremaining: 39.7ms\n",
      "99:\tlearn: 1.6231584\ttotal: 3.98s\tremaining: 0us\n",
      "0:\tlearn: 2.2883568\ttotal: 44.1ms\tremaining: 4.36s\n",
      "1:\tlearn: 2.2747754\ttotal: 82ms\tremaining: 4.01s\n",
      "2:\tlearn: 2.2619825\ttotal: 120ms\tremaining: 3.88s\n",
      "3:\tlearn: 2.2487982\ttotal: 160ms\tremaining: 3.83s\n",
      "4:\tlearn: 2.2360449\ttotal: 199ms\tremaining: 3.78s\n",
      "5:\tlearn: 2.2243268\ttotal: 238ms\tremaining: 3.73s\n",
      "6:\tlearn: 2.2125144\ttotal: 277ms\tremaining: 3.69s\n",
      "7:\tlearn: 2.2005244\ttotal: 317ms\tremaining: 3.65s\n",
      "8:\tlearn: 2.1899120\ttotal: 354ms\tremaining: 3.58s\n",
      "9:\tlearn: 2.1791836\ttotal: 391ms\tremaining: 3.52s\n",
      "10:\tlearn: 2.1685163\ttotal: 431ms\tremaining: 3.48s\n",
      "11:\tlearn: 2.1578298\ttotal: 470ms\tremaining: 3.45s\n",
      "12:\tlearn: 2.1476989\ttotal: 509ms\tremaining: 3.4s\n",
      "13:\tlearn: 2.1372152\ttotal: 548ms\tremaining: 3.36s\n",
      "14:\tlearn: 2.1272772\ttotal: 587ms\tremaining: 3.33s\n",
      "15:\tlearn: 2.1179040\ttotal: 625ms\tremaining: 3.28s\n",
      "16:\tlearn: 2.1077481\ttotal: 664ms\tremaining: 3.24s\n",
      "17:\tlearn: 2.0990454\ttotal: 701ms\tremaining: 3.19s\n",
      "18:\tlearn: 2.0900974\ttotal: 741ms\tremaining: 3.16s\n",
      "19:\tlearn: 2.0815990\ttotal: 779ms\tremaining: 3.12s\n",
      "20:\tlearn: 2.0720929\ttotal: 822ms\tremaining: 3.09s\n",
      "21:\tlearn: 2.0637206\ttotal: 860ms\tremaining: 3.05s\n",
      "22:\tlearn: 2.0545218\ttotal: 899ms\tremaining: 3.01s\n",
      "23:\tlearn: 2.0458339\ttotal: 938ms\tremaining: 2.97s\n",
      "24:\tlearn: 2.0369527\ttotal: 977ms\tremaining: 2.93s\n",
      "25:\tlearn: 2.0287007\ttotal: 1.02s\tremaining: 2.89s\n",
      "26:\tlearn: 2.0201690\ttotal: 1.05s\tremaining: 2.85s\n",
      "27:\tlearn: 2.0120907\ttotal: 1.09s\tremaining: 2.82s\n",
      "28:\tlearn: 2.0040010\ttotal: 1.13s\tremaining: 2.78s\n",
      "29:\tlearn: 1.9970424\ttotal: 1.17s\tremaining: 2.73s\n",
      "30:\tlearn: 1.9886463\ttotal: 1.22s\tremaining: 2.72s\n",
      "31:\tlearn: 1.9812185\ttotal: 1.26s\tremaining: 2.68s\n",
      "32:\tlearn: 1.9731577\ttotal: 1.3s\tremaining: 2.64s\n",
      "33:\tlearn: 1.9654371\ttotal: 1.34s\tremaining: 2.6s\n",
      "34:\tlearn: 1.9575341\ttotal: 1.38s\tremaining: 2.57s\n",
      "35:\tlearn: 1.9509424\ttotal: 1.42s\tremaining: 2.52s\n",
      "36:\tlearn: 1.9438229\ttotal: 1.46s\tremaining: 2.49s\n",
      "37:\tlearn: 1.9371619\ttotal: 1.5s\tremaining: 2.45s\n",
      "38:\tlearn: 1.9306511\ttotal: 1.54s\tremaining: 2.4s\n",
      "39:\tlearn: 1.9235179\ttotal: 1.58s\tremaining: 2.37s\n",
      "40:\tlearn: 1.9162616\ttotal: 1.62s\tremaining: 2.33s\n",
      "41:\tlearn: 1.9100001\ttotal: 1.66s\tremaining: 2.29s\n",
      "42:\tlearn: 1.9044832\ttotal: 1.7s\tremaining: 2.25s\n",
      "43:\tlearn: 1.8976842\ttotal: 1.74s\tremaining: 2.21s\n",
      "44:\tlearn: 1.8919704\ttotal: 1.78s\tremaining: 2.18s\n",
      "45:\tlearn: 1.8855314\ttotal: 1.82s\tremaining: 2.14s\n",
      "46:\tlearn: 1.8790615\ttotal: 1.86s\tremaining: 2.09s\n",
      "47:\tlearn: 1.8736444\ttotal: 1.89s\tremaining: 2.05s\n",
      "48:\tlearn: 1.8677758\ttotal: 1.93s\tremaining: 2.01s\n",
      "49:\tlearn: 1.8627166\ttotal: 1.97s\tremaining: 1.97s\n",
      "50:\tlearn: 1.8559738\ttotal: 2s\tremaining: 1.93s\n",
      "51:\tlearn: 1.8496595\ttotal: 2.05s\tremaining: 1.89s\n",
      "52:\tlearn: 1.8434258\ttotal: 2.08s\tremaining: 1.85s\n",
      "53:\tlearn: 1.8376254\ttotal: 2.12s\tremaining: 1.81s\n",
      "54:\tlearn: 1.8314644\ttotal: 2.16s\tremaining: 1.77s\n",
      "55:\tlearn: 1.8254697\ttotal: 2.2s\tremaining: 1.73s\n",
      "56:\tlearn: 1.8193651\ttotal: 2.24s\tremaining: 1.69s\n",
      "57:\tlearn: 1.8137364\ttotal: 2.28s\tremaining: 1.65s\n",
      "58:\tlearn: 1.8078565\ttotal: 2.32s\tremaining: 1.61s\n",
      "59:\tlearn: 1.8019821\ttotal: 2.36s\tremaining: 1.57s\n",
      "60:\tlearn: 1.7965660\ttotal: 2.4s\tremaining: 1.53s\n",
      "61:\tlearn: 1.7907141\ttotal: 2.44s\tremaining: 1.49s\n",
      "62:\tlearn: 1.7855859\ttotal: 2.47s\tremaining: 1.45s\n",
      "63:\tlearn: 1.7799102\ttotal: 2.51s\tremaining: 1.41s\n",
      "64:\tlearn: 1.7756051\ttotal: 2.55s\tremaining: 1.37s\n",
      "65:\tlearn: 1.7710129\ttotal: 2.58s\tremaining: 1.33s\n",
      "66:\tlearn: 1.7656354\ttotal: 2.62s\tremaining: 1.29s\n",
      "67:\tlearn: 1.7616947\ttotal: 2.66s\tremaining: 1.25s\n",
      "68:\tlearn: 1.7577983\ttotal: 2.7s\tremaining: 1.21s\n",
      "69:\tlearn: 1.7522770\ttotal: 2.73s\tremaining: 1.17s\n",
      "70:\tlearn: 1.7484252\ttotal: 2.77s\tremaining: 1.13s\n",
      "71:\tlearn: 1.7432529\ttotal: 2.81s\tremaining: 1.09s\n",
      "72:\tlearn: 1.7381677\ttotal: 2.85s\tremaining: 1.05s\n",
      "73:\tlearn: 1.7324872\ttotal: 2.89s\tremaining: 1.01s\n",
      "74:\tlearn: 1.7271781\ttotal: 2.93s\tremaining: 976ms\n",
      "75:\tlearn: 1.7224984\ttotal: 2.97s\tremaining: 937ms\n",
      "76:\tlearn: 1.7174174\ttotal: 3s\tremaining: 897ms\n",
      "77:\tlearn: 1.7139526\ttotal: 3.04s\tremaining: 857ms\n",
      "78:\tlearn: 1.7091120\ttotal: 3.08s\tremaining: 819ms\n",
      "79:\tlearn: 1.7039990\ttotal: 3.12s\tremaining: 781ms\n",
      "80:\tlearn: 1.6993294\ttotal: 3.16s\tremaining: 742ms\n",
      "81:\tlearn: 1.6949323\ttotal: 3.2s\tremaining: 702ms\n",
      "82:\tlearn: 1.6903159\ttotal: 3.24s\tremaining: 664ms\n",
      "83:\tlearn: 1.6854478\ttotal: 3.28s\tremaining: 625ms\n",
      "84:\tlearn: 1.6804759\ttotal: 3.33s\tremaining: 587ms\n",
      "85:\tlearn: 1.6766145\ttotal: 3.37s\tremaining: 549ms\n",
      "86:\tlearn: 1.6726585\ttotal: 3.42s\tremaining: 511ms\n",
      "87:\tlearn: 1.6680002\ttotal: 3.46s\tremaining: 472ms\n",
      "88:\tlearn: 1.6644529\ttotal: 3.5s\tremaining: 433ms\n",
      "89:\tlearn: 1.6599897\ttotal: 3.54s\tremaining: 394ms\n",
      "90:\tlearn: 1.6566804\ttotal: 3.58s\tremaining: 355ms\n",
      "91:\tlearn: 1.6522433\ttotal: 3.63s\tremaining: 316ms\n",
      "92:\tlearn: 1.6480631\ttotal: 3.67s\tremaining: 277ms\n",
      "93:\tlearn: 1.6443999\ttotal: 3.72s\tremaining: 237ms\n",
      "94:\tlearn: 1.6412985\ttotal: 3.76s\tremaining: 198ms\n",
      "95:\tlearn: 1.6375063\ttotal: 3.8s\tremaining: 158ms\n",
      "96:\tlearn: 1.6343855\ttotal: 3.84s\tremaining: 119ms\n",
      "97:\tlearn: 1.6302815\ttotal: 3.91s\tremaining: 79.8ms\n",
      "98:\tlearn: 1.6263276\ttotal: 3.95s\tremaining: 39.9ms\n",
      "99:\tlearn: 1.6218665\ttotal: 4s\tremaining: 0us\n",
      "0:\tlearn: 2.2883992\ttotal: 100ms\tremaining: 9.9s\n",
      "1:\tlearn: 2.2748302\ttotal: 143ms\tremaining: 6.99s\n",
      "2:\tlearn: 2.2620491\ttotal: 181ms\tremaining: 5.84s\n",
      "3:\tlearn: 2.2489606\ttotal: 220ms\tremaining: 5.28s\n",
      "4:\tlearn: 2.2362856\ttotal: 260ms\tremaining: 4.94s\n",
      "5:\tlearn: 2.2245520\ttotal: 298ms\tremaining: 4.66s\n",
      "6:\tlearn: 2.2127707\ttotal: 337ms\tremaining: 4.48s\n",
      "7:\tlearn: 2.2008380\ttotal: 377ms\tremaining: 4.33s\n",
      "8:\tlearn: 2.1902233\ttotal: 413ms\tremaining: 4.17s\n",
      "9:\tlearn: 2.1801882\ttotal: 448ms\tremaining: 4.04s\n",
      "10:\tlearn: 2.1693737\ttotal: 488ms\tremaining: 3.94s\n",
      "11:\tlearn: 2.1585790\ttotal: 527ms\tremaining: 3.86s\n",
      "12:\tlearn: 2.1486745\ttotal: 565ms\tremaining: 3.78s\n",
      "13:\tlearn: 2.1380172\ttotal: 604ms\tremaining: 3.71s\n",
      "14:\tlearn: 2.1279667\ttotal: 644ms\tremaining: 3.65s\n",
      "15:\tlearn: 2.1186466\ttotal: 684ms\tremaining: 3.59s\n",
      "16:\tlearn: 2.1083929\ttotal: 723ms\tremaining: 3.53s\n",
      "17:\tlearn: 2.0982911\ttotal: 764ms\tremaining: 3.48s\n",
      "18:\tlearn: 2.0885306\ttotal: 805ms\tremaining: 3.43s\n",
      "19:\tlearn: 2.0799321\ttotal: 846ms\tremaining: 3.38s\n",
      "20:\tlearn: 2.0709670\ttotal: 908ms\tremaining: 3.42s\n",
      "21:\tlearn: 2.0625071\ttotal: 964ms\tremaining: 3.42s\n",
      "22:\tlearn: 2.0535760\ttotal: 1.01s\tremaining: 3.38s\n",
      "23:\tlearn: 2.0448276\ttotal: 1.05s\tremaining: 3.34s\n",
      "24:\tlearn: 2.0362136\ttotal: 1.1s\tremaining: 3.3s\n",
      "25:\tlearn: 2.0280553\ttotal: 1.14s\tremaining: 3.25s\n",
      "26:\tlearn: 2.0198525\ttotal: 1.2s\tremaining: 3.23s\n",
      "27:\tlearn: 2.0118572\ttotal: 1.25s\tremaining: 3.2s\n",
      "28:\tlearn: 2.0043603\ttotal: 1.29s\tremaining: 3.17s\n",
      "29:\tlearn: 1.9966059\ttotal: 1.34s\tremaining: 3.13s\n",
      "30:\tlearn: 1.9892091\ttotal: 1.38s\tremaining: 3.08s\n",
      "31:\tlearn: 1.9822248\ttotal: 1.43s\tremaining: 3.04s\n",
      "32:\tlearn: 1.9749547\ttotal: 1.47s\tremaining: 2.99s\n",
      "33:\tlearn: 1.9677072\ttotal: 1.51s\tremaining: 2.93s\n",
      "34:\tlearn: 1.9597330\ttotal: 1.55s\tremaining: 2.88s\n",
      "35:\tlearn: 1.9531374\ttotal: 1.59s\tremaining: 2.83s\n",
      "36:\tlearn: 1.9461781\ttotal: 1.63s\tremaining: 2.77s\n",
      "37:\tlearn: 1.9384000\ttotal: 1.67s\tremaining: 2.73s\n",
      "38:\tlearn: 1.9318234\ttotal: 1.71s\tremaining: 2.68s\n",
      "39:\tlearn: 1.9246535\ttotal: 1.76s\tremaining: 2.63s\n",
      "40:\tlearn: 1.9173613\ttotal: 1.8s\tremaining: 2.59s\n",
      "41:\tlearn: 1.9110589\ttotal: 1.84s\tremaining: 2.55s\n",
      "42:\tlearn: 1.9055872\ttotal: 1.89s\tremaining: 2.5s\n",
      "43:\tlearn: 1.8990563\ttotal: 1.93s\tremaining: 2.45s\n",
      "44:\tlearn: 1.8932895\ttotal: 1.97s\tremaining: 2.4s\n",
      "45:\tlearn: 1.8865735\ttotal: 2.01s\tremaining: 2.36s\n",
      "46:\tlearn: 1.8799433\ttotal: 2.04s\tremaining: 2.3s\n",
      "47:\tlearn: 1.8730151\ttotal: 2.09s\tremaining: 2.26s\n",
      "48:\tlearn: 1.8670554\ttotal: 2.13s\tremaining: 2.21s\n",
      "49:\tlearn: 1.8618862\ttotal: 2.16s\tremaining: 2.16s\n",
      "50:\tlearn: 1.8555484\ttotal: 2.2s\tremaining: 2.12s\n",
      "51:\tlearn: 1.8496667\ttotal: 2.24s\tremaining: 2.07s\n",
      "52:\tlearn: 1.8442019\ttotal: 2.28s\tremaining: 2.02s\n",
      "53:\tlearn: 1.8384757\ttotal: 2.32s\tremaining: 1.98s\n",
      "54:\tlearn: 1.8324375\ttotal: 2.37s\tremaining: 1.94s\n",
      "55:\tlearn: 1.8271076\ttotal: 2.41s\tremaining: 1.89s\n",
      "56:\tlearn: 1.8207514\ttotal: 2.44s\tremaining: 1.84s\n",
      "57:\tlearn: 1.8157244\ttotal: 2.48s\tremaining: 1.8s\n",
      "58:\tlearn: 1.8097019\ttotal: 2.52s\tremaining: 1.75s\n",
      "59:\tlearn: 1.8038711\ttotal: 2.55s\tremaining: 1.7s\n",
      "60:\tlearn: 1.7979910\ttotal: 2.6s\tremaining: 1.66s\n",
      "61:\tlearn: 1.7930526\ttotal: 2.63s\tremaining: 1.61s\n",
      "62:\tlearn: 1.7877541\ttotal: 2.67s\tremaining: 1.56s\n",
      "63:\tlearn: 1.7819524\ttotal: 2.7s\tremaining: 1.52s\n",
      "64:\tlearn: 1.7757871\ttotal: 2.75s\tremaining: 1.48s\n",
      "65:\tlearn: 1.7712248\ttotal: 2.78s\tremaining: 1.43s\n",
      "66:\tlearn: 1.7657721\ttotal: 2.82s\tremaining: 1.39s\n",
      "67:\tlearn: 1.7611414\ttotal: 2.86s\tremaining: 1.34s\n",
      "68:\tlearn: 1.7570082\ttotal: 2.89s\tremaining: 1.3s\n",
      "69:\tlearn: 1.7515013\ttotal: 2.93s\tremaining: 1.25s\n",
      "70:\tlearn: 1.7476357\ttotal: 2.96s\tremaining: 1.21s\n",
      "71:\tlearn: 1.7425189\ttotal: 3s\tremaining: 1.17s\n",
      "72:\tlearn: 1.7373950\ttotal: 3.04s\tremaining: 1.12s\n",
      "73:\tlearn: 1.7316916\ttotal: 3.08s\tremaining: 1.08s\n",
      "74:\tlearn: 1.7264010\ttotal: 3.12s\tremaining: 1.04s\n",
      "75:\tlearn: 1.7215076\ttotal: 3.16s\tremaining: 997ms\n",
      "76:\tlearn: 1.7167564\ttotal: 3.19s\tremaining: 954ms\n",
      "77:\tlearn: 1.7127616\ttotal: 3.23s\tremaining: 911ms\n",
      "78:\tlearn: 1.7079784\ttotal: 3.27s\tremaining: 869ms\n",
      "79:\tlearn: 1.7028577\ttotal: 3.31s\tremaining: 827ms\n",
      "80:\tlearn: 1.6987693\ttotal: 3.35s\tremaining: 785ms\n",
      "81:\tlearn: 1.6944819\ttotal: 3.38s\tremaining: 743ms\n",
      "82:\tlearn: 1.6901848\ttotal: 3.42s\tremaining: 701ms\n",
      "83:\tlearn: 1.6855935\ttotal: 3.46s\tremaining: 659ms\n",
      "84:\tlearn: 1.6808756\ttotal: 3.5s\tremaining: 618ms\n",
      "85:\tlearn: 1.6770220\ttotal: 3.54s\tremaining: 576ms\n",
      "86:\tlearn: 1.6730836\ttotal: 3.58s\tremaining: 535ms\n",
      "87:\tlearn: 1.6697608\ttotal: 3.62s\tremaining: 493ms\n",
      "88:\tlearn: 1.6662463\ttotal: 3.65s\tremaining: 452ms\n",
      "89:\tlearn: 1.6617143\ttotal: 3.69s\tremaining: 410ms\n",
      "90:\tlearn: 1.6576894\ttotal: 3.73s\tremaining: 369ms\n",
      "91:\tlearn: 1.6532829\ttotal: 3.77s\tremaining: 328ms\n",
      "92:\tlearn: 1.6493256\ttotal: 3.81s\tremaining: 287ms\n",
      "93:\tlearn: 1.6456552\ttotal: 3.85s\tremaining: 246ms\n",
      "94:\tlearn: 1.6425262\ttotal: 3.88s\tremaining: 204ms\n",
      "95:\tlearn: 1.6386574\ttotal: 3.92s\tremaining: 164ms\n",
      "96:\tlearn: 1.6343428\ttotal: 3.96s\tremaining: 123ms\n",
      "97:\tlearn: 1.6297339\ttotal: 4s\tremaining: 81.7ms\n",
      "98:\tlearn: 1.6258189\ttotal: 4.04s\tremaining: 40.8ms\n",
      "99:\tlearn: 1.6220528\ttotal: 4.08s\tremaining: 0us\n",
      "0:\tlearn: 1.8941579\ttotal: 47.5ms\tremaining: 4.7s\n",
      "1:\tlearn: 1.5377570\ttotal: 90.5ms\tremaining: 4.43s\n",
      "2:\tlearn: 1.4084167\ttotal: 137ms\tremaining: 4.42s\n",
      "3:\tlearn: 1.3006020\ttotal: 181ms\tremaining: 4.33s\n",
      "4:\tlearn: 1.1835798\ttotal: 234ms\tremaining: 4.44s\n",
      "5:\tlearn: 1.1186851\ttotal: 275ms\tremaining: 4.31s\n",
      "6:\tlearn: 1.0589720\ttotal: 315ms\tremaining: 4.18s\n",
      "7:\tlearn: 1.0207498\ttotal: 357ms\tremaining: 4.11s\n",
      "8:\tlearn: 0.9716307\ttotal: 397ms\tremaining: 4.01s\n",
      "9:\tlearn: 0.9374245\ttotal: 437ms\tremaining: 3.94s\n",
      "10:\tlearn: 0.9005593\ttotal: 484ms\tremaining: 3.92s\n",
      "11:\tlearn: 0.8791850\ttotal: 530ms\tremaining: 3.89s\n",
      "12:\tlearn: 0.8600551\ttotal: 575ms\tremaining: 3.85s\n",
      "13:\tlearn: 0.8404446\ttotal: 630ms\tremaining: 3.87s\n",
      "14:\tlearn: 0.8211277\ttotal: 670ms\tremaining: 3.8s\n",
      "15:\tlearn: 0.8047691\ttotal: 716ms\tremaining: 3.76s\n",
      "16:\tlearn: 0.7877859\ttotal: 756ms\tremaining: 3.69s\n",
      "17:\tlearn: 0.7710834\ttotal: 791ms\tremaining: 3.6s\n",
      "18:\tlearn: 0.7594162\ttotal: 841ms\tremaining: 3.58s\n",
      "19:\tlearn: 0.7486702\ttotal: 885ms\tremaining: 3.54s\n",
      "20:\tlearn: 0.7343584\ttotal: 933ms\tremaining: 3.51s\n",
      "21:\tlearn: 0.7168879\ttotal: 983ms\tremaining: 3.49s\n",
      "22:\tlearn: 0.7066592\ttotal: 1.02s\tremaining: 3.41s\n",
      "23:\tlearn: 0.6984217\ttotal: 1.06s\tremaining: 3.35s\n",
      "24:\tlearn: 0.6904425\ttotal: 1.1s\tremaining: 3.29s\n",
      "25:\tlearn: 0.6793323\ttotal: 1.13s\tremaining: 3.21s\n",
      "26:\tlearn: 0.6732710\ttotal: 1.19s\tremaining: 3.21s\n",
      "27:\tlearn: 0.6660918\ttotal: 1.24s\tremaining: 3.19s\n",
      "28:\tlearn: 0.6570792\ttotal: 1.29s\tremaining: 3.16s\n",
      "29:\tlearn: 0.6499449\ttotal: 1.34s\tremaining: 3.12s\n",
      "30:\tlearn: 0.6441819\ttotal: 1.38s\tremaining: 3.07s\n",
      "31:\tlearn: 0.6312368\ttotal: 1.44s\tremaining: 3.05s\n",
      "32:\tlearn: 0.6264899\ttotal: 1.49s\tremaining: 3.02s\n",
      "33:\tlearn: 0.6213480\ttotal: 1.54s\tremaining: 2.99s\n",
      "34:\tlearn: 0.6147848\ttotal: 1.57s\tremaining: 2.93s\n",
      "35:\tlearn: 0.6097832\ttotal: 1.62s\tremaining: 2.88s\n",
      "36:\tlearn: 0.6039471\ttotal: 1.67s\tremaining: 2.83s\n",
      "37:\tlearn: 0.5989653\ttotal: 1.7s\tremaining: 2.78s\n",
      "38:\tlearn: 0.5948862\ttotal: 1.74s\tremaining: 2.73s\n",
      "39:\tlearn: 0.5905029\ttotal: 1.79s\tremaining: 2.69s\n",
      "40:\tlearn: 0.5875785\ttotal: 1.84s\tremaining: 2.64s\n",
      "41:\tlearn: 0.5835386\ttotal: 1.89s\tremaining: 2.61s\n",
      "42:\tlearn: 0.5788865\ttotal: 1.94s\tremaining: 2.57s\n",
      "43:\tlearn: 0.5778317\ttotal: 1.98s\tremaining: 2.51s\n",
      "44:\tlearn: 0.5754053\ttotal: 2.01s\tremaining: 2.45s\n",
      "45:\tlearn: 0.5720076\ttotal: 2.04s\tremaining: 2.4s\n",
      "46:\tlearn: 0.5692409\ttotal: 2.08s\tremaining: 2.34s\n",
      "47:\tlearn: 0.5669519\ttotal: 2.11s\tremaining: 2.29s\n",
      "48:\tlearn: 0.5622592\ttotal: 2.15s\tremaining: 2.24s\n",
      "49:\tlearn: 0.5531322\ttotal: 2.2s\tremaining: 2.2s\n",
      "50:\tlearn: 0.5495482\ttotal: 2.24s\tremaining: 2.15s\n",
      "51:\tlearn: 0.5475966\ttotal: 2.29s\tremaining: 2.12s\n",
      "52:\tlearn: 0.5429969\ttotal: 2.34s\tremaining: 2.07s\n",
      "53:\tlearn: 0.5404446\ttotal: 2.38s\tremaining: 2.03s\n",
      "54:\tlearn: 0.5372018\ttotal: 2.42s\tremaining: 1.98s\n",
      "55:\tlearn: 0.5342623\ttotal: 2.46s\tremaining: 1.93s\n",
      "56:\tlearn: 0.5322018\ttotal: 2.49s\tremaining: 1.88s\n",
      "57:\tlearn: 0.5309591\ttotal: 2.52s\tremaining: 1.83s\n",
      "58:\tlearn: 0.5232218\ttotal: 2.56s\tremaining: 1.78s\n",
      "59:\tlearn: 0.5203157\ttotal: 2.61s\tremaining: 1.74s\n",
      "60:\tlearn: 0.5169879\ttotal: 2.66s\tremaining: 1.7s\n",
      "61:\tlearn: 0.5135202\ttotal: 2.69s\tremaining: 1.65s\n",
      "62:\tlearn: 0.5098686\ttotal: 2.73s\tremaining: 1.6s\n",
      "63:\tlearn: 0.5084564\ttotal: 2.77s\tremaining: 1.55s\n",
      "64:\tlearn: 0.5065450\ttotal: 2.8s\tremaining: 1.51s\n",
      "65:\tlearn: 0.5038020\ttotal: 2.84s\tremaining: 1.46s\n",
      "66:\tlearn: 0.5012860\ttotal: 2.88s\tremaining: 1.42s\n",
      "67:\tlearn: 0.4993431\ttotal: 2.91s\tremaining: 1.37s\n",
      "68:\tlearn: 0.4959182\ttotal: 2.95s\tremaining: 1.32s\n",
      "69:\tlearn: 0.4945052\ttotal: 2.99s\tremaining: 1.28s\n",
      "70:\tlearn: 0.4924912\ttotal: 3.04s\tremaining: 1.24s\n",
      "71:\tlearn: 0.4907861\ttotal: 3.08s\tremaining: 1.2s\n",
      "72:\tlearn: 0.4887148\ttotal: 3.13s\tremaining: 1.16s\n",
      "73:\tlearn: 0.4853413\ttotal: 3.18s\tremaining: 1.12s\n",
      "74:\tlearn: 0.4836413\ttotal: 3.23s\tremaining: 1.07s\n",
      "75:\tlearn: 0.4823056\ttotal: 3.27s\tremaining: 1.03s\n",
      "76:\tlearn: 0.4818896\ttotal: 3.3s\tremaining: 986ms\n",
      "77:\tlearn: 0.4789141\ttotal: 3.34s\tremaining: 943ms\n",
      "78:\tlearn: 0.4775549\ttotal: 3.38s\tremaining: 897ms\n",
      "79:\tlearn: 0.4764171\ttotal: 3.42s\tremaining: 855ms\n",
      "80:\tlearn: 0.4741032\ttotal: 3.46s\tremaining: 813ms\n",
      "81:\tlearn: 0.4731012\ttotal: 3.51s\tremaining: 771ms\n",
      "82:\tlearn: 0.4715425\ttotal: 3.55s\tremaining: 727ms\n",
      "83:\tlearn: 0.4698797\ttotal: 3.58s\tremaining: 682ms\n",
      "84:\tlearn: 0.4688604\ttotal: 3.61s\tremaining: 638ms\n",
      "85:\tlearn: 0.4674278\ttotal: 3.66s\tremaining: 595ms\n",
      "86:\tlearn: 0.4666633\ttotal: 3.69s\tremaining: 552ms\n",
      "87:\tlearn: 0.4644778\ttotal: 3.73s\tremaining: 508ms\n",
      "88:\tlearn: 0.4627678\ttotal: 3.76s\tremaining: 465ms\n",
      "89:\tlearn: 0.4619774\ttotal: 3.79s\tremaining: 422ms\n",
      "90:\tlearn: 0.4602432\ttotal: 3.83s\tremaining: 379ms\n",
      "91:\tlearn: 0.4589916\ttotal: 3.87s\tremaining: 337ms\n",
      "92:\tlearn: 0.4581779\ttotal: 3.91s\tremaining: 294ms\n",
      "93:\tlearn: 0.4565887\ttotal: 3.95s\tremaining: 252ms\n",
      "94:\tlearn: 0.4557786\ttotal: 3.98s\tremaining: 210ms\n",
      "95:\tlearn: 0.4542812\ttotal: 4.02s\tremaining: 168ms\n",
      "96:\tlearn: 0.4534410\ttotal: 4.07s\tremaining: 126ms\n",
      "97:\tlearn: 0.4527401\ttotal: 4.11s\tremaining: 83.9ms\n",
      "98:\tlearn: 0.4523114\ttotal: 4.14s\tremaining: 41.9ms\n",
      "99:\tlearn: 0.4512624\ttotal: 4.19s\tremaining: 0us\n",
      "0:\tlearn: 1.8834597\ttotal: 43.9ms\tremaining: 4.34s\n",
      "1:\tlearn: 1.5540128\ttotal: 85.6ms\tremaining: 4.19s\n",
      "2:\tlearn: 1.4013208\ttotal: 121ms\tremaining: 3.9s\n",
      "3:\tlearn: 1.2458418\ttotal: 154ms\tremaining: 3.69s\n",
      "4:\tlearn: 1.1365848\ttotal: 194ms\tremaining: 3.68s\n",
      "5:\tlearn: 1.0819374\ttotal: 228ms\tremaining: 3.57s\n",
      "6:\tlearn: 1.0267887\ttotal: 270ms\tremaining: 3.58s\n",
      "7:\tlearn: 0.9809151\ttotal: 313ms\tremaining: 3.6s\n",
      "8:\tlearn: 0.9480169\ttotal: 353ms\tremaining: 3.57s\n",
      "9:\tlearn: 0.9202955\ttotal: 395ms\tremaining: 3.56s\n",
      "10:\tlearn: 0.8922407\ttotal: 431ms\tremaining: 3.49s\n",
      "11:\tlearn: 0.8741179\ttotal: 466ms\tremaining: 3.41s\n",
      "12:\tlearn: 0.8519269\ttotal: 503ms\tremaining: 3.36s\n",
      "13:\tlearn: 0.8226432\ttotal: 548ms\tremaining: 3.37s\n",
      "14:\tlearn: 0.8048557\ttotal: 605ms\tremaining: 3.43s\n",
      "15:\tlearn: 0.7884799\ttotal: 670ms\tremaining: 3.52s\n",
      "16:\tlearn: 0.7761017\ttotal: 724ms\tremaining: 3.54s\n",
      "17:\tlearn: 0.7622796\ttotal: 765ms\tremaining: 3.48s\n",
      "18:\tlearn: 0.7489421\ttotal: 807ms\tremaining: 3.44s\n",
      "19:\tlearn: 0.7366134\ttotal: 851ms\tremaining: 3.4s\n",
      "20:\tlearn: 0.7260457\ttotal: 889ms\tremaining: 3.35s\n",
      "21:\tlearn: 0.7141922\ttotal: 928ms\tremaining: 3.29s\n",
      "22:\tlearn: 0.6986568\ttotal: 972ms\tremaining: 3.25s\n",
      "23:\tlearn: 0.6909831\ttotal: 1.03s\tremaining: 3.25s\n",
      "24:\tlearn: 0.6840541\ttotal: 1.09s\tremaining: 3.26s\n",
      "25:\tlearn: 0.6782197\ttotal: 1.12s\tremaining: 3.19s\n",
      "26:\tlearn: 0.6709491\ttotal: 1.16s\tremaining: 3.13s\n",
      "27:\tlearn: 0.6644861\ttotal: 1.19s\tremaining: 3.07s\n",
      "28:\tlearn: 0.6584056\ttotal: 1.23s\tremaining: 3.01s\n",
      "29:\tlearn: 0.6518017\ttotal: 1.27s\tremaining: 2.96s\n",
      "30:\tlearn: 0.6456094\ttotal: 1.32s\tremaining: 2.93s\n",
      "31:\tlearn: 0.6376783\ttotal: 1.35s\tremaining: 2.88s\n",
      "32:\tlearn: 0.6328615\ttotal: 1.39s\tremaining: 2.83s\n",
      "33:\tlearn: 0.6290328\ttotal: 1.43s\tremaining: 2.78s\n",
      "34:\tlearn: 0.6223129\ttotal: 1.47s\tremaining: 2.73s\n",
      "35:\tlearn: 0.6157237\ttotal: 1.51s\tremaining: 2.68s\n",
      "36:\tlearn: 0.6074052\ttotal: 1.55s\tremaining: 2.65s\n",
      "37:\tlearn: 0.6018483\ttotal: 1.6s\tremaining: 2.6s\n",
      "38:\tlearn: 0.5927888\ttotal: 1.65s\tremaining: 2.57s\n",
      "39:\tlearn: 0.5888363\ttotal: 1.68s\tremaining: 2.52s\n",
      "40:\tlearn: 0.5817276\ttotal: 1.72s\tremaining: 2.48s\n",
      "41:\tlearn: 0.5767348\ttotal: 1.76s\tremaining: 2.43s\n",
      "42:\tlearn: 0.5735479\ttotal: 1.8s\tremaining: 2.39s\n",
      "43:\tlearn: 0.5694541\ttotal: 1.85s\tremaining: 2.35s\n",
      "44:\tlearn: 0.5657482\ttotal: 1.9s\tremaining: 2.32s\n",
      "45:\tlearn: 0.5639371\ttotal: 1.94s\tremaining: 2.28s\n",
      "46:\tlearn: 0.5600321\ttotal: 1.99s\tremaining: 2.25s\n",
      "47:\tlearn: 0.5584318\ttotal: 2.04s\tremaining: 2.21s\n",
      "48:\tlearn: 0.5562943\ttotal: 2.08s\tremaining: 2.16s\n",
      "49:\tlearn: 0.5536819\ttotal: 2.11s\tremaining: 2.11s\n",
      "50:\tlearn: 0.5520482\ttotal: 2.16s\tremaining: 2.07s\n",
      "51:\tlearn: 0.5499600\ttotal: 2.21s\tremaining: 2.04s\n",
      "52:\tlearn: 0.5462017\ttotal: 2.25s\tremaining: 1.99s\n",
      "53:\tlearn: 0.5448236\ttotal: 2.28s\tremaining: 1.94s\n",
      "54:\tlearn: 0.5419467\ttotal: 2.33s\tremaining: 1.9s\n",
      "55:\tlearn: 0.5393025\ttotal: 2.37s\tremaining: 1.86s\n",
      "56:\tlearn: 0.5366186\ttotal: 2.41s\tremaining: 1.82s\n",
      "57:\tlearn: 0.5337652\ttotal: 2.45s\tremaining: 1.77s\n",
      "58:\tlearn: 0.5301090\ttotal: 2.48s\tremaining: 1.72s\n",
      "59:\tlearn: 0.5277180\ttotal: 2.52s\tremaining: 1.68s\n",
      "60:\tlearn: 0.5265383\ttotal: 2.55s\tremaining: 1.63s\n",
      "61:\tlearn: 0.5248206\ttotal: 2.59s\tremaining: 1.59s\n",
      "62:\tlearn: 0.5229260\ttotal: 2.62s\tremaining: 1.54s\n",
      "63:\tlearn: 0.5200752\ttotal: 2.66s\tremaining: 1.5s\n",
      "64:\tlearn: 0.5191973\ttotal: 2.7s\tremaining: 1.45s\n",
      "65:\tlearn: 0.5180151\ttotal: 2.74s\tremaining: 1.41s\n",
      "66:\tlearn: 0.5145069\ttotal: 2.79s\tremaining: 1.37s\n",
      "67:\tlearn: 0.5123982\ttotal: 2.83s\tremaining: 1.33s\n",
      "68:\tlearn: 0.5091433\ttotal: 2.87s\tremaining: 1.29s\n",
      "69:\tlearn: 0.5061089\ttotal: 2.9s\tremaining: 1.25s\n",
      "70:\tlearn: 0.5046669\ttotal: 2.95s\tremaining: 1.2s\n",
      "71:\tlearn: 0.5031017\ttotal: 2.98s\tremaining: 1.16s\n",
      "72:\tlearn: 0.5022770\ttotal: 3.02s\tremaining: 1.12s\n",
      "73:\tlearn: 0.5010679\ttotal: 3.06s\tremaining: 1.07s\n",
      "74:\tlearn: 0.4982435\ttotal: 3.1s\tremaining: 1.03s\n",
      "75:\tlearn: 0.4962811\ttotal: 3.14s\tremaining: 992ms\n",
      "76:\tlearn: 0.4942958\ttotal: 3.17s\tremaining: 949ms\n",
      "77:\tlearn: 0.4932639\ttotal: 3.21s\tremaining: 907ms\n",
      "78:\tlearn: 0.4899938\ttotal: 3.26s\tremaining: 866ms\n",
      "79:\tlearn: 0.4879656\ttotal: 3.29s\tremaining: 823ms\n",
      "80:\tlearn: 0.4859217\ttotal: 3.33s\tremaining: 783ms\n",
      "81:\tlearn: 0.4839566\ttotal: 3.38s\tremaining: 741ms\n",
      "82:\tlearn: 0.4809102\ttotal: 3.42s\tremaining: 701ms\n",
      "83:\tlearn: 0.4799534\ttotal: 3.47s\tremaining: 661ms\n",
      "84:\tlearn: 0.4788286\ttotal: 3.51s\tremaining: 619ms\n",
      "85:\tlearn: 0.4781631\ttotal: 3.54s\tremaining: 576ms\n",
      "86:\tlearn: 0.4767701\ttotal: 3.58s\tremaining: 535ms\n",
      "87:\tlearn: 0.4760200\ttotal: 3.63s\tremaining: 495ms\n",
      "88:\tlearn: 0.4751508\ttotal: 3.67s\tremaining: 454ms\n",
      "89:\tlearn: 0.4734897\ttotal: 3.72s\tremaining: 413ms\n",
      "90:\tlearn: 0.4720575\ttotal: 3.76s\tremaining: 372ms\n",
      "91:\tlearn: 0.4713224\ttotal: 3.8s\tremaining: 331ms\n",
      "92:\tlearn: 0.4695097\ttotal: 3.86s\tremaining: 290ms\n",
      "93:\tlearn: 0.4669752\ttotal: 3.9s\tremaining: 249ms\n",
      "94:\tlearn: 0.4656454\ttotal: 3.96s\tremaining: 208ms\n",
      "95:\tlearn: 0.4636399\ttotal: 4.02s\tremaining: 167ms\n",
      "96:\tlearn: 0.4627287\ttotal: 4.07s\tremaining: 126ms\n",
      "97:\tlearn: 0.4620114\ttotal: 4.1s\tremaining: 83.8ms\n",
      "98:\tlearn: 0.4612748\ttotal: 4.15s\tremaining: 41.9ms\n",
      "99:\tlearn: 0.4605582\ttotal: 4.2s\tremaining: 0us\n",
      "0:\tlearn: 1.8848559\ttotal: 44.9ms\tremaining: 4.44s\n",
      "1:\tlearn: 1.5549957\ttotal: 85.9ms\tremaining: 4.21s\n",
      "2:\tlearn: 1.4022477\ttotal: 121ms\tremaining: 3.91s\n",
      "3:\tlearn: 1.2476357\ttotal: 154ms\tremaining: 3.68s\n",
      "4:\tlearn: 1.1361741\ttotal: 193ms\tremaining: 3.66s\n",
      "5:\tlearn: 1.0813948\ttotal: 227ms\tremaining: 3.55s\n",
      "6:\tlearn: 1.0469191\ttotal: 263ms\tremaining: 3.5s\n",
      "7:\tlearn: 0.9993784\ttotal: 302ms\tremaining: 3.48s\n",
      "8:\tlearn: 0.9548924\ttotal: 345ms\tremaining: 3.49s\n",
      "9:\tlearn: 0.9190057\ttotal: 389ms\tremaining: 3.5s\n",
      "10:\tlearn: 0.8963639\ttotal: 432ms\tremaining: 3.5s\n",
      "11:\tlearn: 0.8719764\ttotal: 474ms\tremaining: 3.48s\n",
      "12:\tlearn: 0.8515393\ttotal: 509ms\tremaining: 3.41s\n",
      "13:\tlearn: 0.8341757\ttotal: 555ms\tremaining: 3.41s\n",
      "14:\tlearn: 0.8183941\ttotal: 592ms\tremaining: 3.35s\n",
      "15:\tlearn: 0.7988227\ttotal: 637ms\tremaining: 3.35s\n",
      "16:\tlearn: 0.7800358\ttotal: 675ms\tremaining: 3.3s\n",
      "17:\tlearn: 0.7634180\ttotal: 721ms\tremaining: 3.28s\n",
      "18:\tlearn: 0.7519515\ttotal: 763ms\tremaining: 3.25s\n",
      "19:\tlearn: 0.7382603\ttotal: 799ms\tremaining: 3.2s\n",
      "20:\tlearn: 0.7237255\ttotal: 838ms\tremaining: 3.15s\n",
      "21:\tlearn: 0.7122259\ttotal: 872ms\tremaining: 3.09s\n",
      "22:\tlearn: 0.7008680\ttotal: 915ms\tremaining: 3.06s\n",
      "23:\tlearn: 0.6902221\ttotal: 950ms\tremaining: 3.01s\n",
      "24:\tlearn: 0.6826637\ttotal: 988ms\tremaining: 2.96s\n",
      "25:\tlearn: 0.6774936\ttotal: 1.02s\tremaining: 2.92s\n",
      "26:\tlearn: 0.6708397\ttotal: 1.06s\tremaining: 2.87s\n",
      "27:\tlearn: 0.6593400\ttotal: 1.1s\tremaining: 2.84s\n",
      "28:\tlearn: 0.6526211\ttotal: 1.15s\tremaining: 2.81s\n",
      "29:\tlearn: 0.6441020\ttotal: 1.18s\tremaining: 2.76s\n",
      "30:\tlearn: 0.6386812\ttotal: 1.23s\tremaining: 2.73s\n",
      "31:\tlearn: 0.6324780\ttotal: 1.26s\tremaining: 2.69s\n",
      "32:\tlearn: 0.6281617\ttotal: 1.3s\tremaining: 2.63s\n",
      "33:\tlearn: 0.6234609\ttotal: 1.34s\tremaining: 2.6s\n",
      "34:\tlearn: 0.6154425\ttotal: 1.38s\tremaining: 2.57s\n",
      "35:\tlearn: 0.6088129\ttotal: 1.43s\tremaining: 2.54s\n",
      "36:\tlearn: 0.6063166\ttotal: 1.46s\tremaining: 2.48s\n",
      "37:\tlearn: 0.5978882\ttotal: 1.5s\tremaining: 2.44s\n",
      "38:\tlearn: 0.5949962\ttotal: 1.53s\tremaining: 2.39s\n",
      "39:\tlearn: 0.5855861\ttotal: 1.58s\tremaining: 2.37s\n",
      "40:\tlearn: 0.5818000\ttotal: 1.62s\tremaining: 2.33s\n",
      "41:\tlearn: 0.5799099\ttotal: 1.65s\tremaining: 2.28s\n",
      "42:\tlearn: 0.5773687\ttotal: 1.68s\tremaining: 2.23s\n",
      "43:\tlearn: 0.5727760\ttotal: 1.73s\tremaining: 2.2s\n",
      "44:\tlearn: 0.5703810\ttotal: 1.76s\tremaining: 2.15s\n",
      "45:\tlearn: 0.5663332\ttotal: 1.79s\tremaining: 2.11s\n",
      "46:\tlearn: 0.5636925\ttotal: 1.83s\tremaining: 2.06s\n",
      "47:\tlearn: 0.5609492\ttotal: 1.86s\tremaining: 2.02s\n",
      "48:\tlearn: 0.5580420\ttotal: 1.9s\tremaining: 1.98s\n",
      "49:\tlearn: 0.5531303\ttotal: 1.94s\tremaining: 1.94s\n",
      "50:\tlearn: 0.5507185\ttotal: 1.99s\tremaining: 1.91s\n",
      "51:\tlearn: 0.5478515\ttotal: 2.03s\tremaining: 1.87s\n",
      "52:\tlearn: 0.5457618\ttotal: 2.06s\tremaining: 1.83s\n",
      "53:\tlearn: 0.5418238\ttotal: 2.1s\tremaining: 1.79s\n",
      "54:\tlearn: 0.5401352\ttotal: 2.14s\tremaining: 1.75s\n",
      "55:\tlearn: 0.5381053\ttotal: 2.17s\tremaining: 1.71s\n",
      "56:\tlearn: 0.5358999\ttotal: 2.22s\tremaining: 1.67s\n",
      "57:\tlearn: 0.5350996\ttotal: 2.25s\tremaining: 1.63s\n",
      "58:\tlearn: 0.5319285\ttotal: 2.29s\tremaining: 1.59s\n",
      "59:\tlearn: 0.5273763\ttotal: 2.34s\tremaining: 1.56s\n",
      "60:\tlearn: 0.5253778\ttotal: 2.37s\tremaining: 1.51s\n",
      "61:\tlearn: 0.5225271\ttotal: 2.4s\tremaining: 1.47s\n",
      "62:\tlearn: 0.5204938\ttotal: 2.44s\tremaining: 1.43s\n",
      "63:\tlearn: 0.5178152\ttotal: 2.49s\tremaining: 1.4s\n",
      "64:\tlearn: 0.5168256\ttotal: 2.52s\tremaining: 1.36s\n",
      "65:\tlearn: 0.5134723\ttotal: 2.56s\tremaining: 1.32s\n",
      "66:\tlearn: 0.5092048\ttotal: 2.6s\tremaining: 1.28s\n",
      "67:\tlearn: 0.5075732\ttotal: 2.65s\tremaining: 1.25s\n",
      "68:\tlearn: 0.5060896\ttotal: 2.68s\tremaining: 1.2s\n",
      "69:\tlearn: 0.5050911\ttotal: 2.71s\tremaining: 1.16s\n",
      "70:\tlearn: 0.5045044\ttotal: 2.75s\tremaining: 1.12s\n",
      "71:\tlearn: 0.5023971\ttotal: 2.79s\tremaining: 1.08s\n",
      "72:\tlearn: 0.4987602\ttotal: 2.83s\tremaining: 1.05s\n",
      "73:\tlearn: 0.4974069\ttotal: 2.87s\tremaining: 1.01s\n",
      "74:\tlearn: 0.4961567\ttotal: 2.91s\tremaining: 969ms\n",
      "75:\tlearn: 0.4950185\ttotal: 2.94s\tremaining: 929ms\n",
      "76:\tlearn: 0.4919222\ttotal: 2.99s\tremaining: 892ms\n",
      "77:\tlearn: 0.4896734\ttotal: 3.02s\tremaining: 853ms\n",
      "78:\tlearn: 0.4861611\ttotal: 3.06s\tremaining: 814ms\n",
      "79:\tlearn: 0.4837060\ttotal: 3.1s\tremaining: 776ms\n",
      "80:\tlearn: 0.4830984\ttotal: 3.14s\tremaining: 736ms\n",
      "81:\tlearn: 0.4808416\ttotal: 3.19s\tremaining: 699ms\n",
      "82:\tlearn: 0.4796376\ttotal: 3.22s\tremaining: 659ms\n",
      "83:\tlearn: 0.4787908\ttotal: 3.25s\tremaining: 620ms\n",
      "84:\tlearn: 0.4768036\ttotal: 3.29s\tremaining: 581ms\n",
      "85:\tlearn: 0.4760887\ttotal: 3.32s\tremaining: 541ms\n",
      "86:\tlearn: 0.4744569\ttotal: 3.36s\tremaining: 503ms\n",
      "87:\tlearn: 0.4725603\ttotal: 3.41s\tremaining: 465ms\n",
      "88:\tlearn: 0.4687873\ttotal: 3.46s\tremaining: 427ms\n",
      "89:\tlearn: 0.4666960\ttotal: 3.5s\tremaining: 389ms\n",
      "90:\tlearn: 0.4659517\ttotal: 3.54s\tremaining: 350ms\n",
      "91:\tlearn: 0.4646222\ttotal: 3.58s\tremaining: 311ms\n",
      "92:\tlearn: 0.4627535\ttotal: 3.62s\tremaining: 273ms\n",
      "93:\tlearn: 0.4620502\ttotal: 3.66s\tremaining: 234ms\n",
      "94:\tlearn: 0.4610435\ttotal: 3.7s\tremaining: 195ms\n",
      "95:\tlearn: 0.4606506\ttotal: 3.75s\tremaining: 156ms\n",
      "96:\tlearn: 0.4595431\ttotal: 3.79s\tremaining: 117ms\n",
      "97:\tlearn: 0.4583582\ttotal: 3.83s\tremaining: 78.1ms\n",
      "98:\tlearn: 0.4571612\ttotal: 3.86s\tremaining: 39ms\n",
      "99:\tlearn: 0.4545488\ttotal: 3.9s\tremaining: 0us\n",
      "0:\tlearn: 1.9155414\ttotal: 44ms\tremaining: 4.35s\n",
      "1:\tlearn: 1.4969725\ttotal: 82.6ms\tremaining: 4.05s\n",
      "2:\tlearn: 1.3707797\ttotal: 117ms\tremaining: 3.77s\n",
      "3:\tlearn: 1.2806549\ttotal: 149ms\tremaining: 3.58s\n",
      "4:\tlearn: 1.1714322\ttotal: 193ms\tremaining: 3.67s\n",
      "5:\tlearn: 1.0706660\ttotal: 238ms\tremaining: 3.73s\n",
      "6:\tlearn: 1.0035574\ttotal: 280ms\tremaining: 3.73s\n",
      "7:\tlearn: 0.9521157\ttotal: 322ms\tremaining: 3.7s\n",
      "8:\tlearn: 0.8996467\ttotal: 363ms\tremaining: 3.67s\n",
      "9:\tlearn: 0.8653891\ttotal: 409ms\tremaining: 3.68s\n",
      "10:\tlearn: 0.8391918\ttotal: 444ms\tremaining: 3.59s\n",
      "11:\tlearn: 0.8227849\ttotal: 478ms\tremaining: 3.51s\n",
      "12:\tlearn: 0.8074811\ttotal: 515ms\tremaining: 3.44s\n",
      "13:\tlearn: 0.7785301\ttotal: 550ms\tremaining: 3.38s\n",
      "14:\tlearn: 0.7680335\ttotal: 582ms\tremaining: 3.3s\n",
      "15:\tlearn: 0.7598727\ttotal: 615ms\tremaining: 3.23s\n",
      "16:\tlearn: 0.7401163\ttotal: 655ms\tremaining: 3.2s\n",
      "17:\tlearn: 0.7285407\ttotal: 690ms\tremaining: 3.14s\n",
      "18:\tlearn: 0.7135153\ttotal: 736ms\tremaining: 3.14s\n",
      "19:\tlearn: 0.6972458\ttotal: 772ms\tremaining: 3.09s\n",
      "20:\tlearn: 0.6878590\ttotal: 812ms\tremaining: 3.06s\n",
      "21:\tlearn: 0.6848515\ttotal: 845ms\tremaining: 3s\n",
      "22:\tlearn: 0.6778936\ttotal: 878ms\tremaining: 2.94s\n",
      "23:\tlearn: 2.4265578\ttotal: 914ms\tremaining: 2.89s\n",
      "24:\tlearn: 9.3774052\ttotal: 950ms\tremaining: 2.85s\n",
      "25:\tlearn: 8.9754260\ttotal: 996ms\tremaining: 2.83s\n",
      "26:\tlearn: 8.4166506\ttotal: 1.03s\tremaining: 2.79s\n",
      "27:\tlearn: 7.8815757\ttotal: 1.07s\tremaining: 2.74s\n",
      "28:\tlearn: 7.5630135\ttotal: 1.1s\tremaining: 2.7s\n",
      "29:\tlearn: 6.9269663\ttotal: 1.14s\tremaining: 2.66s\n",
      "30:\tlearn: 6.2969779\ttotal: 1.17s\tremaining: 2.61s\n",
      "31:\tlearn: 5.8928638\ttotal: 1.21s\tremaining: 2.57s\n",
      "32:\tlearn: 5.8825887\ttotal: 1.25s\tremaining: 2.54s\n",
      "33:\tlearn: 5.3967077\ttotal: 1.28s\tremaining: 2.49s\n",
      "34:\tlearn: 4.7863558\ttotal: 1.32s\tremaining: 2.45s\n",
      "35:\tlearn: 4.1879601\ttotal: 1.35s\tremaining: 2.41s\n",
      "36:\tlearn: 5.2184059\ttotal: 1.39s\tremaining: 2.37s\n",
      "37:\tlearn: 8.1246968\ttotal: 1.43s\tremaining: 2.33s\n",
      "38:\tlearn: 8.1184749\ttotal: 1.46s\tremaining: 2.29s\n",
      "39:\tlearn: 7.8103880\ttotal: 1.5s\tremaining: 2.25s\n",
      "40:\tlearn: 7.5112801\ttotal: 1.53s\tremaining: 2.21s\n",
      "41:\tlearn: 7.5002947\ttotal: 1.57s\tremaining: 2.17s\n",
      "42:\tlearn: 7.2579037\ttotal: 1.61s\tremaining: 2.13s\n",
      "43:\tlearn: 7.2512438\ttotal: 1.65s\tremaining: 2.1s\n",
      "44:\tlearn: 6.9105668\ttotal: 1.68s\tremaining: 2.06s\n",
      "45:\tlearn: 6.9017890\ttotal: 1.73s\tremaining: 2.03s\n",
      "46:\tlearn: 6.5970290\ttotal: 1.76s\tremaining: 1.99s\n",
      "47:\tlearn: 6.5927547\ttotal: 1.8s\tremaining: 1.95s\n",
      "48:\tlearn: 6.5892724\ttotal: 1.83s\tremaining: 1.91s\n",
      "49:\tlearn: 6.5871056\ttotal: 1.86s\tremaining: 1.86s\n",
      "50:\tlearn: 6.5817839\ttotal: 1.92s\tremaining: 1.84s\n",
      "51:\tlearn: 6.5757986\ttotal: 1.96s\tremaining: 1.81s\n",
      "52:\tlearn: 6.5736018\ttotal: 1.99s\tremaining: 1.76s\n",
      "53:\tlearn: 6.5639869\ttotal: 2.03s\tremaining: 1.73s\n",
      "54:\tlearn: 6.5609878\ttotal: 2.07s\tremaining: 1.7s\n",
      "55:\tlearn: 6.5487283\ttotal: 2.12s\tremaining: 1.66s\n",
      "56:\tlearn: 6.2925513\ttotal: 2.15s\tremaining: 1.63s\n",
      "57:\tlearn: 6.2891308\ttotal: 2.19s\tremaining: 1.58s\n",
      "58:\tlearn: 6.2822298\ttotal: 2.23s\tremaining: 1.55s\n",
      "59:\tlearn: 6.0181592\ttotal: 2.27s\tremaining: 1.51s\n",
      "60:\tlearn: 6.0097583\ttotal: 2.31s\tremaining: 1.47s\n",
      "61:\tlearn: 5.6263746\ttotal: 2.34s\tremaining: 1.43s\n",
      "62:\tlearn: 5.6223480\ttotal: 2.38s\tremaining: 1.4s\n",
      "63:\tlearn: 5.3419216\ttotal: 2.41s\tremaining: 1.36s\n",
      "64:\tlearn: 5.3360586\ttotal: 2.45s\tremaining: 1.32s\n",
      "65:\tlearn: 5.1996170\ttotal: 2.5s\tremaining: 1.29s\n",
      "66:\tlearn: 5.1964925\ttotal: 2.54s\tremaining: 1.25s\n",
      "67:\tlearn: 5.0035945\ttotal: 2.58s\tremaining: 1.21s\n",
      "68:\tlearn: 4.9996537\ttotal: 2.61s\tremaining: 1.17s\n",
      "69:\tlearn: 4.8189683\ttotal: 2.64s\tremaining: 1.13s\n",
      "70:\tlearn: 4.5946716\ttotal: 2.68s\tremaining: 1.09s\n",
      "71:\tlearn: 4.5861338\ttotal: 2.71s\tremaining: 1.05s\n",
      "72:\tlearn: 4.4134258\ttotal: 2.75s\tremaining: 1.02s\n",
      "73:\tlearn: 4.4095037\ttotal: 2.78s\tremaining: 978ms\n",
      "74:\tlearn: 4.0582856\ttotal: 2.82s\tremaining: 940ms\n",
      "75:\tlearn: 3.8996077\ttotal: 2.85s\tremaining: 902ms\n",
      "76:\tlearn: 3.8957983\ttotal: 2.9s\tremaining: 865ms\n",
      "77:\tlearn: 3.8492414\ttotal: 2.93s\tremaining: 827ms\n",
      "78:\tlearn: 3.7532586\ttotal: 2.97s\tremaining: 789ms\n",
      "79:\tlearn: 3.7188624\ttotal: 3s\tremaining: 750ms\n",
      "80:\tlearn: 3.7133645\ttotal: 3.05s\tremaining: 716ms\n",
      "81:\tlearn: 3.7114984\ttotal: 3.08s\tremaining: 677ms\n",
      "82:\tlearn: 3.7048689\ttotal: 3.12s\tremaining: 639ms\n",
      "83:\tlearn: 3.7008201\ttotal: 3.16s\tremaining: 602ms\n",
      "84:\tlearn: 3.6982370\ttotal: 3.19s\tremaining: 564ms\n",
      "85:\tlearn: 3.6954903\ttotal: 3.23s\tremaining: 526ms\n",
      "86:\tlearn: 3.6927905\ttotal: 3.27s\tremaining: 488ms\n",
      "87:\tlearn: 3.6910870\ttotal: 3.31s\tremaining: 451ms\n",
      "88:\tlearn: 3.6309302\ttotal: 3.35s\tremaining: 414ms\n",
      "89:\tlearn: 3.6269010\ttotal: 3.4s\tremaining: 377ms\n",
      "90:\tlearn: 3.6258232\ttotal: 3.43s\tremaining: 339ms\n",
      "91:\tlearn: 3.6243823\ttotal: 3.47s\tremaining: 302ms\n",
      "92:\tlearn: 3.6219200\ttotal: 3.51s\tremaining: 264ms\n",
      "93:\tlearn: 3.6206297\ttotal: 3.54s\tremaining: 226ms\n",
      "94:\tlearn: 3.6188379\ttotal: 3.59s\tremaining: 189ms\n",
      "95:\tlearn: 3.6175778\ttotal: 3.63s\tremaining: 151ms\n",
      "96:\tlearn: 3.6159015\ttotal: 3.67s\tremaining: 114ms\n",
      "97:\tlearn: 3.6107243\ttotal: 3.72s\tremaining: 75.9ms\n",
      "98:\tlearn: 3.6088140\ttotal: 3.76s\tremaining: 38ms\n",
      "99:\tlearn: 3.6059867\ttotal: 3.81s\tremaining: 0us\n",
      "0:\tlearn: 1.9728942\ttotal: 43.2ms\tremaining: 4.27s\n",
      "1:\tlearn: 1.5743907\ttotal: 83.2ms\tremaining: 4.07s\n",
      "2:\tlearn: 1.4035716\ttotal: 118ms\tremaining: 3.8s\n",
      "3:\tlearn: 1.2718791\ttotal: 150ms\tremaining: 3.6s\n",
      "4:\tlearn: 1.1924597\ttotal: 190ms\tremaining: 3.62s\n",
      "5:\tlearn: 1.0872659\ttotal: 236ms\tremaining: 3.7s\n",
      "6:\tlearn: 1.0338429\ttotal: 277ms\tremaining: 3.67s\n",
      "7:\tlearn: 0.9786056\ttotal: 316ms\tremaining: 3.64s\n",
      "8:\tlearn: 1.0188792\ttotal: 357ms\tremaining: 3.61s\n",
      "9:\tlearn: 0.9277885\ttotal: 394ms\tremaining: 3.54s\n",
      "10:\tlearn: 0.8929927\ttotal: 438ms\tremaining: 3.54s\n",
      "11:\tlearn: 0.8686064\ttotal: 485ms\tremaining: 3.55s\n",
      "12:\tlearn: 0.8459450\ttotal: 533ms\tremaining: 3.56s\n",
      "13:\tlearn: 0.8268179\ttotal: 578ms\tremaining: 3.55s\n",
      "14:\tlearn: 0.8048642\ttotal: 612ms\tremaining: 3.47s\n",
      "15:\tlearn: 0.7829528\ttotal: 654ms\tremaining: 3.43s\n",
      "16:\tlearn: 0.7732590\ttotal: 696ms\tremaining: 3.4s\n",
      "17:\tlearn: 0.7623329\ttotal: 732ms\tremaining: 3.33s\n",
      "18:\tlearn: 0.7458578\ttotal: 770ms\tremaining: 3.28s\n",
      "19:\tlearn: 0.7332818\ttotal: 809ms\tremaining: 3.23s\n",
      "20:\tlearn: 0.7233125\ttotal: 843ms\tremaining: 3.17s\n",
      "21:\tlearn: 0.7139192\ttotal: 884ms\tremaining: 3.13s\n",
      "22:\tlearn: 0.6976049\ttotal: 919ms\tremaining: 3.08s\n",
      "23:\tlearn: 0.6886449\ttotal: 955ms\tremaining: 3.02s\n",
      "24:\tlearn: 0.6778566\ttotal: 997ms\tremaining: 2.99s\n",
      "25:\tlearn: 0.6679564\ttotal: 1.03s\tremaining: 2.93s\n",
      "26:\tlearn: 0.6539480\ttotal: 1.08s\tremaining: 2.92s\n",
      "27:\tlearn: 0.6469826\ttotal: 1.11s\tremaining: 2.86s\n",
      "28:\tlearn: 0.6411270\ttotal: 1.15s\tremaining: 2.81s\n",
      "29:\tlearn: 0.6352875\ttotal: 1.19s\tremaining: 2.78s\n",
      "30:\tlearn: 0.6304245\ttotal: 1.23s\tremaining: 2.74s\n",
      "31:\tlearn: 0.6251654\ttotal: 1.27s\tremaining: 2.7s\n",
      "32:\tlearn: 0.6193801\ttotal: 1.31s\tremaining: 2.67s\n",
      "33:\tlearn: 0.6128602\ttotal: 1.35s\tremaining: 2.62s\n",
      "34:\tlearn: 0.6084042\ttotal: 1.39s\tremaining: 2.58s\n",
      "35:\tlearn: 0.6060606\ttotal: 1.43s\tremaining: 2.54s\n",
      "36:\tlearn: 0.6036634\ttotal: 1.47s\tremaining: 2.5s\n",
      "37:\tlearn: 0.5969902\ttotal: 1.51s\tremaining: 2.46s\n",
      "38:\tlearn: 0.5912307\ttotal: 1.54s\tremaining: 2.42s\n",
      "39:\tlearn: 0.5884477\ttotal: 1.58s\tremaining: 2.37s\n",
      "40:\tlearn: 0.5857831\ttotal: 1.61s\tremaining: 2.32s\n",
      "41:\tlearn: 0.5802621\ttotal: 1.66s\tremaining: 2.29s\n",
      "42:\tlearn: 0.5741529\ttotal: 1.7s\tremaining: 2.26s\n",
      "43:\tlearn: 0.5723145\ttotal: 1.74s\tremaining: 2.21s\n",
      "44:\tlearn: 0.5669041\ttotal: 1.77s\tremaining: 2.17s\n",
      "45:\tlearn: 0.5659493\ttotal: 1.81s\tremaining: 2.12s\n",
      "46:\tlearn: 0.5633825\ttotal: 1.84s\tremaining: 2.08s\n",
      "47:\tlearn: 0.5606708\ttotal: 1.89s\tremaining: 2.04s\n",
      "48:\tlearn: 0.5587442\ttotal: 1.93s\tremaining: 2.01s\n",
      "49:\tlearn: 0.5559305\ttotal: 1.98s\tremaining: 1.98s\n",
      "50:\tlearn: 0.5551558\ttotal: 2.02s\tremaining: 1.94s\n",
      "51:\tlearn: 0.5527420\ttotal: 2.06s\tremaining: 1.9s\n",
      "52:\tlearn: 0.5459324\ttotal: 2.1s\tremaining: 1.86s\n",
      "53:\tlearn: 0.5438685\ttotal: 2.14s\tremaining: 1.82s\n",
      "54:\tlearn: 0.5390658\ttotal: 2.19s\tremaining: 1.79s\n",
      "55:\tlearn: 0.5346173\ttotal: 2.22s\tremaining: 1.74s\n",
      "56:\tlearn: 0.5331877\ttotal: 2.26s\tremaining: 1.71s\n",
      "57:\tlearn: 0.5302485\ttotal: 2.31s\tremaining: 1.67s\n",
      "58:\tlearn: 0.5238510\ttotal: 2.35s\tremaining: 1.63s\n",
      "59:\tlearn: 0.5221987\ttotal: 2.38s\tremaining: 1.59s\n",
      "60:\tlearn: 0.5200096\ttotal: 2.42s\tremaining: 1.55s\n",
      "61:\tlearn: 0.5165949\ttotal: 2.47s\tremaining: 1.51s\n",
      "62:\tlearn: 0.5149437\ttotal: 2.5s\tremaining: 1.47s\n",
      "63:\tlearn: 0.5109806\ttotal: 2.54s\tremaining: 1.43s\n",
      "64:\tlearn: 0.5092894\ttotal: 2.59s\tremaining: 1.4s\n",
      "65:\tlearn: 0.5070958\ttotal: 2.63s\tremaining: 1.35s\n",
      "66:\tlearn: 0.5061947\ttotal: 2.66s\tremaining: 1.31s\n",
      "67:\tlearn: 0.5036785\ttotal: 2.69s\tremaining: 1.27s\n",
      "68:\tlearn: 0.5010188\ttotal: 2.73s\tremaining: 1.23s\n",
      "69:\tlearn: 0.5002279\ttotal: 2.77s\tremaining: 1.19s\n",
      "70:\tlearn: 0.4988038\ttotal: 2.8s\tremaining: 1.14s\n",
      "71:\tlearn: 0.4965390\ttotal: 2.84s\tremaining: 1.11s\n",
      "72:\tlearn: 0.4955953\ttotal: 2.88s\tremaining: 1.06s\n",
      "73:\tlearn: 0.4940673\ttotal: 2.91s\tremaining: 1.02s\n",
      "74:\tlearn: 0.4920358\ttotal: 2.95s\tremaining: 984ms\n",
      "75:\tlearn: 0.4913907\ttotal: 2.98s\tremaining: 943ms\n",
      "76:\tlearn: 0.4903718\ttotal: 3.03s\tremaining: 906ms\n",
      "77:\tlearn: 0.4898770\ttotal: 3.07s\tremaining: 865ms\n",
      "78:\tlearn: 0.4892447\ttotal: 3.1s\tremaining: 825ms\n",
      "79:\tlearn: 0.4879079\ttotal: 3.14s\tremaining: 786ms\n",
      "80:\tlearn: 0.4873030\ttotal: 3.18s\tremaining: 745ms\n",
      "81:\tlearn: 0.4857415\ttotal: 3.22s\tremaining: 707ms\n",
      "82:\tlearn: 0.4850539\ttotal: 3.25s\tremaining: 667ms\n",
      "83:\tlearn: 0.4832566\ttotal: 3.29s\tremaining: 627ms\n",
      "84:\tlearn: 0.4816093\ttotal: 3.34s\tremaining: 590ms\n",
      "85:\tlearn: 0.4806946\ttotal: 3.38s\tremaining: 549ms\n",
      "86:\tlearn: 0.4777343\ttotal: 3.42s\tremaining: 511ms\n",
      "87:\tlearn: 0.4761939\ttotal: 3.46s\tremaining: 471ms\n",
      "88:\tlearn: 0.4755181\ttotal: 3.49s\tremaining: 431ms\n",
      "89:\tlearn: 0.4742180\ttotal: 3.53s\tremaining: 392ms\n",
      "90:\tlearn: 0.4722960\ttotal: 3.57s\tremaining: 353ms\n",
      "91:\tlearn: 0.4713513\ttotal: 3.6s\tremaining: 313ms\n",
      "92:\tlearn: 0.4693906\ttotal: 3.65s\tremaining: 274ms\n",
      "93:\tlearn: 0.4689047\ttotal: 3.68s\tremaining: 235ms\n",
      "94:\tlearn: 0.4676217\ttotal: 3.72s\tremaining: 196ms\n",
      "95:\tlearn: 0.4671423\ttotal: 3.76s\tremaining: 157ms\n",
      "96:\tlearn: 0.4661639\ttotal: 3.8s\tremaining: 117ms\n",
      "97:\tlearn: 0.4643651\ttotal: 3.84s\tremaining: 78.4ms\n",
      "98:\tlearn: 0.4635956\ttotal: 3.89s\tremaining: 39.3ms\n",
      "99:\tlearn: 0.4627888\ttotal: 3.93s\tremaining: 0us\n",
      "0:\tlearn: 1.9740091\ttotal: 43.2ms\tremaining: 4.28s\n",
      "1:\tlearn: 1.5796705\ttotal: 82ms\tremaining: 4.02s\n",
      "2:\tlearn: 1.4104517\ttotal: 116ms\tremaining: 3.76s\n",
      "3:\tlearn: 1.2653408\ttotal: 149ms\tremaining: 3.58s\n",
      "4:\tlearn: 1.1855630\ttotal: 189ms\tremaining: 3.58s\n",
      "5:\tlearn: 1.0800257\ttotal: 231ms\tremaining: 3.62s\n",
      "6:\tlearn: 1.0240466\ttotal: 272ms\tremaining: 3.61s\n",
      "7:\tlearn: 0.9678568\ttotal: 311ms\tremaining: 3.58s\n",
      "8:\tlearn: 0.9332587\ttotal: 357ms\tremaining: 3.61s\n",
      "9:\tlearn: 0.9047029\ttotal: 400ms\tremaining: 3.6s\n",
      "10:\tlearn: 0.8776080\ttotal: 436ms\tremaining: 3.53s\n",
      "11:\tlearn: 0.8403938\ttotal: 480ms\tremaining: 3.52s\n",
      "12:\tlearn: 0.8200677\ttotal: 526ms\tremaining: 3.52s\n",
      "13:\tlearn: 0.7974067\ttotal: 570ms\tremaining: 3.5s\n",
      "14:\tlearn: 0.7796228\ttotal: 604ms\tremaining: 3.42s\n",
      "15:\tlearn: 0.7750726\ttotal: 642ms\tremaining: 3.37s\n",
      "16:\tlearn: 0.7436266\ttotal: 689ms\tremaining: 3.36s\n",
      "17:\tlearn: 0.7245391\ttotal: 744ms\tremaining: 3.39s\n",
      "18:\tlearn: 0.7139764\ttotal: 786ms\tremaining: 3.35s\n",
      "19:\tlearn: 0.7020607\ttotal: 833ms\tremaining: 3.33s\n",
      "20:\tlearn: 0.6932765\ttotal: 868ms\tremaining: 3.26s\n",
      "21:\tlearn: 0.6818193\ttotal: 917ms\tremaining: 3.25s\n",
      "22:\tlearn: 0.6673020\ttotal: 952ms\tremaining: 3.19s\n",
      "23:\tlearn: 0.6606854\ttotal: 985ms\tremaining: 3.12s\n",
      "24:\tlearn: 0.6510309\ttotal: 1.03s\tremaining: 3.09s\n",
      "25:\tlearn: 0.6468226\ttotal: 1.06s\tremaining: 3.03s\n",
      "26:\tlearn: 0.6422220\ttotal: 1.1s\tremaining: 2.97s\n",
      "27:\tlearn: 0.6346341\ttotal: 1.13s\tremaining: 2.91s\n",
      "28:\tlearn: 0.6313354\ttotal: 1.16s\tremaining: 2.85s\n",
      "29:\tlearn: 0.6231194\ttotal: 1.21s\tremaining: 2.81s\n",
      "30:\tlearn: 0.6126287\ttotal: 1.25s\tremaining: 2.78s\n",
      "31:\tlearn: 0.6072379\ttotal: 1.29s\tremaining: 2.74s\n",
      "32:\tlearn: 0.6029206\ttotal: 1.33s\tremaining: 2.7s\n",
      "33:\tlearn: 0.6001159\ttotal: 1.36s\tremaining: 2.65s\n",
      "34:\tlearn: 0.5917683\ttotal: 1.41s\tremaining: 2.62s\n",
      "35:\tlearn: 0.5894889\ttotal: 1.45s\tremaining: 2.57s\n",
      "36:\tlearn: 0.5860175\ttotal: 1.49s\tremaining: 2.54s\n",
      "37:\tlearn: 0.5807961\ttotal: 1.53s\tremaining: 2.5s\n",
      "38:\tlearn: 0.5779734\ttotal: 1.57s\tremaining: 2.45s\n",
      "39:\tlearn: 0.5737482\ttotal: 1.62s\tremaining: 2.42s\n",
      "40:\tlearn: 0.5702743\ttotal: 1.66s\tremaining: 2.38s\n",
      "41:\tlearn: 0.5689355\ttotal: 1.69s\tremaining: 2.33s\n",
      "42:\tlearn: 0.5671406\ttotal: 1.73s\tremaining: 2.29s\n",
      "43:\tlearn: 0.5639991\ttotal: 1.76s\tremaining: 2.25s\n",
      "44:\tlearn: 0.5630879\ttotal: 1.8s\tremaining: 2.2s\n",
      "45:\tlearn: 0.5588995\ttotal: 1.83s\tremaining: 2.15s\n",
      "46:\tlearn: 0.5567358\ttotal: 1.86s\tremaining: 2.1s\n",
      "47:\tlearn: 0.5539073\ttotal: 1.91s\tremaining: 2.06s\n",
      "48:\tlearn: 0.5488129\ttotal: 1.95s\tremaining: 2.02s\n",
      "49:\tlearn: 0.5475431\ttotal: 1.98s\tremaining: 1.98s\n",
      "50:\tlearn: 0.5456751\ttotal: 2.02s\tremaining: 1.94s\n",
      "51:\tlearn: 0.5434263\ttotal: 2.07s\tremaining: 1.91s\n",
      "52:\tlearn: 0.5359980\ttotal: 2.11s\tremaining: 1.87s\n",
      "53:\tlearn: 0.5331816\ttotal: 2.14s\tremaining: 1.82s\n",
      "54:\tlearn: 0.5313094\ttotal: 2.18s\tremaining: 1.78s\n",
      "55:\tlearn: 0.5302576\ttotal: 2.21s\tremaining: 1.74s\n",
      "56:\tlearn: 0.5272983\ttotal: 2.26s\tremaining: 1.7s\n",
      "57:\tlearn: 0.5254131\ttotal: 2.29s\tremaining: 1.66s\n",
      "58:\tlearn: 0.5241064\ttotal: 2.33s\tremaining: 1.62s\n",
      "59:\tlearn: 0.5224020\ttotal: 2.36s\tremaining: 1.57s\n",
      "60:\tlearn: 0.5178685\ttotal: 2.39s\tremaining: 1.53s\n",
      "61:\tlearn: 0.5171182\ttotal: 2.43s\tremaining: 1.49s\n",
      "62:\tlearn: 0.5145148\ttotal: 2.46s\tremaining: 1.44s\n",
      "63:\tlearn: 0.5123234\ttotal: 2.5s\tremaining: 1.41s\n",
      "64:\tlearn: 0.5091653\ttotal: 2.54s\tremaining: 1.37s\n",
      "65:\tlearn: 0.5073812\ttotal: 2.59s\tremaining: 1.33s\n",
      "66:\tlearn: 0.5052297\ttotal: 2.63s\tremaining: 1.3s\n",
      "67:\tlearn: 0.5045479\ttotal: 2.67s\tremaining: 1.25s\n",
      "68:\tlearn: 0.5026964\ttotal: 2.7s\tremaining: 1.21s\n",
      "69:\tlearn: 0.5008030\ttotal: 2.74s\tremaining: 1.18s\n",
      "70:\tlearn: 0.4998434\ttotal: 2.79s\tremaining: 1.14s\n",
      "71:\tlearn: 0.4982610\ttotal: 2.83s\tremaining: 1.1s\n",
      "72:\tlearn: 0.4943911\ttotal: 2.88s\tremaining: 1.06s\n",
      "73:\tlearn: 0.4920271\ttotal: 2.92s\tremaining: 1.03s\n",
      "74:\tlearn: 0.4898332\ttotal: 2.96s\tremaining: 986ms\n",
      "75:\tlearn: 0.4884220\ttotal: 2.99s\tremaining: 944ms\n",
      "76:\tlearn: 0.4863920\ttotal: 3.03s\tremaining: 906ms\n",
      "77:\tlearn: 0.4853563\ttotal: 3.08s\tremaining: 867ms\n",
      "78:\tlearn: 0.4843221\ttotal: 3.11s\tremaining: 826ms\n",
      "79:\tlearn: 0.4829012\ttotal: 3.15s\tremaining: 788ms\n",
      "80:\tlearn: 0.4807803\ttotal: 3.19s\tremaining: 748ms\n",
      "81:\tlearn: 0.4793121\ttotal: 3.23s\tremaining: 709ms\n",
      "82:\tlearn: 0.4754049\ttotal: 3.27s\tremaining: 670ms\n",
      "83:\tlearn: 0.4733308\ttotal: 3.31s\tremaining: 630ms\n",
      "84:\tlearn: 0.4717318\ttotal: 3.34s\tremaining: 590ms\n",
      "85:\tlearn: 0.4694423\ttotal: 3.39s\tremaining: 551ms\n",
      "86:\tlearn: 0.4678781\ttotal: 3.43s\tremaining: 513ms\n",
      "87:\tlearn: 0.4670948\ttotal: 3.46s\tremaining: 473ms\n",
      "88:\tlearn: 0.4657852\ttotal: 3.5s\tremaining: 432ms\n",
      "89:\tlearn: 0.4646444\ttotal: 3.54s\tremaining: 393ms\n",
      "90:\tlearn: 0.4632721\ttotal: 3.58s\tremaining: 354ms\n",
      "91:\tlearn: 0.4618484\ttotal: 3.61s\tremaining: 314ms\n",
      "92:\tlearn: 0.4597662\ttotal: 3.65s\tremaining: 275ms\n",
      "93:\tlearn: 0.4592566\ttotal: 3.68s\tremaining: 235ms\n",
      "94:\tlearn: 0.4582192\ttotal: 3.73s\tremaining: 196ms\n",
      "95:\tlearn: 0.4569324\ttotal: 3.77s\tremaining: 157ms\n",
      "96:\tlearn: 0.4557487\ttotal: 3.81s\tremaining: 118ms\n",
      "97:\tlearn: 0.4554183\ttotal: 3.84s\tremaining: 78.3ms\n",
      "98:\tlearn: 0.4547349\ttotal: 3.87s\tremaining: 39.1ms\n",
      "99:\tlearn: 0.4541925\ttotal: 3.9s\tremaining: 0us\n",
      "0:\tlearn: 2.2887424\ttotal: 42.7ms\tremaining: 8.5s\n",
      "1:\tlearn: 2.2751298\ttotal: 80.3ms\tremaining: 7.95s\n",
      "2:\tlearn: 2.2622099\ttotal: 117ms\tremaining: 7.71s\n",
      "3:\tlearn: 2.2490670\ttotal: 155ms\tremaining: 7.62s\n",
      "4:\tlearn: 2.2363366\ttotal: 194ms\tremaining: 7.56s\n",
      "5:\tlearn: 2.2245693\ttotal: 231ms\tremaining: 7.48s\n",
      "6:\tlearn: 2.2127840\ttotal: 271ms\tremaining: 7.48s\n",
      "7:\tlearn: 2.2008081\ttotal: 312ms\tremaining: 7.48s\n",
      "8:\tlearn: 2.1901309\ttotal: 349ms\tremaining: 7.41s\n",
      "9:\tlearn: 2.1801158\ttotal: 387ms\tremaining: 7.35s\n",
      "10:\tlearn: 2.1693255\ttotal: 427ms\tremaining: 7.34s\n",
      "11:\tlearn: 2.1585238\ttotal: 468ms\tremaining: 7.33s\n",
      "12:\tlearn: 2.1485154\ttotal: 506ms\tremaining: 7.28s\n",
      "13:\tlearn: 2.1385680\ttotal: 545ms\tremaining: 7.24s\n",
      "14:\tlearn: 2.1285154\ttotal: 584ms\tremaining: 7.21s\n",
      "15:\tlearn: 2.1193603\ttotal: 624ms\tremaining: 7.17s\n",
      "16:\tlearn: 2.1090073\ttotal: 664ms\tremaining: 7.14s\n",
      "17:\tlearn: 2.0993106\ttotal: 706ms\tremaining: 7.13s\n",
      "18:\tlearn: 2.0902894\ttotal: 749ms\tremaining: 7.13s\n",
      "19:\tlearn: 2.0817092\ttotal: 791ms\tremaining: 7.12s\n",
      "20:\tlearn: 2.0723877\ttotal: 835ms\tremaining: 7.12s\n",
      "21:\tlearn: 2.0628424\ttotal: 875ms\tremaining: 7.08s\n",
      "22:\tlearn: 2.0536874\ttotal: 915ms\tremaining: 7.04s\n",
      "23:\tlearn: 2.0449460\ttotal: 954ms\tremaining: 7s\n",
      "24:\tlearn: 2.0361634\ttotal: 994ms\tremaining: 6.96s\n",
      "25:\tlearn: 2.0278805\ttotal: 1.03s\tremaining: 6.91s\n",
      "26:\tlearn: 2.0194461\ttotal: 1.07s\tremaining: 6.87s\n",
      "27:\tlearn: 2.0113292\ttotal: 1.11s\tremaining: 6.84s\n",
      "28:\tlearn: 2.0043285\ttotal: 1.15s\tremaining: 6.79s\n",
      "29:\tlearn: 1.9972894\ttotal: 1.19s\tremaining: 6.75s\n",
      "30:\tlearn: 1.9890015\ttotal: 1.23s\tremaining: 6.73s\n",
      "31:\tlearn: 1.9814869\ttotal: 1.27s\tremaining: 6.68s\n",
      "32:\tlearn: 1.9734434\ttotal: 1.31s\tremaining: 6.65s\n",
      "33:\tlearn: 1.9657063\ttotal: 1.35s\tremaining: 6.61s\n",
      "34:\tlearn: 1.9582717\ttotal: 1.39s\tremaining: 6.57s\n",
      "35:\tlearn: 1.9516144\ttotal: 1.43s\tremaining: 6.52s\n",
      "36:\tlearn: 1.9444247\ttotal: 1.47s\tremaining: 6.48s\n",
      "37:\tlearn: 1.9380457\ttotal: 1.51s\tremaining: 6.44s\n",
      "38:\tlearn: 1.9309670\ttotal: 1.55s\tremaining: 6.4s\n",
      "39:\tlearn: 1.9238867\ttotal: 1.59s\tremaining: 6.36s\n",
      "40:\tlearn: 1.9165813\ttotal: 1.64s\tremaining: 6.34s\n",
      "41:\tlearn: 1.9095740\ttotal: 1.69s\tremaining: 6.34s\n",
      "42:\tlearn: 1.9038248\ttotal: 1.72s\tremaining: 6.28s\n",
      "43:\tlearn: 1.8973022\ttotal: 1.76s\tremaining: 6.24s\n",
      "44:\tlearn: 1.8915187\ttotal: 1.8s\tremaining: 6.21s\n",
      "45:\tlearn: 1.8850661\ttotal: 1.84s\tremaining: 6.17s\n",
      "46:\tlearn: 1.8786885\ttotal: 1.88s\tremaining: 6.12s\n",
      "47:\tlearn: 1.8731814\ttotal: 1.92s\tremaining: 6.07s\n",
      "48:\tlearn: 1.8673253\ttotal: 1.96s\tremaining: 6.03s\n",
      "49:\tlearn: 1.8623094\ttotal: 1.99s\tremaining: 5.97s\n",
      "50:\tlearn: 1.8569124\ttotal: 2.03s\tremaining: 5.92s\n",
      "51:\tlearn: 1.8509751\ttotal: 2.07s\tremaining: 5.88s\n",
      "52:\tlearn: 1.8444884\ttotal: 2.1s\tremaining: 5.83s\n",
      "53:\tlearn: 1.8387943\ttotal: 2.14s\tremaining: 5.79s\n",
      "54:\tlearn: 1.8326855\ttotal: 2.18s\tremaining: 5.76s\n",
      "55:\tlearn: 1.8267279\ttotal: 2.22s\tremaining: 5.72s\n",
      "56:\tlearn: 1.8206892\ttotal: 2.26s\tremaining: 5.67s\n",
      "57:\tlearn: 1.8150449\ttotal: 2.3s\tremaining: 5.63s\n",
      "58:\tlearn: 1.8092092\ttotal: 2.34s\tremaining: 5.6s\n",
      "59:\tlearn: 1.8046725\ttotal: 2.38s\tremaining: 5.55s\n",
      "60:\tlearn: 1.7991361\ttotal: 2.42s\tremaining: 5.51s\n",
      "61:\tlearn: 1.7940032\ttotal: 2.45s\tremaining: 5.46s\n",
      "62:\tlearn: 1.7890862\ttotal: 2.49s\tremaining: 5.41s\n",
      "63:\tlearn: 1.7830559\ttotal: 2.52s\tremaining: 5.37s\n",
      "64:\tlearn: 1.7770346\ttotal: 2.57s\tremaining: 5.33s\n",
      "65:\tlearn: 1.7723723\ttotal: 2.6s\tremaining: 5.29s\n",
      "66:\tlearn: 1.7671987\ttotal: 2.64s\tremaining: 5.25s\n",
      "67:\tlearn: 1.7632785\ttotal: 2.68s\tremaining: 5.2s\n",
      "68:\tlearn: 1.7585778\ttotal: 2.72s\tremaining: 5.16s\n",
      "69:\tlearn: 1.7535022\ttotal: 2.75s\tremaining: 5.12s\n",
      "70:\tlearn: 1.7490805\ttotal: 2.79s\tremaining: 5.07s\n",
      "71:\tlearn: 1.7434536\ttotal: 2.83s\tremaining: 5.03s\n",
      "72:\tlearn: 1.7396763\ttotal: 2.87s\tremaining: 4.99s\n",
      "73:\tlearn: 1.7340763\ttotal: 2.91s\tremaining: 4.95s\n",
      "74:\tlearn: 1.7288672\ttotal: 2.95s\tremaining: 4.91s\n",
      "75:\tlearn: 1.7240401\ttotal: 2.98s\tremaining: 4.87s\n",
      "76:\tlearn: 1.7189574\ttotal: 3.02s\tremaining: 4.83s\n",
      "77:\tlearn: 1.7140687\ttotal: 3.06s\tremaining: 4.79s\n",
      "78:\tlearn: 1.7092807\ttotal: 3.11s\tremaining: 4.76s\n",
      "79:\tlearn: 1.7056039\ttotal: 3.14s\tremaining: 4.71s\n",
      "80:\tlearn: 1.7013964\ttotal: 3.18s\tremaining: 4.68s\n",
      "81:\tlearn: 1.6967745\ttotal: 3.22s\tremaining: 4.63s\n",
      "82:\tlearn: 1.6922210\ttotal: 3.26s\tremaining: 4.6s\n",
      "83:\tlearn: 1.6873883\ttotal: 3.3s\tremaining: 4.56s\n",
      "84:\tlearn: 1.6826793\ttotal: 3.34s\tremaining: 4.52s\n",
      "85:\tlearn: 1.6789364\ttotal: 3.39s\tremaining: 4.49s\n",
      "86:\tlearn: 1.6753551\ttotal: 3.42s\tremaining: 4.45s\n",
      "87:\tlearn: 1.6707249\ttotal: 3.46s\tremaining: 4.41s\n",
      "88:\tlearn: 1.6660465\ttotal: 3.51s\tremaining: 4.37s\n",
      "89:\tlearn: 1.6617257\ttotal: 3.54s\tremaining: 4.33s\n",
      "90:\tlearn: 1.6576780\ttotal: 3.58s\tremaining: 4.29s\n",
      "91:\tlearn: 1.6536925\ttotal: 3.62s\tremaining: 4.24s\n",
      "92:\tlearn: 1.6495228\ttotal: 3.65s\tremaining: 4.2s\n",
      "93:\tlearn: 1.6448501\ttotal: 3.69s\tremaining: 4.17s\n",
      "94:\tlearn: 1.6417529\ttotal: 3.73s\tremaining: 4.12s\n",
      "95:\tlearn: 1.6377168\ttotal: 3.77s\tremaining: 4.08s\n",
      "96:\tlearn: 1.6346604\ttotal: 3.81s\tremaining: 4.04s\n",
      "97:\tlearn: 1.6314673\ttotal: 3.84s\tremaining: 4s\n",
      "98:\tlearn: 1.6276022\ttotal: 3.88s\tremaining: 3.96s\n",
      "99:\tlearn: 1.6231584\ttotal: 3.92s\tremaining: 3.92s\n",
      "100:\tlearn: 1.6194367\ttotal: 3.96s\tremaining: 3.88s\n",
      "101:\tlearn: 1.6155793\ttotal: 3.99s\tremaining: 3.83s\n",
      "102:\tlearn: 1.6117447\ttotal: 4.03s\tremaining: 3.79s\n",
      "103:\tlearn: 1.6076931\ttotal: 4.07s\tremaining: 3.75s\n",
      "104:\tlearn: 1.6045129\ttotal: 4.1s\tremaining: 3.71s\n",
      "105:\tlearn: 1.6015977\ttotal: 4.14s\tremaining: 3.67s\n",
      "106:\tlearn: 1.5975174\ttotal: 4.18s\tremaining: 3.63s\n",
      "107:\tlearn: 1.5929717\ttotal: 4.22s\tremaining: 3.6s\n",
      "108:\tlearn: 1.5898101\ttotal: 4.26s\tremaining: 3.56s\n",
      "109:\tlearn: 1.5863024\ttotal: 4.3s\tremaining: 3.52s\n",
      "110:\tlearn: 1.5818842\ttotal: 4.34s\tremaining: 3.48s\n",
      "111:\tlearn: 1.5788314\ttotal: 4.38s\tremaining: 3.44s\n",
      "112:\tlearn: 1.5754896\ttotal: 4.41s\tremaining: 3.4s\n",
      "113:\tlearn: 1.5718603\ttotal: 4.45s\tremaining: 3.36s\n",
      "114:\tlearn: 1.5683018\ttotal: 4.49s\tremaining: 3.32s\n",
      "115:\tlearn: 1.5645126\ttotal: 4.53s\tremaining: 3.28s\n",
      "116:\tlearn: 1.5619496\ttotal: 4.56s\tremaining: 3.24s\n",
      "117:\tlearn: 1.5581971\ttotal: 4.6s\tremaining: 3.2s\n",
      "118:\tlearn: 1.5553830\ttotal: 4.64s\tremaining: 3.16s\n",
      "119:\tlearn: 1.5520151\ttotal: 4.68s\tremaining: 3.12s\n",
      "120:\tlearn: 1.5495287\ttotal: 4.71s\tremaining: 3.08s\n",
      "121:\tlearn: 1.5465945\ttotal: 4.75s\tremaining: 3.04s\n",
      "122:\tlearn: 1.5434726\ttotal: 4.78s\tremaining: 2.99s\n",
      "123:\tlearn: 1.5394023\ttotal: 4.82s\tremaining: 2.96s\n",
      "124:\tlearn: 1.5359223\ttotal: 4.87s\tremaining: 2.92s\n",
      "125:\tlearn: 1.5323537\ttotal: 4.9s\tremaining: 2.88s\n",
      "126:\tlearn: 1.5293490\ttotal: 4.93s\tremaining: 2.84s\n",
      "127:\tlearn: 1.5267467\ttotal: 4.97s\tremaining: 2.79s\n",
      "128:\tlearn: 1.5240230\ttotal: 5.01s\tremaining: 2.75s\n",
      "129:\tlearn: 1.5205041\ttotal: 5.05s\tremaining: 2.72s\n",
      "130:\tlearn: 1.5161060\ttotal: 5.09s\tremaining: 2.68s\n",
      "131:\tlearn: 1.5134378\ttotal: 5.13s\tremaining: 2.64s\n",
      "132:\tlearn: 1.5108955\ttotal: 5.16s\tremaining: 2.6s\n",
      "133:\tlearn: 1.5073942\ttotal: 5.2s\tremaining: 2.56s\n",
      "134:\tlearn: 1.5045531\ttotal: 5.24s\tremaining: 2.52s\n",
      "135:\tlearn: 1.5021005\ttotal: 5.28s\tremaining: 2.48s\n",
      "136:\tlearn: 1.4998683\ttotal: 5.31s\tremaining: 2.44s\n",
      "137:\tlearn: 1.4961700\ttotal: 5.35s\tremaining: 2.4s\n",
      "138:\tlearn: 1.4932172\ttotal: 5.39s\tremaining: 2.36s\n",
      "139:\tlearn: 1.4900052\ttotal: 5.42s\tremaining: 2.32s\n",
      "140:\tlearn: 1.4871570\ttotal: 5.46s\tremaining: 2.29s\n",
      "141:\tlearn: 1.4839002\ttotal: 5.5s\tremaining: 2.25s\n",
      "142:\tlearn: 1.4802270\ttotal: 5.54s\tremaining: 2.21s\n",
      "143:\tlearn: 1.4775317\ttotal: 5.58s\tremaining: 2.17s\n",
      "144:\tlearn: 1.4751271\ttotal: 5.62s\tremaining: 2.13s\n",
      "145:\tlearn: 1.4724354\ttotal: 5.65s\tremaining: 2.09s\n",
      "146:\tlearn: 1.4702350\ttotal: 5.68s\tremaining: 2.05s\n",
      "147:\tlearn: 1.4680922\ttotal: 5.72s\tremaining: 2.01s\n",
      "148:\tlearn: 1.4650357\ttotal: 5.76s\tremaining: 1.97s\n",
      "149:\tlearn: 1.4623199\ttotal: 5.8s\tremaining: 1.93s\n",
      "150:\tlearn: 1.4602433\ttotal: 5.83s\tremaining: 1.89s\n",
      "151:\tlearn: 1.4578330\ttotal: 5.87s\tremaining: 1.85s\n",
      "152:\tlearn: 1.4543978\ttotal: 5.91s\tremaining: 1.81s\n",
      "153:\tlearn: 1.4516510\ttotal: 5.95s\tremaining: 1.78s\n",
      "154:\tlearn: 1.4488010\ttotal: 5.98s\tremaining: 1.74s\n",
      "155:\tlearn: 1.4458317\ttotal: 6.02s\tremaining: 1.7s\n",
      "156:\tlearn: 1.4428404\ttotal: 6.07s\tremaining: 1.66s\n",
      "157:\tlearn: 1.4408700\ttotal: 6.1s\tremaining: 1.62s\n",
      "158:\tlearn: 1.4381029\ttotal: 6.14s\tremaining: 1.58s\n",
      "159:\tlearn: 1.4359168\ttotal: 6.18s\tremaining: 1.54s\n",
      "160:\tlearn: 1.4339347\ttotal: 6.21s\tremaining: 1.5s\n",
      "161:\tlearn: 1.4302194\ttotal: 6.25s\tremaining: 1.47s\n",
      "162:\tlearn: 1.4276528\ttotal: 6.29s\tremaining: 1.43s\n",
      "163:\tlearn: 1.4261312\ttotal: 6.33s\tremaining: 1.39s\n",
      "164:\tlearn: 1.4233489\ttotal: 6.37s\tremaining: 1.35s\n",
      "165:\tlearn: 1.4209589\ttotal: 6.4s\tremaining: 1.31s\n",
      "166:\tlearn: 1.4173271\ttotal: 6.45s\tremaining: 1.27s\n",
      "167:\tlearn: 1.4154786\ttotal: 6.48s\tremaining: 1.23s\n",
      "168:\tlearn: 1.4127258\ttotal: 6.52s\tremaining: 1.2s\n",
      "169:\tlearn: 1.4107277\ttotal: 6.55s\tremaining: 1.16s\n",
      "170:\tlearn: 1.4090617\ttotal: 6.59s\tremaining: 1.12s\n",
      "171:\tlearn: 1.4068004\ttotal: 6.62s\tremaining: 1.08s\n",
      "172:\tlearn: 1.4048443\ttotal: 6.66s\tremaining: 1.04s\n",
      "173:\tlearn: 1.4028722\ttotal: 6.7s\tremaining: 1s\n",
      "174:\tlearn: 1.3993411\ttotal: 6.74s\tremaining: 963ms\n",
      "175:\tlearn: 1.3977523\ttotal: 6.77s\tremaining: 924ms\n",
      "176:\tlearn: 1.3953163\ttotal: 6.81s\tremaining: 885ms\n",
      "177:\tlearn: 1.3926267\ttotal: 6.85s\tremaining: 847ms\n",
      "178:\tlearn: 1.3896180\ttotal: 6.89s\tremaining: 809ms\n",
      "179:\tlearn: 1.3871088\ttotal: 6.93s\tremaining: 770ms\n",
      "180:\tlearn: 1.3837615\ttotal: 6.97s\tremaining: 732ms\n",
      "181:\tlearn: 1.3807292\ttotal: 7.02s\tremaining: 694ms\n",
      "182:\tlearn: 1.3784982\ttotal: 7.06s\tremaining: 656ms\n",
      "183:\tlearn: 1.3767979\ttotal: 7.09s\tremaining: 617ms\n",
      "184:\tlearn: 1.3735147\ttotal: 7.13s\tremaining: 578ms\n",
      "185:\tlearn: 1.3703797\ttotal: 7.17s\tremaining: 540ms\n",
      "186:\tlearn: 1.3684187\ttotal: 7.21s\tremaining: 502ms\n",
      "187:\tlearn: 1.3663422\ttotal: 7.25s\tremaining: 463ms\n",
      "188:\tlearn: 1.3639942\ttotal: 7.29s\tremaining: 424ms\n",
      "189:\tlearn: 1.3623572\ttotal: 7.32s\tremaining: 385ms\n",
      "190:\tlearn: 1.3601967\ttotal: 7.36s\tremaining: 347ms\n",
      "191:\tlearn: 1.3579682\ttotal: 7.39s\tremaining: 308ms\n",
      "192:\tlearn: 1.3554199\ttotal: 7.43s\tremaining: 270ms\n",
      "193:\tlearn: 1.3524622\ttotal: 7.48s\tremaining: 231ms\n",
      "194:\tlearn: 1.3504127\ttotal: 7.52s\tremaining: 193ms\n",
      "195:\tlearn: 1.3482554\ttotal: 7.56s\tremaining: 154ms\n",
      "196:\tlearn: 1.3458583\ttotal: 7.59s\tremaining: 116ms\n",
      "197:\tlearn: 1.3434908\ttotal: 7.64s\tremaining: 77.1ms\n",
      "198:\tlearn: 1.3418674\ttotal: 7.67s\tremaining: 38.5ms\n",
      "199:\tlearn: 1.3391635\ttotal: 7.71s\tremaining: 0us\n",
      "0:\tlearn: 2.2883568\ttotal: 43.2ms\tremaining: 8.6s\n",
      "1:\tlearn: 2.2747754\ttotal: 81.7ms\tremaining: 8.09s\n",
      "2:\tlearn: 2.2619825\ttotal: 121ms\tremaining: 7.96s\n",
      "3:\tlearn: 2.2487982\ttotal: 160ms\tremaining: 7.86s\n",
      "4:\tlearn: 2.2360449\ttotal: 200ms\tremaining: 7.82s\n",
      "5:\tlearn: 2.2243268\ttotal: 241ms\tremaining: 7.78s\n",
      "6:\tlearn: 2.2125144\ttotal: 281ms\tremaining: 7.75s\n",
      "7:\tlearn: 2.2005244\ttotal: 322ms\tremaining: 7.72s\n",
      "8:\tlearn: 2.1899120\ttotal: 361ms\tremaining: 7.66s\n",
      "9:\tlearn: 2.1791836\ttotal: 400ms\tremaining: 7.59s\n",
      "10:\tlearn: 2.1685163\ttotal: 441ms\tremaining: 7.58s\n",
      "11:\tlearn: 2.1578298\ttotal: 482ms\tremaining: 7.56s\n",
      "12:\tlearn: 2.1476989\ttotal: 522ms\tremaining: 7.51s\n",
      "13:\tlearn: 2.1372152\ttotal: 562ms\tremaining: 7.46s\n",
      "14:\tlearn: 2.1272772\ttotal: 603ms\tremaining: 7.43s\n",
      "15:\tlearn: 2.1179040\ttotal: 643ms\tremaining: 7.39s\n",
      "16:\tlearn: 2.1077481\ttotal: 684ms\tremaining: 7.36s\n",
      "17:\tlearn: 2.0990454\ttotal: 724ms\tremaining: 7.32s\n",
      "18:\tlearn: 2.0900974\ttotal: 764ms\tremaining: 7.28s\n",
      "19:\tlearn: 2.0815990\ttotal: 805ms\tremaining: 7.24s\n",
      "20:\tlearn: 2.0720929\ttotal: 849ms\tremaining: 7.24s\n",
      "21:\tlearn: 2.0637206\ttotal: 889ms\tremaining: 7.2s\n",
      "22:\tlearn: 2.0545218\ttotal: 930ms\tremaining: 7.15s\n",
      "23:\tlearn: 2.0458339\ttotal: 971ms\tremaining: 7.12s\n",
      "24:\tlearn: 2.0369527\ttotal: 1.01s\tremaining: 7.08s\n",
      "25:\tlearn: 2.0287007\ttotal: 1.05s\tremaining: 7.04s\n",
      "26:\tlearn: 2.0201690\ttotal: 1.09s\tremaining: 7s\n",
      "27:\tlearn: 2.0120907\ttotal: 1.14s\tremaining: 7s\n",
      "28:\tlearn: 2.0040010\ttotal: 1.18s\tremaining: 6.95s\n",
      "29:\tlearn: 1.9970424\ttotal: 1.22s\tremaining: 6.9s\n",
      "30:\tlearn: 1.9886463\ttotal: 1.26s\tremaining: 6.88s\n",
      "31:\tlearn: 1.9812185\ttotal: 1.3s\tremaining: 6.84s\n",
      "32:\tlearn: 1.9731577\ttotal: 1.34s\tremaining: 6.81s\n",
      "33:\tlearn: 1.9654371\ttotal: 1.39s\tremaining: 6.77s\n",
      "34:\tlearn: 1.9575341\ttotal: 1.43s\tremaining: 6.74s\n",
      "35:\tlearn: 1.9509424\ttotal: 1.47s\tremaining: 6.69s\n",
      "36:\tlearn: 1.9438229\ttotal: 1.51s\tremaining: 6.64s\n",
      "37:\tlearn: 1.9371619\ttotal: 1.55s\tremaining: 6.6s\n",
      "38:\tlearn: 1.9306511\ttotal: 1.59s\tremaining: 6.56s\n",
      "39:\tlearn: 1.9235179\ttotal: 1.63s\tremaining: 6.52s\n",
      "40:\tlearn: 1.9162616\ttotal: 1.67s\tremaining: 6.49s\n",
      "41:\tlearn: 1.9100001\ttotal: 1.71s\tremaining: 6.45s\n",
      "42:\tlearn: 1.9044832\ttotal: 1.75s\tremaining: 6.41s\n",
      "43:\tlearn: 1.8976842\ttotal: 1.8s\tremaining: 6.37s\n",
      "44:\tlearn: 1.8919704\ttotal: 1.84s\tremaining: 6.33s\n",
      "45:\tlearn: 1.8855314\ttotal: 1.88s\tremaining: 6.29s\n",
      "46:\tlearn: 1.8790615\ttotal: 1.92s\tremaining: 6.23s\n",
      "47:\tlearn: 1.8736444\ttotal: 1.95s\tremaining: 6.19s\n",
      "48:\tlearn: 1.8677758\ttotal: 1.99s\tremaining: 6.15s\n",
      "49:\tlearn: 1.8627166\ttotal: 2.03s\tremaining: 6.1s\n",
      "50:\tlearn: 1.8559738\ttotal: 2.07s\tremaining: 6.04s\n",
      "51:\tlearn: 1.8496595\ttotal: 2.11s\tremaining: 6.01s\n",
      "52:\tlearn: 1.8434258\ttotal: 2.15s\tremaining: 5.96s\n",
      "53:\tlearn: 1.8376254\ttotal: 2.19s\tremaining: 5.92s\n",
      "54:\tlearn: 1.8314644\ttotal: 2.23s\tremaining: 5.88s\n",
      "55:\tlearn: 1.8254697\ttotal: 2.27s\tremaining: 5.84s\n",
      "56:\tlearn: 1.8193651\ttotal: 2.31s\tremaining: 5.79s\n",
      "57:\tlearn: 1.8137364\ttotal: 2.35s\tremaining: 5.75s\n",
      "58:\tlearn: 1.8078565\ttotal: 2.39s\tremaining: 5.71s\n",
      "59:\tlearn: 1.8019821\ttotal: 2.43s\tremaining: 5.67s\n",
      "60:\tlearn: 1.7965660\ttotal: 2.47s\tremaining: 5.63s\n",
      "61:\tlearn: 1.7907141\ttotal: 2.51s\tremaining: 5.58s\n",
      "62:\tlearn: 1.7855859\ttotal: 2.54s\tremaining: 5.54s\n",
      "63:\tlearn: 1.7799102\ttotal: 2.58s\tremaining: 5.49s\n",
      "64:\tlearn: 1.7756051\ttotal: 2.62s\tremaining: 5.44s\n",
      "65:\tlearn: 1.7710129\ttotal: 2.66s\tremaining: 5.4s\n",
      "66:\tlearn: 1.7656354\ttotal: 2.7s\tremaining: 5.36s\n",
      "67:\tlearn: 1.7616947\ttotal: 2.74s\tremaining: 5.31s\n",
      "68:\tlearn: 1.7577983\ttotal: 2.77s\tremaining: 5.27s\n",
      "69:\tlearn: 1.7522770\ttotal: 2.81s\tremaining: 5.22s\n",
      "70:\tlearn: 1.7484252\ttotal: 2.85s\tremaining: 5.18s\n",
      "71:\tlearn: 1.7432529\ttotal: 2.89s\tremaining: 5.14s\n",
      "72:\tlearn: 1.7381677\ttotal: 2.93s\tremaining: 5.1s\n",
      "73:\tlearn: 1.7324872\ttotal: 2.97s\tremaining: 5.06s\n",
      "74:\tlearn: 1.7271781\ttotal: 3.01s\tremaining: 5.02s\n",
      "75:\tlearn: 1.7224984\ttotal: 3.05s\tremaining: 4.98s\n",
      "76:\tlearn: 1.7174174\ttotal: 3.09s\tremaining: 4.94s\n",
      "77:\tlearn: 1.7139526\ttotal: 3.13s\tremaining: 4.89s\n",
      "78:\tlearn: 1.7091120\ttotal: 3.17s\tremaining: 4.86s\n",
      "79:\tlearn: 1.7039990\ttotal: 3.21s\tremaining: 4.82s\n",
      "80:\tlearn: 1.6993294\ttotal: 3.25s\tremaining: 4.78s\n",
      "81:\tlearn: 1.6949323\ttotal: 3.29s\tremaining: 4.73s\n",
      "82:\tlearn: 1.6903159\ttotal: 3.33s\tremaining: 4.7s\n",
      "83:\tlearn: 1.6854478\ttotal: 3.37s\tremaining: 4.66s\n",
      "84:\tlearn: 1.6804759\ttotal: 3.42s\tremaining: 4.62s\n",
      "85:\tlearn: 1.6766145\ttotal: 3.46s\tremaining: 4.58s\n",
      "86:\tlearn: 1.6726585\ttotal: 3.5s\tremaining: 4.55s\n",
      "87:\tlearn: 1.6680002\ttotal: 3.54s\tremaining: 4.51s\n",
      "88:\tlearn: 1.6644529\ttotal: 3.58s\tremaining: 4.47s\n",
      "89:\tlearn: 1.6599897\ttotal: 3.62s\tremaining: 4.43s\n",
      "90:\tlearn: 1.6566804\ttotal: 3.66s\tremaining: 4.38s\n",
      "91:\tlearn: 1.6522433\ttotal: 3.7s\tremaining: 4.34s\n",
      "92:\tlearn: 1.6480631\ttotal: 3.74s\tremaining: 4.3s\n",
      "93:\tlearn: 1.6443999\ttotal: 3.78s\tremaining: 4.27s\n",
      "94:\tlearn: 1.6412985\ttotal: 3.82s\tremaining: 4.22s\n",
      "95:\tlearn: 1.6375063\ttotal: 3.86s\tremaining: 4.18s\n",
      "96:\tlearn: 1.6343855\ttotal: 3.9s\tremaining: 4.14s\n",
      "97:\tlearn: 1.6302815\ttotal: 3.94s\tremaining: 4.1s\n",
      "98:\tlearn: 1.6263276\ttotal: 3.98s\tremaining: 4.06s\n",
      "99:\tlearn: 1.6218665\ttotal: 4.02s\tremaining: 4.02s\n",
      "100:\tlearn: 1.6183941\ttotal: 4.06s\tremaining: 3.98s\n",
      "101:\tlearn: 1.6145655\ttotal: 4.1s\tremaining: 3.94s\n",
      "102:\tlearn: 1.6106932\ttotal: 4.15s\tremaining: 3.9s\n",
      "103:\tlearn: 1.6067621\ttotal: 4.2s\tremaining: 3.88s\n",
      "104:\tlearn: 1.6038223\ttotal: 4.24s\tremaining: 3.84s\n",
      "105:\tlearn: 1.6010093\ttotal: 4.28s\tremaining: 3.8s\n",
      "106:\tlearn: 1.5968999\ttotal: 4.33s\tremaining: 3.76s\n",
      "107:\tlearn: 1.5931426\ttotal: 4.37s\tremaining: 3.72s\n",
      "108:\tlearn: 1.5886763\ttotal: 4.42s\tremaining: 3.69s\n",
      "109:\tlearn: 1.5846565\ttotal: 4.46s\tremaining: 3.65s\n",
      "110:\tlearn: 1.5802582\ttotal: 4.5s\tremaining: 3.61s\n",
      "111:\tlearn: 1.5771651\ttotal: 4.54s\tremaining: 3.57s\n",
      "112:\tlearn: 1.5738040\ttotal: 4.58s\tremaining: 3.53s\n",
      "113:\tlearn: 1.5702057\ttotal: 4.62s\tremaining: 3.49s\n",
      "114:\tlearn: 1.5662354\ttotal: 4.67s\tremaining: 3.45s\n",
      "115:\tlearn: 1.5625353\ttotal: 4.7s\tremaining: 3.41s\n",
      "116:\tlearn: 1.5599196\ttotal: 4.74s\tremaining: 3.37s\n",
      "117:\tlearn: 1.5574381\ttotal: 4.78s\tremaining: 3.32s\n",
      "118:\tlearn: 1.5546198\ttotal: 4.82s\tremaining: 3.28s\n",
      "119:\tlearn: 1.5511223\ttotal: 4.86s\tremaining: 3.24s\n",
      "120:\tlearn: 1.5479283\ttotal: 4.9s\tremaining: 3.2s\n",
      "121:\tlearn: 1.5451711\ttotal: 4.93s\tremaining: 3.15s\n",
      "122:\tlearn: 1.5419353\ttotal: 4.98s\tremaining: 3.12s\n",
      "123:\tlearn: 1.5381498\ttotal: 5.03s\tremaining: 3.08s\n",
      "124:\tlearn: 1.5354255\ttotal: 5.06s\tremaining: 3.04s\n",
      "125:\tlearn: 1.5322244\ttotal: 5.12s\tremaining: 3.01s\n",
      "126:\tlearn: 1.5291455\ttotal: 5.25s\tremaining: 3.02s\n",
      "127:\tlearn: 1.5252632\ttotal: 5.3s\tremaining: 2.98s\n",
      "128:\tlearn: 1.5217665\ttotal: 5.35s\tremaining: 2.94s\n",
      "129:\tlearn: 1.5185928\ttotal: 5.39s\tremaining: 2.9s\n",
      "130:\tlearn: 1.5141452\ttotal: 5.45s\tremaining: 2.87s\n",
      "131:\tlearn: 1.5111886\ttotal: 5.5s\tremaining: 2.83s\n",
      "132:\tlearn: 1.5086299\ttotal: 5.54s\tremaining: 2.79s\n",
      "133:\tlearn: 1.5051073\ttotal: 5.58s\tremaining: 2.75s\n",
      "134:\tlearn: 1.5024438\ttotal: 5.63s\tremaining: 2.71s\n",
      "135:\tlearn: 1.5000202\ttotal: 5.67s\tremaining: 2.67s\n",
      "136:\tlearn: 1.4965229\ttotal: 5.71s\tremaining: 2.63s\n",
      "137:\tlearn: 1.4923047\ttotal: 5.76s\tremaining: 2.59s\n",
      "138:\tlearn: 1.4894977\ttotal: 5.8s\tremaining: 2.54s\n",
      "139:\tlearn: 1.4862730\ttotal: 5.83s\tremaining: 2.5s\n",
      "140:\tlearn: 1.4832524\ttotal: 5.87s\tremaining: 2.46s\n",
      "141:\tlearn: 1.4799182\ttotal: 5.92s\tremaining: 2.42s\n",
      "142:\tlearn: 1.4764992\ttotal: 5.96s\tremaining: 2.38s\n",
      "143:\tlearn: 1.4738118\ttotal: 6s\tremaining: 2.33s\n",
      "144:\tlearn: 1.4706138\ttotal: 6.04s\tremaining: 2.29s\n",
      "145:\tlearn: 1.4679240\ttotal: 6.08s\tremaining: 2.25s\n",
      "146:\tlearn: 1.4658114\ttotal: 6.11s\tremaining: 2.2s\n",
      "147:\tlearn: 1.4627684\ttotal: 6.16s\tremaining: 2.16s\n",
      "148:\tlearn: 1.4604355\ttotal: 6.2s\tremaining: 2.12s\n",
      "149:\tlearn: 1.4579841\ttotal: 6.24s\tremaining: 2.08s\n",
      "150:\tlearn: 1.4556808\ttotal: 6.28s\tremaining: 2.04s\n",
      "151:\tlearn: 1.4530243\ttotal: 6.33s\tremaining: 2s\n",
      "152:\tlearn: 1.4496261\ttotal: 6.37s\tremaining: 1.96s\n",
      "153:\tlearn: 1.4462288\ttotal: 6.42s\tremaining: 1.92s\n",
      "154:\tlearn: 1.4433637\ttotal: 6.46s\tremaining: 1.87s\n",
      "155:\tlearn: 1.4404047\ttotal: 6.5s\tremaining: 1.83s\n",
      "156:\tlearn: 1.4374075\ttotal: 6.54s\tremaining: 1.79s\n",
      "157:\tlearn: 1.4352482\ttotal: 6.58s\tremaining: 1.75s\n",
      "158:\tlearn: 1.4325780\ttotal: 6.62s\tremaining: 1.71s\n",
      "159:\tlearn: 1.4303046\ttotal: 6.66s\tremaining: 1.67s\n",
      "160:\tlearn: 1.4283018\ttotal: 6.7s\tremaining: 1.62s\n",
      "161:\tlearn: 1.4245533\ttotal: 6.75s\tremaining: 1.58s\n",
      "162:\tlearn: 1.4229012\ttotal: 6.79s\tremaining: 1.54s\n",
      "163:\tlearn: 1.4212272\ttotal: 6.83s\tremaining: 1.5s\n",
      "164:\tlearn: 1.4187682\ttotal: 6.87s\tremaining: 1.46s\n",
      "165:\tlearn: 1.4161471\ttotal: 6.91s\tremaining: 1.42s\n",
      "166:\tlearn: 1.4138299\ttotal: 6.96s\tremaining: 1.38s\n",
      "167:\tlearn: 1.4119825\ttotal: 7s\tremaining: 1.33s\n",
      "168:\tlearn: 1.4091540\ttotal: 7.04s\tremaining: 1.29s\n",
      "169:\tlearn: 1.4067736\ttotal: 7.09s\tremaining: 1.25s\n",
      "170:\tlearn: 1.4040700\ttotal: 7.13s\tremaining: 1.21s\n",
      "171:\tlearn: 1.4023145\ttotal: 7.17s\tremaining: 1.17s\n",
      "172:\tlearn: 1.3994941\ttotal: 7.21s\tremaining: 1.13s\n",
      "173:\tlearn: 1.3968893\ttotal: 7.25s\tremaining: 1.08s\n",
      "174:\tlearn: 1.3934008\ttotal: 7.3s\tremaining: 1.04s\n",
      "175:\tlearn: 1.3913289\ttotal: 7.34s\tremaining: 1s\n",
      "176:\tlearn: 1.3892866\ttotal: 7.38s\tremaining: 959ms\n",
      "177:\tlearn: 1.3867325\ttotal: 7.42s\tremaining: 917ms\n",
      "178:\tlearn: 1.3842510\ttotal: 7.46s\tremaining: 876ms\n",
      "179:\tlearn: 1.3822721\ttotal: 7.5s\tremaining: 834ms\n",
      "180:\tlearn: 1.3789324\ttotal: 7.55s\tremaining: 793ms\n",
      "181:\tlearn: 1.3760079\ttotal: 7.6s\tremaining: 751ms\n",
      "182:\tlearn: 1.3737389\ttotal: 7.63s\tremaining: 709ms\n",
      "183:\tlearn: 1.3720212\ttotal: 7.67s\tremaining: 667ms\n",
      "184:\tlearn: 1.3696728\ttotal: 7.71s\tremaining: 625ms\n",
      "185:\tlearn: 1.3665678\ttotal: 7.75s\tremaining: 584ms\n",
      "186:\tlearn: 1.3647063\ttotal: 7.8s\tremaining: 542ms\n",
      "187:\tlearn: 1.3626209\ttotal: 7.84s\tremaining: 500ms\n",
      "188:\tlearn: 1.3603533\ttotal: 7.88s\tremaining: 459ms\n",
      "189:\tlearn: 1.3587631\ttotal: 7.92s\tremaining: 417ms\n",
      "190:\tlearn: 1.3568812\ttotal: 7.96s\tremaining: 375ms\n",
      "191:\tlearn: 1.3548217\ttotal: 8s\tremaining: 333ms\n",
      "192:\tlearn: 1.3526056\ttotal: 8.04s\tremaining: 292ms\n",
      "193:\tlearn: 1.3501245\ttotal: 8.09s\tremaining: 250ms\n",
      "194:\tlearn: 1.3482926\ttotal: 8.13s\tremaining: 208ms\n",
      "195:\tlearn: 1.3455365\ttotal: 8.17s\tremaining: 167ms\n",
      "196:\tlearn: 1.3440718\ttotal: 8.21s\tremaining: 125ms\n",
      "197:\tlearn: 1.3425015\ttotal: 8.25s\tremaining: 83.3ms\n",
      "198:\tlearn: 1.3401685\ttotal: 8.29s\tremaining: 41.7ms\n",
      "199:\tlearn: 1.3381588\ttotal: 8.34s\tremaining: 0us\n",
      "0:\tlearn: 2.2883992\ttotal: 47.7ms\tremaining: 9.5s\n",
      "1:\tlearn: 2.2748302\ttotal: 87.1ms\tremaining: 8.63s\n",
      "2:\tlearn: 2.2620491\ttotal: 126ms\tremaining: 8.26s\n",
      "3:\tlearn: 2.2489606\ttotal: 167ms\tremaining: 8.16s\n",
      "4:\tlearn: 2.2362856\ttotal: 207ms\tremaining: 8.09s\n",
      "5:\tlearn: 2.2245520\ttotal: 248ms\tremaining: 8.01s\n",
      "6:\tlearn: 2.2127707\ttotal: 290ms\tremaining: 7.99s\n",
      "7:\tlearn: 2.2008380\ttotal: 331ms\tremaining: 7.96s\n",
      "8:\tlearn: 2.1902233\ttotal: 371ms\tremaining: 7.88s\n",
      "9:\tlearn: 2.1801882\ttotal: 410ms\tremaining: 7.79s\n",
      "10:\tlearn: 2.1693737\ttotal: 452ms\tremaining: 7.76s\n",
      "11:\tlearn: 2.1585790\ttotal: 494ms\tremaining: 7.73s\n",
      "12:\tlearn: 2.1486745\ttotal: 535ms\tremaining: 7.7s\n",
      "13:\tlearn: 2.1380172\ttotal: 576ms\tremaining: 7.65s\n",
      "14:\tlearn: 2.1279667\ttotal: 617ms\tremaining: 7.61s\n",
      "15:\tlearn: 2.1186466\ttotal: 659ms\tremaining: 7.58s\n",
      "16:\tlearn: 2.1083929\ttotal: 700ms\tremaining: 7.54s\n",
      "17:\tlearn: 2.0982911\ttotal: 744ms\tremaining: 7.52s\n",
      "18:\tlearn: 2.0885306\ttotal: 785ms\tremaining: 7.48s\n",
      "19:\tlearn: 2.0799321\ttotal: 826ms\tremaining: 7.43s\n",
      "20:\tlearn: 2.0709670\ttotal: 868ms\tremaining: 7.4s\n",
      "21:\tlearn: 2.0625071\ttotal: 914ms\tremaining: 7.39s\n",
      "22:\tlearn: 2.0535760\ttotal: 964ms\tremaining: 7.42s\n",
      "23:\tlearn: 2.0448276\ttotal: 1.01s\tremaining: 7.39s\n",
      "24:\tlearn: 2.0362136\ttotal: 1.05s\tremaining: 7.34s\n",
      "25:\tlearn: 2.0280553\ttotal: 1.09s\tremaining: 7.33s\n",
      "26:\tlearn: 2.0198525\ttotal: 1.14s\tremaining: 7.29s\n",
      "27:\tlearn: 2.0118572\ttotal: 1.18s\tremaining: 7.25s\n",
      "28:\tlearn: 2.0043603\ttotal: 1.22s\tremaining: 7.2s\n",
      "29:\tlearn: 1.9966059\ttotal: 1.26s\tremaining: 7.14s\n",
      "30:\tlearn: 1.9892091\ttotal: 1.3s\tremaining: 7.09s\n",
      "31:\tlearn: 1.9822248\ttotal: 1.34s\tremaining: 7.04s\n",
      "32:\tlearn: 1.9749547\ttotal: 1.38s\tremaining: 7s\n",
      "33:\tlearn: 1.9677072\ttotal: 1.43s\tremaining: 6.96s\n",
      "34:\tlearn: 1.9597330\ttotal: 1.48s\tremaining: 6.99s\n",
      "35:\tlearn: 1.9531374\ttotal: 1.53s\tremaining: 6.97s\n",
      "36:\tlearn: 1.9461781\ttotal: 1.57s\tremaining: 6.93s\n",
      "37:\tlearn: 1.9384000\ttotal: 1.62s\tremaining: 6.9s\n",
      "38:\tlearn: 1.9318234\ttotal: 1.66s\tremaining: 6.85s\n",
      "39:\tlearn: 1.9246535\ttotal: 1.7s\tremaining: 6.81s\n",
      "40:\tlearn: 1.9173613\ttotal: 1.75s\tremaining: 6.8s\n",
      "41:\tlearn: 1.9110589\ttotal: 1.8s\tremaining: 6.76s\n",
      "42:\tlearn: 1.9055872\ttotal: 1.84s\tremaining: 6.71s\n",
      "43:\tlearn: 1.8990563\ttotal: 1.88s\tremaining: 6.67s\n",
      "44:\tlearn: 1.8932895\ttotal: 1.92s\tremaining: 6.63s\n",
      "45:\tlearn: 1.8865735\ttotal: 1.97s\tremaining: 6.59s\n",
      "46:\tlearn: 1.8799433\ttotal: 2s\tremaining: 6.53s\n",
      "47:\tlearn: 1.8730151\ttotal: 2.05s\tremaining: 6.5s\n",
      "48:\tlearn: 1.8670554\ttotal: 2.1s\tremaining: 6.46s\n",
      "49:\tlearn: 1.8618862\ttotal: 2.13s\tremaining: 6.41s\n",
      "50:\tlearn: 1.8555484\ttotal: 2.18s\tremaining: 6.36s\n",
      "51:\tlearn: 1.8496667\ttotal: 2.22s\tremaining: 6.32s\n",
      "52:\tlearn: 1.8442019\ttotal: 2.26s\tremaining: 6.27s\n",
      "53:\tlearn: 1.8384757\ttotal: 2.3s\tremaining: 6.22s\n",
      "54:\tlearn: 1.8324375\ttotal: 2.35s\tremaining: 6.18s\n",
      "55:\tlearn: 1.8271076\ttotal: 2.39s\tremaining: 6.14s\n",
      "56:\tlearn: 1.8207514\ttotal: 2.43s\tremaining: 6.09s\n",
      "57:\tlearn: 1.8157244\ttotal: 2.47s\tremaining: 6.04s\n",
      "58:\tlearn: 1.8097019\ttotal: 2.5s\tremaining: 5.99s\n",
      "59:\tlearn: 1.8038711\ttotal: 2.54s\tremaining: 5.94s\n",
      "60:\tlearn: 1.7979910\ttotal: 2.59s\tremaining: 5.9s\n",
      "61:\tlearn: 1.7930526\ttotal: 2.63s\tremaining: 5.85s\n",
      "62:\tlearn: 1.7877541\ttotal: 2.67s\tremaining: 5.8s\n",
      "63:\tlearn: 1.7819524\ttotal: 2.71s\tremaining: 5.75s\n",
      "64:\tlearn: 1.7757871\ttotal: 2.75s\tremaining: 5.71s\n",
      "65:\tlearn: 1.7712248\ttotal: 2.79s\tremaining: 5.66s\n",
      "66:\tlearn: 1.7657721\ttotal: 2.83s\tremaining: 5.62s\n",
      "67:\tlearn: 1.7611414\ttotal: 2.87s\tremaining: 5.58s\n",
      "68:\tlearn: 1.7570082\ttotal: 2.91s\tremaining: 5.53s\n",
      "69:\tlearn: 1.7515013\ttotal: 2.95s\tremaining: 5.48s\n",
      "70:\tlearn: 1.7476357\ttotal: 2.99s\tremaining: 5.43s\n",
      "71:\tlearn: 1.7425189\ttotal: 3.03s\tremaining: 5.39s\n",
      "72:\tlearn: 1.7373950\ttotal: 3.07s\tremaining: 5.34s\n",
      "73:\tlearn: 1.7316916\ttotal: 3.12s\tremaining: 5.31s\n",
      "74:\tlearn: 1.7264010\ttotal: 3.16s\tremaining: 5.26s\n",
      "75:\tlearn: 1.7215076\ttotal: 3.2s\tremaining: 5.21s\n",
      "76:\tlearn: 1.7167564\ttotal: 3.24s\tremaining: 5.17s\n",
      "77:\tlearn: 1.7127616\ttotal: 3.27s\tremaining: 5.12s\n",
      "78:\tlearn: 1.7079784\ttotal: 3.32s\tremaining: 5.08s\n",
      "79:\tlearn: 1.7028577\ttotal: 3.36s\tremaining: 5.04s\n",
      "80:\tlearn: 1.6987693\ttotal: 3.4s\tremaining: 5s\n",
      "81:\tlearn: 1.6944819\ttotal: 3.44s\tremaining: 4.95s\n",
      "82:\tlearn: 1.6901848\ttotal: 3.48s\tremaining: 4.91s\n",
      "83:\tlearn: 1.6855935\ttotal: 3.52s\tremaining: 4.87s\n",
      "84:\tlearn: 1.6808756\ttotal: 3.56s\tremaining: 4.82s\n",
      "85:\tlearn: 1.6770220\ttotal: 3.61s\tremaining: 4.79s\n",
      "86:\tlearn: 1.6730836\ttotal: 3.65s\tremaining: 4.75s\n",
      "87:\tlearn: 1.6697608\ttotal: 3.69s\tremaining: 4.7s\n",
      "88:\tlearn: 1.6662463\ttotal: 3.73s\tremaining: 4.65s\n",
      "89:\tlearn: 1.6617143\ttotal: 3.77s\tremaining: 4.61s\n",
      "90:\tlearn: 1.6576894\ttotal: 3.81s\tremaining: 4.57s\n",
      "91:\tlearn: 1.6532829\ttotal: 3.86s\tremaining: 4.53s\n",
      "92:\tlearn: 1.6493256\ttotal: 3.9s\tremaining: 4.49s\n",
      "93:\tlearn: 1.6456552\ttotal: 3.94s\tremaining: 4.45s\n",
      "94:\tlearn: 1.6425262\ttotal: 3.98s\tremaining: 4.4s\n",
      "95:\tlearn: 1.6386574\ttotal: 4.03s\tremaining: 4.36s\n",
      "96:\tlearn: 1.6343428\ttotal: 4.07s\tremaining: 4.32s\n",
      "97:\tlearn: 1.6297339\ttotal: 4.11s\tremaining: 4.28s\n",
      "98:\tlearn: 1.6258189\ttotal: 4.15s\tremaining: 4.23s\n",
      "99:\tlearn: 1.6220528\ttotal: 4.19s\tremaining: 4.19s\n",
      "100:\tlearn: 1.6183658\ttotal: 4.23s\tremaining: 4.14s\n",
      "101:\tlearn: 1.6144176\ttotal: 4.26s\tremaining: 4.1s\n",
      "102:\tlearn: 1.6114095\ttotal: 4.3s\tremaining: 4.05s\n",
      "103:\tlearn: 1.6077128\ttotal: 4.34s\tremaining: 4.01s\n",
      "104:\tlearn: 1.6043901\ttotal: 4.38s\tremaining: 3.96s\n",
      "105:\tlearn: 1.6015716\ttotal: 4.42s\tremaining: 3.92s\n",
      "106:\tlearn: 1.5973986\ttotal: 4.46s\tremaining: 3.88s\n",
      "107:\tlearn: 1.5933373\ttotal: 4.51s\tremaining: 3.84s\n",
      "108:\tlearn: 1.5895112\ttotal: 4.55s\tremaining: 3.8s\n",
      "109:\tlearn: 1.5861428\ttotal: 4.59s\tremaining: 3.76s\n",
      "110:\tlearn: 1.5821663\ttotal: 4.64s\tremaining: 3.72s\n",
      "111:\tlearn: 1.5786242\ttotal: 4.68s\tremaining: 3.68s\n",
      "112:\tlearn: 1.5751751\ttotal: 4.72s\tremaining: 3.63s\n",
      "113:\tlearn: 1.5716104\ttotal: 4.76s\tremaining: 3.59s\n",
      "114:\tlearn: 1.5676007\ttotal: 4.8s\tremaining: 3.55s\n",
      "115:\tlearn: 1.5644600\ttotal: 4.84s\tremaining: 3.51s\n",
      "116:\tlearn: 1.5618162\ttotal: 4.88s\tremaining: 3.46s\n",
      "117:\tlearn: 1.5582818\ttotal: 4.92s\tremaining: 3.42s\n",
      "118:\tlearn: 1.5553951\ttotal: 4.96s\tremaining: 3.38s\n",
      "119:\tlearn: 1.5514767\ttotal: 5s\tremaining: 3.33s\n",
      "120:\tlearn: 1.5482968\ttotal: 5.04s\tremaining: 3.29s\n",
      "121:\tlearn: 1.5446236\ttotal: 5.08s\tremaining: 3.25s\n",
      "122:\tlearn: 1.5414473\ttotal: 5.12s\tremaining: 3.2s\n",
      "123:\tlearn: 1.5379166\ttotal: 5.16s\tremaining: 3.16s\n",
      "124:\tlearn: 1.5345516\ttotal: 5.2s\tremaining: 3.12s\n",
      "125:\tlearn: 1.5313868\ttotal: 5.24s\tremaining: 3.08s\n",
      "126:\tlearn: 1.5285957\ttotal: 5.28s\tremaining: 3.03s\n",
      "127:\tlearn: 1.5246652\ttotal: 5.32s\tremaining: 2.99s\n",
      "128:\tlearn: 1.5220072\ttotal: 5.36s\tremaining: 2.95s\n",
      "129:\tlearn: 1.5195666\ttotal: 5.4s\tremaining: 2.91s\n",
      "130:\tlearn: 1.5150828\ttotal: 5.44s\tremaining: 2.87s\n",
      "131:\tlearn: 1.5122456\ttotal: 5.48s\tremaining: 2.82s\n",
      "132:\tlearn: 1.5093376\ttotal: 5.52s\tremaining: 2.78s\n",
      "133:\tlearn: 1.5058280\ttotal: 5.58s\tremaining: 2.75s\n",
      "134:\tlearn: 1.5024659\ttotal: 5.64s\tremaining: 2.71s\n",
      "135:\tlearn: 1.4999480\ttotal: 5.67s\tremaining: 2.67s\n",
      "136:\tlearn: 1.4965344\ttotal: 5.71s\tremaining: 2.63s\n",
      "137:\tlearn: 1.4923272\ttotal: 5.76s\tremaining: 2.59s\n",
      "138:\tlearn: 1.4898651\ttotal: 5.79s\tremaining: 2.54s\n",
      "139:\tlearn: 1.4876471\ttotal: 5.83s\tremaining: 2.5s\n",
      "140:\tlearn: 1.4846538\ttotal: 5.88s\tremaining: 2.46s\n",
      "141:\tlearn: 1.4813212\ttotal: 5.97s\tremaining: 2.44s\n",
      "142:\tlearn: 1.4778765\ttotal: 6.02s\tremaining: 2.4s\n",
      "143:\tlearn: 1.4758016\ttotal: 6.07s\tremaining: 2.36s\n",
      "144:\tlearn: 1.4737024\ttotal: 6.1s\tremaining: 2.31s\n",
      "145:\tlearn: 1.4710381\ttotal: 6.14s\tremaining: 2.27s\n",
      "146:\tlearn: 1.4687800\ttotal: 6.17s\tremaining: 2.23s\n",
      "147:\tlearn: 1.4655943\ttotal: 6.21s\tremaining: 2.18s\n",
      "148:\tlearn: 1.4620314\ttotal: 6.27s\tremaining: 2.15s\n",
      "149:\tlearn: 1.4597078\ttotal: 6.32s\tremaining: 2.11s\n",
      "150:\tlearn: 1.4575878\ttotal: 6.37s\tremaining: 2.07s\n",
      "151:\tlearn: 1.4550650\ttotal: 6.41s\tremaining: 2.02s\n",
      "152:\tlearn: 1.4533876\ttotal: 6.45s\tremaining: 1.98s\n",
      "153:\tlearn: 1.4500217\ttotal: 6.49s\tremaining: 1.94s\n",
      "154:\tlearn: 1.4466431\ttotal: 6.54s\tremaining: 1.9s\n",
      "155:\tlearn: 1.4436762\ttotal: 6.58s\tremaining: 1.85s\n",
      "156:\tlearn: 1.4409106\ttotal: 6.63s\tremaining: 1.82s\n",
      "157:\tlearn: 1.4375391\ttotal: 6.69s\tremaining: 1.78s\n",
      "158:\tlearn: 1.4348178\ttotal: 6.74s\tremaining: 1.74s\n",
      "159:\tlearn: 1.4329199\ttotal: 6.79s\tremaining: 1.7s\n",
      "160:\tlearn: 1.4308908\ttotal: 6.83s\tremaining: 1.65s\n",
      "161:\tlearn: 1.4270835\ttotal: 6.87s\tremaining: 1.61s\n",
      "162:\tlearn: 1.4254170\ttotal: 6.91s\tremaining: 1.57s\n",
      "163:\tlearn: 1.4234167\ttotal: 6.95s\tremaining: 1.52s\n",
      "164:\tlearn: 1.4207153\ttotal: 6.98s\tremaining: 1.48s\n",
      "165:\tlearn: 1.4181568\ttotal: 7.02s\tremaining: 1.44s\n",
      "166:\tlearn: 1.4146000\ttotal: 7.07s\tremaining: 1.4s\n",
      "167:\tlearn: 1.4127369\ttotal: 7.12s\tremaining: 1.36s\n",
      "168:\tlearn: 1.4099098\ttotal: 7.17s\tremaining: 1.31s\n",
      "169:\tlearn: 1.4075216\ttotal: 7.21s\tremaining: 1.27s\n",
      "170:\tlearn: 1.4058308\ttotal: 7.25s\tremaining: 1.23s\n",
      "171:\tlearn: 1.4031708\ttotal: 7.28s\tremaining: 1.19s\n",
      "172:\tlearn: 1.4007687\ttotal: 7.32s\tremaining: 1.14s\n",
      "173:\tlearn: 1.3987205\ttotal: 7.36s\tremaining: 1.1s\n",
      "174:\tlearn: 1.3959272\ttotal: 7.4s\tremaining: 1.06s\n",
      "175:\tlearn: 1.3943053\ttotal: 7.43s\tremaining: 1.01s\n",
      "176:\tlearn: 1.3922715\ttotal: 7.47s\tremaining: 971ms\n",
      "177:\tlearn: 1.3895682\ttotal: 7.51s\tremaining: 929ms\n",
      "178:\tlearn: 1.3873293\ttotal: 7.55s\tremaining: 886ms\n",
      "179:\tlearn: 1.3849808\ttotal: 7.58s\tremaining: 843ms\n",
      "180:\tlearn: 1.3815620\ttotal: 7.63s\tremaining: 801ms\n",
      "181:\tlearn: 1.3786321\ttotal: 7.67s\tremaining: 759ms\n",
      "182:\tlearn: 1.3763699\ttotal: 7.71s\tremaining: 716ms\n",
      "183:\tlearn: 1.3734222\ttotal: 7.75s\tremaining: 674ms\n",
      "184:\tlearn: 1.3713395\ttotal: 7.79s\tremaining: 632ms\n",
      "185:\tlearn: 1.3688235\ttotal: 7.83s\tremaining: 590ms\n",
      "186:\tlearn: 1.3668941\ttotal: 7.87s\tremaining: 547ms\n",
      "187:\tlearn: 1.3651637\ttotal: 7.9s\tremaining: 505ms\n",
      "188:\tlearn: 1.3621581\ttotal: 7.95s\tremaining: 463ms\n",
      "189:\tlearn: 1.3602117\ttotal: 7.99s\tremaining: 420ms\n",
      "190:\tlearn: 1.3580366\ttotal: 8.02s\tremaining: 378ms\n",
      "191:\tlearn: 1.3558519\ttotal: 8.06s\tremaining: 336ms\n",
      "192:\tlearn: 1.3536327\ttotal: 8.11s\tremaining: 294ms\n",
      "193:\tlearn: 1.3507501\ttotal: 8.15s\tremaining: 252ms\n",
      "194:\tlearn: 1.3489039\ttotal: 8.19s\tremaining: 210ms\n",
      "195:\tlearn: 1.3462904\ttotal: 8.23s\tremaining: 168ms\n",
      "196:\tlearn: 1.3447914\ttotal: 8.27s\tremaining: 126ms\n",
      "197:\tlearn: 1.3431977\ttotal: 8.3s\tremaining: 83.9ms\n",
      "198:\tlearn: 1.3415813\ttotal: 8.34s\tremaining: 41.9ms\n",
      "199:\tlearn: 1.3396791\ttotal: 8.37s\tremaining: 0us\n",
      "0:\tlearn: 1.8941579\ttotal: 42.5ms\tremaining: 8.47s\n",
      "1:\tlearn: 1.5377570\ttotal: 81.7ms\tremaining: 8.09s\n",
      "2:\tlearn: 1.4084167\ttotal: 115ms\tremaining: 7.56s\n",
      "3:\tlearn: 1.3006020\ttotal: 149ms\tremaining: 7.29s\n",
      "4:\tlearn: 1.1835798\ttotal: 191ms\tremaining: 7.46s\n",
      "5:\tlearn: 1.1186851\ttotal: 234ms\tremaining: 7.56s\n",
      "6:\tlearn: 1.0589720\ttotal: 278ms\tremaining: 7.67s\n",
      "7:\tlearn: 1.0207498\ttotal: 327ms\tremaining: 7.84s\n",
      "8:\tlearn: 0.9716307\ttotal: 368ms\tremaining: 7.81s\n",
      "9:\tlearn: 0.9374245\ttotal: 409ms\tremaining: 7.77s\n",
      "10:\tlearn: 0.9005593\ttotal: 446ms\tremaining: 7.66s\n",
      "11:\tlearn: 0.8791850\ttotal: 482ms\tremaining: 7.54s\n",
      "12:\tlearn: 0.8600551\ttotal: 517ms\tremaining: 7.44s\n",
      "13:\tlearn: 0.8404446\ttotal: 564ms\tremaining: 7.49s\n",
      "14:\tlearn: 0.8211277\ttotal: 607ms\tremaining: 7.48s\n",
      "15:\tlearn: 0.8047691\ttotal: 655ms\tremaining: 7.54s\n",
      "16:\tlearn: 0.7877859\ttotal: 697ms\tremaining: 7.5s\n",
      "17:\tlearn: 0.7710834\ttotal: 733ms\tremaining: 7.41s\n",
      "18:\tlearn: 0.7594162\ttotal: 782ms\tremaining: 7.45s\n",
      "19:\tlearn: 0.7486702\ttotal: 818ms\tremaining: 7.36s\n",
      "20:\tlearn: 0.7343584\ttotal: 855ms\tremaining: 7.29s\n",
      "21:\tlearn: 0.7168879\ttotal: 895ms\tremaining: 7.24s\n",
      "22:\tlearn: 0.7066592\ttotal: 931ms\tremaining: 7.16s\n",
      "23:\tlearn: 0.6984217\ttotal: 973ms\tremaining: 7.13s\n",
      "24:\tlearn: 0.6904425\ttotal: 1.01s\tremaining: 7.08s\n",
      "25:\tlearn: 0.6793323\ttotal: 1.04s\tremaining: 6.99s\n",
      "26:\tlearn: 0.6732710\ttotal: 1.09s\tremaining: 7s\n",
      "27:\tlearn: 0.6660918\ttotal: 1.13s\tremaining: 6.93s\n",
      "28:\tlearn: 0.6570792\ttotal: 1.18s\tremaining: 6.94s\n",
      "29:\tlearn: 0.6499449\ttotal: 1.22s\tremaining: 6.93s\n",
      "30:\tlearn: 0.6441819\ttotal: 1.26s\tremaining: 6.89s\n",
      "31:\tlearn: 0.6312368\ttotal: 1.31s\tremaining: 6.87s\n",
      "32:\tlearn: 0.6264899\ttotal: 1.35s\tremaining: 6.83s\n",
      "33:\tlearn: 0.6213480\ttotal: 1.39s\tremaining: 6.8s\n",
      "34:\tlearn: 0.6147848\ttotal: 1.43s\tremaining: 6.73s\n",
      "35:\tlearn: 0.6097832\ttotal: 1.47s\tremaining: 6.71s\n",
      "36:\tlearn: 0.6039471\ttotal: 1.52s\tremaining: 6.69s\n",
      "37:\tlearn: 0.5989653\ttotal: 1.55s\tremaining: 6.63s\n",
      "38:\tlearn: 0.5948862\ttotal: 1.6s\tremaining: 6.59s\n",
      "39:\tlearn: 0.5905029\ttotal: 1.65s\tremaining: 6.58s\n",
      "40:\tlearn: 0.5875785\ttotal: 1.69s\tremaining: 6.55s\n",
      "41:\tlearn: 0.5835386\ttotal: 1.73s\tremaining: 6.5s\n",
      "42:\tlearn: 0.5788865\ttotal: 1.77s\tremaining: 6.47s\n",
      "43:\tlearn: 0.5778317\ttotal: 1.8s\tremaining: 6.4s\n",
      "44:\tlearn: 0.5754053\ttotal: 1.84s\tremaining: 6.34s\n",
      "45:\tlearn: 0.5720076\ttotal: 1.88s\tremaining: 6.28s\n",
      "46:\tlearn: 0.5692409\ttotal: 1.91s\tremaining: 6.22s\n",
      "47:\tlearn: 0.5669519\ttotal: 1.95s\tremaining: 6.16s\n",
      "48:\tlearn: 0.5622592\ttotal: 1.99s\tremaining: 6.12s\n",
      "49:\tlearn: 0.5531322\ttotal: 2.03s\tremaining: 6.09s\n",
      "50:\tlearn: 0.5495482\ttotal: 2.06s\tremaining: 6.03s\n",
      "51:\tlearn: 0.5475966\ttotal: 2.11s\tremaining: 6.01s\n",
      "52:\tlearn: 0.5429969\ttotal: 2.15s\tremaining: 5.96s\n",
      "53:\tlearn: 0.5404446\ttotal: 2.19s\tremaining: 5.92s\n",
      "54:\tlearn: 0.5372018\ttotal: 2.23s\tremaining: 5.88s\n",
      "55:\tlearn: 0.5342623\ttotal: 2.27s\tremaining: 5.84s\n",
      "56:\tlearn: 0.5322018\ttotal: 2.31s\tremaining: 5.79s\n",
      "57:\tlearn: 0.5309591\ttotal: 2.34s\tremaining: 5.73s\n",
      "58:\tlearn: 0.5232218\ttotal: 2.38s\tremaining: 5.69s\n",
      "59:\tlearn: 0.5203157\ttotal: 2.42s\tremaining: 5.65s\n",
      "60:\tlearn: 0.5169879\ttotal: 2.47s\tremaining: 5.63s\n",
      "61:\tlearn: 0.5135202\ttotal: 2.51s\tremaining: 5.58s\n",
      "62:\tlearn: 0.5098686\ttotal: 2.55s\tremaining: 5.54s\n",
      "63:\tlearn: 0.5084564\ttotal: 2.58s\tremaining: 5.48s\n",
      "64:\tlearn: 0.5065450\ttotal: 2.62s\tremaining: 5.43s\n",
      "65:\tlearn: 0.5038020\ttotal: 2.65s\tremaining: 5.39s\n",
      "66:\tlearn: 0.5012860\ttotal: 2.69s\tremaining: 5.35s\n",
      "67:\tlearn: 0.4993431\ttotal: 2.73s\tremaining: 5.3s\n",
      "68:\tlearn: 0.4959182\ttotal: 2.77s\tremaining: 5.26s\n",
      "69:\tlearn: 0.4945052\ttotal: 2.81s\tremaining: 5.22s\n",
      "70:\tlearn: 0.4924912\ttotal: 2.85s\tremaining: 5.18s\n",
      "71:\tlearn: 0.4907861\ttotal: 2.9s\tremaining: 5.15s\n",
      "72:\tlearn: 0.4887148\ttotal: 2.94s\tremaining: 5.12s\n",
      "73:\tlearn: 0.4853413\ttotal: 3s\tremaining: 5.1s\n",
      "74:\tlearn: 0.4836413\ttotal: 3.04s\tremaining: 5.07s\n",
      "75:\tlearn: 0.4823056\ttotal: 3.08s\tremaining: 5.03s\n",
      "76:\tlearn: 0.4818896\ttotal: 3.11s\tremaining: 4.97s\n",
      "77:\tlearn: 0.4789141\ttotal: 3.16s\tremaining: 4.94s\n",
      "78:\tlearn: 0.4775549\ttotal: 3.19s\tremaining: 4.89s\n",
      "79:\tlearn: 0.4764171\ttotal: 3.23s\tremaining: 4.85s\n",
      "80:\tlearn: 0.4741032\ttotal: 3.28s\tremaining: 4.82s\n",
      "81:\tlearn: 0.4731012\ttotal: 3.33s\tremaining: 4.79s\n",
      "82:\tlearn: 0.4715425\ttotal: 3.37s\tremaining: 4.75s\n",
      "83:\tlearn: 0.4698797\ttotal: 3.4s\tremaining: 4.7s\n",
      "84:\tlearn: 0.4688604\ttotal: 3.44s\tremaining: 4.65s\n",
      "85:\tlearn: 0.4674278\ttotal: 3.48s\tremaining: 4.61s\n",
      "86:\tlearn: 0.4666633\ttotal: 3.51s\tremaining: 4.56s\n",
      "87:\tlearn: 0.4644778\ttotal: 3.55s\tremaining: 4.52s\n",
      "88:\tlearn: 0.4627678\ttotal: 3.58s\tremaining: 4.47s\n",
      "89:\tlearn: 0.4619774\ttotal: 3.62s\tremaining: 4.42s\n",
      "90:\tlearn: 0.4602432\ttotal: 3.66s\tremaining: 4.38s\n",
      "91:\tlearn: 0.4589916\ttotal: 3.7s\tremaining: 4.34s\n",
      "92:\tlearn: 0.4581779\ttotal: 3.74s\tremaining: 4.3s\n",
      "93:\tlearn: 0.4565887\ttotal: 3.77s\tremaining: 4.25s\n",
      "94:\tlearn: 0.4557786\ttotal: 3.81s\tremaining: 4.21s\n",
      "95:\tlearn: 0.4542812\ttotal: 3.85s\tremaining: 4.17s\n",
      "96:\tlearn: 0.4534410\ttotal: 3.9s\tremaining: 4.14s\n",
      "97:\tlearn: 0.4527401\ttotal: 3.94s\tremaining: 4.1s\n",
      "98:\tlearn: 0.4523114\ttotal: 3.98s\tremaining: 4.06s\n",
      "99:\tlearn: 0.4512624\ttotal: 4.02s\tremaining: 4.02s\n",
      "100:\tlearn: 0.4501310\ttotal: 4.07s\tremaining: 3.99s\n",
      "101:\tlearn: 0.4487767\ttotal: 4.11s\tremaining: 3.95s\n",
      "102:\tlearn: 0.4480596\ttotal: 4.16s\tremaining: 3.92s\n",
      "103:\tlearn: 0.4472899\ttotal: 4.2s\tremaining: 3.87s\n",
      "104:\tlearn: 0.4455143\ttotal: 4.23s\tremaining: 3.83s\n",
      "105:\tlearn: 0.4445690\ttotal: 4.26s\tremaining: 3.78s\n",
      "106:\tlearn: 0.4436039\ttotal: 4.31s\tremaining: 3.75s\n",
      "107:\tlearn: 0.4421053\ttotal: 4.35s\tremaining: 3.71s\n",
      "108:\tlearn: 0.4407306\ttotal: 4.39s\tremaining: 3.67s\n",
      "109:\tlearn: 0.4400754\ttotal: 4.42s\tremaining: 3.62s\n",
      "110:\tlearn: 0.4390184\ttotal: 4.46s\tremaining: 3.58s\n",
      "111:\tlearn: 0.4382138\ttotal: 4.51s\tremaining: 3.54s\n",
      "112:\tlearn: 0.4374362\ttotal: 4.54s\tremaining: 3.5s\n",
      "113:\tlearn: 0.4368631\ttotal: 4.58s\tremaining: 3.45s\n",
      "114:\tlearn: 0.4349352\ttotal: 4.62s\tremaining: 3.41s\n",
      "115:\tlearn: 0.4341974\ttotal: 4.66s\tremaining: 3.37s\n",
      "116:\tlearn: 0.4335031\ttotal: 4.7s\tremaining: 3.33s\n",
      "117:\tlearn: 0.4324348\ttotal: 4.73s\tremaining: 3.29s\n",
      "118:\tlearn: 0.4316694\ttotal: 4.77s\tremaining: 3.25s\n",
      "119:\tlearn: 0.4305017\ttotal: 4.81s\tremaining: 3.21s\n",
      "120:\tlearn: 0.4298900\ttotal: 4.84s\tremaining: 3.16s\n",
      "121:\tlearn: 0.4280573\ttotal: 4.89s\tremaining: 3.12s\n",
      "122:\tlearn: 0.4271609\ttotal: 4.92s\tremaining: 3.08s\n",
      "123:\tlearn: 0.4267153\ttotal: 4.96s\tremaining: 3.04s\n",
      "124:\tlearn: 0.4257445\ttotal: 5s\tremaining: 3s\n",
      "125:\tlearn: 0.4246563\ttotal: 5.04s\tremaining: 2.96s\n",
      "126:\tlearn: 0.4238397\ttotal: 5.09s\tremaining: 2.92s\n",
      "127:\tlearn: 0.4223813\ttotal: 5.13s\tremaining: 2.89s\n",
      "128:\tlearn: 0.4216299\ttotal: 5.17s\tremaining: 2.84s\n",
      "129:\tlearn: 0.4200013\ttotal: 5.21s\tremaining: 2.81s\n",
      "130:\tlearn: 0.4190186\ttotal: 5.26s\tremaining: 2.77s\n",
      "131:\tlearn: 0.4186145\ttotal: 5.29s\tremaining: 2.73s\n",
      "132:\tlearn: 0.4171428\ttotal: 5.33s\tremaining: 2.68s\n",
      "133:\tlearn: 0.4168613\ttotal: 5.36s\tremaining: 2.64s\n",
      "134:\tlearn: 0.4155373\ttotal: 5.41s\tremaining: 2.6s\n",
      "135:\tlearn: 0.4147990\ttotal: 5.45s\tremaining: 2.56s\n",
      "136:\tlearn: 0.4143747\ttotal: 5.49s\tremaining: 2.52s\n",
      "137:\tlearn: 0.4133239\ttotal: 5.52s\tremaining: 2.48s\n",
      "138:\tlearn: 0.4131097\ttotal: 5.56s\tremaining: 2.44s\n",
      "139:\tlearn: 0.4127131\ttotal: 5.59s\tremaining: 2.4s\n",
      "140:\tlearn: 0.4121093\ttotal: 5.63s\tremaining: 2.35s\n",
      "141:\tlearn: 0.4112301\ttotal: 5.67s\tremaining: 2.32s\n",
      "142:\tlearn: 0.4109948\ttotal: 5.71s\tremaining: 2.27s\n",
      "143:\tlearn: 0.4098500\ttotal: 5.76s\tremaining: 2.24s\n",
      "144:\tlearn: 0.4085823\ttotal: 5.81s\tremaining: 2.2s\n",
      "145:\tlearn: 0.4078048\ttotal: 5.85s\tremaining: 2.17s\n",
      "146:\tlearn: 0.4075489\ttotal: 5.89s\tremaining: 2.12s\n",
      "147:\tlearn: 0.4071822\ttotal: 5.92s\tremaining: 2.08s\n",
      "148:\tlearn: 0.4060001\ttotal: 5.96s\tremaining: 2.04s\n",
      "149:\tlearn: 0.4056103\ttotal: 6s\tremaining: 2s\n",
      "150:\tlearn: 0.4054118\ttotal: 6.03s\tremaining: 1.96s\n",
      "151:\tlearn: 0.4049268\ttotal: 6.07s\tremaining: 1.92s\n",
      "152:\tlearn: 0.4045171\ttotal: 6.1s\tremaining: 1.87s\n",
      "153:\tlearn: 0.4037804\ttotal: 6.15s\tremaining: 1.84s\n",
      "154:\tlearn: 0.4032728\ttotal: 6.19s\tremaining: 1.8s\n",
      "155:\tlearn: 0.4027799\ttotal: 6.23s\tremaining: 1.76s\n",
      "156:\tlearn: 0.4021171\ttotal: 6.27s\tremaining: 1.72s\n",
      "157:\tlearn: 0.4013972\ttotal: 6.32s\tremaining: 1.68s\n",
      "158:\tlearn: 0.4010155\ttotal: 6.36s\tremaining: 1.64s\n",
      "159:\tlearn: 0.4003475\ttotal: 6.4s\tremaining: 1.6s\n",
      "160:\tlearn: 0.3994659\ttotal: 6.43s\tremaining: 1.56s\n",
      "161:\tlearn: 0.3983528\ttotal: 6.47s\tremaining: 1.52s\n",
      "162:\tlearn: 0.3980845\ttotal: 6.51s\tremaining: 1.48s\n",
      "163:\tlearn: 0.3971790\ttotal: 6.55s\tremaining: 1.44s\n",
      "164:\tlearn: 0.3966314\ttotal: 6.59s\tremaining: 1.4s\n",
      "165:\tlearn: 0.3954045\ttotal: 6.63s\tremaining: 1.36s\n",
      "166:\tlearn: 0.3951892\ttotal: 6.66s\tremaining: 1.32s\n",
      "167:\tlearn: 0.3945718\ttotal: 6.71s\tremaining: 1.28s\n",
      "168:\tlearn: 0.3942301\ttotal: 6.75s\tremaining: 1.24s\n",
      "169:\tlearn: 0.3936351\ttotal: 6.79s\tremaining: 1.2s\n",
      "170:\tlearn: 0.3932572\ttotal: 6.83s\tremaining: 1.16s\n",
      "171:\tlearn: 0.3928867\ttotal: 6.87s\tremaining: 1.12s\n",
      "172:\tlearn: 0.3923692\ttotal: 6.91s\tremaining: 1.08s\n",
      "173:\tlearn: 0.3921915\ttotal: 6.98s\tremaining: 1.04s\n",
      "174:\tlearn: 0.3916553\ttotal: 7.04s\tremaining: 1.01s\n",
      "175:\tlearn: 0.3911697\ttotal: 7.09s\tremaining: 967ms\n",
      "176:\tlearn: 0.3910519\ttotal: 7.13s\tremaining: 926ms\n",
      "177:\tlearn: 0.3907916\ttotal: 7.16s\tremaining: 885ms\n",
      "178:\tlearn: 0.3904160\ttotal: 7.2s\tremaining: 844ms\n",
      "179:\tlearn: 0.3899499\ttotal: 7.24s\tremaining: 804ms\n",
      "180:\tlearn: 0.3896134\ttotal: 7.29s\tremaining: 765ms\n",
      "181:\tlearn: 0.3893643\ttotal: 7.34s\tremaining: 726ms\n",
      "182:\tlearn: 0.3888245\ttotal: 7.39s\tremaining: 687ms\n",
      "183:\tlearn: 0.3884049\ttotal: 7.43s\tremaining: 646ms\n",
      "184:\tlearn: 0.3881290\ttotal: 7.48s\tremaining: 606ms\n",
      "185:\tlearn: 0.3877123\ttotal: 7.53s\tremaining: 567ms\n",
      "186:\tlearn: 0.3871010\ttotal: 7.57s\tremaining: 526ms\n",
      "187:\tlearn: 0.3869090\ttotal: 7.6s\tremaining: 485ms\n",
      "188:\tlearn: 0.3865689\ttotal: 7.64s\tremaining: 444ms\n",
      "189:\tlearn: 0.3862893\ttotal: 7.67s\tremaining: 404ms\n",
      "190:\tlearn: 0.3858321\ttotal: 7.71s\tremaining: 363ms\n",
      "191:\tlearn: 0.3846751\ttotal: 7.75s\tremaining: 323ms\n",
      "192:\tlearn: 0.3844980\ttotal: 7.79s\tremaining: 283ms\n",
      "193:\tlearn: 0.3840004\ttotal: 7.83s\tremaining: 242ms\n",
      "194:\tlearn: 0.3835853\ttotal: 7.87s\tremaining: 202ms\n",
      "195:\tlearn: 0.3828420\ttotal: 7.92s\tremaining: 162ms\n",
      "196:\tlearn: 0.3823610\ttotal: 7.96s\tremaining: 121ms\n",
      "197:\tlearn: 0.3820942\ttotal: 7.99s\tremaining: 80.7ms\n",
      "198:\tlearn: 0.3813785\ttotal: 8.04s\tremaining: 40.4ms\n",
      "199:\tlearn: 0.3808635\ttotal: 8.08s\tremaining: 0us\n",
      "0:\tlearn: 1.8834597\ttotal: 45.8ms\tremaining: 9.12s\n",
      "1:\tlearn: 1.5540128\ttotal: 86.9ms\tremaining: 8.6s\n",
      "2:\tlearn: 1.4013208\ttotal: 123ms\tremaining: 8.05s\n",
      "3:\tlearn: 1.2458418\ttotal: 157ms\tremaining: 7.68s\n",
      "4:\tlearn: 1.1365848\ttotal: 199ms\tremaining: 7.75s\n",
      "5:\tlearn: 1.0819374\ttotal: 235ms\tremaining: 7.59s\n",
      "6:\tlearn: 1.0267887\ttotal: 280ms\tremaining: 7.72s\n",
      "7:\tlearn: 0.9809151\ttotal: 340ms\tremaining: 8.16s\n",
      "8:\tlearn: 0.9480169\ttotal: 388ms\tremaining: 8.23s\n",
      "9:\tlearn: 0.9202955\ttotal: 433ms\tremaining: 8.22s\n",
      "10:\tlearn: 0.8922407\ttotal: 470ms\tremaining: 8.08s\n",
      "11:\tlearn: 0.8741179\ttotal: 511ms\tremaining: 8.01s\n",
      "12:\tlearn: 0.8519269\ttotal: 549ms\tremaining: 7.89s\n",
      "13:\tlearn: 0.8226432\ttotal: 589ms\tremaining: 7.83s\n",
      "14:\tlearn: 0.8048557\ttotal: 639ms\tremaining: 7.88s\n",
      "15:\tlearn: 0.7884799\ttotal: 690ms\tremaining: 7.94s\n",
      "16:\tlearn: 0.7761017\ttotal: 735ms\tremaining: 7.91s\n",
      "17:\tlearn: 0.7622796\ttotal: 775ms\tremaining: 7.84s\n",
      "18:\tlearn: 0.7489421\ttotal: 825ms\tremaining: 7.86s\n",
      "19:\tlearn: 0.7366134\ttotal: 872ms\tremaining: 7.85s\n",
      "20:\tlearn: 0.7260457\ttotal: 911ms\tremaining: 7.77s\n",
      "21:\tlearn: 0.7141922\ttotal: 952ms\tremaining: 7.7s\n",
      "22:\tlearn: 0.6986568\ttotal: 996ms\tremaining: 7.67s\n",
      "23:\tlearn: 0.6909831\ttotal: 1.04s\tremaining: 7.64s\n",
      "24:\tlearn: 0.6840541\ttotal: 1.09s\tremaining: 7.64s\n",
      "25:\tlearn: 0.6782197\ttotal: 1.13s\tremaining: 7.53s\n",
      "26:\tlearn: 0.6709491\ttotal: 1.17s\tremaining: 7.46s\n",
      "27:\tlearn: 0.6644861\ttotal: 1.21s\tremaining: 7.41s\n",
      "28:\tlearn: 0.6584056\ttotal: 1.24s\tremaining: 7.32s\n",
      "29:\tlearn: 0.6518017\ttotal: 1.28s\tremaining: 7.28s\n",
      "30:\tlearn: 0.6456094\ttotal: 1.33s\tremaining: 7.27s\n",
      "31:\tlearn: 0.6376783\ttotal: 1.37s\tremaining: 7.2s\n",
      "32:\tlearn: 0.6328615\ttotal: 1.41s\tremaining: 7.15s\n",
      "33:\tlearn: 0.6290328\ttotal: 1.45s\tremaining: 7.1s\n",
      "34:\tlearn: 0.6223129\ttotal: 1.49s\tremaining: 7.04s\n",
      "35:\tlearn: 0.6157237\ttotal: 1.53s\tremaining: 6.97s\n",
      "36:\tlearn: 0.6074052\ttotal: 1.58s\tremaining: 6.96s\n",
      "37:\tlearn: 0.6018483\ttotal: 1.62s\tremaining: 6.92s\n",
      "38:\tlearn: 0.5927888\ttotal: 1.67s\tremaining: 6.9s\n",
      "39:\tlearn: 0.5888363\ttotal: 1.7s\tremaining: 6.82s\n",
      "40:\tlearn: 0.5817276\ttotal: 1.75s\tremaining: 6.77s\n",
      "41:\tlearn: 0.5767348\ttotal: 1.79s\tremaining: 6.72s\n",
      "42:\tlearn: 0.5735479\ttotal: 1.83s\tremaining: 6.68s\n",
      "43:\tlearn: 0.5694541\ttotal: 1.88s\tremaining: 6.66s\n",
      "44:\tlearn: 0.5657482\ttotal: 1.92s\tremaining: 6.63s\n",
      "45:\tlearn: 0.5639371\ttotal: 1.96s\tremaining: 6.55s\n",
      "46:\tlearn: 0.5600321\ttotal: 2s\tremaining: 6.51s\n",
      "47:\tlearn: 0.5584318\ttotal: 2.04s\tremaining: 6.45s\n",
      "48:\tlearn: 0.5562943\ttotal: 2.07s\tremaining: 6.38s\n",
      "49:\tlearn: 0.5536819\ttotal: 2.11s\tremaining: 6.33s\n",
      "50:\tlearn: 0.5520482\ttotal: 2.15s\tremaining: 6.29s\n",
      "51:\tlearn: 0.5499600\ttotal: 2.2s\tremaining: 6.27s\n",
      "52:\tlearn: 0.5462017\ttotal: 2.25s\tremaining: 6.23s\n",
      "53:\tlearn: 0.5448236\ttotal: 2.28s\tremaining: 6.16s\n",
      "54:\tlearn: 0.5419467\ttotal: 2.32s\tremaining: 6.13s\n",
      "55:\tlearn: 0.5393025\ttotal: 2.37s\tremaining: 6.1s\n",
      "56:\tlearn: 0.5366186\ttotal: 2.41s\tremaining: 6.06s\n",
      "57:\tlearn: 0.5337652\ttotal: 2.45s\tremaining: 6s\n",
      "58:\tlearn: 0.5301090\ttotal: 2.48s\tremaining: 5.94s\n",
      "59:\tlearn: 0.5277180\ttotal: 2.52s\tremaining: 5.88s\n",
      "60:\tlearn: 0.5265383\ttotal: 2.55s\tremaining: 5.82s\n",
      "61:\tlearn: 0.5248206\ttotal: 2.59s\tremaining: 5.77s\n",
      "62:\tlearn: 0.5229260\ttotal: 2.63s\tremaining: 5.71s\n",
      "63:\tlearn: 0.5200752\ttotal: 2.67s\tremaining: 5.68s\n",
      "64:\tlearn: 0.5191973\ttotal: 2.71s\tremaining: 5.62s\n",
      "65:\tlearn: 0.5180151\ttotal: 2.75s\tremaining: 5.59s\n",
      "66:\tlearn: 0.5145069\ttotal: 2.8s\tremaining: 5.56s\n",
      "67:\tlearn: 0.5123982\ttotal: 2.85s\tremaining: 5.53s\n",
      "68:\tlearn: 0.5091433\ttotal: 2.89s\tremaining: 5.49s\n",
      "69:\tlearn: 0.5061089\ttotal: 2.92s\tremaining: 5.43s\n",
      "70:\tlearn: 0.5046669\ttotal: 2.97s\tremaining: 5.39s\n",
      "71:\tlearn: 0.5031017\ttotal: 3s\tremaining: 5.34s\n",
      "72:\tlearn: 0.5022770\ttotal: 3.04s\tremaining: 5.3s\n",
      "73:\tlearn: 0.5010679\ttotal: 3.08s\tremaining: 5.24s\n",
      "74:\tlearn: 0.4982435\ttotal: 3.13s\tremaining: 5.21s\n",
      "75:\tlearn: 0.4962811\ttotal: 3.17s\tremaining: 5.17s\n",
      "76:\tlearn: 0.4942958\ttotal: 3.2s\tremaining: 5.11s\n",
      "77:\tlearn: 0.4932639\ttotal: 3.24s\tremaining: 5.07s\n",
      "78:\tlearn: 0.4899938\ttotal: 3.29s\tremaining: 5.04s\n",
      "79:\tlearn: 0.4879656\ttotal: 3.33s\tremaining: 4.99s\n",
      "80:\tlearn: 0.4859217\ttotal: 3.37s\tremaining: 4.96s\n",
      "81:\tlearn: 0.4839566\ttotal: 3.42s\tremaining: 4.92s\n",
      "82:\tlearn: 0.4809102\ttotal: 3.47s\tremaining: 4.89s\n",
      "83:\tlearn: 0.4799534\ttotal: 3.52s\tremaining: 4.86s\n",
      "84:\tlearn: 0.4788286\ttotal: 3.56s\tremaining: 4.81s\n",
      "85:\tlearn: 0.4781631\ttotal: 3.59s\tremaining: 4.76s\n",
      "86:\tlearn: 0.4767701\ttotal: 3.64s\tremaining: 4.72s\n",
      "87:\tlearn: 0.4760200\ttotal: 3.68s\tremaining: 4.68s\n",
      "88:\tlearn: 0.4751508\ttotal: 3.71s\tremaining: 4.63s\n",
      "89:\tlearn: 0.4734897\ttotal: 3.75s\tremaining: 4.58s\n",
      "90:\tlearn: 0.4720575\ttotal: 3.8s\tremaining: 4.55s\n",
      "91:\tlearn: 0.4713224\ttotal: 3.83s\tremaining: 4.5s\n",
      "92:\tlearn: 0.4695097\ttotal: 3.87s\tremaining: 4.46s\n",
      "93:\tlearn: 0.4669752\ttotal: 3.91s\tremaining: 4.41s\n",
      "94:\tlearn: 0.4656454\ttotal: 3.96s\tremaining: 4.38s\n",
      "95:\tlearn: 0.4636399\ttotal: 4.01s\tremaining: 4.35s\n",
      "96:\tlearn: 0.4627287\ttotal: 4.06s\tremaining: 4.31s\n",
      "97:\tlearn: 0.4620114\ttotal: 4.09s\tremaining: 4.26s\n",
      "98:\tlearn: 0.4612748\ttotal: 4.13s\tremaining: 4.21s\n",
      "99:\tlearn: 0.4605582\ttotal: 4.17s\tremaining: 4.17s\n",
      "100:\tlearn: 0.4594902\ttotal: 4.21s\tremaining: 4.13s\n",
      "101:\tlearn: 0.4574187\ttotal: 4.25s\tremaining: 4.08s\n",
      "102:\tlearn: 0.4562384\ttotal: 4.29s\tremaining: 4.04s\n",
      "103:\tlearn: 0.4545779\ttotal: 4.33s\tremaining: 4s\n",
      "104:\tlearn: 0.4538330\ttotal: 4.37s\tremaining: 3.95s\n",
      "105:\tlearn: 0.4531009\ttotal: 4.43s\tremaining: 3.93s\n",
      "106:\tlearn: 0.4515395\ttotal: 4.5s\tremaining: 3.91s\n",
      "107:\tlearn: 0.4511435\ttotal: 4.54s\tremaining: 3.86s\n",
      "108:\tlearn: 0.4501809\ttotal: 4.59s\tremaining: 3.83s\n",
      "109:\tlearn: 0.4490708\ttotal: 4.64s\tremaining: 3.79s\n",
      "110:\tlearn: 0.4483959\ttotal: 4.68s\tremaining: 3.75s\n",
      "111:\tlearn: 0.4475007\ttotal: 4.74s\tremaining: 3.73s\n",
      "112:\tlearn: 0.4469563\ttotal: 4.79s\tremaining: 3.69s\n",
      "113:\tlearn: 0.4443268\ttotal: 4.84s\tremaining: 3.65s\n",
      "114:\tlearn: 0.4433468\ttotal: 4.89s\tremaining: 3.61s\n",
      "115:\tlearn: 0.4425416\ttotal: 4.93s\tremaining: 3.57s\n",
      "116:\tlearn: 0.4420229\ttotal: 4.97s\tremaining: 3.52s\n",
      "117:\tlearn: 0.4411220\ttotal: 5s\tremaining: 3.48s\n",
      "118:\tlearn: 0.4408159\ttotal: 5.04s\tremaining: 3.43s\n",
      "119:\tlearn: 0.4403018\ttotal: 5.07s\tremaining: 3.38s\n",
      "120:\tlearn: 0.4398178\ttotal: 5.11s\tremaining: 3.33s\n",
      "121:\tlearn: 0.4386684\ttotal: 5.15s\tremaining: 3.29s\n",
      "122:\tlearn: 0.4377241\ttotal: 5.19s\tremaining: 3.25s\n",
      "123:\tlearn: 0.4374223\ttotal: 5.22s\tremaining: 3.2s\n",
      "124:\tlearn: 0.4367553\ttotal: 5.26s\tremaining: 3.15s\n",
      "125:\tlearn: 0.4356151\ttotal: 5.3s\tremaining: 3.11s\n",
      "126:\tlearn: 0.4345952\ttotal: 5.34s\tremaining: 3.07s\n",
      "127:\tlearn: 0.4341887\ttotal: 5.38s\tremaining: 3.02s\n",
      "128:\tlearn: 0.4333927\ttotal: 5.42s\tremaining: 2.98s\n",
      "129:\tlearn: 0.4327651\ttotal: 5.46s\tremaining: 2.94s\n",
      "130:\tlearn: 0.4319113\ttotal: 5.5s\tremaining: 2.9s\n",
      "131:\tlearn: 0.4312719\ttotal: 5.53s\tremaining: 2.85s\n",
      "132:\tlearn: 0.4304088\ttotal: 5.58s\tremaining: 2.81s\n",
      "133:\tlearn: 0.4296213\ttotal: 5.61s\tremaining: 2.76s\n",
      "134:\tlearn: 0.4291881\ttotal: 5.65s\tremaining: 2.72s\n",
      "135:\tlearn: 0.4280244\ttotal: 5.68s\tremaining: 2.67s\n",
      "136:\tlearn: 0.4277937\ttotal: 5.72s\tremaining: 2.63s\n",
      "137:\tlearn: 0.4267537\ttotal: 5.76s\tremaining: 2.59s\n",
      "138:\tlearn: 0.4259246\ttotal: 5.8s\tremaining: 2.54s\n",
      "139:\tlearn: 0.4255108\ttotal: 5.83s\tremaining: 2.5s\n",
      "140:\tlearn: 0.4247694\ttotal: 5.87s\tremaining: 2.46s\n",
      "141:\tlearn: 0.4237080\ttotal: 5.91s\tremaining: 2.42s\n",
      "142:\tlearn: 0.4233552\ttotal: 5.95s\tremaining: 2.37s\n",
      "143:\tlearn: 0.4224067\ttotal: 5.99s\tremaining: 2.33s\n",
      "144:\tlearn: 0.4217895\ttotal: 6.03s\tremaining: 2.29s\n",
      "145:\tlearn: 0.4205950\ttotal: 6.07s\tremaining: 2.24s\n",
      "146:\tlearn: 0.4199588\ttotal: 6.12s\tremaining: 2.21s\n",
      "147:\tlearn: 0.4191488\ttotal: 6.16s\tremaining: 2.16s\n",
      "148:\tlearn: 0.4181733\ttotal: 6.21s\tremaining: 2.12s\n",
      "149:\tlearn: 0.4178315\ttotal: 6.24s\tremaining: 2.08s\n",
      "150:\tlearn: 0.4169328\ttotal: 6.29s\tremaining: 2.04s\n",
      "151:\tlearn: 0.4162581\ttotal: 6.32s\tremaining: 2s\n",
      "152:\tlearn: 0.4158128\ttotal: 6.36s\tremaining: 1.95s\n",
      "153:\tlearn: 0.4151004\ttotal: 6.4s\tremaining: 1.91s\n",
      "154:\tlearn: 0.4147398\ttotal: 6.43s\tremaining: 1.87s\n",
      "155:\tlearn: 0.4142010\ttotal: 6.48s\tremaining: 1.83s\n",
      "156:\tlearn: 0.4135287\ttotal: 6.52s\tremaining: 1.78s\n",
      "157:\tlearn: 0.4133569\ttotal: 6.55s\tremaining: 1.74s\n",
      "158:\tlearn: 0.4127835\ttotal: 6.6s\tremaining: 1.7s\n",
      "159:\tlearn: 0.4114282\ttotal: 6.65s\tremaining: 1.66s\n",
      "160:\tlearn: 0.4109778\ttotal: 6.69s\tremaining: 1.62s\n",
      "161:\tlearn: 0.4105261\ttotal: 6.73s\tremaining: 1.58s\n",
      "162:\tlearn: 0.4102204\ttotal: 6.76s\tremaining: 1.53s\n",
      "163:\tlearn: 0.4097372\ttotal: 6.8s\tremaining: 1.49s\n",
      "164:\tlearn: 0.4089787\ttotal: 6.84s\tremaining: 1.45s\n",
      "165:\tlearn: 0.4085207\ttotal: 6.88s\tremaining: 1.41s\n",
      "166:\tlearn: 0.4078254\ttotal: 6.92s\tremaining: 1.37s\n",
      "167:\tlearn: 0.4074131\ttotal: 6.95s\tremaining: 1.32s\n",
      "168:\tlearn: 0.4068997\ttotal: 6.99s\tremaining: 1.28s\n",
      "169:\tlearn: 0.4064772\ttotal: 7.02s\tremaining: 1.24s\n",
      "170:\tlearn: 0.4056355\ttotal: 7.07s\tremaining: 1.2s\n",
      "171:\tlearn: 0.4054019\ttotal: 7.1s\tremaining: 1.16s\n",
      "172:\tlearn: 0.4050303\ttotal: 7.14s\tremaining: 1.11s\n",
      "173:\tlearn: 0.4047888\ttotal: 7.18s\tremaining: 1.07s\n",
      "174:\tlearn: 0.4043598\ttotal: 7.23s\tremaining: 1.03s\n",
      "175:\tlearn: 0.4041620\ttotal: 7.26s\tremaining: 991ms\n",
      "176:\tlearn: 0.4032749\ttotal: 7.31s\tremaining: 950ms\n",
      "177:\tlearn: 0.4028868\ttotal: 7.34s\tremaining: 907ms\n",
      "178:\tlearn: 0.4026648\ttotal: 7.38s\tremaining: 865ms\n",
      "179:\tlearn: 0.4020528\ttotal: 7.42s\tremaining: 825ms\n",
      "180:\tlearn: 0.4017745\ttotal: 7.46s\tremaining: 783ms\n",
      "181:\tlearn: 0.3999945\ttotal: 7.5s\tremaining: 742ms\n",
      "182:\tlearn: 0.3995932\ttotal: 7.53s\tremaining: 700ms\n",
      "183:\tlearn: 0.3990769\ttotal: 7.57s\tremaining: 659ms\n",
      "184:\tlearn: 0.3988439\ttotal: 7.61s\tremaining: 617ms\n",
      "185:\tlearn: 0.3984084\ttotal: 7.64s\tremaining: 575ms\n",
      "186:\tlearn: 0.3974320\ttotal: 7.69s\tremaining: 535ms\n",
      "187:\tlearn: 0.3972300\ttotal: 7.72s\tremaining: 493ms\n",
      "188:\tlearn: 0.3970753\ttotal: 7.76s\tremaining: 452ms\n",
      "189:\tlearn: 0.3967046\ttotal: 7.8s\tremaining: 411ms\n",
      "190:\tlearn: 0.3957985\ttotal: 7.85s\tremaining: 370ms\n",
      "191:\tlearn: 0.3948291\ttotal: 7.9s\tremaining: 329ms\n",
      "192:\tlearn: 0.3945192\ttotal: 7.93s\tremaining: 288ms\n",
      "193:\tlearn: 0.3939636\ttotal: 7.97s\tremaining: 246ms\n",
      "194:\tlearn: 0.3932975\ttotal: 8s\tremaining: 205ms\n",
      "195:\tlearn: 0.3931910\ttotal: 8.04s\tremaining: 164ms\n",
      "196:\tlearn: 0.3919309\ttotal: 8.08s\tremaining: 123ms\n",
      "197:\tlearn: 0.3917024\ttotal: 8.11s\tremaining: 82ms\n",
      "198:\tlearn: 0.3914625\ttotal: 8.15s\tremaining: 40.9ms\n",
      "199:\tlearn: 0.3911162\ttotal: 8.19s\tremaining: 0us\n",
      "0:\tlearn: 1.8848559\ttotal: 48.8ms\tremaining: 9.72s\n",
      "1:\tlearn: 1.5549957\ttotal: 89.1ms\tremaining: 8.82s\n",
      "2:\tlearn: 1.4022477\ttotal: 124ms\tremaining: 8.14s\n",
      "3:\tlearn: 1.2476357\ttotal: 158ms\tremaining: 7.76s\n",
      "4:\tlearn: 1.1361741\ttotal: 200ms\tremaining: 7.81s\n",
      "5:\tlearn: 1.0813948\ttotal: 236ms\tremaining: 7.61s\n",
      "6:\tlearn: 1.0469191\ttotal: 274ms\tremaining: 7.54s\n",
      "7:\tlearn: 0.9993784\ttotal: 313ms\tremaining: 7.51s\n",
      "8:\tlearn: 0.9548924\ttotal: 357ms\tremaining: 7.58s\n",
      "9:\tlearn: 0.9190057\ttotal: 404ms\tremaining: 7.67s\n",
      "10:\tlearn: 0.8963639\ttotal: 451ms\tremaining: 7.74s\n",
      "11:\tlearn: 0.8719764\ttotal: 495ms\tremaining: 7.76s\n",
      "12:\tlearn: 0.8515393\ttotal: 532ms\tremaining: 7.65s\n",
      "13:\tlearn: 0.8341757\ttotal: 580ms\tremaining: 7.71s\n",
      "14:\tlearn: 0.8183941\ttotal: 620ms\tremaining: 7.65s\n",
      "15:\tlearn: 0.7988227\ttotal: 668ms\tremaining: 7.68s\n",
      "16:\tlearn: 0.7800358\ttotal: 708ms\tremaining: 7.62s\n",
      "17:\tlearn: 0.7634180\ttotal: 755ms\tremaining: 7.63s\n",
      "18:\tlearn: 0.7519515\ttotal: 800ms\tremaining: 7.62s\n",
      "19:\tlearn: 0.7382603\ttotal: 837ms\tremaining: 7.53s\n",
      "20:\tlearn: 0.7237255\ttotal: 878ms\tremaining: 7.48s\n",
      "21:\tlearn: 0.7122259\ttotal: 913ms\tremaining: 7.38s\n",
      "22:\tlearn: 0.7008680\ttotal: 958ms\tremaining: 7.37s\n",
      "23:\tlearn: 0.6902221\ttotal: 994ms\tremaining: 7.29s\n",
      "24:\tlearn: 0.6826637\ttotal: 1.03s\tremaining: 7.23s\n",
      "25:\tlearn: 0.6774936\ttotal: 1.07s\tremaining: 7.17s\n",
      "26:\tlearn: 0.6708397\ttotal: 1.11s\tremaining: 7.13s\n",
      "27:\tlearn: 0.6593400\ttotal: 1.16s\tremaining: 7.12s\n",
      "28:\tlearn: 0.6526211\ttotal: 1.2s\tremaining: 7.1s\n",
      "29:\tlearn: 0.6441020\ttotal: 1.24s\tremaining: 7.03s\n",
      "30:\tlearn: 0.6386812\ttotal: 1.29s\tremaining: 7.02s\n",
      "31:\tlearn: 0.6324780\ttotal: 1.33s\tremaining: 6.97s\n",
      "32:\tlearn: 0.6281617\ttotal: 1.36s\tremaining: 6.89s\n",
      "33:\tlearn: 0.6234609\ttotal: 1.41s\tremaining: 6.86s\n",
      "34:\tlearn: 0.6154425\ttotal: 1.45s\tremaining: 6.81s\n",
      "35:\tlearn: 0.6088129\ttotal: 1.49s\tremaining: 6.78s\n",
      "36:\tlearn: 0.6063166\ttotal: 1.52s\tremaining: 6.7s\n",
      "37:\tlearn: 0.5978882\ttotal: 1.56s\tremaining: 6.66s\n",
      "38:\tlearn: 0.5949962\ttotal: 1.6s\tremaining: 6.59s\n",
      "39:\tlearn: 0.5855861\ttotal: 1.64s\tremaining: 6.58s\n",
      "40:\tlearn: 0.5818000\ttotal: 1.69s\tremaining: 6.54s\n",
      "41:\tlearn: 0.5799099\ttotal: 1.72s\tremaining: 6.48s\n",
      "42:\tlearn: 0.5773687\ttotal: 1.75s\tremaining: 6.41s\n",
      "43:\tlearn: 0.5727760\ttotal: 1.8s\tremaining: 6.38s\n",
      "44:\tlearn: 0.5703810\ttotal: 1.83s\tremaining: 6.32s\n",
      "45:\tlearn: 0.5663332\ttotal: 1.87s\tremaining: 6.26s\n",
      "46:\tlearn: 0.5636925\ttotal: 1.91s\tremaining: 6.2s\n",
      "47:\tlearn: 0.5609492\ttotal: 1.95s\tremaining: 6.16s\n",
      "48:\tlearn: 0.5580420\ttotal: 1.98s\tremaining: 6.1s\n",
      "49:\tlearn: 0.5531303\ttotal: 2.02s\tremaining: 6.07s\n",
      "50:\tlearn: 0.5507185\ttotal: 2.07s\tremaining: 6.05s\n",
      "51:\tlearn: 0.5478515\ttotal: 2.12s\tremaining: 6.02s\n",
      "52:\tlearn: 0.5457618\ttotal: 2.15s\tremaining: 5.96s\n",
      "53:\tlearn: 0.5418238\ttotal: 2.19s\tremaining: 5.93s\n",
      "54:\tlearn: 0.5401352\ttotal: 2.23s\tremaining: 5.88s\n",
      "55:\tlearn: 0.5381053\ttotal: 2.27s\tremaining: 5.83s\n",
      "56:\tlearn: 0.5358999\ttotal: 2.31s\tremaining: 5.8s\n",
      "57:\tlearn: 0.5350996\ttotal: 2.34s\tremaining: 5.74s\n",
      "58:\tlearn: 0.5319285\ttotal: 2.38s\tremaining: 5.7s\n",
      "59:\tlearn: 0.5273763\ttotal: 2.43s\tremaining: 5.67s\n",
      "60:\tlearn: 0.5253778\ttotal: 2.47s\tremaining: 5.63s\n",
      "61:\tlearn: 0.5225271\ttotal: 2.51s\tremaining: 5.58s\n",
      "62:\tlearn: 0.5204938\ttotal: 2.54s\tremaining: 5.53s\n",
      "63:\tlearn: 0.5178152\ttotal: 2.6s\tremaining: 5.51s\n",
      "64:\tlearn: 0.5168256\ttotal: 2.63s\tremaining: 5.46s\n",
      "65:\tlearn: 0.5134723\ttotal: 2.67s\tremaining: 5.42s\n",
      "66:\tlearn: 0.5092048\ttotal: 2.71s\tremaining: 5.39s\n",
      "67:\tlearn: 0.5075732\ttotal: 2.76s\tremaining: 5.37s\n",
      "68:\tlearn: 0.5060896\ttotal: 2.8s\tremaining: 5.32s\n",
      "69:\tlearn: 0.5050911\ttotal: 2.83s\tremaining: 5.26s\n",
      "70:\tlearn: 0.5045044\ttotal: 2.87s\tremaining: 5.21s\n",
      "71:\tlearn: 0.5023971\ttotal: 2.91s\tremaining: 5.17s\n",
      "72:\tlearn: 0.4987602\ttotal: 2.96s\tremaining: 5.16s\n",
      "73:\tlearn: 0.4974069\ttotal: 3.02s\tremaining: 5.14s\n",
      "74:\tlearn: 0.4961567\ttotal: 3.07s\tremaining: 5.11s\n",
      "75:\tlearn: 0.4950185\ttotal: 3.12s\tremaining: 5.09s\n",
      "76:\tlearn: 0.4919222\ttotal: 3.18s\tremaining: 5.07s\n",
      "77:\tlearn: 0.4896734\ttotal: 3.21s\tremaining: 5.03s\n",
      "78:\tlearn: 0.4861611\ttotal: 3.26s\tremaining: 4.99s\n",
      "79:\tlearn: 0.4837060\ttotal: 3.3s\tremaining: 4.95s\n",
      "80:\tlearn: 0.4830984\ttotal: 3.33s\tremaining: 4.89s\n",
      "81:\tlearn: 0.4808416\ttotal: 3.39s\tremaining: 4.88s\n",
      "82:\tlearn: 0.4796376\ttotal: 3.44s\tremaining: 4.85s\n",
      "83:\tlearn: 0.4787908\ttotal: 3.48s\tremaining: 4.81s\n",
      "84:\tlearn: 0.4768036\ttotal: 3.53s\tremaining: 4.78s\n",
      "85:\tlearn: 0.4760887\ttotal: 3.57s\tremaining: 4.73s\n",
      "86:\tlearn: 0.4744569\ttotal: 3.61s\tremaining: 4.69s\n",
      "87:\tlearn: 0.4725603\ttotal: 3.66s\tremaining: 4.66s\n",
      "88:\tlearn: 0.4687873\ttotal: 3.71s\tremaining: 4.62s\n",
      "89:\tlearn: 0.4666960\ttotal: 3.75s\tremaining: 4.59s\n",
      "90:\tlearn: 0.4659517\ttotal: 3.79s\tremaining: 4.54s\n",
      "91:\tlearn: 0.4646222\ttotal: 3.85s\tremaining: 4.52s\n",
      "92:\tlearn: 0.4627535\ttotal: 3.91s\tremaining: 4.5s\n",
      "93:\tlearn: 0.4620502\ttotal: 3.95s\tremaining: 4.46s\n",
      "94:\tlearn: 0.4610435\ttotal: 3.99s\tremaining: 4.41s\n",
      "95:\tlearn: 0.4606506\ttotal: 4.03s\tremaining: 4.36s\n",
      "96:\tlearn: 0.4595431\ttotal: 4.07s\tremaining: 4.32s\n",
      "97:\tlearn: 0.4583582\ttotal: 4.1s\tremaining: 4.27s\n",
      "98:\tlearn: 0.4571612\ttotal: 4.14s\tremaining: 4.22s\n",
      "99:\tlearn: 0.4545488\ttotal: 4.18s\tremaining: 4.18s\n",
      "100:\tlearn: 0.4537475\ttotal: 4.22s\tremaining: 4.14s\n",
      "101:\tlearn: 0.4524470\ttotal: 4.27s\tremaining: 4.1s\n",
      "102:\tlearn: 0.4518007\ttotal: 4.32s\tremaining: 4.07s\n",
      "103:\tlearn: 0.4514251\ttotal: 4.35s\tremaining: 4.02s\n",
      "104:\tlearn: 0.4509834\ttotal: 4.39s\tremaining: 3.97s\n",
      "105:\tlearn: 0.4505517\ttotal: 4.42s\tremaining: 3.92s\n",
      "106:\tlearn: 0.4492990\ttotal: 4.46s\tremaining: 3.88s\n",
      "107:\tlearn: 0.4490096\ttotal: 4.5s\tremaining: 3.83s\n",
      "108:\tlearn: 0.4480113\ttotal: 4.53s\tremaining: 3.79s\n",
      "109:\tlearn: 0.4469218\ttotal: 4.57s\tremaining: 3.74s\n",
      "110:\tlearn: 0.4465419\ttotal: 4.6s\tremaining: 3.69s\n",
      "111:\tlearn: 0.4453659\ttotal: 4.65s\tremaining: 3.65s\n",
      "112:\tlearn: 0.4448578\ttotal: 4.69s\tremaining: 3.61s\n",
      "113:\tlearn: 0.4445289\ttotal: 4.72s\tremaining: 3.56s\n",
      "114:\tlearn: 0.4424403\ttotal: 4.77s\tremaining: 3.52s\n",
      "115:\tlearn: 0.4417818\ttotal: 4.81s\tremaining: 3.48s\n",
      "116:\tlearn: 0.4413428\ttotal: 4.84s\tremaining: 3.43s\n",
      "117:\tlearn: 0.4409110\ttotal: 4.88s\tremaining: 3.39s\n",
      "118:\tlearn: 0.4382266\ttotal: 4.92s\tremaining: 3.35s\n",
      "119:\tlearn: 0.4378653\ttotal: 4.96s\tremaining: 3.31s\n",
      "120:\tlearn: 0.4373558\ttotal: 4.99s\tremaining: 3.26s\n",
      "121:\tlearn: 0.4369245\ttotal: 5.03s\tremaining: 3.21s\n",
      "122:\tlearn: 0.4360583\ttotal: 5.07s\tremaining: 3.18s\n",
      "123:\tlearn: 0.4350133\ttotal: 5.12s\tremaining: 3.14s\n",
      "124:\tlearn: 0.4339664\ttotal: 5.16s\tremaining: 3.1s\n",
      "125:\tlearn: 0.4327589\ttotal: 5.21s\tremaining: 3.06s\n",
      "126:\tlearn: 0.4323950\ttotal: 5.24s\tremaining: 3.01s\n",
      "127:\tlearn: 0.4315831\ttotal: 5.28s\tremaining: 2.97s\n",
      "128:\tlearn: 0.4304872\ttotal: 5.31s\tremaining: 2.92s\n",
      "129:\tlearn: 0.4294223\ttotal: 5.36s\tremaining: 2.88s\n",
      "130:\tlearn: 0.4285255\ttotal: 5.41s\tremaining: 2.85s\n",
      "131:\tlearn: 0.4278805\ttotal: 5.44s\tremaining: 2.8s\n",
      "132:\tlearn: 0.4272790\ttotal: 5.5s\tremaining: 2.77s\n",
      "133:\tlearn: 0.4267872\ttotal: 5.55s\tremaining: 2.73s\n",
      "134:\tlearn: 0.4259052\ttotal: 5.61s\tremaining: 2.7s\n",
      "135:\tlearn: 0.4253692\ttotal: 5.67s\tremaining: 2.67s\n",
      "136:\tlearn: 0.4242199\ttotal: 5.72s\tremaining: 2.63s\n",
      "137:\tlearn: 0.4239354\ttotal: 5.77s\tremaining: 2.59s\n",
      "138:\tlearn: 0.4231595\ttotal: 5.81s\tremaining: 2.55s\n",
      "139:\tlearn: 0.4228401\ttotal: 5.85s\tremaining: 2.51s\n",
      "140:\tlearn: 0.4219550\ttotal: 5.9s\tremaining: 2.47s\n",
      "141:\tlearn: 0.4210888\ttotal: 5.94s\tremaining: 2.42s\n",
      "142:\tlearn: 0.4208281\ttotal: 5.97s\tremaining: 2.38s\n",
      "143:\tlearn: 0.4202754\ttotal: 6.01s\tremaining: 2.34s\n",
      "144:\tlearn: 0.4197215\ttotal: 6.05s\tremaining: 2.29s\n",
      "145:\tlearn: 0.4194455\ttotal: 6.09s\tremaining: 2.25s\n",
      "146:\tlearn: 0.4189155\ttotal: 6.13s\tremaining: 2.21s\n",
      "147:\tlearn: 0.4183676\ttotal: 6.16s\tremaining: 2.17s\n",
      "148:\tlearn: 0.4176026\ttotal: 6.2s\tremaining: 2.12s\n",
      "149:\tlearn: 0.4165636\ttotal: 6.24s\tremaining: 2.08s\n",
      "150:\tlearn: 0.4153371\ttotal: 6.28s\tremaining: 2.04s\n",
      "151:\tlearn: 0.4149369\ttotal: 6.33s\tremaining: 2s\n",
      "152:\tlearn: 0.4142826\ttotal: 6.37s\tremaining: 1.96s\n",
      "153:\tlearn: 0.4138749\ttotal: 6.4s\tremaining: 1.91s\n",
      "154:\tlearn: 0.4133103\ttotal: 6.44s\tremaining: 1.87s\n",
      "155:\tlearn: 0.4128895\ttotal: 6.49s\tremaining: 1.83s\n",
      "156:\tlearn: 0.4117025\ttotal: 6.53s\tremaining: 1.79s\n",
      "157:\tlearn: 0.4111490\ttotal: 6.56s\tremaining: 1.74s\n",
      "158:\tlearn: 0.4102152\ttotal: 6.6s\tremaining: 1.7s\n",
      "159:\tlearn: 0.4092706\ttotal: 6.65s\tremaining: 1.66s\n",
      "160:\tlearn: 0.4089709\ttotal: 6.68s\tremaining: 1.62s\n",
      "161:\tlearn: 0.4083322\ttotal: 6.73s\tremaining: 1.58s\n",
      "162:\tlearn: 0.4078982\ttotal: 6.76s\tremaining: 1.53s\n",
      "163:\tlearn: 0.4070056\ttotal: 6.8s\tremaining: 1.49s\n",
      "164:\tlearn: 0.4057550\ttotal: 6.84s\tremaining: 1.45s\n",
      "165:\tlearn: 0.4048576\ttotal: 6.88s\tremaining: 1.41s\n",
      "166:\tlearn: 0.4045737\ttotal: 6.91s\tremaining: 1.37s\n",
      "167:\tlearn: 0.4041921\ttotal: 6.96s\tremaining: 1.33s\n",
      "168:\tlearn: 0.4033034\ttotal: 7.01s\tremaining: 1.28s\n",
      "169:\tlearn: 0.4028395\ttotal: 7.04s\tremaining: 1.24s\n",
      "170:\tlearn: 0.4014848\ttotal: 7.09s\tremaining: 1.2s\n",
      "171:\tlearn: 0.4003671\ttotal: 7.13s\tremaining: 1.16s\n",
      "172:\tlearn: 0.3998375\ttotal: 7.17s\tremaining: 1.12s\n",
      "173:\tlearn: 0.3991609\ttotal: 7.22s\tremaining: 1.08s\n",
      "174:\tlearn: 0.3986852\ttotal: 7.25s\tremaining: 1.04s\n",
      "175:\tlearn: 0.3977268\ttotal: 7.3s\tremaining: 995ms\n",
      "176:\tlearn: 0.3961854\ttotal: 7.33s\tremaining: 953ms\n",
      "177:\tlearn: 0.3953613\ttotal: 7.38s\tremaining: 913ms\n",
      "178:\tlearn: 0.3941689\ttotal: 7.43s\tremaining: 872ms\n",
      "179:\tlearn: 0.3933740\ttotal: 7.48s\tremaining: 831ms\n",
      "180:\tlearn: 0.3931056\ttotal: 7.51s\tremaining: 789ms\n",
      "181:\tlearn: 0.3923562\ttotal: 7.55s\tremaining: 747ms\n",
      "182:\tlearn: 0.3916795\ttotal: 7.59s\tremaining: 705ms\n",
      "183:\tlearn: 0.3910749\ttotal: 7.63s\tremaining: 663ms\n",
      "184:\tlearn: 0.3900880\ttotal: 7.68s\tremaining: 622ms\n",
      "185:\tlearn: 0.3897518\ttotal: 7.71s\tremaining: 580ms\n",
      "186:\tlearn: 0.3894970\ttotal: 7.75s\tremaining: 538ms\n",
      "187:\tlearn: 0.3891965\ttotal: 7.78s\tremaining: 497ms\n",
      "188:\tlearn: 0.3885553\ttotal: 7.83s\tremaining: 456ms\n",
      "189:\tlearn: 0.3883360\ttotal: 7.86s\tremaining: 414ms\n",
      "190:\tlearn: 0.3880470\ttotal: 7.9s\tremaining: 372ms\n",
      "191:\tlearn: 0.3875225\ttotal: 7.94s\tremaining: 331ms\n",
      "192:\tlearn: 0.3870411\ttotal: 7.99s\tremaining: 290ms\n",
      "193:\tlearn: 0.3865504\ttotal: 8.03s\tremaining: 248ms\n",
      "194:\tlearn: 0.3860337\ttotal: 8.07s\tremaining: 207ms\n",
      "195:\tlearn: 0.3857430\ttotal: 8.11s\tremaining: 165ms\n",
      "196:\tlearn: 0.3855739\ttotal: 8.14s\tremaining: 124ms\n",
      "197:\tlearn: 0.3854494\ttotal: 8.18s\tremaining: 82.6ms\n",
      "198:\tlearn: 0.3848328\ttotal: 8.22s\tremaining: 41.3ms\n",
      "199:\tlearn: 0.3845290\ttotal: 8.26s\tremaining: 0us\n",
      "0:\tlearn: 1.9155414\ttotal: 43.4ms\tremaining: 8.63s\n",
      "1:\tlearn: 1.4969725\ttotal: 82.4ms\tremaining: 8.15s\n",
      "2:\tlearn: 1.3707797\ttotal: 117ms\tremaining: 7.68s\n",
      "3:\tlearn: 1.2806549\ttotal: 150ms\tremaining: 7.35s\n",
      "4:\tlearn: 1.1714322\ttotal: 196ms\tremaining: 7.64s\n",
      "5:\tlearn: 1.0706660\ttotal: 243ms\tremaining: 7.87s\n",
      "6:\tlearn: 1.0035574\ttotal: 291ms\tremaining: 8.04s\n",
      "7:\tlearn: 0.9521157\ttotal: 336ms\tremaining: 8.07s\n",
      "8:\tlearn: 0.8996467\ttotal: 385ms\tremaining: 8.17s\n",
      "9:\tlearn: 0.8653891\ttotal: 435ms\tremaining: 8.27s\n",
      "10:\tlearn: 0.8391918\ttotal: 472ms\tremaining: 8.11s\n",
      "11:\tlearn: 0.8227849\ttotal: 508ms\tremaining: 7.96s\n",
      "12:\tlearn: 0.8074811\ttotal: 544ms\tremaining: 7.82s\n",
      "13:\tlearn: 0.7785301\ttotal: 582ms\tremaining: 7.73s\n",
      "14:\tlearn: 0.7680335\ttotal: 617ms\tremaining: 7.61s\n",
      "15:\tlearn: 0.7598727\ttotal: 654ms\tremaining: 7.52s\n",
      "16:\tlearn: 0.7401163\ttotal: 699ms\tremaining: 7.53s\n",
      "17:\tlearn: 0.7285407\ttotal: 742ms\tremaining: 7.5s\n",
      "18:\tlearn: 0.7135153\ttotal: 796ms\tremaining: 7.58s\n",
      "19:\tlearn: 0.6972458\ttotal: 837ms\tremaining: 7.53s\n",
      "20:\tlearn: 0.6878590\ttotal: 879ms\tremaining: 7.49s\n",
      "21:\tlearn: 0.6848515\ttotal: 914ms\tremaining: 7.39s\n",
      "22:\tlearn: 0.6778936\ttotal: 957ms\tremaining: 7.36s\n",
      "23:\tlearn: 2.4265578\ttotal: 995ms\tremaining: 7.29s\n",
      "24:\tlearn: 9.3774052\ttotal: 1.03s\tremaining: 7.22s\n",
      "25:\tlearn: 8.9754260\ttotal: 1.08s\tremaining: 7.21s\n",
      "26:\tlearn: 8.4166506\ttotal: 1.11s\tremaining: 7.13s\n",
      "27:\tlearn: 7.8815757\ttotal: 1.15s\tremaining: 7.08s\n",
      "28:\tlearn: 7.5630135\ttotal: 1.21s\tremaining: 7.11s\n",
      "29:\tlearn: 6.9269663\ttotal: 1.25s\tremaining: 7.11s\n",
      "30:\tlearn: 6.2969779\ttotal: 1.3s\tremaining: 7.1s\n",
      "31:\tlearn: 5.8928638\ttotal: 1.35s\tremaining: 7.08s\n",
      "32:\tlearn: 5.8825887\ttotal: 1.4s\tremaining: 7.08s\n",
      "33:\tlearn: 5.3967077\ttotal: 1.44s\tremaining: 7.04s\n",
      "34:\tlearn: 4.7863558\ttotal: 1.48s\tremaining: 6.99s\n",
      "35:\tlearn: 4.1879601\ttotal: 1.52s\tremaining: 6.92s\n",
      "36:\tlearn: 5.2184059\ttotal: 1.56s\tremaining: 6.86s\n",
      "37:\tlearn: 8.1246968\ttotal: 1.6s\tremaining: 6.83s\n",
      "38:\tlearn: 8.1184749\ttotal: 1.64s\tremaining: 6.78s\n",
      "39:\tlearn: 7.8103880\ttotal: 1.69s\tremaining: 6.77s\n",
      "40:\tlearn: 7.5112801\ttotal: 1.74s\tremaining: 6.75s\n",
      "41:\tlearn: 7.5002947\ttotal: 1.79s\tremaining: 6.74s\n",
      "42:\tlearn: 7.2579037\ttotal: 1.83s\tremaining: 6.68s\n",
      "43:\tlearn: 7.2512438\ttotal: 1.87s\tremaining: 6.63s\n",
      "44:\tlearn: 6.9105668\ttotal: 1.9s\tremaining: 6.56s\n",
      "45:\tlearn: 6.9017890\ttotal: 1.95s\tremaining: 6.53s\n",
      "46:\tlearn: 6.5970290\ttotal: 1.99s\tremaining: 6.47s\n",
      "47:\tlearn: 6.5927547\ttotal: 2.02s\tremaining: 6.41s\n",
      "48:\tlearn: 6.5892724\ttotal: 2.06s\tremaining: 6.34s\n",
      "49:\tlearn: 6.5871056\ttotal: 2.09s\tremaining: 6.28s\n",
      "50:\tlearn: 6.5817839\ttotal: 2.14s\tremaining: 6.26s\n",
      "51:\tlearn: 6.5757986\ttotal: 2.19s\tremaining: 6.24s\n",
      "52:\tlearn: 6.5736018\ttotal: 2.24s\tremaining: 6.21s\n",
      "53:\tlearn: 6.5639869\ttotal: 2.3s\tremaining: 6.21s\n",
      "54:\tlearn: 6.5609878\ttotal: 2.34s\tremaining: 6.17s\n",
      "55:\tlearn: 6.5487283\ttotal: 2.38s\tremaining: 6.13s\n",
      "56:\tlearn: 6.2925513\ttotal: 2.43s\tremaining: 6.09s\n",
      "57:\tlearn: 6.2891308\ttotal: 2.46s\tremaining: 6.03s\n",
      "58:\tlearn: 6.2822298\ttotal: 2.52s\tremaining: 6.02s\n",
      "59:\tlearn: 6.0181592\ttotal: 2.57s\tremaining: 5.99s\n",
      "60:\tlearn: 6.0097583\ttotal: 2.62s\tremaining: 5.96s\n",
      "61:\tlearn: 5.6263746\ttotal: 2.66s\tremaining: 5.92s\n",
      "62:\tlearn: 5.6223480\ttotal: 2.7s\tremaining: 5.86s\n",
      "63:\tlearn: 5.3419216\ttotal: 2.73s\tremaining: 5.81s\n",
      "64:\tlearn: 5.3360586\ttotal: 2.77s\tremaining: 5.76s\n",
      "65:\tlearn: 5.1996170\ttotal: 2.82s\tremaining: 5.73s\n",
      "66:\tlearn: 5.1964925\ttotal: 2.86s\tremaining: 5.69s\n",
      "67:\tlearn: 5.0035945\ttotal: 2.9s\tremaining: 5.63s\n",
      "68:\tlearn: 4.9996537\ttotal: 2.94s\tremaining: 5.58s\n",
      "69:\tlearn: 4.8189683\ttotal: 2.98s\tremaining: 5.53s\n",
      "70:\tlearn: 4.5946716\ttotal: 3.01s\tremaining: 5.47s\n",
      "71:\tlearn: 4.5861338\ttotal: 3.05s\tremaining: 5.42s\n",
      "72:\tlearn: 4.4134258\ttotal: 3.09s\tremaining: 5.37s\n",
      "73:\tlearn: 4.4095037\ttotal: 3.12s\tremaining: 5.31s\n",
      "74:\tlearn: 4.0582856\ttotal: 3.16s\tremaining: 5.26s\n",
      "75:\tlearn: 3.8996077\ttotal: 3.19s\tremaining: 5.21s\n",
      "76:\tlearn: 3.8957983\ttotal: 3.24s\tremaining: 5.17s\n",
      "77:\tlearn: 3.8492414\ttotal: 3.27s\tremaining: 5.12s\n",
      "78:\tlearn: 3.7532586\ttotal: 3.31s\tremaining: 5.07s\n",
      "79:\tlearn: 3.7188624\ttotal: 3.35s\tremaining: 5.02s\n",
      "80:\tlearn: 3.7133645\ttotal: 3.4s\tremaining: 4.99s\n",
      "81:\tlearn: 3.7114984\ttotal: 3.43s\tremaining: 4.94s\n",
      "82:\tlearn: 3.7048689\ttotal: 3.47s\tremaining: 4.89s\n",
      "83:\tlearn: 3.7008201\ttotal: 3.53s\tremaining: 4.87s\n",
      "84:\tlearn: 3.6982370\ttotal: 3.58s\tremaining: 4.84s\n",
      "85:\tlearn: 3.6954903\ttotal: 3.62s\tremaining: 4.8s\n",
      "86:\tlearn: 3.6927905\ttotal: 3.68s\tremaining: 4.78s\n",
      "87:\tlearn: 3.6910870\ttotal: 3.74s\tremaining: 4.76s\n",
      "88:\tlearn: 3.6309302\ttotal: 3.79s\tremaining: 4.73s\n",
      "89:\tlearn: 3.6269010\ttotal: 3.84s\tremaining: 4.69s\n",
      "90:\tlearn: 3.6258232\ttotal: 3.87s\tremaining: 4.64s\n",
      "91:\tlearn: 3.6243823\ttotal: 3.92s\tremaining: 4.6s\n",
      "92:\tlearn: 3.6219200\ttotal: 3.96s\tremaining: 4.55s\n",
      "93:\tlearn: 3.6206297\ttotal: 3.99s\tremaining: 4.5s\n",
      "94:\tlearn: 3.6188379\ttotal: 4.04s\tremaining: 4.47s\n",
      "95:\tlearn: 3.6175778\ttotal: 4.1s\tremaining: 4.44s\n",
      "96:\tlearn: 3.6159015\ttotal: 4.15s\tremaining: 4.41s\n",
      "97:\tlearn: 3.6107243\ttotal: 4.2s\tremaining: 4.37s\n",
      "98:\tlearn: 3.6088140\ttotal: 4.25s\tremaining: 4.34s\n",
      "99:\tlearn: 3.6059867\ttotal: 4.31s\tremaining: 4.31s\n",
      "100:\tlearn: 3.5924927\ttotal: 4.36s\tremaining: 4.27s\n",
      "101:\tlearn: 3.5885362\ttotal: 4.39s\tremaining: 4.22s\n",
      "102:\tlearn: 3.5548913\ttotal: 4.43s\tremaining: 4.17s\n",
      "103:\tlearn: 3.5050179\ttotal: 4.47s\tremaining: 4.13s\n",
      "104:\tlearn: 3.4744519\ttotal: 4.51s\tremaining: 4.08s\n",
      "105:\tlearn: 3.4722694\ttotal: 4.54s\tremaining: 4.03s\n",
      "106:\tlearn: 3.4713833\ttotal: 4.58s\tremaining: 3.98s\n",
      "107:\tlearn: 3.4684667\ttotal: 4.61s\tremaining: 3.93s\n",
      "108:\tlearn: 3.4666748\ttotal: 4.66s\tremaining: 3.89s\n",
      "109:\tlearn: 3.4657121\ttotal: 4.69s\tremaining: 3.84s\n",
      "110:\tlearn: 3.4569633\ttotal: 4.74s\tremaining: 3.8s\n",
      "111:\tlearn: 3.4554642\ttotal: 4.78s\tremaining: 3.75s\n",
      "112:\tlearn: 3.4537536\ttotal: 4.81s\tremaining: 3.7s\n",
      "113:\tlearn: 3.4508384\ttotal: 4.85s\tremaining: 3.66s\n",
      "114:\tlearn: 3.4489964\ttotal: 4.89s\tremaining: 3.61s\n",
      "115:\tlearn: 3.4479191\ttotal: 4.92s\tremaining: 3.56s\n",
      "116:\tlearn: 3.4451311\ttotal: 4.96s\tremaining: 3.52s\n",
      "117:\tlearn: 3.4435984\ttotal: 5s\tremaining: 3.48s\n",
      "118:\tlearn: 3.4427309\ttotal: 5.04s\tremaining: 3.43s\n",
      "119:\tlearn: 3.4399428\ttotal: 5.08s\tremaining: 3.38s\n",
      "120:\tlearn: 3.4384792\ttotal: 5.12s\tremaining: 3.34s\n",
      "121:\tlearn: 3.4342842\ttotal: 5.19s\tremaining: 3.32s\n",
      "122:\tlearn: 3.4252409\ttotal: 5.24s\tremaining: 3.28s\n",
      "123:\tlearn: 3.4240303\ttotal: 5.29s\tremaining: 3.24s\n",
      "124:\tlearn: 3.4225812\ttotal: 5.34s\tremaining: 3.2s\n",
      "125:\tlearn: 3.4205672\ttotal: 5.4s\tremaining: 3.17s\n",
      "126:\tlearn: 3.4189924\ttotal: 5.44s\tremaining: 3.13s\n",
      "127:\tlearn: 3.4156934\ttotal: 5.49s\tremaining: 3.09s\n",
      "128:\tlearn: 3.4131276\ttotal: 5.54s\tremaining: 3.05s\n",
      "129:\tlearn: 3.4092464\ttotal: 5.58s\tremaining: 3.01s\n",
      "130:\tlearn: 3.4076238\ttotal: 5.63s\tremaining: 2.96s\n",
      "131:\tlearn: 3.4062357\ttotal: 5.66s\tremaining: 2.92s\n",
      "132:\tlearn: 3.4051411\ttotal: 5.7s\tremaining: 2.87s\n",
      "133:\tlearn: 3.4046689\ttotal: 5.73s\tremaining: 2.82s\n",
      "134:\tlearn: 3.4039221\ttotal: 5.76s\tremaining: 2.78s\n",
      "135:\tlearn: 3.4029961\ttotal: 5.82s\tremaining: 2.74s\n",
      "136:\tlearn: 3.4025024\ttotal: 5.87s\tremaining: 2.7s\n",
      "137:\tlearn: 3.4018453\ttotal: 5.92s\tremaining: 2.66s\n",
      "138:\tlearn: 3.4013556\ttotal: 5.96s\tremaining: 2.62s\n",
      "139:\tlearn: 3.4005621\ttotal: 6s\tremaining: 2.57s\n",
      "140:\tlearn: 3.3983609\ttotal: 6.05s\tremaining: 2.53s\n",
      "141:\tlearn: 3.3966408\ttotal: 6.09s\tremaining: 2.49s\n",
      "142:\tlearn: 3.3693354\ttotal: 6.13s\tremaining: 2.44s\n",
      "143:\tlearn: 3.2980206\ttotal: 6.17s\tremaining: 2.4s\n",
      "144:\tlearn: 3.2966576\ttotal: 6.2s\tremaining: 2.35s\n",
      "145:\tlearn: 3.2954584\ttotal: 6.25s\tremaining: 2.31s\n",
      "146:\tlearn: 3.2944523\ttotal: 6.29s\tremaining: 2.27s\n",
      "147:\tlearn: 3.2922823\ttotal: 6.35s\tremaining: 2.23s\n",
      "148:\tlearn: 3.2897454\ttotal: 6.4s\tremaining: 2.19s\n",
      "149:\tlearn: 3.2882426\ttotal: 6.45s\tremaining: 2.15s\n",
      "150:\tlearn: 3.2875675\ttotal: 6.49s\tremaining: 2.1s\n",
      "151:\tlearn: 3.2864404\ttotal: 6.54s\tremaining: 2.06s\n",
      "152:\tlearn: 3.2858452\ttotal: 6.58s\tremaining: 2.02s\n",
      "153:\tlearn: 3.2840572\ttotal: 6.63s\tremaining: 1.98s\n",
      "154:\tlearn: 3.2831348\ttotal: 6.67s\tremaining: 1.94s\n",
      "155:\tlearn: 3.2792537\ttotal: 6.73s\tremaining: 1.9s\n",
      "156:\tlearn: 3.2779445\ttotal: 6.76s\tremaining: 1.85s\n",
      "157:\tlearn: 3.2774854\ttotal: 6.8s\tremaining: 1.81s\n",
      "158:\tlearn: 3.2753067\ttotal: 6.83s\tremaining: 1.76s\n",
      "159:\tlearn: 3.2747034\ttotal: 6.87s\tremaining: 1.72s\n",
      "160:\tlearn: 3.2732417\ttotal: 6.91s\tremaining: 1.67s\n",
      "161:\tlearn: 3.2603166\ttotal: 6.94s\tremaining: 1.63s\n",
      "162:\tlearn: 3.2588488\ttotal: 6.98s\tremaining: 1.58s\n",
      "163:\tlearn: 3.2566459\ttotal: 7.02s\tremaining: 1.54s\n",
      "164:\tlearn: 3.2555669\ttotal: 7.06s\tremaining: 1.5s\n",
      "165:\tlearn: 3.2538759\ttotal: 7.13s\tremaining: 1.46s\n",
      "166:\tlearn: 3.2532709\ttotal: 7.17s\tremaining: 1.42s\n",
      "167:\tlearn: 3.2193168\ttotal: 7.22s\tremaining: 1.38s\n",
      "168:\tlearn: 3.2185242\ttotal: 7.25s\tremaining: 1.33s\n",
      "169:\tlearn: 3.2175695\ttotal: 7.29s\tremaining: 1.29s\n",
      "170:\tlearn: 3.2169806\ttotal: 7.33s\tremaining: 1.24s\n",
      "171:\tlearn: 3.2155092\ttotal: 7.38s\tremaining: 1.2s\n",
      "172:\tlearn: 3.2149656\ttotal: 7.41s\tremaining: 1.16s\n",
      "173:\tlearn: 3.2142579\ttotal: 7.46s\tremaining: 1.11s\n",
      "174:\tlearn: 3.2127261\ttotal: 7.49s\tremaining: 1.07s\n",
      "175:\tlearn: 3.2120069\ttotal: 7.53s\tremaining: 1.03s\n",
      "176:\tlearn: 3.2112457\ttotal: 7.57s\tremaining: 983ms\n",
      "177:\tlearn: 3.2101344\ttotal: 7.6s\tremaining: 939ms\n",
      "178:\tlearn: 3.2097628\ttotal: 7.64s\tremaining: 896ms\n",
      "179:\tlearn: 3.2084565\ttotal: 7.7s\tremaining: 855ms\n",
      "180:\tlearn: 3.2059225\ttotal: 7.75s\tremaining: 813ms\n",
      "181:\tlearn: 3.2036751\ttotal: 7.81s\tremaining: 772ms\n",
      "182:\tlearn: 3.1715293\ttotal: 7.85s\tremaining: 729ms\n",
      "183:\tlearn: 3.1683721\ttotal: 7.89s\tremaining: 687ms\n",
      "184:\tlearn: 3.1671497\ttotal: 7.93s\tremaining: 643ms\n",
      "185:\tlearn: 3.1174335\ttotal: 7.98s\tremaining: 601ms\n",
      "186:\tlearn: 3.0875510\ttotal: 8.02s\tremaining: 557ms\n",
      "187:\tlearn: 3.0864532\ttotal: 8.06s\tremaining: 515ms\n",
      "188:\tlearn: 2.9156742\ttotal: 8.11s\tremaining: 472ms\n",
      "189:\tlearn: 2.9103850\ttotal: 8.17s\tremaining: 430ms\n",
      "190:\tlearn: 2.8941144\ttotal: 8.22s\tremaining: 387ms\n",
      "191:\tlearn: 2.8645386\ttotal: 8.27s\tremaining: 344ms\n",
      "192:\tlearn: 2.8324444\ttotal: 8.3s\tremaining: 301ms\n",
      "193:\tlearn: 2.6136013\ttotal: 8.35s\tremaining: 258ms\n",
      "194:\tlearn: 2.6129495\ttotal: 8.38s\tremaining: 215ms\n",
      "195:\tlearn: 2.6125523\ttotal: 8.41s\tremaining: 172ms\n",
      "196:\tlearn: 2.6117159\ttotal: 8.46s\tremaining: 129ms\n",
      "197:\tlearn: 2.6112082\ttotal: 8.49s\tremaining: 85.8ms\n",
      "198:\tlearn: 2.5779240\ttotal: 8.53s\tremaining: 42.8ms\n",
      "199:\tlearn: 2.5770212\ttotal: 8.58s\tremaining: 0us\n",
      "0:\tlearn: 1.9728942\ttotal: 42.8ms\tremaining: 8.52s\n",
      "1:\tlearn: 1.5743907\ttotal: 81.5ms\tremaining: 8.07s\n",
      "2:\tlearn: 1.4035716\ttotal: 116ms\tremaining: 7.61s\n",
      "3:\tlearn: 1.2718791\ttotal: 151ms\tremaining: 7.39s\n",
      "4:\tlearn: 1.1924597\ttotal: 192ms\tremaining: 7.51s\n",
      "5:\tlearn: 1.0872659\ttotal: 240ms\tremaining: 7.76s\n",
      "6:\tlearn: 1.0338429\ttotal: 281ms\tremaining: 7.75s\n",
      "7:\tlearn: 0.9786056\ttotal: 321ms\tremaining: 7.71s\n",
      "8:\tlearn: 1.0188792\ttotal: 363ms\tremaining: 7.7s\n",
      "9:\tlearn: 0.9277885\ttotal: 400ms\tremaining: 7.6s\n",
      "10:\tlearn: 0.8929927\ttotal: 445ms\tremaining: 7.64s\n",
      "11:\tlearn: 0.8686064\ttotal: 493ms\tremaining: 7.72s\n",
      "12:\tlearn: 0.8459450\ttotal: 542ms\tremaining: 7.79s\n",
      "13:\tlearn: 0.8268179\ttotal: 588ms\tremaining: 7.81s\n",
      "14:\tlearn: 0.8048642\ttotal: 622ms\tremaining: 7.67s\n",
      "15:\tlearn: 0.7829528\ttotal: 665ms\tremaining: 7.64s\n",
      "16:\tlearn: 0.7732590\ttotal: 708ms\tremaining: 7.62s\n",
      "17:\tlearn: 0.7623329\ttotal: 748ms\tremaining: 7.57s\n",
      "18:\tlearn: 0.7458578\ttotal: 789ms\tremaining: 7.51s\n",
      "19:\tlearn: 0.7332818\ttotal: 828ms\tremaining: 7.45s\n",
      "20:\tlearn: 0.7233125\ttotal: 863ms\tremaining: 7.36s\n",
      "21:\tlearn: 0.7139192\ttotal: 905ms\tremaining: 7.33s\n",
      "22:\tlearn: 0.6976049\ttotal: 941ms\tremaining: 7.24s\n",
      "23:\tlearn: 0.6886449\ttotal: 978ms\tremaining: 7.17s\n",
      "24:\tlearn: 0.6778566\ttotal: 1.02s\tremaining: 7.14s\n",
      "25:\tlearn: 0.6679564\ttotal: 1.05s\tremaining: 7.06s\n",
      "26:\tlearn: 0.6539480\ttotal: 1.1s\tremaining: 7.07s\n",
      "27:\tlearn: 0.6469826\ttotal: 1.14s\tremaining: 7s\n",
      "28:\tlearn: 0.6411270\ttotal: 1.17s\tremaining: 6.92s\n",
      "29:\tlearn: 0.6352875\ttotal: 1.22s\tremaining: 6.91s\n",
      "30:\tlearn: 0.6304245\ttotal: 1.25s\tremaining: 6.85s\n",
      "31:\tlearn: 0.6251654\ttotal: 1.3s\tremaining: 6.81s\n",
      "32:\tlearn: 0.6193801\ttotal: 1.34s\tremaining: 6.78s\n",
      "33:\tlearn: 0.6128602\ttotal: 1.38s\tremaining: 6.73s\n",
      "34:\tlearn: 0.6084042\ttotal: 1.42s\tremaining: 6.69s\n",
      "35:\tlearn: 0.6060606\ttotal: 1.46s\tremaining: 6.64s\n",
      "36:\tlearn: 0.6036634\ttotal: 1.5s\tremaining: 6.59s\n",
      "37:\tlearn: 0.5969902\ttotal: 1.54s\tremaining: 6.55s\n",
      "38:\tlearn: 0.5912307\ttotal: 1.57s\tremaining: 6.5s\n",
      "39:\tlearn: 0.5884477\ttotal: 1.61s\tremaining: 6.44s\n",
      "40:\tlearn: 0.5857831\ttotal: 1.64s\tremaining: 6.37s\n",
      "41:\tlearn: 0.5802621\ttotal: 1.69s\tremaining: 6.36s\n",
      "42:\tlearn: 0.5741529\ttotal: 1.73s\tremaining: 6.33s\n",
      "43:\tlearn: 0.5723145\ttotal: 1.77s\tremaining: 6.28s\n",
      "44:\tlearn: 0.5669041\ttotal: 1.8s\tremaining: 6.21s\n",
      "45:\tlearn: 0.5659493\ttotal: 1.84s\tremaining: 6.15s\n",
      "46:\tlearn: 0.5633825\ttotal: 1.87s\tremaining: 6.1s\n",
      "47:\tlearn: 0.5606708\ttotal: 1.92s\tremaining: 6.08s\n",
      "48:\tlearn: 0.5587442\ttotal: 1.97s\tremaining: 6.06s\n",
      "49:\tlearn: 0.5559305\ttotal: 2.02s\tremaining: 6.06s\n",
      "50:\tlearn: 0.5551558\ttotal: 2.07s\tremaining: 6.05s\n",
      "51:\tlearn: 0.5527420\ttotal: 2.13s\tremaining: 6.06s\n",
      "52:\tlearn: 0.5459324\ttotal: 2.18s\tremaining: 6.04s\n",
      "53:\tlearn: 0.5438685\ttotal: 2.21s\tremaining: 5.98s\n",
      "54:\tlearn: 0.5390658\ttotal: 2.26s\tremaining: 5.96s\n",
      "55:\tlearn: 0.5346173\ttotal: 2.3s\tremaining: 5.91s\n",
      "56:\tlearn: 0.5331877\ttotal: 2.34s\tremaining: 5.87s\n",
      "57:\tlearn: 0.5302485\ttotal: 2.39s\tremaining: 5.84s\n",
      "58:\tlearn: 0.5238510\ttotal: 2.43s\tremaining: 5.81s\n",
      "59:\tlearn: 0.5221987\ttotal: 2.46s\tremaining: 5.75s\n",
      "60:\tlearn: 0.5200096\ttotal: 2.5s\tremaining: 5.71s\n",
      "61:\tlearn: 0.5165949\ttotal: 2.55s\tremaining: 5.67s\n",
      "62:\tlearn: 0.5149437\ttotal: 2.58s\tremaining: 5.62s\n",
      "63:\tlearn: 0.5109806\ttotal: 2.62s\tremaining: 5.58s\n",
      "64:\tlearn: 0.5092894\ttotal: 2.67s\tremaining: 5.55s\n",
      "65:\tlearn: 0.5070958\ttotal: 2.71s\tremaining: 5.5s\n",
      "66:\tlearn: 0.5061947\ttotal: 2.74s\tremaining: 5.45s\n",
      "67:\tlearn: 0.5036785\ttotal: 2.78s\tremaining: 5.39s\n",
      "68:\tlearn: 0.5010188\ttotal: 2.82s\tremaining: 5.36s\n",
      "69:\tlearn: 0.5002279\ttotal: 2.86s\tremaining: 5.3s\n",
      "70:\tlearn: 0.4988038\ttotal: 2.89s\tremaining: 5.25s\n",
      "71:\tlearn: 0.4965390\ttotal: 2.94s\tremaining: 5.22s\n",
      "72:\tlearn: 0.4955953\ttotal: 2.97s\tremaining: 5.17s\n",
      "73:\tlearn: 0.4940673\ttotal: 3s\tremaining: 5.12s\n",
      "74:\tlearn: 0.4920358\ttotal: 3.04s\tremaining: 5.07s\n",
      "75:\tlearn: 0.4913907\ttotal: 3.08s\tremaining: 5.02s\n",
      "76:\tlearn: 0.4903718\ttotal: 3.13s\tremaining: 4.99s\n",
      "77:\tlearn: 0.4898770\ttotal: 3.16s\tremaining: 4.94s\n",
      "78:\tlearn: 0.4892447\ttotal: 3.2s\tremaining: 4.9s\n",
      "79:\tlearn: 0.4879079\ttotal: 3.24s\tremaining: 4.86s\n",
      "80:\tlearn: 0.4873030\ttotal: 3.27s\tremaining: 4.81s\n",
      "81:\tlearn: 0.4857415\ttotal: 3.31s\tremaining: 4.77s\n",
      "82:\tlearn: 0.4850539\ttotal: 3.35s\tremaining: 4.72s\n",
      "83:\tlearn: 0.4832566\ttotal: 3.39s\tremaining: 4.68s\n",
      "84:\tlearn: 0.4816093\ttotal: 3.44s\tremaining: 4.65s\n",
      "85:\tlearn: 0.4806946\ttotal: 3.47s\tremaining: 4.6s\n",
      "86:\tlearn: 0.4777343\ttotal: 3.52s\tremaining: 4.57s\n",
      "87:\tlearn: 0.4761939\ttotal: 3.55s\tremaining: 4.52s\n",
      "88:\tlearn: 0.4755181\ttotal: 3.59s\tremaining: 4.47s\n",
      "89:\tlearn: 0.4742180\ttotal: 3.63s\tremaining: 4.43s\n",
      "90:\tlearn: 0.4722960\ttotal: 3.67s\tremaining: 4.39s\n",
      "91:\tlearn: 0.4713513\ttotal: 3.7s\tremaining: 4.34s\n",
      "92:\tlearn: 0.4693906\ttotal: 3.74s\tremaining: 4.31s\n",
      "93:\tlearn: 0.4689047\ttotal: 3.78s\tremaining: 4.26s\n",
      "94:\tlearn: 0.4676217\ttotal: 3.82s\tremaining: 4.22s\n",
      "95:\tlearn: 0.4671423\ttotal: 3.86s\tremaining: 4.18s\n",
      "96:\tlearn: 0.4661639\ttotal: 3.9s\tremaining: 4.14s\n",
      "97:\tlearn: 0.4643651\ttotal: 3.94s\tremaining: 4.11s\n",
      "98:\tlearn: 0.4635956\ttotal: 3.99s\tremaining: 4.07s\n",
      "99:\tlearn: 0.4627888\ttotal: 4.03s\tremaining: 4.03s\n",
      "100:\tlearn: 0.4613760\ttotal: 4.07s\tremaining: 3.99s\n",
      "101:\tlearn: 0.4606592\ttotal: 4.1s\tremaining: 3.94s\n",
      "102:\tlearn: 0.4595485\ttotal: 4.14s\tremaining: 3.9s\n",
      "103:\tlearn: 0.4587245\ttotal: 4.19s\tremaining: 3.87s\n",
      "104:\tlearn: 0.4579037\ttotal: 4.22s\tremaining: 3.82s\n",
      "105:\tlearn: 0.4575195\ttotal: 4.25s\tremaining: 3.77s\n",
      "106:\tlearn: 0.4550949\ttotal: 4.3s\tremaining: 3.74s\n",
      "107:\tlearn: 0.4546984\ttotal: 4.34s\tremaining: 3.69s\n",
      "108:\tlearn: 0.4540867\ttotal: 4.38s\tremaining: 3.66s\n",
      "109:\tlearn: 0.4532915\ttotal: 4.42s\tremaining: 3.62s\n",
      "110:\tlearn: 0.4522526\ttotal: 4.46s\tremaining: 3.57s\n",
      "111:\tlearn: 0.4491562\ttotal: 4.5s\tremaining: 3.54s\n",
      "112:\tlearn: 0.4469966\ttotal: 4.56s\tremaining: 3.51s\n",
      "113:\tlearn: 0.4465313\ttotal: 4.6s\tremaining: 3.47s\n",
      "114:\tlearn: 0.4460146\ttotal: 4.65s\tremaining: 3.44s\n",
      "115:\tlearn: 0.4456167\ttotal: 4.69s\tremaining: 3.39s\n",
      "116:\tlearn: 0.4440475\ttotal: 4.73s\tremaining: 3.36s\n",
      "117:\tlearn: 0.4435091\ttotal: 4.77s\tremaining: 3.31s\n",
      "118:\tlearn: 0.4424156\ttotal: 4.81s\tremaining: 3.27s\n",
      "119:\tlearn: 0.4418622\ttotal: 4.84s\tremaining: 3.23s\n",
      "120:\tlearn: 0.4411506\ttotal: 4.88s\tremaining: 3.18s\n",
      "121:\tlearn: 0.4404091\ttotal: 4.91s\tremaining: 3.14s\n",
      "122:\tlearn: 0.4390857\ttotal: 4.96s\tremaining: 3.1s\n",
      "123:\tlearn: 0.4383377\ttotal: 4.99s\tremaining: 3.06s\n",
      "124:\tlearn: 0.4375324\ttotal: 5.03s\tremaining: 3.02s\n",
      "125:\tlearn: 0.4357297\ttotal: 5.07s\tremaining: 2.98s\n",
      "126:\tlearn: 0.4348047\ttotal: 5.11s\tremaining: 2.94s\n",
      "127:\tlearn: 0.4338712\ttotal: 5.15s\tremaining: 2.9s\n",
      "128:\tlearn: 0.4329368\ttotal: 5.19s\tremaining: 2.86s\n",
      "129:\tlearn: 0.4323625\ttotal: 5.23s\tremaining: 2.81s\n",
      "130:\tlearn: 0.4320112\ttotal: 5.26s\tremaining: 2.77s\n",
      "131:\tlearn: 0.4316061\ttotal: 5.3s\tremaining: 2.73s\n",
      "132:\tlearn: 0.4309536\ttotal: 5.33s\tremaining: 2.69s\n",
      "133:\tlearn: 0.4305894\ttotal: 5.37s\tremaining: 2.65s\n",
      "134:\tlearn: 0.4290169\ttotal: 5.42s\tremaining: 2.61s\n",
      "135:\tlearn: 0.4285918\ttotal: 5.45s\tremaining: 2.56s\n",
      "136:\tlearn: 0.4278775\ttotal: 5.48s\tremaining: 2.52s\n",
      "137:\tlearn: 0.4273257\ttotal: 5.52s\tremaining: 2.48s\n",
      "138:\tlearn: 0.4255172\ttotal: 5.57s\tremaining: 2.44s\n",
      "139:\tlearn: 0.4249171\ttotal: 5.61s\tremaining: 2.41s\n",
      "140:\tlearn: 0.4245573\ttotal: 5.65s\tremaining: 2.36s\n",
      "141:\tlearn: 0.4232057\ttotal: 5.69s\tremaining: 2.33s\n",
      "142:\tlearn: 0.4220589\ttotal: 5.74s\tremaining: 2.29s\n",
      "143:\tlearn: 0.4200199\ttotal: 5.78s\tremaining: 2.25s\n",
      "144:\tlearn: 0.4193544\ttotal: 5.82s\tremaining: 2.21s\n",
      "145:\tlearn: 0.4187848\ttotal: 5.86s\tremaining: 2.17s\n",
      "146:\tlearn: 0.4186666\ttotal: 5.9s\tremaining: 2.13s\n",
      "147:\tlearn: 0.4174545\ttotal: 5.95s\tremaining: 2.09s\n",
      "148:\tlearn: 0.4166641\ttotal: 5.99s\tremaining: 2.05s\n",
      "149:\tlearn: 0.4158939\ttotal: 6.03s\tremaining: 2.01s\n",
      "150:\tlearn: 0.4149651\ttotal: 6.07s\tremaining: 1.97s\n",
      "151:\tlearn: 0.4144181\ttotal: 6.11s\tremaining: 1.93s\n",
      "152:\tlearn: 0.4136353\ttotal: 6.15s\tremaining: 1.89s\n",
      "153:\tlearn: 0.4130909\ttotal: 6.18s\tremaining: 1.85s\n",
      "154:\tlearn: 0.4128369\ttotal: 6.22s\tremaining: 1.8s\n",
      "155:\tlearn: 0.4124218\ttotal: 6.25s\tremaining: 1.76s\n",
      "156:\tlearn: 0.4117802\ttotal: 6.29s\tremaining: 1.72s\n",
      "157:\tlearn: 0.4112411\ttotal: 6.33s\tremaining: 1.68s\n",
      "158:\tlearn: 0.4108742\ttotal: 6.37s\tremaining: 1.64s\n",
      "159:\tlearn: 0.4103486\ttotal: 6.4s\tremaining: 1.6s\n",
      "160:\tlearn: 0.4098916\ttotal: 6.44s\tremaining: 1.56s\n",
      "161:\tlearn: 0.4097634\ttotal: 6.47s\tremaining: 1.52s\n",
      "162:\tlearn: 0.4092276\ttotal: 6.51s\tremaining: 1.48s\n",
      "163:\tlearn: 0.4087229\ttotal: 6.54s\tremaining: 1.44s\n",
      "164:\tlearn: 0.4077997\ttotal: 6.58s\tremaining: 1.4s\n",
      "165:\tlearn: 0.4067956\ttotal: 6.63s\tremaining: 1.36s\n",
      "166:\tlearn: 0.4060986\ttotal: 6.67s\tremaining: 1.32s\n",
      "167:\tlearn: 0.4053808\ttotal: 6.7s\tremaining: 1.28s\n",
      "168:\tlearn: 0.4050711\ttotal: 6.74s\tremaining: 1.24s\n",
      "169:\tlearn: 0.4044397\ttotal: 6.79s\tremaining: 1.2s\n",
      "170:\tlearn: 0.4033753\ttotal: 6.83s\tremaining: 1.16s\n",
      "171:\tlearn: 0.4026938\ttotal: 6.87s\tremaining: 1.12s\n",
      "172:\tlearn: 0.4023133\ttotal: 6.9s\tremaining: 1.08s\n",
      "173:\tlearn: 0.4016534\ttotal: 6.95s\tremaining: 1.04s\n",
      "174:\tlearn: 0.4010870\ttotal: 6.99s\tremaining: 998ms\n",
      "175:\tlearn: 0.4005867\ttotal: 7.03s\tremaining: 958ms\n",
      "176:\tlearn: 0.4004111\ttotal: 7.06s\tremaining: 918ms\n",
      "177:\tlearn: 0.4001785\ttotal: 7.09s\tremaining: 877ms\n",
      "178:\tlearn: 0.3996023\ttotal: 7.13s\tremaining: 836ms\n",
      "179:\tlearn: 0.3987210\ttotal: 7.17s\tremaining: 797ms\n",
      "180:\tlearn: 0.3984373\ttotal: 7.21s\tremaining: 756ms\n",
      "181:\tlearn: 0.3966223\ttotal: 7.24s\tremaining: 716ms\n",
      "182:\tlearn: 0.3963306\ttotal: 7.27s\tremaining: 676ms\n",
      "183:\tlearn: 0.3962352\ttotal: 7.31s\tremaining: 635ms\n",
      "184:\tlearn: 0.3955394\ttotal: 7.34s\tremaining: 595ms\n",
      "185:\tlearn: 0.3945161\ttotal: 7.38s\tremaining: 556ms\n",
      "186:\tlearn: 0.3933788\ttotal: 7.42s\tremaining: 516ms\n",
      "187:\tlearn: 0.3930582\ttotal: 7.46s\tremaining: 476ms\n",
      "188:\tlearn: 0.3923664\ttotal: 7.5s\tremaining: 437ms\n",
      "189:\tlearn: 0.3917918\ttotal: 7.55s\tremaining: 397ms\n",
      "190:\tlearn: 0.3897563\ttotal: 7.59s\tremaining: 358ms\n",
      "191:\tlearn: 0.3885890\ttotal: 7.63s\tremaining: 318ms\n",
      "192:\tlearn: 0.3878592\ttotal: 7.67s\tremaining: 278ms\n",
      "193:\tlearn: 0.3869592\ttotal: 7.71s\tremaining: 238ms\n",
      "194:\tlearn: 0.3866029\ttotal: 7.74s\tremaining: 198ms\n",
      "195:\tlearn: 0.3863701\ttotal: 7.77s\tremaining: 159ms\n",
      "196:\tlearn: 0.3858734\ttotal: 7.81s\tremaining: 119ms\n",
      "197:\tlearn: 0.3850982\ttotal: 7.86s\tremaining: 79.4ms\n",
      "198:\tlearn: 0.3844577\ttotal: 7.9s\tremaining: 39.7ms\n",
      "199:\tlearn: 0.3838327\ttotal: 7.93s\tremaining: 0us\n",
      "0:\tlearn: 1.9740091\ttotal: 96.9ms\tremaining: 19.3s\n",
      "1:\tlearn: 1.5796705\ttotal: 142ms\tremaining: 14.1s\n",
      "2:\tlearn: 1.4104517\ttotal: 184ms\tremaining: 12.1s\n",
      "3:\tlearn: 1.2653408\ttotal: 221ms\tremaining: 10.8s\n",
      "4:\tlearn: 1.1855630\ttotal: 267ms\tremaining: 10.4s\n",
      "5:\tlearn: 1.0800257\ttotal: 313ms\tremaining: 10.1s\n",
      "6:\tlearn: 1.0240466\ttotal: 359ms\tremaining: 9.9s\n",
      "7:\tlearn: 0.9678568\ttotal: 407ms\tremaining: 9.76s\n",
      "8:\tlearn: 0.9332587\ttotal: 458ms\tremaining: 9.72s\n",
      "9:\tlearn: 0.9047029\ttotal: 506ms\tremaining: 9.62s\n",
      "10:\tlearn: 0.8776080\ttotal: 546ms\tremaining: 9.39s\n",
      "11:\tlearn: 0.8403938\ttotal: 596ms\tremaining: 9.34s\n",
      "12:\tlearn: 0.8200677\ttotal: 647ms\tremaining: 9.31s\n",
      "13:\tlearn: 0.7974067\ttotal: 695ms\tremaining: 9.23s\n",
      "14:\tlearn: 0.7796228\ttotal: 732ms\tremaining: 9.03s\n",
      "15:\tlearn: 0.7750726\ttotal: 774ms\tremaining: 8.9s\n",
      "16:\tlearn: 0.7436266\ttotal: 819ms\tremaining: 8.81s\n",
      "17:\tlearn: 0.7245391\ttotal: 867ms\tremaining: 8.77s\n",
      "18:\tlearn: 0.7139764\ttotal: 905ms\tremaining: 8.63s\n",
      "19:\tlearn: 0.7020607\ttotal: 955ms\tremaining: 8.59s\n",
      "20:\tlearn: 0.6932765\ttotal: 993ms\tremaining: 8.46s\n",
      "21:\tlearn: 0.6818193\ttotal: 1.04s\tremaining: 8.45s\n",
      "22:\tlearn: 0.6673020\ttotal: 1.08s\tremaining: 8.32s\n",
      "23:\tlearn: 0.6606854\ttotal: 1.11s\tremaining: 8.18s\n",
      "24:\tlearn: 0.6510309\ttotal: 1.16s\tremaining: 8.14s\n",
      "25:\tlearn: 0.6468226\ttotal: 1.2s\tremaining: 8.03s\n",
      "26:\tlearn: 0.6422220\ttotal: 1.24s\tremaining: 7.92s\n",
      "27:\tlearn: 0.6346341\ttotal: 1.27s\tremaining: 7.81s\n",
      "28:\tlearn: 0.6313354\ttotal: 1.31s\tremaining: 7.71s\n",
      "29:\tlearn: 0.6231194\ttotal: 1.35s\tremaining: 7.67s\n",
      "30:\tlearn: 0.6126287\ttotal: 1.4s\tremaining: 7.66s\n",
      "31:\tlearn: 0.6072379\ttotal: 1.45s\tremaining: 7.6s\n",
      "32:\tlearn: 0.6029206\ttotal: 1.5s\tremaining: 7.57s\n",
      "33:\tlearn: 0.6001159\ttotal: 1.53s\tremaining: 7.48s\n",
      "34:\tlearn: 0.5917683\ttotal: 1.58s\tremaining: 7.45s\n",
      "35:\tlearn: 0.5894889\ttotal: 1.62s\tremaining: 7.4s\n",
      "36:\tlearn: 0.5860175\ttotal: 1.67s\tremaining: 7.37s\n",
      "37:\tlearn: 0.5807961\ttotal: 1.72s\tremaining: 7.34s\n",
      "38:\tlearn: 0.5779734\ttotal: 1.76s\tremaining: 7.26s\n",
      "39:\tlearn: 0.5737482\ttotal: 1.81s\tremaining: 7.23s\n",
      "40:\tlearn: 0.5702743\ttotal: 1.85s\tremaining: 7.18s\n",
      "41:\tlearn: 0.5689355\ttotal: 1.89s\tremaining: 7.1s\n",
      "42:\tlearn: 0.5671406\ttotal: 1.93s\tremaining: 7.03s\n",
      "43:\tlearn: 0.5639991\ttotal: 1.96s\tremaining: 6.96s\n",
      "44:\tlearn: 0.5630879\ttotal: 2s\tremaining: 6.88s\n",
      "45:\tlearn: 0.5588995\ttotal: 2.03s\tremaining: 6.8s\n",
      "46:\tlearn: 0.5567358\ttotal: 2.07s\tremaining: 6.73s\n",
      "47:\tlearn: 0.5539073\ttotal: 2.11s\tremaining: 6.69s\n",
      "48:\tlearn: 0.5488129\ttotal: 2.15s\tremaining: 6.64s\n",
      "49:\tlearn: 0.5475431\ttotal: 2.19s\tremaining: 6.57s\n",
      "50:\tlearn: 0.5456751\ttotal: 2.23s\tremaining: 6.51s\n",
      "51:\tlearn: 0.5434263\ttotal: 2.27s\tremaining: 6.47s\n",
      "52:\tlearn: 0.5359980\ttotal: 2.32s\tremaining: 6.43s\n",
      "53:\tlearn: 0.5331816\ttotal: 2.36s\tremaining: 6.37s\n",
      "54:\tlearn: 0.5313094\ttotal: 2.4s\tremaining: 6.32s\n",
      "55:\tlearn: 0.5302576\ttotal: 2.46s\tremaining: 6.32s\n",
      "56:\tlearn: 0.5272983\ttotal: 2.51s\tremaining: 6.3s\n",
      "57:\tlearn: 0.5254131\ttotal: 2.55s\tremaining: 6.24s\n",
      "58:\tlearn: 0.5241064\ttotal: 2.58s\tremaining: 6.17s\n",
      "59:\tlearn: 0.5224020\ttotal: 2.62s\tremaining: 6.11s\n",
      "60:\tlearn: 0.5178685\ttotal: 2.65s\tremaining: 6.05s\n",
      "61:\tlearn: 0.5171182\ttotal: 2.69s\tremaining: 5.98s\n",
      "62:\tlearn: 0.5145148\ttotal: 2.72s\tremaining: 5.92s\n",
      "63:\tlearn: 0.5123234\ttotal: 2.77s\tremaining: 5.88s\n",
      "64:\tlearn: 0.5091653\ttotal: 2.81s\tremaining: 5.84s\n",
      "65:\tlearn: 0.5073812\ttotal: 2.85s\tremaining: 5.8s\n",
      "66:\tlearn: 0.5052297\ttotal: 2.9s\tremaining: 5.77s\n",
      "67:\tlearn: 0.5045479\ttotal: 2.94s\tremaining: 5.71s\n",
      "68:\tlearn: 0.5026964\ttotal: 2.98s\tremaining: 5.65s\n",
      "69:\tlearn: 0.5008030\ttotal: 3.02s\tremaining: 5.61s\n",
      "70:\tlearn: 0.4998434\ttotal: 3.06s\tremaining: 5.57s\n",
      "71:\tlearn: 0.4982610\ttotal: 3.11s\tremaining: 5.53s\n",
      "72:\tlearn: 0.4943911\ttotal: 3.15s\tremaining: 5.49s\n",
      "73:\tlearn: 0.4920271\ttotal: 3.2s\tremaining: 5.45s\n",
      "74:\tlearn: 0.4898332\ttotal: 3.24s\tremaining: 5.4s\n",
      "75:\tlearn: 0.4884220\ttotal: 3.27s\tremaining: 5.34s\n",
      "76:\tlearn: 0.4863920\ttotal: 3.32s\tremaining: 5.3s\n",
      "77:\tlearn: 0.4853563\ttotal: 3.36s\tremaining: 5.26s\n",
      "78:\tlearn: 0.4843221\ttotal: 3.4s\tremaining: 5.2s\n",
      "79:\tlearn: 0.4829012\ttotal: 3.44s\tremaining: 5.17s\n",
      "80:\tlearn: 0.4807803\ttotal: 3.48s\tremaining: 5.12s\n",
      "81:\tlearn: 0.4793121\ttotal: 3.53s\tremaining: 5.08s\n",
      "82:\tlearn: 0.4754049\ttotal: 3.57s\tremaining: 5.04s\n",
      "83:\tlearn: 0.4733308\ttotal: 3.61s\tremaining: 4.99s\n",
      "84:\tlearn: 0.4717318\ttotal: 3.65s\tremaining: 4.93s\n",
      "85:\tlearn: 0.4694423\ttotal: 3.69s\tremaining: 4.89s\n",
      "86:\tlearn: 0.4678781\ttotal: 3.74s\tremaining: 4.86s\n",
      "87:\tlearn: 0.4670948\ttotal: 3.77s\tremaining: 4.8s\n",
      "88:\tlearn: 0.4657852\ttotal: 3.81s\tremaining: 4.75s\n",
      "89:\tlearn: 0.4646444\ttotal: 3.85s\tremaining: 4.71s\n",
      "90:\tlearn: 0.4632721\ttotal: 3.89s\tremaining: 4.66s\n",
      "91:\tlearn: 0.4618484\ttotal: 3.93s\tremaining: 4.61s\n",
      "92:\tlearn: 0.4597662\ttotal: 3.96s\tremaining: 4.56s\n",
      "93:\tlearn: 0.4592566\ttotal: 4s\tremaining: 4.51s\n",
      "94:\tlearn: 0.4582192\ttotal: 4.05s\tremaining: 4.47s\n",
      "95:\tlearn: 0.4569324\ttotal: 4.09s\tremaining: 4.43s\n",
      "96:\tlearn: 0.4557487\ttotal: 4.12s\tremaining: 4.38s\n",
      "97:\tlearn: 0.4554183\ttotal: 4.16s\tremaining: 4.33s\n",
      "98:\tlearn: 0.4547349\ttotal: 4.19s\tremaining: 4.28s\n",
      "99:\tlearn: 0.4541925\ttotal: 4.23s\tremaining: 4.23s\n",
      "100:\tlearn: 0.4528854\ttotal: 4.26s\tremaining: 4.18s\n",
      "101:\tlearn: 0.4509473\ttotal: 4.31s\tremaining: 4.14s\n",
      "102:\tlearn: 0.4499718\ttotal: 4.36s\tremaining: 4.1s\n",
      "103:\tlearn: 0.4470947\ttotal: 4.4s\tremaining: 4.07s\n",
      "104:\tlearn: 0.4465050\ttotal: 4.44s\tremaining: 4.02s\n",
      "105:\tlearn: 0.4459316\ttotal: 4.47s\tremaining: 3.97s\n",
      "106:\tlearn: 0.4453010\ttotal: 4.51s\tremaining: 3.92s\n",
      "107:\tlearn: 0.4444239\ttotal: 4.55s\tremaining: 3.88s\n",
      "108:\tlearn: 0.4434718\ttotal: 4.6s\tremaining: 3.84s\n",
      "109:\tlearn: 0.4425927\ttotal: 4.63s\tremaining: 3.79s\n",
      "110:\tlearn: 0.4416565\ttotal: 4.68s\tremaining: 3.75s\n",
      "111:\tlearn: 0.4410830\ttotal: 4.72s\tremaining: 3.71s\n",
      "112:\tlearn: 0.4404595\ttotal: 4.78s\tremaining: 3.68s\n",
      "113:\tlearn: 0.4397379\ttotal: 4.82s\tremaining: 3.64s\n",
      "114:\tlearn: 0.4388434\ttotal: 4.86s\tremaining: 3.6s\n",
      "115:\tlearn: 0.4375482\ttotal: 4.91s\tremaining: 3.56s\n",
      "116:\tlearn: 0.4370090\ttotal: 4.95s\tremaining: 3.51s\n",
      "117:\tlearn: 0.4356594\ttotal: 4.99s\tremaining: 3.47s\n",
      "118:\tlearn: 0.4353109\ttotal: 5.03s\tremaining: 3.42s\n",
      "119:\tlearn: 0.4338203\ttotal: 5.06s\tremaining: 3.38s\n",
      "120:\tlearn: 0.4334211\ttotal: 5.1s\tremaining: 3.33s\n",
      "121:\tlearn: 0.4319188\ttotal: 5.15s\tremaining: 3.29s\n",
      "122:\tlearn: 0.4306302\ttotal: 5.2s\tremaining: 3.25s\n",
      "123:\tlearn: 0.4299608\ttotal: 5.24s\tremaining: 3.21s\n",
      "124:\tlearn: 0.4285248\ttotal: 5.28s\tremaining: 3.17s\n",
      "125:\tlearn: 0.4279878\ttotal: 5.31s\tremaining: 3.12s\n",
      "126:\tlearn: 0.4271823\ttotal: 5.36s\tremaining: 3.08s\n",
      "127:\tlearn: 0.4264993\ttotal: 5.39s\tremaining: 3.03s\n",
      "128:\tlearn: 0.4260113\ttotal: 5.43s\tremaining: 2.99s\n",
      "129:\tlearn: 0.4249039\ttotal: 5.47s\tremaining: 2.94s\n",
      "130:\tlearn: 0.4244720\ttotal: 5.5s\tremaining: 2.9s\n",
      "131:\tlearn: 0.4231034\ttotal: 5.55s\tremaining: 2.86s\n",
      "132:\tlearn: 0.4216805\ttotal: 5.59s\tremaining: 2.81s\n",
      "133:\tlearn: 0.4204250\ttotal: 5.63s\tremaining: 2.77s\n",
      "134:\tlearn: 0.4193271\ttotal: 5.67s\tremaining: 2.73s\n",
      "135:\tlearn: 0.4184208\ttotal: 5.74s\tremaining: 2.7s\n",
      "136:\tlearn: 0.4164149\ttotal: 5.78s\tremaining: 2.66s\n",
      "137:\tlearn: 0.4158341\ttotal: 5.81s\tremaining: 2.61s\n",
      "138:\tlearn: 0.4149449\ttotal: 5.86s\tremaining: 2.57s\n",
      "139:\tlearn: 0.4142875\ttotal: 5.9s\tremaining: 2.53s\n",
      "140:\tlearn: 0.4136745\ttotal: 5.94s\tremaining: 2.48s\n",
      "141:\tlearn: 0.4132536\ttotal: 5.98s\tremaining: 2.44s\n",
      "142:\tlearn: 0.4082415\ttotal: 6.03s\tremaining: 2.4s\n",
      "143:\tlearn: 0.4078715\ttotal: 6.08s\tremaining: 2.36s\n",
      "144:\tlearn: 0.4066010\ttotal: 6.12s\tremaining: 2.32s\n",
      "145:\tlearn: 0.4063549\ttotal: 6.16s\tremaining: 2.28s\n",
      "146:\tlearn: 0.4055931\ttotal: 6.22s\tremaining: 2.24s\n",
      "147:\tlearn: 0.4051886\ttotal: 6.27s\tremaining: 2.2s\n",
      "148:\tlearn: 0.4043186\ttotal: 6.3s\tremaining: 2.16s\n",
      "149:\tlearn: 0.4039090\ttotal: 6.34s\tremaining: 2.11s\n",
      "150:\tlearn: 0.4032819\ttotal: 6.37s\tremaining: 2.07s\n",
      "151:\tlearn: 0.4024947\ttotal: 6.42s\tremaining: 2.02s\n",
      "152:\tlearn: 0.4018856\ttotal: 6.45s\tremaining: 1.98s\n",
      "153:\tlearn: 0.4014613\ttotal: 6.48s\tremaining: 1.94s\n",
      "154:\tlearn: 0.4008761\ttotal: 6.52s\tremaining: 1.89s\n",
      "155:\tlearn: 0.3998907\ttotal: 6.57s\tremaining: 1.85s\n",
      "156:\tlearn: 0.3995475\ttotal: 6.62s\tremaining: 1.81s\n",
      "157:\tlearn: 0.3989469\ttotal: 6.66s\tremaining: 1.77s\n",
      "158:\tlearn: 0.3982915\ttotal: 6.72s\tremaining: 1.73s\n",
      "159:\tlearn: 0.3974033\ttotal: 6.77s\tremaining: 1.69s\n",
      "160:\tlearn: 0.3968954\ttotal: 6.81s\tremaining: 1.65s\n",
      "161:\tlearn: 0.3964038\ttotal: 6.85s\tremaining: 1.61s\n",
      "162:\tlearn: 0.3958305\ttotal: 6.88s\tremaining: 1.56s\n",
      "163:\tlearn: 0.3955391\ttotal: 6.92s\tremaining: 1.52s\n",
      "164:\tlearn: 0.3950609\ttotal: 6.95s\tremaining: 1.47s\n",
      "165:\tlearn: 0.3944606\ttotal: 6.99s\tremaining: 1.43s\n",
      "166:\tlearn: 0.3938509\ttotal: 7.04s\tremaining: 1.39s\n",
      "167:\tlearn: 0.3936049\ttotal: 7.09s\tremaining: 1.35s\n",
      "168:\tlearn: 0.3930720\ttotal: 7.13s\tremaining: 1.31s\n",
      "169:\tlearn: 0.3924593\ttotal: 7.18s\tremaining: 1.27s\n",
      "170:\tlearn: 0.3921372\ttotal: 7.21s\tremaining: 1.22s\n",
      "171:\tlearn: 0.3918947\ttotal: 7.25s\tremaining: 1.18s\n",
      "172:\tlearn: 0.3905012\ttotal: 7.31s\tremaining: 1.14s\n",
      "173:\tlearn: 0.3898443\ttotal: 7.37s\tremaining: 1.1s\n",
      "174:\tlearn: 0.3896690\ttotal: 7.41s\tremaining: 1.06s\n",
      "175:\tlearn: 0.3891801\ttotal: 7.44s\tremaining: 1.01s\n",
      "176:\tlearn: 0.3886793\ttotal: 7.48s\tremaining: 972ms\n",
      "177:\tlearn: 0.3883736\ttotal: 7.51s\tremaining: 928ms\n",
      "178:\tlearn: 0.3877752\ttotal: 7.55s\tremaining: 886ms\n",
      "179:\tlearn: 0.3873238\ttotal: 7.59s\tremaining: 844ms\n",
      "180:\tlearn: 0.3870303\ttotal: 7.63s\tremaining: 801ms\n",
      "181:\tlearn: 0.3859122\ttotal: 7.69s\tremaining: 761ms\n",
      "182:\tlearn: 0.3855603\ttotal: 7.73s\tremaining: 718ms\n",
      "183:\tlearn: 0.3847788\ttotal: 7.77s\tremaining: 675ms\n",
      "184:\tlearn: 0.3843517\ttotal: 7.81s\tremaining: 633ms\n",
      "185:\tlearn: 0.3833395\ttotal: 7.86s\tremaining: 591ms\n",
      "186:\tlearn: 0.3827226\ttotal: 7.9s\tremaining: 549ms\n",
      "187:\tlearn: 0.3822157\ttotal: 7.95s\tremaining: 507ms\n",
      "188:\tlearn: 0.3811856\ttotal: 8s\tremaining: 466ms\n",
      "189:\tlearn: 0.3803871\ttotal: 8.04s\tremaining: 423ms\n",
      "190:\tlearn: 0.3800266\ttotal: 8.07s\tremaining: 380ms\n",
      "191:\tlearn: 0.3792343\ttotal: 8.11s\tremaining: 338ms\n",
      "192:\tlearn: 0.3784976\ttotal: 8.15s\tremaining: 295ms\n",
      "193:\tlearn: 0.3781841\ttotal: 8.19s\tremaining: 253ms\n",
      "194:\tlearn: 0.3773758\ttotal: 8.23s\tremaining: 211ms\n",
      "195:\tlearn: 0.3771347\ttotal: 8.27s\tremaining: 169ms\n",
      "196:\tlearn: 0.3766960\ttotal: 8.3s\tremaining: 126ms\n",
      "197:\tlearn: 0.3755962\ttotal: 8.34s\tremaining: 84.3ms\n",
      "198:\tlearn: 0.3746309\ttotal: 8.38s\tremaining: 42.1ms\n",
      "199:\tlearn: 0.3744051\ttotal: 8.42s\tremaining: 0us\n",
      "0:\tlearn: 2.2756282\ttotal: 95.6ms\tremaining: 4.68s\n",
      "1:\tlearn: 2.2504542\ttotal: 178ms\tremaining: 4.26s\n",
      "2:\tlearn: 2.2268848\ttotal: 251ms\tremaining: 3.94s\n",
      "3:\tlearn: 2.2034461\ttotal: 328ms\tremaining: 3.77s\n",
      "4:\tlearn: 2.1800353\ttotal: 411ms\tremaining: 3.7s\n",
      "5:\tlearn: 2.1589622\ttotal: 490ms\tremaining: 3.59s\n",
      "6:\tlearn: 2.1387904\ttotal: 573ms\tremaining: 3.52s\n",
      "7:\tlearn: 2.1194893\ttotal: 652ms\tremaining: 3.42s\n",
      "8:\tlearn: 2.0991401\ttotal: 737ms\tremaining: 3.36s\n",
      "9:\tlearn: 2.0797159\ttotal: 825ms\tremaining: 3.3s\n",
      "10:\tlearn: 2.0624048\ttotal: 912ms\tremaining: 3.23s\n",
      "11:\tlearn: 2.0458741\ttotal: 995ms\tremaining: 3.15s\n",
      "12:\tlearn: 2.0302765\ttotal: 1.08s\tremaining: 3.08s\n",
      "13:\tlearn: 2.0134852\ttotal: 1.18s\tremaining: 3.02s\n",
      "14:\tlearn: 1.9974696\ttotal: 1.26s\tremaining: 2.94s\n",
      "15:\tlearn: 1.9801576\ttotal: 1.35s\tremaining: 2.87s\n",
      "16:\tlearn: 1.9631199\ttotal: 1.44s\tremaining: 2.79s\n",
      "17:\tlearn: 1.9483252\ttotal: 1.52s\tremaining: 2.71s\n",
      "18:\tlearn: 1.9349998\ttotal: 1.61s\tremaining: 2.63s\n",
      "19:\tlearn: 1.9200673\ttotal: 1.7s\tremaining: 2.56s\n",
      "20:\tlearn: 1.9058736\ttotal: 1.79s\tremaining: 2.48s\n",
      "21:\tlearn: 1.8915828\ttotal: 1.89s\tremaining: 2.4s\n",
      "22:\tlearn: 1.8769847\ttotal: 1.98s\tremaining: 2.32s\n",
      "23:\tlearn: 1.8648099\ttotal: 2.06s\tremaining: 2.23s\n",
      "24:\tlearn: 1.8519857\ttotal: 2.15s\tremaining: 2.15s\n",
      "25:\tlearn: 1.8381391\ttotal: 2.24s\tremaining: 2.07s\n",
      "26:\tlearn: 1.8262921\ttotal: 2.32s\tremaining: 1.98s\n",
      "27:\tlearn: 1.8137760\ttotal: 2.4s\tremaining: 1.89s\n",
      "28:\tlearn: 1.8021825\ttotal: 2.49s\tremaining: 1.8s\n",
      "29:\tlearn: 1.7909263\ttotal: 2.57s\tremaining: 1.71s\n",
      "30:\tlearn: 1.7796770\ttotal: 2.65s\tremaining: 1.63s\n",
      "31:\tlearn: 1.7666104\ttotal: 2.74s\tremaining: 1.54s\n",
      "32:\tlearn: 1.7547963\ttotal: 2.83s\tremaining: 1.46s\n",
      "33:\tlearn: 1.7459996\ttotal: 2.91s\tremaining: 1.37s\n",
      "34:\tlearn: 1.7339920\ttotal: 3.02s\tremaining: 1.29s\n",
      "35:\tlearn: 1.7223199\ttotal: 3.13s\tremaining: 1.22s\n",
      "36:\tlearn: 1.7120850\ttotal: 3.21s\tremaining: 1.13s\n",
      "37:\tlearn: 1.7019442\ttotal: 3.3s\tremaining: 1.04s\n",
      "38:\tlearn: 1.6924788\ttotal: 3.4s\tremaining: 958ms\n",
      "39:\tlearn: 1.6819899\ttotal: 3.49s\tremaining: 873ms\n",
      "40:\tlearn: 1.6728333\ttotal: 3.58s\tremaining: 786ms\n",
      "41:\tlearn: 1.6630244\ttotal: 3.67s\tremaining: 699ms\n",
      "42:\tlearn: 1.6547669\ttotal: 3.75s\tremaining: 611ms\n",
      "43:\tlearn: 1.6452349\ttotal: 3.85s\tremaining: 525ms\n",
      "44:\tlearn: 1.6370997\ttotal: 3.95s\tremaining: 439ms\n",
      "45:\tlearn: 1.6285728\ttotal: 4.03s\tremaining: 350ms\n",
      "46:\tlearn: 1.6190982\ttotal: 4.13s\tremaining: 263ms\n",
      "47:\tlearn: 1.6104807\ttotal: 4.23s\tremaining: 176ms\n",
      "48:\tlearn: 1.6020463\ttotal: 4.33s\tremaining: 88.3ms\n",
      "49:\tlearn: 1.5928468\ttotal: 4.43s\tremaining: 0us\n",
      "0:\tlearn: 2.2745478\ttotal: 90.6ms\tremaining: 4.44s\n",
      "1:\tlearn: 2.2491091\ttotal: 167ms\tremaining: 4.01s\n",
      "2:\tlearn: 2.2248687\ttotal: 245ms\tremaining: 3.84s\n",
      "3:\tlearn: 2.2015363\ttotal: 325ms\tremaining: 3.74s\n",
      "4:\tlearn: 2.1793654\ttotal: 405ms\tremaining: 3.65s\n",
      "5:\tlearn: 2.1570508\ttotal: 492ms\tremaining: 3.61s\n",
      "6:\tlearn: 2.1369424\ttotal: 571ms\tremaining: 3.51s\n",
      "7:\tlearn: 2.1163147\ttotal: 654ms\tremaining: 3.43s\n",
      "8:\tlearn: 2.0974866\ttotal: 738ms\tremaining: 3.36s\n",
      "9:\tlearn: 2.0770918\ttotal: 832ms\tremaining: 3.33s\n",
      "10:\tlearn: 2.0572351\ttotal: 921ms\tremaining: 3.27s\n",
      "11:\tlearn: 2.0405087\ttotal: 1s\tremaining: 3.17s\n",
      "12:\tlearn: 2.0249213\ttotal: 1.08s\tremaining: 3.08s\n",
      "13:\tlearn: 2.0082455\ttotal: 1.17s\tremaining: 3.01s\n",
      "14:\tlearn: 1.9921855\ttotal: 1.25s\tremaining: 2.92s\n",
      "15:\tlearn: 1.9761503\ttotal: 1.34s\tremaining: 2.85s\n",
      "16:\tlearn: 1.9615636\ttotal: 1.43s\tremaining: 2.78s\n",
      "17:\tlearn: 1.9466888\ttotal: 1.52s\tremaining: 2.7s\n",
      "18:\tlearn: 1.9333366\ttotal: 1.61s\tremaining: 2.62s\n",
      "19:\tlearn: 1.9183910\ttotal: 1.71s\tremaining: 2.56s\n",
      "20:\tlearn: 1.9047091\ttotal: 1.8s\tremaining: 2.48s\n",
      "21:\tlearn: 1.8929217\ttotal: 1.88s\tremaining: 2.4s\n",
      "22:\tlearn: 1.8793373\ttotal: 1.98s\tremaining: 2.33s\n",
      "23:\tlearn: 1.8643355\ttotal: 2.08s\tremaining: 2.26s\n",
      "24:\tlearn: 1.8511005\ttotal: 2.18s\tremaining: 2.18s\n",
      "25:\tlearn: 1.8379911\ttotal: 2.27s\tremaining: 2.1s\n",
      "26:\tlearn: 1.8261560\ttotal: 2.37s\tremaining: 2.02s\n",
      "27:\tlearn: 1.8134640\ttotal: 2.45s\tremaining: 1.93s\n",
      "28:\tlearn: 1.8017106\ttotal: 2.55s\tremaining: 1.84s\n",
      "29:\tlearn: 1.7889316\ttotal: 2.65s\tremaining: 1.76s\n",
      "30:\tlearn: 1.7776919\ttotal: 2.74s\tremaining: 1.68s\n",
      "31:\tlearn: 1.7647214\ttotal: 2.84s\tremaining: 1.6s\n",
      "32:\tlearn: 1.7524029\ttotal: 2.94s\tremaining: 1.51s\n",
      "33:\tlearn: 1.7420787\ttotal: 3.03s\tremaining: 1.43s\n",
      "34:\tlearn: 1.7304279\ttotal: 3.13s\tremaining: 1.34s\n",
      "35:\tlearn: 1.7191754\ttotal: 3.24s\tremaining: 1.26s\n",
      "36:\tlearn: 1.7084387\ttotal: 3.33s\tremaining: 1.17s\n",
      "37:\tlearn: 1.6967500\ttotal: 3.42s\tremaining: 1.08s\n",
      "38:\tlearn: 1.6872836\ttotal: 3.51s\tremaining: 990ms\n",
      "39:\tlearn: 1.6769896\ttotal: 3.6s\tremaining: 900ms\n",
      "40:\tlearn: 1.6677922\ttotal: 3.69s\tremaining: 810ms\n",
      "41:\tlearn: 1.6580497\ttotal: 3.79s\tremaining: 721ms\n",
      "42:\tlearn: 1.6485962\ttotal: 3.88s\tremaining: 631ms\n",
      "43:\tlearn: 1.6400718\ttotal: 3.96s\tremaining: 540ms\n",
      "44:\tlearn: 1.6316004\ttotal: 4.05s\tremaining: 450ms\n",
      "45:\tlearn: 1.6220881\ttotal: 4.14s\tremaining: 360ms\n",
      "46:\tlearn: 1.6128068\ttotal: 4.24s\tremaining: 270ms\n",
      "47:\tlearn: 1.6036514\ttotal: 4.33s\tremaining: 180ms\n",
      "48:\tlearn: 1.5953113\ttotal: 4.41s\tremaining: 90ms\n",
      "49:\tlearn: 1.5863937\ttotal: 4.5s\tremaining: 0us\n",
      "0:\tlearn: 2.2745527\ttotal: 98.9ms\tremaining: 4.84s\n",
      "1:\tlearn: 2.2483020\ttotal: 185ms\tremaining: 4.44s\n",
      "2:\tlearn: 2.2237348\ttotal: 261ms\tremaining: 4.09s\n",
      "3:\tlearn: 2.2001446\ttotal: 342ms\tremaining: 3.93s\n",
      "4:\tlearn: 2.1779610\ttotal: 422ms\tremaining: 3.79s\n",
      "5:\tlearn: 2.1567463\ttotal: 501ms\tremaining: 3.67s\n",
      "6:\tlearn: 2.1368141\ttotal: 583ms\tremaining: 3.58s\n",
      "7:\tlearn: 2.1159693\ttotal: 669ms\tremaining: 3.51s\n",
      "8:\tlearn: 2.0955090\ttotal: 757ms\tremaining: 3.45s\n",
      "9:\tlearn: 2.0752417\ttotal: 848ms\tremaining: 3.39s\n",
      "10:\tlearn: 2.0578462\ttotal: 931ms\tremaining: 3.3s\n",
      "11:\tlearn: 2.0411178\ttotal: 1.01s\tremaining: 3.2s\n",
      "12:\tlearn: 2.0255488\ttotal: 1.09s\tremaining: 3.1s\n",
      "13:\tlearn: 2.0090437\ttotal: 1.17s\tremaining: 3.01s\n",
      "14:\tlearn: 1.9930720\ttotal: 1.25s\tremaining: 2.92s\n",
      "15:\tlearn: 1.9786468\ttotal: 1.35s\tremaining: 2.88s\n",
      "16:\tlearn: 1.9635703\ttotal: 1.44s\tremaining: 2.8s\n",
      "17:\tlearn: 1.9486229\ttotal: 1.53s\tremaining: 2.73s\n",
      "18:\tlearn: 1.9352437\ttotal: 1.63s\tremaining: 2.65s\n",
      "19:\tlearn: 1.9202594\ttotal: 1.72s\tremaining: 2.58s\n",
      "20:\tlearn: 1.9061861\ttotal: 1.82s\tremaining: 2.51s\n",
      "21:\tlearn: 1.8938795\ttotal: 1.91s\tremaining: 2.43s\n",
      "22:\tlearn: 1.8790681\ttotal: 2s\tremaining: 2.35s\n",
      "23:\tlearn: 1.8642363\ttotal: 2.09s\tremaining: 2.26s\n",
      "24:\tlearn: 1.8515717\ttotal: 2.18s\tremaining: 2.18s\n",
      "25:\tlearn: 1.8385113\ttotal: 2.27s\tremaining: 2.09s\n",
      "26:\tlearn: 1.8266342\ttotal: 2.36s\tremaining: 2.01s\n",
      "27:\tlearn: 1.8141225\ttotal: 2.45s\tremaining: 1.93s\n",
      "28:\tlearn: 1.8010874\ttotal: 2.54s\tremaining: 1.84s\n",
      "29:\tlearn: 1.7885986\ttotal: 2.63s\tremaining: 1.75s\n",
      "30:\tlearn: 1.7772518\ttotal: 2.73s\tremaining: 1.67s\n",
      "31:\tlearn: 1.7649699\ttotal: 2.82s\tremaining: 1.58s\n",
      "32:\tlearn: 1.7526377\ttotal: 2.91s\tremaining: 1.5s\n",
      "33:\tlearn: 1.7411382\ttotal: 3s\tremaining: 1.41s\n",
      "34:\tlearn: 1.7293323\ttotal: 3.12s\tremaining: 1.34s\n",
      "35:\tlearn: 1.7179613\ttotal: 3.23s\tremaining: 1.26s\n",
      "36:\tlearn: 1.7070240\ttotal: 3.33s\tremaining: 1.17s\n",
      "37:\tlearn: 1.6959472\ttotal: 3.42s\tremaining: 1.08s\n",
      "38:\tlearn: 1.6864904\ttotal: 3.51s\tremaining: 989ms\n",
      "39:\tlearn: 1.6761457\ttotal: 3.6s\tremaining: 900ms\n",
      "40:\tlearn: 1.6671505\ttotal: 3.69s\tremaining: 809ms\n",
      "41:\tlearn: 1.6574689\ttotal: 3.78s\tremaining: 720ms\n",
      "42:\tlearn: 1.6476955\ttotal: 3.88s\tremaining: 632ms\n",
      "43:\tlearn: 1.6389069\ttotal: 3.98s\tremaining: 543ms\n",
      "44:\tlearn: 1.6295991\ttotal: 4.08s\tremaining: 454ms\n",
      "45:\tlearn: 1.6202857\ttotal: 4.19s\tremaining: 364ms\n",
      "46:\tlearn: 1.6114148\ttotal: 4.3s\tremaining: 275ms\n",
      "47:\tlearn: 1.6023835\ttotal: 4.39s\tremaining: 183ms\n",
      "48:\tlearn: 1.5941333\ttotal: 4.49s\tremaining: 91.5ms\n",
      "49:\tlearn: 1.5854408\ttotal: 4.58s\tremaining: 0us\n",
      "0:\tlearn: 1.5161069\ttotal: 85ms\tremaining: 4.17s\n",
      "1:\tlearn: 1.2497339\ttotal: 150ms\tremaining: 3.6s\n",
      "2:\tlearn: 1.1053270\ttotal: 239ms\tremaining: 3.75s\n",
      "3:\tlearn: 0.9531728\ttotal: 347ms\tremaining: 3.99s\n",
      "4:\tlearn: 0.8881169\ttotal: 434ms\tremaining: 3.9s\n",
      "5:\tlearn: 0.8357729\ttotal: 527ms\tremaining: 3.86s\n",
      "6:\tlearn: 0.7875413\ttotal: 626ms\tremaining: 3.85s\n",
      "7:\tlearn: 0.7571742\ttotal: 710ms\tremaining: 3.73s\n",
      "8:\tlearn: 0.7293294\ttotal: 792ms\tremaining: 3.61s\n",
      "9:\tlearn: 0.6921629\ttotal: 889ms\tremaining: 3.56s\n",
      "10:\tlearn: 0.6620651\ttotal: 983ms\tremaining: 3.49s\n",
      "11:\tlearn: 0.6408625\ttotal: 1.08s\tremaining: 3.41s\n",
      "12:\tlearn: 0.6257649\ttotal: 1.16s\tremaining: 3.3s\n",
      "13:\tlearn: 0.6142029\ttotal: 1.25s\tremaining: 3.21s\n",
      "14:\tlearn: 0.6019845\ttotal: 1.32s\tremaining: 3.09s\n",
      "15:\tlearn: 0.5943024\ttotal: 1.4s\tremaining: 2.98s\n",
      "16:\tlearn: 0.5810199\ttotal: 1.48s\tremaining: 2.88s\n",
      "17:\tlearn: 0.5745064\ttotal: 1.57s\tremaining: 2.78s\n",
      "18:\tlearn: 0.5639842\ttotal: 1.65s\tremaining: 2.69s\n",
      "19:\tlearn: 0.5574174\ttotal: 1.72s\tremaining: 2.59s\n",
      "20:\tlearn: 0.5497371\ttotal: 1.82s\tremaining: 2.51s\n",
      "21:\tlearn: 0.5425708\ttotal: 1.91s\tremaining: 2.42s\n",
      "22:\tlearn: 0.5337820\ttotal: 2s\tremaining: 2.35s\n",
      "23:\tlearn: 0.5266947\ttotal: 2.09s\tremaining: 2.27s\n",
      "24:\tlearn: 0.5237619\ttotal: 2.17s\tremaining: 2.17s\n",
      "25:\tlearn: 0.5190033\ttotal: 2.25s\tremaining: 2.08s\n",
      "26:\tlearn: 0.5069624\ttotal: 2.34s\tremaining: 2s\n",
      "27:\tlearn: 0.4995519\ttotal: 2.42s\tremaining: 1.9s\n",
      "28:\tlearn: 0.4931026\ttotal: 2.5s\tremaining: 1.81s\n",
      "29:\tlearn: 0.4884657\ttotal: 2.58s\tremaining: 1.72s\n",
      "30:\tlearn: 0.4831926\ttotal: 2.65s\tremaining: 1.63s\n",
      "31:\tlearn: 0.4802191\ttotal: 2.73s\tremaining: 1.53s\n",
      "32:\tlearn: 0.4751489\ttotal: 2.81s\tremaining: 1.45s\n",
      "33:\tlearn: 0.4708665\ttotal: 2.9s\tremaining: 1.36s\n",
      "34:\tlearn: 0.4677607\ttotal: 2.97s\tremaining: 1.27s\n",
      "35:\tlearn: 0.4648248\ttotal: 3.03s\tremaining: 1.18s\n",
      "36:\tlearn: 0.4616323\ttotal: 3.12s\tremaining: 1.09s\n",
      "37:\tlearn: 0.4592780\ttotal: 3.2s\tremaining: 1.01s\n",
      "38:\tlearn: 0.4561741\ttotal: 3.29s\tremaining: 927ms\n",
      "39:\tlearn: 0.4527649\ttotal: 3.36s\tremaining: 839ms\n",
      "40:\tlearn: 0.4513067\ttotal: 3.42s\tremaining: 750ms\n",
      "41:\tlearn: 0.4477085\ttotal: 3.53s\tremaining: 672ms\n",
      "42:\tlearn: 0.4443095\ttotal: 3.62s\tremaining: 589ms\n",
      "43:\tlearn: 0.4395263\ttotal: 3.71s\tremaining: 507ms\n",
      "44:\tlearn: 0.4380757\ttotal: 3.78s\tremaining: 420ms\n",
      "45:\tlearn: 0.4362752\ttotal: 3.86s\tremaining: 336ms\n",
      "46:\tlearn: 0.4341125\ttotal: 3.94s\tremaining: 251ms\n",
      "47:\tlearn: 0.4320587\ttotal: 4.03s\tremaining: 168ms\n",
      "48:\tlearn: 0.4306897\ttotal: 4.1s\tremaining: 83.6ms\n",
      "49:\tlearn: 0.4294855\ttotal: 4.16s\tremaining: 0us\n",
      "0:\tlearn: 1.4859815\ttotal: 119ms\tremaining: 5.83s\n",
      "1:\tlearn: 1.2176614\ttotal: 184ms\tremaining: 4.41s\n",
      "2:\tlearn: 1.0582276\ttotal: 266ms\tremaining: 4.17s\n",
      "3:\tlearn: 0.9526077\ttotal: 358ms\tremaining: 4.12s\n",
      "4:\tlearn: 0.8951146\ttotal: 442ms\tremaining: 3.98s\n",
      "5:\tlearn: 0.8491664\ttotal: 526ms\tremaining: 3.85s\n",
      "6:\tlearn: 0.7857463\ttotal: 618ms\tremaining: 3.79s\n",
      "7:\tlearn: 0.7441137\ttotal: 701ms\tremaining: 3.68s\n",
      "8:\tlearn: 0.7092327\ttotal: 792ms\tremaining: 3.61s\n",
      "9:\tlearn: 0.6835149\ttotal: 877ms\tremaining: 3.51s\n",
      "10:\tlearn: 0.6589470\ttotal: 952ms\tremaining: 3.37s\n",
      "11:\tlearn: 0.6448432\ttotal: 1.03s\tremaining: 3.27s\n",
      "12:\tlearn: 0.6294034\ttotal: 1.1s\tremaining: 3.15s\n",
      "13:\tlearn: 0.6155853\ttotal: 1.18s\tremaining: 3.04s\n",
      "14:\tlearn: 0.6034235\ttotal: 1.27s\tremaining: 2.96s\n",
      "15:\tlearn: 0.5910996\ttotal: 1.34s\tremaining: 2.85s\n",
      "16:\tlearn: 0.5806671\ttotal: 1.42s\tremaining: 2.76s\n",
      "17:\tlearn: 0.5714467\ttotal: 1.5s\tremaining: 2.67s\n",
      "18:\tlearn: 0.5585376\ttotal: 1.58s\tremaining: 2.59s\n",
      "19:\tlearn: 0.5527907\ttotal: 1.65s\tremaining: 2.48s\n",
      "20:\tlearn: 0.5475708\ttotal: 1.73s\tremaining: 2.39s\n",
      "21:\tlearn: 0.5379247\ttotal: 1.82s\tremaining: 2.32s\n",
      "22:\tlearn: 0.5324436\ttotal: 1.89s\tremaining: 2.22s\n",
      "23:\tlearn: 0.5261746\ttotal: 1.95s\tremaining: 2.12s\n",
      "24:\tlearn: 0.5202973\ttotal: 2.03s\tremaining: 2.03s\n",
      "25:\tlearn: 0.5148082\ttotal: 2.09s\tremaining: 1.93s\n",
      "26:\tlearn: 0.5122796\ttotal: 2.16s\tremaining: 1.84s\n",
      "27:\tlearn: 0.5075930\ttotal: 2.25s\tremaining: 1.77s\n",
      "28:\tlearn: 0.5005131\ttotal: 2.33s\tremaining: 1.69s\n",
      "29:\tlearn: 0.4968232\ttotal: 2.42s\tremaining: 1.61s\n",
      "30:\tlearn: 0.4908081\ttotal: 2.5s\tremaining: 1.53s\n",
      "31:\tlearn: 0.4865722\ttotal: 2.57s\tremaining: 1.45s\n",
      "32:\tlearn: 0.4816390\ttotal: 2.64s\tremaining: 1.36s\n",
      "33:\tlearn: 0.4773866\ttotal: 2.71s\tremaining: 1.27s\n",
      "34:\tlearn: 0.4726524\ttotal: 2.77s\tremaining: 1.19s\n",
      "35:\tlearn: 0.4695806\ttotal: 2.84s\tremaining: 1.1s\n",
      "36:\tlearn: 0.4632039\ttotal: 2.92s\tremaining: 1.03s\n",
      "37:\tlearn: 0.4605342\ttotal: 3s\tremaining: 948ms\n",
      "38:\tlearn: 0.4557980\ttotal: 3.09s\tremaining: 870ms\n",
      "39:\tlearn: 0.4505694\ttotal: 3.17s\tremaining: 791ms\n",
      "40:\tlearn: 0.4489074\ttotal: 3.23s\tremaining: 710ms\n",
      "41:\tlearn: 0.4477119\ttotal: 3.29s\tremaining: 628ms\n",
      "42:\tlearn: 0.4435602\ttotal: 3.37s\tremaining: 549ms\n",
      "43:\tlearn: 0.4412110\ttotal: 3.45s\tremaining: 470ms\n",
      "44:\tlearn: 0.4377220\ttotal: 3.53s\tremaining: 393ms\n",
      "45:\tlearn: 0.4348937\ttotal: 3.61s\tremaining: 314ms\n",
      "46:\tlearn: 0.4328495\ttotal: 3.68s\tremaining: 235ms\n",
      "47:\tlearn: 0.4304757\ttotal: 3.75s\tremaining: 156ms\n",
      "48:\tlearn: 0.4284822\ttotal: 3.82s\tremaining: 78ms\n",
      "49:\tlearn: 0.4270062\ttotal: 3.88s\tremaining: 0us\n",
      "0:\tlearn: 1.4907512\ttotal: 86.1ms\tremaining: 4.22s\n",
      "1:\tlearn: 1.2237881\ttotal: 148ms\tremaining: 3.56s\n",
      "2:\tlearn: 1.0670628\ttotal: 232ms\tremaining: 3.63s\n",
      "3:\tlearn: 0.9617266\ttotal: 319ms\tremaining: 3.66s\n",
      "4:\tlearn: 0.8981958\ttotal: 393ms\tremaining: 3.54s\n",
      "5:\tlearn: 0.8317747\ttotal: 488ms\tremaining: 3.58s\n",
      "6:\tlearn: 0.7881228\ttotal: 573ms\tremaining: 3.52s\n",
      "7:\tlearn: 0.7520878\ttotal: 657ms\tremaining: 3.45s\n",
      "8:\tlearn: 0.7235711\ttotal: 738ms\tremaining: 3.36s\n",
      "9:\tlearn: 0.6974600\ttotal: 822ms\tremaining: 3.29s\n",
      "10:\tlearn: 0.6723062\ttotal: 914ms\tremaining: 3.24s\n",
      "11:\tlearn: 0.6546348\ttotal: 993ms\tremaining: 3.15s\n",
      "12:\tlearn: 0.6438483\ttotal: 1.05s\tremaining: 3s\n",
      "13:\tlearn: 0.6264111\ttotal: 1.14s\tremaining: 2.94s\n",
      "14:\tlearn: 0.6102708\ttotal: 1.24s\tremaining: 2.88s\n",
      "15:\tlearn: 0.5980970\ttotal: 1.31s\tremaining: 2.78s\n",
      "16:\tlearn: 0.5837638\ttotal: 1.39s\tremaining: 2.71s\n",
      "17:\tlearn: 0.5779625\ttotal: 1.47s\tremaining: 2.61s\n",
      "18:\tlearn: 0.5675015\ttotal: 1.56s\tremaining: 2.55s\n",
      "19:\tlearn: 0.5581601\ttotal: 1.64s\tremaining: 2.45s\n",
      "20:\tlearn: 0.5510124\ttotal: 1.71s\tremaining: 2.36s\n",
      "21:\tlearn: 0.5433212\ttotal: 1.79s\tremaining: 2.28s\n",
      "22:\tlearn: 0.5270742\ttotal: 1.88s\tremaining: 2.21s\n",
      "23:\tlearn: 0.5193950\ttotal: 1.96s\tremaining: 2.13s\n",
      "24:\tlearn: 0.5132939\ttotal: 2.04s\tremaining: 2.04s\n",
      "25:\tlearn: 0.5058294\ttotal: 2.12s\tremaining: 1.96s\n",
      "26:\tlearn: 0.5022085\ttotal: 2.19s\tremaining: 1.86s\n",
      "27:\tlearn: 0.4993424\ttotal: 2.25s\tremaining: 1.77s\n",
      "28:\tlearn: 0.4950145\ttotal: 2.34s\tremaining: 1.69s\n",
      "29:\tlearn: 0.4911516\ttotal: 2.41s\tremaining: 1.61s\n",
      "30:\tlearn: 0.4871259\ttotal: 2.49s\tremaining: 1.52s\n",
      "31:\tlearn: 0.4829130\ttotal: 2.56s\tremaining: 1.44s\n",
      "32:\tlearn: 0.4767003\ttotal: 2.64s\tremaining: 1.36s\n",
      "33:\tlearn: 0.4723086\ttotal: 2.74s\tremaining: 1.29s\n",
      "34:\tlearn: 0.4694545\ttotal: 2.82s\tremaining: 1.21s\n",
      "35:\tlearn: 0.4647552\ttotal: 2.94s\tremaining: 1.14s\n",
      "36:\tlearn: 0.4610493\ttotal: 3.03s\tremaining: 1.06s\n",
      "37:\tlearn: 0.4582854\ttotal: 3.12s\tremaining: 986ms\n",
      "38:\tlearn: 0.4560894\ttotal: 3.18s\tremaining: 898ms\n",
      "39:\tlearn: 0.4508372\ttotal: 3.26s\tremaining: 815ms\n",
      "40:\tlearn: 0.4481908\ttotal: 3.32s\tremaining: 729ms\n",
      "41:\tlearn: 0.4447618\ttotal: 3.39s\tremaining: 646ms\n",
      "42:\tlearn: 0.4408313\ttotal: 3.49s\tremaining: 568ms\n",
      "43:\tlearn: 0.4391245\ttotal: 3.58s\tremaining: 488ms\n",
      "44:\tlearn: 0.4371992\ttotal: 3.66s\tremaining: 406ms\n",
      "45:\tlearn: 0.4359221\ttotal: 3.72s\tremaining: 324ms\n",
      "46:\tlearn: 0.4313744\ttotal: 3.79s\tremaining: 242ms\n",
      "47:\tlearn: 0.4273621\ttotal: 3.88s\tremaining: 162ms\n",
      "48:\tlearn: 0.4264564\ttotal: 3.94s\tremaining: 80.4ms\n",
      "49:\tlearn: 0.4242933\ttotal: 4.02s\tremaining: 0us\n",
      "0:\tlearn: 1.6173405\ttotal: 104ms\tremaining: 5.1s\n",
      "1:\tlearn: 1.3610505\ttotal: 194ms\tremaining: 4.65s\n",
      "2:\tlearn: 1.2383489\ttotal: 285ms\tremaining: 4.47s\n",
      "3:\tlearn: 1.0831542\ttotal: 365ms\tremaining: 4.2s\n",
      "4:\tlearn: 0.9829870\ttotal: 463ms\tremaining: 4.17s\n",
      "5:\tlearn: 0.9397884\ttotal: 569ms\tremaining: 4.17s\n",
      "6:\tlearn: 0.8998009\ttotal: 653ms\tremaining: 4.01s\n",
      "7:\tlearn: 0.8514544\ttotal: 730ms\tremaining: 3.83s\n",
      "8:\tlearn: 0.7994444\ttotal: 811ms\tremaining: 3.69s\n",
      "9:\tlearn: 0.7756806\ttotal: 891ms\tremaining: 3.56s\n",
      "10:\tlearn: 0.7457416\ttotal: 1s\tremaining: 3.56s\n",
      "11:\tlearn: 0.7209276\ttotal: 1.08s\tremaining: 3.43s\n",
      "12:\tlearn: 0.7026217\ttotal: 1.16s\tremaining: 3.31s\n",
      "13:\tlearn: 0.6855301\ttotal: 1.23s\tremaining: 3.17s\n",
      "14:\tlearn: 0.6617941\ttotal: 1.32s\tremaining: 3.07s\n",
      "15:\tlearn: 0.6409414\ttotal: 1.4s\tremaining: 2.97s\n",
      "16:\tlearn: 0.6303556\ttotal: 1.49s\tremaining: 2.9s\n",
      "17:\tlearn: 0.6178826\ttotal: 1.57s\tremaining: 2.8s\n",
      "18:\tlearn: 0.6091777\ttotal: 1.66s\tremaining: 2.71s\n",
      "19:\tlearn: 0.6042056\ttotal: 1.73s\tremaining: 2.59s\n",
      "20:\tlearn: 0.6010288\ttotal: 1.8s\tremaining: 2.48s\n",
      "21:\tlearn: 0.5943810\ttotal: 1.87s\tremaining: 2.38s\n",
      "22:\tlearn: 0.5873646\ttotal: 1.95s\tremaining: 2.28s\n",
      "23:\tlearn: 0.5805283\ttotal: 2.02s\tremaining: 2.19s\n",
      "24:\tlearn: 0.5749564\ttotal: 2.08s\tremaining: 2.08s\n",
      "25:\tlearn: 0.5637090\ttotal: 2.2s\tremaining: 2.03s\n",
      "26:\tlearn: 0.5571651\ttotal: 2.28s\tremaining: 1.94s\n",
      "27:\tlearn: 0.5538908\ttotal: 2.34s\tremaining: 1.84s\n",
      "28:\tlearn: 0.5477294\ttotal: 2.42s\tremaining: 1.75s\n",
      "29:\tlearn: 0.5397188\ttotal: 2.5s\tremaining: 1.67s\n",
      "30:\tlearn: 0.5311299\ttotal: 2.61s\tremaining: 1.6s\n",
      "31:\tlearn: 0.5258997\ttotal: 2.7s\tremaining: 1.52s\n",
      "32:\tlearn: 0.5233370\ttotal: 2.78s\tremaining: 1.43s\n",
      "33:\tlearn: 0.5200332\ttotal: 2.88s\tremaining: 1.35s\n",
      "34:\tlearn: 0.5187748\ttotal: 2.94s\tremaining: 1.26s\n",
      "35:\tlearn: 0.5157007\ttotal: 3.01s\tremaining: 1.17s\n",
      "36:\tlearn: 0.5123004\ttotal: 3.07s\tremaining: 1.08s\n",
      "37:\tlearn: 0.5110807\ttotal: 3.13s\tremaining: 988ms\n",
      "38:\tlearn: 0.5086228\ttotal: 3.21s\tremaining: 906ms\n",
      "39:\tlearn: 0.5054616\ttotal: 3.31s\tremaining: 828ms\n",
      "40:\tlearn: 0.5012277\ttotal: 3.4s\tremaining: 746ms\n",
      "41:\tlearn: 0.4981952\ttotal: 3.48s\tremaining: 663ms\n",
      "42:\tlearn: 0.4957518\ttotal: 3.56s\tremaining: 580ms\n",
      "43:\tlearn: 0.4878490\ttotal: 3.67s\tremaining: 501ms\n",
      "44:\tlearn: 0.4825031\ttotal: 3.74s\tremaining: 416ms\n",
      "45:\tlearn: 0.4808215\ttotal: 3.81s\tremaining: 332ms\n",
      "46:\tlearn: 0.4757149\ttotal: 3.9s\tremaining: 249ms\n",
      "47:\tlearn: 0.4718580\ttotal: 3.98s\tremaining: 166ms\n",
      "48:\tlearn: 0.4670354\ttotal: 4.08s\tremaining: 83.2ms\n",
      "49:\tlearn: 0.4632454\ttotal: 4.17s\tremaining: 0us\n",
      "0:\tlearn: 1.5904964\ttotal: 108ms\tremaining: 5.28s\n",
      "1:\tlearn: 1.2868761\ttotal: 186ms\tremaining: 4.46s\n",
      "2:\tlearn: 1.2069274\ttotal: 289ms\tremaining: 4.53s\n",
      "3:\tlearn: 1.2591811\ttotal: 406ms\tremaining: 4.67s\n",
      "4:\tlearn: 1.2358491\ttotal: 491ms\tremaining: 4.42s\n",
      "5:\tlearn: 1.1135678\ttotal: 599ms\tremaining: 4.39s\n",
      "6:\tlearn: 1.2131935\ttotal: 696ms\tremaining: 4.28s\n",
      "7:\tlearn: 1.0560568\ttotal: 794ms\tremaining: 4.17s\n",
      "8:\tlearn: 0.9978661\ttotal: 905ms\tremaining: 4.12s\n",
      "9:\tlearn: 0.9668202\ttotal: 995ms\tremaining: 3.98s\n",
      "10:\tlearn: 0.9282470\ttotal: 1.08s\tremaining: 3.83s\n",
      "11:\tlearn: 0.8936989\ttotal: 1.17s\tremaining: 3.71s\n",
      "12:\tlearn: 0.8631421\ttotal: 1.26s\tremaining: 3.58s\n",
      "13:\tlearn: 0.8320332\ttotal: 1.35s\tremaining: 3.47s\n",
      "14:\tlearn: 0.8719433\ttotal: 1.43s\tremaining: 3.33s\n",
      "15:\tlearn: 0.8270734\ttotal: 1.5s\tremaining: 3.19s\n",
      "16:\tlearn: 0.8129897\ttotal: 1.58s\tremaining: 3.06s\n",
      "17:\tlearn: 0.7952248\ttotal: 1.67s\tremaining: 2.96s\n",
      "18:\tlearn: 0.7811221\ttotal: 1.75s\tremaining: 2.86s\n",
      "19:\tlearn: 0.7727428\ttotal: 1.83s\tremaining: 2.75s\n",
      "20:\tlearn: 0.7676297\ttotal: 1.9s\tremaining: 2.62s\n",
      "21:\tlearn: 0.7569438\ttotal: 1.98s\tremaining: 2.52s\n",
      "22:\tlearn: 0.7502177\ttotal: 2.04s\tremaining: 2.4s\n",
      "23:\tlearn: 0.7322262\ttotal: 2.13s\tremaining: 2.3s\n",
      "24:\tlearn: 0.7260848\ttotal: 2.2s\tremaining: 2.2s\n",
      "25:\tlearn: 0.7219858\ttotal: 2.26s\tremaining: 2.09s\n",
      "26:\tlearn: 0.7177420\ttotal: 2.33s\tremaining: 1.98s\n",
      "27:\tlearn: 0.7119295\ttotal: 2.39s\tremaining: 1.88s\n",
      "28:\tlearn: 0.6964787\ttotal: 2.48s\tremaining: 1.8s\n",
      "29:\tlearn: 0.6917295\ttotal: 2.56s\tremaining: 1.71s\n",
      "30:\tlearn: 0.6885751\ttotal: 2.62s\tremaining: 1.6s\n",
      "31:\tlearn: 0.6796224\ttotal: 2.7s\tremaining: 1.52s\n",
      "32:\tlearn: 0.6753834\ttotal: 2.77s\tremaining: 1.43s\n",
      "33:\tlearn: 0.6666199\ttotal: 2.89s\tremaining: 1.36s\n",
      "34:\tlearn: 0.6633736\ttotal: 2.95s\tremaining: 1.26s\n",
      "35:\tlearn: 0.6609227\ttotal: 3.02s\tremaining: 1.17s\n",
      "36:\tlearn: 0.6581662\ttotal: 3.08s\tremaining: 1.08s\n",
      "37:\tlearn: 0.6381378\ttotal: 3.15s\tremaining: 996ms\n",
      "38:\tlearn: 0.6323538\ttotal: 3.22s\tremaining: 907ms\n",
      "39:\tlearn: 0.6263121\ttotal: 3.28s\tremaining: 821ms\n",
      "40:\tlearn: 0.6246289\ttotal: 3.36s\tremaining: 737ms\n",
      "41:\tlearn: 0.6228307\ttotal: 3.42s\tremaining: 651ms\n",
      "42:\tlearn: 0.6192888\ttotal: 3.48s\tremaining: 567ms\n",
      "43:\tlearn: 0.6153719\ttotal: 3.55s\tremaining: 484ms\n",
      "44:\tlearn: 0.6116215\ttotal: 3.62s\tremaining: 402ms\n",
      "45:\tlearn: 0.6094971\ttotal: 3.69s\tremaining: 321ms\n",
      "46:\tlearn: 0.6021314\ttotal: 3.77s\tremaining: 241ms\n",
      "47:\tlearn: 0.5999093\ttotal: 3.84s\tremaining: 160ms\n",
      "48:\tlearn: 0.5961066\ttotal: 3.92s\tremaining: 79.9ms\n",
      "49:\tlearn: 0.5944487\ttotal: 3.97s\tremaining: 0us\n",
      "0:\tlearn: 1.5969118\ttotal: 83.9ms\tremaining: 4.11s\n",
      "1:\tlearn: 1.3103836\ttotal: 148ms\tremaining: 3.54s\n",
      "2:\tlearn: 1.2129746\ttotal: 235ms\tremaining: 3.68s\n",
      "3:\tlearn: 1.0905230\ttotal: 327ms\tremaining: 3.76s\n",
      "4:\tlearn: 0.9797581\ttotal: 414ms\tremaining: 3.73s\n",
      "5:\tlearn: 0.9616224\ttotal: 500ms\tremaining: 3.67s\n",
      "6:\tlearn: 0.8911732\ttotal: 584ms\tremaining: 3.59s\n",
      "7:\tlearn: 0.8292906\ttotal: 672ms\tremaining: 3.53s\n",
      "8:\tlearn: 0.7856031\ttotal: 803ms\tremaining: 3.66s\n",
      "9:\tlearn: 0.7552508\ttotal: 958ms\tremaining: 3.83s\n",
      "10:\tlearn: 0.7170867\ttotal: 1.07s\tremaining: 3.81s\n",
      "11:\tlearn: 0.6883282\ttotal: 1.16s\tremaining: 3.66s\n",
      "12:\tlearn: 0.6652474\ttotal: 1.23s\tremaining: 3.51s\n",
      "13:\tlearn: 0.6484559\ttotal: 1.31s\tremaining: 3.36s\n",
      "14:\tlearn: 0.6320572\ttotal: 1.39s\tremaining: 3.25s\n",
      "15:\tlearn: 0.6170387\ttotal: 1.48s\tremaining: 3.13s\n",
      "16:\tlearn: 0.6065463\ttotal: 1.57s\tremaining: 3.05s\n",
      "17:\tlearn: 0.5939297\ttotal: 1.68s\tremaining: 2.99s\n",
      "18:\tlearn: 0.5826200\ttotal: 1.79s\tremaining: 2.92s\n",
      "19:\tlearn: 0.5760293\ttotal: 1.87s\tremaining: 2.81s\n",
      "20:\tlearn: 0.5689355\ttotal: 1.97s\tremaining: 2.72s\n",
      "21:\tlearn: 0.5646152\ttotal: 2.05s\tremaining: 2.61s\n",
      "22:\tlearn: 0.5624195\ttotal: 2.11s\tremaining: 2.47s\n",
      "23:\tlearn: 0.5588198\ttotal: 2.17s\tremaining: 2.35s\n",
      "24:\tlearn: 0.5494935\ttotal: 2.26s\tremaining: 2.26s\n",
      "25:\tlearn: 0.5401635\ttotal: 2.34s\tremaining: 2.16s\n",
      "26:\tlearn: 0.5361847\ttotal: 2.44s\tremaining: 2.08s\n",
      "27:\tlearn: 0.5325413\ttotal: 2.53s\tremaining: 1.99s\n",
      "28:\tlearn: 0.5285964\ttotal: 2.6s\tremaining: 1.88s\n",
      "29:\tlearn: 0.5254682\ttotal: 2.67s\tremaining: 1.78s\n",
      "30:\tlearn: 0.5203986\ttotal: 2.75s\tremaining: 1.69s\n",
      "31:\tlearn: 0.5172851\ttotal: 2.84s\tremaining: 1.6s\n",
      "32:\tlearn: 0.5128248\ttotal: 2.93s\tremaining: 1.51s\n",
      "33:\tlearn: 0.5101976\ttotal: 3.01s\tremaining: 1.42s\n",
      "34:\tlearn: 0.5077774\ttotal: 3.09s\tremaining: 1.32s\n",
      "35:\tlearn: 0.5011240\ttotal: 3.15s\tremaining: 1.22s\n",
      "36:\tlearn: 0.4971370\ttotal: 3.23s\tremaining: 1.14s\n",
      "37:\tlearn: 0.4934769\ttotal: 3.31s\tremaining: 1.04s\n",
      "38:\tlearn: 0.4889136\ttotal: 3.4s\tremaining: 960ms\n",
      "39:\tlearn: 0.4842181\ttotal: 3.5s\tremaining: 875ms\n",
      "40:\tlearn: 0.4790665\ttotal: 3.59s\tremaining: 789ms\n",
      "41:\tlearn: 0.4764736\ttotal: 3.66s\tremaining: 697ms\n",
      "42:\tlearn: 0.4718285\ttotal: 3.74s\tremaining: 608ms\n",
      "43:\tlearn: 0.4703387\ttotal: 3.82s\tremaining: 520ms\n",
      "44:\tlearn: 0.4694928\ttotal: 3.89s\tremaining: 433ms\n",
      "45:\tlearn: 0.4681639\ttotal: 3.97s\tremaining: 345ms\n",
      "46:\tlearn: 0.4664499\ttotal: 4.04s\tremaining: 258ms\n",
      "47:\tlearn: 0.4632181\ttotal: 4.11s\tremaining: 171ms\n",
      "48:\tlearn: 0.4602233\ttotal: 4.18s\tremaining: 85.4ms\n",
      "49:\tlearn: 0.4582348\ttotal: 4.26s\tremaining: 0us\n",
      "0:\tlearn: 2.2756282\ttotal: 143ms\tremaining: 14.1s\n",
      "1:\tlearn: 2.2504542\ttotal: 219ms\tremaining: 10.7s\n",
      "2:\tlearn: 2.2268848\ttotal: 293ms\tremaining: 9.47s\n",
      "3:\tlearn: 2.2034461\ttotal: 370ms\tremaining: 8.87s\n",
      "4:\tlearn: 2.1800353\ttotal: 454ms\tremaining: 8.62s\n",
      "5:\tlearn: 2.1589622\ttotal: 530ms\tremaining: 8.31s\n",
      "6:\tlearn: 2.1387904\ttotal: 609ms\tremaining: 8.09s\n",
      "7:\tlearn: 2.1194893\ttotal: 687ms\tremaining: 7.9s\n",
      "8:\tlearn: 2.0991401\ttotal: 773ms\tremaining: 7.81s\n",
      "9:\tlearn: 2.0797159\ttotal: 860ms\tremaining: 7.74s\n",
      "10:\tlearn: 2.0624048\ttotal: 940ms\tremaining: 7.61s\n",
      "11:\tlearn: 2.0458741\ttotal: 1.02s\tremaining: 7.48s\n",
      "12:\tlearn: 2.0302765\ttotal: 1.1s\tremaining: 7.4s\n",
      "13:\tlearn: 2.0134852\ttotal: 1.19s\tremaining: 7.32s\n",
      "14:\tlearn: 1.9974696\ttotal: 1.27s\tremaining: 7.21s\n",
      "15:\tlearn: 1.9801576\ttotal: 1.36s\tremaining: 7.13s\n",
      "16:\tlearn: 1.9631199\ttotal: 1.45s\tremaining: 7.06s\n",
      "17:\tlearn: 1.9483252\ttotal: 1.53s\tremaining: 6.97s\n",
      "18:\tlearn: 1.9349998\ttotal: 1.61s\tremaining: 6.87s\n",
      "19:\tlearn: 1.9200673\ttotal: 1.7s\tremaining: 6.81s\n",
      "20:\tlearn: 1.9058736\ttotal: 1.79s\tremaining: 6.74s\n",
      "21:\tlearn: 1.8915828\ttotal: 1.89s\tremaining: 6.69s\n",
      "22:\tlearn: 1.8769847\ttotal: 1.98s\tremaining: 6.62s\n",
      "23:\tlearn: 1.8648099\ttotal: 2.06s\tremaining: 6.53s\n",
      "24:\tlearn: 1.8519857\ttotal: 2.16s\tremaining: 6.49s\n",
      "25:\tlearn: 1.8381391\ttotal: 2.25s\tremaining: 6.41s\n",
      "26:\tlearn: 1.8262921\ttotal: 2.34s\tremaining: 6.32s\n",
      "27:\tlearn: 1.8137760\ttotal: 2.42s\tremaining: 6.21s\n",
      "28:\tlearn: 1.8021825\ttotal: 2.5s\tremaining: 6.13s\n",
      "29:\tlearn: 1.7909263\ttotal: 2.59s\tremaining: 6.04s\n",
      "30:\tlearn: 1.7796770\ttotal: 2.69s\tremaining: 5.98s\n",
      "31:\tlearn: 1.7666104\ttotal: 2.81s\tremaining: 5.97s\n",
      "32:\tlearn: 1.7547963\ttotal: 2.9s\tremaining: 5.89s\n",
      "33:\tlearn: 1.7459996\ttotal: 2.98s\tremaining: 5.78s\n",
      "34:\tlearn: 1.7339920\ttotal: 3.08s\tremaining: 5.72s\n",
      "35:\tlearn: 1.7223199\ttotal: 3.18s\tremaining: 5.66s\n",
      "36:\tlearn: 1.7120850\ttotal: 3.26s\tremaining: 5.56s\n",
      "37:\tlearn: 1.7019442\ttotal: 3.36s\tremaining: 5.48s\n",
      "38:\tlearn: 1.6924788\ttotal: 3.45s\tremaining: 5.39s\n",
      "39:\tlearn: 1.6819899\ttotal: 3.54s\tremaining: 5.31s\n",
      "40:\tlearn: 1.6728333\ttotal: 3.63s\tremaining: 5.22s\n",
      "41:\tlearn: 1.6630244\ttotal: 3.72s\tremaining: 5.13s\n",
      "42:\tlearn: 1.6547669\ttotal: 3.81s\tremaining: 5.05s\n",
      "43:\tlearn: 1.6452349\ttotal: 3.9s\tremaining: 4.97s\n",
      "44:\tlearn: 1.6370997\ttotal: 3.99s\tremaining: 4.87s\n",
      "45:\tlearn: 1.6285728\ttotal: 4.07s\tremaining: 4.78s\n",
      "46:\tlearn: 1.6190982\ttotal: 4.17s\tremaining: 4.7s\n",
      "47:\tlearn: 1.6104807\ttotal: 4.26s\tremaining: 4.62s\n",
      "48:\tlearn: 1.6020463\ttotal: 4.35s\tremaining: 4.53s\n",
      "49:\tlearn: 1.5928468\ttotal: 4.43s\tremaining: 4.43s\n",
      "50:\tlearn: 1.5844217\ttotal: 4.52s\tremaining: 4.34s\n",
      "51:\tlearn: 1.5766308\ttotal: 4.61s\tremaining: 4.26s\n",
      "52:\tlearn: 1.5673758\ttotal: 4.7s\tremaining: 4.17s\n",
      "53:\tlearn: 1.5588601\ttotal: 4.8s\tremaining: 4.09s\n",
      "54:\tlearn: 1.5516005\ttotal: 4.88s\tremaining: 4s\n",
      "55:\tlearn: 1.5433873\ttotal: 4.97s\tremaining: 3.91s\n",
      "56:\tlearn: 1.5360875\ttotal: 5.06s\tremaining: 3.82s\n",
      "57:\tlearn: 1.5287793\ttotal: 5.14s\tremaining: 3.72s\n",
      "58:\tlearn: 1.5211384\ttotal: 5.23s\tremaining: 3.63s\n",
      "59:\tlearn: 1.5132376\ttotal: 5.32s\tremaining: 3.54s\n",
      "60:\tlearn: 1.5065747\ttotal: 5.4s\tremaining: 3.45s\n",
      "61:\tlearn: 1.4990832\ttotal: 5.49s\tremaining: 3.37s\n",
      "62:\tlearn: 1.4921304\ttotal: 5.59s\tremaining: 3.28s\n",
      "63:\tlearn: 1.4848171\ttotal: 5.68s\tremaining: 3.19s\n",
      "64:\tlearn: 1.4778031\ttotal: 5.77s\tremaining: 3.11s\n",
      "65:\tlearn: 1.4701706\ttotal: 5.86s\tremaining: 3.02s\n",
      "66:\tlearn: 1.4634391\ttotal: 5.95s\tremaining: 2.93s\n",
      "67:\tlearn: 1.4560855\ttotal: 6.04s\tremaining: 2.84s\n",
      "68:\tlearn: 1.4499583\ttotal: 6.12s\tremaining: 2.75s\n",
      "69:\tlearn: 1.4434459\ttotal: 6.21s\tremaining: 2.66s\n",
      "70:\tlearn: 1.4378745\ttotal: 6.29s\tremaining: 2.57s\n",
      "71:\tlearn: 1.4314756\ttotal: 6.38s\tremaining: 2.48s\n",
      "72:\tlearn: 1.4254876\ttotal: 6.46s\tremaining: 2.39s\n",
      "73:\tlearn: 1.4188693\ttotal: 6.54s\tremaining: 2.3s\n",
      "74:\tlearn: 1.4126911\ttotal: 6.63s\tremaining: 2.21s\n",
      "75:\tlearn: 1.4074864\ttotal: 6.72s\tremaining: 2.12s\n",
      "76:\tlearn: 1.4018986\ttotal: 6.8s\tremaining: 2.03s\n",
      "77:\tlearn: 1.3955521\ttotal: 6.89s\tremaining: 1.94s\n",
      "78:\tlearn: 1.3903655\ttotal: 6.97s\tremaining: 1.85s\n",
      "79:\tlearn: 1.3857381\ttotal: 7.05s\tremaining: 1.76s\n",
      "80:\tlearn: 1.3806541\ttotal: 7.13s\tremaining: 1.67s\n",
      "81:\tlearn: 1.3748759\ttotal: 7.22s\tremaining: 1.58s\n",
      "82:\tlearn: 1.3689754\ttotal: 7.3s\tremaining: 1.5s\n",
      "83:\tlearn: 1.3630267\ttotal: 7.39s\tremaining: 1.41s\n",
      "84:\tlearn: 1.3570733\ttotal: 7.49s\tremaining: 1.32s\n",
      "85:\tlearn: 1.3516045\ttotal: 7.58s\tremaining: 1.23s\n",
      "86:\tlearn: 1.3458217\ttotal: 7.67s\tremaining: 1.15s\n",
      "87:\tlearn: 1.3403653\ttotal: 7.75s\tremaining: 1.06s\n",
      "88:\tlearn: 1.3358159\ttotal: 7.82s\tremaining: 967ms\n",
      "89:\tlearn: 1.3313733\ttotal: 7.9s\tremaining: 878ms\n",
      "90:\tlearn: 1.3268484\ttotal: 7.98s\tremaining: 789ms\n",
      "91:\tlearn: 1.3221128\ttotal: 8.06s\tremaining: 701ms\n",
      "92:\tlearn: 1.3179038\ttotal: 8.13s\tremaining: 612ms\n",
      "93:\tlearn: 1.3131651\ttotal: 8.21s\tremaining: 524ms\n",
      "94:\tlearn: 1.3092564\ttotal: 8.28s\tremaining: 436ms\n",
      "95:\tlearn: 1.3048717\ttotal: 8.38s\tremaining: 349ms\n",
      "96:\tlearn: 1.3005995\ttotal: 8.46s\tremaining: 262ms\n",
      "97:\tlearn: 1.2966938\ttotal: 8.56s\tremaining: 175ms\n",
      "98:\tlearn: 1.2922096\ttotal: 8.64s\tremaining: 87.3ms\n",
      "99:\tlearn: 1.2877058\ttotal: 8.72s\tremaining: 0us\n",
      "0:\tlearn: 2.2745478\ttotal: 91.7ms\tremaining: 9.08s\n",
      "1:\tlearn: 2.2491091\ttotal: 167ms\tremaining: 8.19s\n",
      "2:\tlearn: 2.2248687\ttotal: 242ms\tremaining: 7.81s\n",
      "3:\tlearn: 2.2015363\ttotal: 318ms\tremaining: 7.63s\n",
      "4:\tlearn: 2.1793654\ttotal: 398ms\tremaining: 7.56s\n",
      "5:\tlearn: 2.1570508\ttotal: 484ms\tremaining: 7.59s\n",
      "6:\tlearn: 2.1369424\ttotal: 564ms\tremaining: 7.49s\n",
      "7:\tlearn: 2.1163147\ttotal: 646ms\tremaining: 7.43s\n",
      "8:\tlearn: 2.0974866\ttotal: 746ms\tremaining: 7.55s\n",
      "9:\tlearn: 2.0770918\ttotal: 835ms\tremaining: 7.52s\n",
      "10:\tlearn: 2.0572351\ttotal: 922ms\tremaining: 7.46s\n",
      "11:\tlearn: 2.0405087\ttotal: 1s\tremaining: 7.34s\n",
      "12:\tlearn: 2.0249213\ttotal: 1.08s\tremaining: 7.23s\n",
      "13:\tlearn: 2.0082455\ttotal: 1.17s\tremaining: 7.17s\n",
      "14:\tlearn: 1.9921855\ttotal: 1.25s\tremaining: 7.07s\n",
      "15:\tlearn: 1.9761503\ttotal: 1.33s\tremaining: 7s\n",
      "16:\tlearn: 1.9615636\ttotal: 1.42s\tremaining: 6.93s\n",
      "17:\tlearn: 1.9466888\ttotal: 1.5s\tremaining: 6.85s\n",
      "18:\tlearn: 1.9333366\ttotal: 1.58s\tremaining: 6.75s\n",
      "19:\tlearn: 1.9183910\ttotal: 1.67s\tremaining: 6.69s\n",
      "20:\tlearn: 1.9047091\ttotal: 1.76s\tremaining: 6.61s\n",
      "21:\tlearn: 1.8929217\ttotal: 1.83s\tremaining: 6.5s\n",
      "22:\tlearn: 1.8793373\ttotal: 1.92s\tremaining: 6.44s\n",
      "23:\tlearn: 1.8643355\ttotal: 2.01s\tremaining: 6.37s\n",
      "24:\tlearn: 1.8511005\ttotal: 2.1s\tremaining: 6.3s\n",
      "25:\tlearn: 1.8379911\ttotal: 2.19s\tremaining: 6.22s\n",
      "26:\tlearn: 1.8261560\ttotal: 2.27s\tremaining: 6.14s\n",
      "27:\tlearn: 1.8134640\ttotal: 2.35s\tremaining: 6.04s\n",
      "28:\tlearn: 1.8017106\ttotal: 2.43s\tremaining: 5.96s\n",
      "29:\tlearn: 1.7889316\ttotal: 2.52s\tremaining: 5.89s\n",
      "30:\tlearn: 1.7776919\ttotal: 2.62s\tremaining: 5.82s\n",
      "31:\tlearn: 1.7647214\ttotal: 2.7s\tremaining: 5.75s\n",
      "32:\tlearn: 1.7524029\ttotal: 2.79s\tremaining: 5.68s\n",
      "33:\tlearn: 1.7420787\ttotal: 2.88s\tremaining: 5.59s\n",
      "34:\tlearn: 1.7304279\ttotal: 2.98s\tremaining: 5.53s\n",
      "35:\tlearn: 1.7191754\ttotal: 3.08s\tremaining: 5.47s\n",
      "36:\tlearn: 1.7084387\ttotal: 3.17s\tremaining: 5.39s\n",
      "37:\tlearn: 1.6967500\ttotal: 3.26s\tremaining: 5.31s\n",
      "38:\tlearn: 1.6872836\ttotal: 3.34s\tremaining: 5.23s\n",
      "39:\tlearn: 1.6769896\ttotal: 3.44s\tremaining: 5.16s\n",
      "40:\tlearn: 1.6677922\ttotal: 3.52s\tremaining: 5.07s\n",
      "41:\tlearn: 1.6580497\ttotal: 3.62s\tremaining: 5s\n",
      "42:\tlearn: 1.6485962\ttotal: 3.71s\tremaining: 4.92s\n",
      "43:\tlearn: 1.6400718\ttotal: 3.79s\tremaining: 4.82s\n",
      "44:\tlearn: 1.6316004\ttotal: 3.87s\tremaining: 4.73s\n",
      "45:\tlearn: 1.6220881\ttotal: 3.96s\tremaining: 4.65s\n",
      "46:\tlearn: 1.6128068\ttotal: 4.05s\tremaining: 4.57s\n",
      "47:\tlearn: 1.6036514\ttotal: 4.14s\tremaining: 4.48s\n",
      "48:\tlearn: 1.5953113\ttotal: 4.22s\tremaining: 4.4s\n",
      "49:\tlearn: 1.5863937\ttotal: 4.31s\tremaining: 4.31s\n",
      "50:\tlearn: 1.5777035\ttotal: 4.4s\tremaining: 4.22s\n",
      "51:\tlearn: 1.5700545\ttotal: 4.48s\tremaining: 4.13s\n",
      "52:\tlearn: 1.5609995\ttotal: 4.56s\tremaining: 4.05s\n",
      "53:\tlearn: 1.5529153\ttotal: 4.65s\tremaining: 3.96s\n",
      "54:\tlearn: 1.5455154\ttotal: 4.72s\tremaining: 3.87s\n",
      "55:\tlearn: 1.5373922\ttotal: 4.82s\tremaining: 3.79s\n",
      "56:\tlearn: 1.5300767\ttotal: 4.9s\tremaining: 3.7s\n",
      "57:\tlearn: 1.5227784\ttotal: 4.98s\tremaining: 3.6s\n",
      "58:\tlearn: 1.5153023\ttotal: 5.07s\tremaining: 3.52s\n",
      "59:\tlearn: 1.5077675\ttotal: 5.16s\tremaining: 3.44s\n",
      "60:\tlearn: 1.5011833\ttotal: 5.24s\tremaining: 3.35s\n",
      "61:\tlearn: 1.4941243\ttotal: 5.34s\tremaining: 3.27s\n",
      "62:\tlearn: 1.4869275\ttotal: 5.43s\tremaining: 3.19s\n",
      "63:\tlearn: 1.4797484\ttotal: 5.52s\tremaining: 3.1s\n",
      "64:\tlearn: 1.4730172\ttotal: 5.61s\tremaining: 3.02s\n",
      "65:\tlearn: 1.4655454\ttotal: 5.7s\tremaining: 2.93s\n",
      "66:\tlearn: 1.4595652\ttotal: 5.79s\tremaining: 2.85s\n",
      "67:\tlearn: 1.4523818\ttotal: 5.88s\tremaining: 2.77s\n",
      "68:\tlearn: 1.4457170\ttotal: 5.96s\tremaining: 2.68s\n",
      "69:\tlearn: 1.4397227\ttotal: 6.04s\tremaining: 2.59s\n",
      "70:\tlearn: 1.4338370\ttotal: 6.12s\tremaining: 2.5s\n",
      "71:\tlearn: 1.4273352\ttotal: 6.21s\tremaining: 2.42s\n",
      "72:\tlearn: 1.4208947\ttotal: 6.31s\tremaining: 2.33s\n",
      "73:\tlearn: 1.4153907\ttotal: 6.39s\tremaining: 2.25s\n",
      "74:\tlearn: 1.4095525\ttotal: 6.48s\tremaining: 2.16s\n",
      "75:\tlearn: 1.4043894\ttotal: 6.57s\tremaining: 2.07s\n",
      "76:\tlearn: 1.3989861\ttotal: 6.65s\tremaining: 1.99s\n",
      "77:\tlearn: 1.3924319\ttotal: 6.75s\tremaining: 1.9s\n",
      "78:\tlearn: 1.3873662\ttotal: 6.83s\tremaining: 1.81s\n",
      "79:\tlearn: 1.3823791\ttotal: 6.91s\tremaining: 1.73s\n",
      "80:\tlearn: 1.3773625\ttotal: 6.99s\tremaining: 1.64s\n",
      "81:\tlearn: 1.3715460\ttotal: 7.08s\tremaining: 1.55s\n",
      "82:\tlearn: 1.3658593\ttotal: 7.16s\tremaining: 1.47s\n",
      "83:\tlearn: 1.3599959\ttotal: 7.25s\tremaining: 1.38s\n",
      "84:\tlearn: 1.3549072\ttotal: 7.33s\tremaining: 1.29s\n",
      "85:\tlearn: 1.3494997\ttotal: 7.42s\tremaining: 1.21s\n",
      "86:\tlearn: 1.3442854\ttotal: 7.5s\tremaining: 1.12s\n",
      "87:\tlearn: 1.3389186\ttotal: 7.58s\tremaining: 1.03s\n",
      "88:\tlearn: 1.3342402\ttotal: 7.64s\tremaining: 945ms\n",
      "89:\tlearn: 1.3296371\ttotal: 7.72s\tremaining: 858ms\n",
      "90:\tlearn: 1.3251353\ttotal: 7.8s\tremaining: 771ms\n",
      "91:\tlearn: 1.3200123\ttotal: 7.88s\tremaining: 686ms\n",
      "92:\tlearn: 1.3159329\ttotal: 7.95s\tremaining: 598ms\n",
      "93:\tlearn: 1.3112317\ttotal: 8.03s\tremaining: 513ms\n",
      "94:\tlearn: 1.3072548\ttotal: 8.1s\tremaining: 427ms\n",
      "95:\tlearn: 1.3028852\ttotal: 8.18s\tremaining: 341ms\n",
      "96:\tlearn: 1.2986706\ttotal: 8.27s\tremaining: 256ms\n",
      "97:\tlearn: 1.2943526\ttotal: 8.35s\tremaining: 170ms\n",
      "98:\tlearn: 1.2901212\ttotal: 8.42s\tremaining: 85.1ms\n",
      "99:\tlearn: 1.2851408\ttotal: 8.52s\tremaining: 0us\n",
      "0:\tlearn: 2.2745527\ttotal: 98.8ms\tremaining: 9.78s\n",
      "1:\tlearn: 2.2483020\ttotal: 182ms\tremaining: 8.93s\n",
      "2:\tlearn: 2.2237348\ttotal: 258ms\tremaining: 8.34s\n",
      "3:\tlearn: 2.2001446\ttotal: 363ms\tremaining: 8.72s\n",
      "4:\tlearn: 2.1779610\ttotal: 466ms\tremaining: 8.86s\n",
      "5:\tlearn: 2.1567463\ttotal: 561ms\tremaining: 8.79s\n",
      "6:\tlearn: 2.1368141\ttotal: 639ms\tremaining: 8.49s\n",
      "7:\tlearn: 2.1159693\ttotal: 722ms\tremaining: 8.3s\n",
      "8:\tlearn: 2.0955090\ttotal: 812ms\tremaining: 8.21s\n",
      "9:\tlearn: 2.0752417\ttotal: 904ms\tremaining: 8.13s\n",
      "10:\tlearn: 2.0578462\ttotal: 987ms\tremaining: 7.99s\n",
      "11:\tlearn: 2.0411178\ttotal: 1.07s\tremaining: 7.83s\n",
      "12:\tlearn: 2.0255488\ttotal: 1.15s\tremaining: 7.68s\n",
      "13:\tlearn: 2.0090437\ttotal: 1.23s\tremaining: 7.58s\n",
      "14:\tlearn: 1.9930720\ttotal: 1.32s\tremaining: 7.49s\n",
      "15:\tlearn: 1.9786468\ttotal: 1.44s\tremaining: 7.54s\n",
      "16:\tlearn: 1.9635703\ttotal: 1.51s\tremaining: 7.4s\n",
      "17:\tlearn: 1.9486229\ttotal: 1.6s\tremaining: 7.28s\n",
      "18:\tlearn: 1.9352437\ttotal: 1.68s\tremaining: 7.17s\n",
      "19:\tlearn: 1.9202594\ttotal: 1.77s\tremaining: 7.08s\n",
      "20:\tlearn: 1.9061861\ttotal: 1.85s\tremaining: 6.98s\n",
      "21:\tlearn: 1.8938795\ttotal: 1.94s\tremaining: 6.88s\n",
      "22:\tlearn: 1.8790681\ttotal: 2.03s\tremaining: 6.78s\n",
      "23:\tlearn: 1.8642363\ttotal: 2.12s\tremaining: 6.72s\n",
      "24:\tlearn: 1.8515717\ttotal: 2.21s\tremaining: 6.65s\n",
      "25:\tlearn: 1.8385113\ttotal: 2.3s\tremaining: 6.56s\n",
      "26:\tlearn: 1.8266342\ttotal: 2.39s\tremaining: 6.46s\n",
      "27:\tlearn: 1.8141225\ttotal: 2.52s\tremaining: 6.47s\n",
      "28:\tlearn: 1.8010874\ttotal: 2.6s\tremaining: 6.38s\n",
      "29:\tlearn: 1.7885986\ttotal: 2.69s\tremaining: 6.28s\n",
      "30:\tlearn: 1.7772518\ttotal: 2.79s\tremaining: 6.2s\n",
      "31:\tlearn: 1.7649699\ttotal: 2.88s\tremaining: 6.13s\n",
      "32:\tlearn: 1.7526377\ttotal: 2.98s\tremaining: 6.06s\n",
      "33:\tlearn: 1.7411382\ttotal: 3.07s\tremaining: 5.97s\n",
      "34:\tlearn: 1.7293323\ttotal: 3.17s\tremaining: 5.89s\n",
      "35:\tlearn: 1.7179613\ttotal: 3.27s\tremaining: 5.82s\n",
      "36:\tlearn: 1.7070240\ttotal: 3.37s\tremaining: 5.74s\n",
      "37:\tlearn: 1.6959472\ttotal: 3.46s\tremaining: 5.65s\n",
      "38:\tlearn: 1.6864904\ttotal: 3.55s\tremaining: 5.55s\n",
      "39:\tlearn: 1.6761457\ttotal: 3.64s\tremaining: 5.46s\n",
      "40:\tlearn: 1.6671505\ttotal: 3.73s\tremaining: 5.36s\n",
      "41:\tlearn: 1.6574689\ttotal: 3.81s\tremaining: 5.27s\n",
      "42:\tlearn: 1.6476955\ttotal: 3.9s\tremaining: 5.17s\n",
      "43:\tlearn: 1.6389069\ttotal: 3.99s\tremaining: 5.08s\n",
      "44:\tlearn: 1.6295991\ttotal: 4.08s\tremaining: 4.99s\n",
      "45:\tlearn: 1.6202857\ttotal: 4.17s\tremaining: 4.89s\n",
      "46:\tlearn: 1.6114148\ttotal: 4.26s\tremaining: 4.8s\n",
      "47:\tlearn: 1.6023835\ttotal: 4.34s\tremaining: 4.7s\n",
      "48:\tlearn: 1.5941333\ttotal: 4.43s\tremaining: 4.61s\n",
      "49:\tlearn: 1.5854408\ttotal: 4.52s\tremaining: 4.52s\n",
      "50:\tlearn: 1.5766516\ttotal: 4.61s\tremaining: 4.42s\n",
      "51:\tlearn: 1.5688339\ttotal: 4.69s\tremaining: 4.33s\n",
      "52:\tlearn: 1.5605270\ttotal: 4.78s\tremaining: 4.24s\n",
      "53:\tlearn: 1.5524747\ttotal: 4.87s\tremaining: 4.15s\n",
      "54:\tlearn: 1.5449691\ttotal: 4.95s\tremaining: 4.05s\n",
      "55:\tlearn: 1.5372823\ttotal: 5.04s\tremaining: 3.96s\n",
      "56:\tlearn: 1.5304021\ttotal: 5.13s\tremaining: 3.87s\n",
      "57:\tlearn: 1.5232046\ttotal: 5.21s\tremaining: 3.77s\n",
      "58:\tlearn: 1.5158143\ttotal: 5.29s\tremaining: 3.68s\n",
      "59:\tlearn: 1.5085726\ttotal: 5.39s\tremaining: 3.59s\n",
      "60:\tlearn: 1.5019107\ttotal: 5.48s\tremaining: 3.5s\n",
      "61:\tlearn: 1.4951393\ttotal: 5.57s\tremaining: 3.41s\n",
      "62:\tlearn: 1.4880399\ttotal: 5.66s\tremaining: 3.32s\n",
      "63:\tlearn: 1.4808903\ttotal: 5.76s\tremaining: 3.24s\n",
      "64:\tlearn: 1.4750400\ttotal: 5.84s\tremaining: 3.15s\n",
      "65:\tlearn: 1.4676540\ttotal: 5.94s\tremaining: 3.06s\n",
      "66:\tlearn: 1.4616303\ttotal: 6.03s\tremaining: 2.97s\n",
      "67:\tlearn: 1.4543717\ttotal: 6.13s\tremaining: 2.88s\n",
      "68:\tlearn: 1.4478419\ttotal: 6.22s\tremaining: 2.79s\n",
      "69:\tlearn: 1.4412956\ttotal: 6.3s\tremaining: 2.7s\n",
      "70:\tlearn: 1.4354530\ttotal: 6.38s\tremaining: 2.61s\n",
      "71:\tlearn: 1.4298563\ttotal: 6.45s\tremaining: 2.51s\n",
      "72:\tlearn: 1.4249559\ttotal: 6.53s\tremaining: 2.42s\n",
      "73:\tlearn: 1.4194738\ttotal: 6.62s\tremaining: 2.33s\n",
      "74:\tlearn: 1.4135270\ttotal: 6.7s\tremaining: 2.23s\n",
      "75:\tlearn: 1.4080210\ttotal: 6.78s\tremaining: 2.14s\n",
      "76:\tlearn: 1.4021731\ttotal: 6.87s\tremaining: 2.05s\n",
      "77:\tlearn: 1.3976484\ttotal: 6.94s\tremaining: 1.96s\n",
      "78:\tlearn: 1.3921583\ttotal: 7.03s\tremaining: 1.87s\n",
      "79:\tlearn: 1.3863840\ttotal: 7.11s\tremaining: 1.78s\n",
      "80:\tlearn: 1.3811652\ttotal: 7.21s\tremaining: 1.69s\n",
      "81:\tlearn: 1.3753716\ttotal: 7.31s\tremaining: 1.6s\n",
      "82:\tlearn: 1.3705142\ttotal: 7.41s\tremaining: 1.52s\n",
      "83:\tlearn: 1.3645548\ttotal: 7.5s\tremaining: 1.43s\n",
      "84:\tlearn: 1.3591780\ttotal: 7.61s\tremaining: 1.34s\n",
      "85:\tlearn: 1.3537475\ttotal: 7.74s\tremaining: 1.26s\n",
      "86:\tlearn: 1.3479344\ttotal: 7.89s\tremaining: 1.18s\n",
      "87:\tlearn: 1.3425274\ttotal: 7.97s\tremaining: 1.09s\n",
      "88:\tlearn: 1.3383691\ttotal: 8.06s\tremaining: 996ms\n",
      "89:\tlearn: 1.3332631\ttotal: 8.15s\tremaining: 905ms\n",
      "90:\tlearn: 1.3283747\ttotal: 8.23s\tremaining: 814ms\n",
      "91:\tlearn: 1.3240460\ttotal: 8.32s\tremaining: 723ms\n",
      "92:\tlearn: 1.3199267\ttotal: 8.38s\tremaining: 631ms\n",
      "93:\tlearn: 1.3151783\ttotal: 8.48s\tremaining: 541ms\n",
      "94:\tlearn: 1.3111637\ttotal: 8.56s\tremaining: 450ms\n",
      "95:\tlearn: 1.3068112\ttotal: 8.64s\tremaining: 360ms\n",
      "96:\tlearn: 1.3030133\ttotal: 8.72s\tremaining: 270ms\n",
      "97:\tlearn: 1.2986118\ttotal: 8.8s\tremaining: 180ms\n",
      "98:\tlearn: 1.2943707\ttotal: 8.88s\tremaining: 89.7ms\n",
      "99:\tlearn: 1.2898878\ttotal: 8.96s\tremaining: 0us\n",
      "0:\tlearn: 1.5161069\ttotal: 96.5ms\tremaining: 9.55s\n",
      "1:\tlearn: 1.2497339\ttotal: 160ms\tremaining: 7.83s\n",
      "2:\tlearn: 1.1053270\ttotal: 242ms\tremaining: 7.81s\n",
      "3:\tlearn: 0.9531728\ttotal: 336ms\tremaining: 8.07s\n",
      "4:\tlearn: 0.8881169\ttotal: 415ms\tremaining: 7.89s\n",
      "5:\tlearn: 0.8357729\ttotal: 508ms\tremaining: 7.95s\n",
      "6:\tlearn: 0.7875413\ttotal: 609ms\tremaining: 8.09s\n",
      "7:\tlearn: 0.7571742\ttotal: 694ms\tremaining: 7.98s\n",
      "8:\tlearn: 0.7293294\ttotal: 780ms\tremaining: 7.89s\n",
      "9:\tlearn: 0.6921629\ttotal: 905ms\tremaining: 8.15s\n",
      "10:\tlearn: 0.6620651\ttotal: 1.03s\tremaining: 8.35s\n",
      "11:\tlearn: 0.6408625\ttotal: 1.13s\tremaining: 8.29s\n",
      "12:\tlearn: 0.6257649\ttotal: 1.21s\tremaining: 8.11s\n",
      "13:\tlearn: 0.6142029\ttotal: 1.3s\tremaining: 7.98s\n",
      "14:\tlearn: 0.6019845\ttotal: 1.39s\tremaining: 7.88s\n",
      "15:\tlearn: 0.5943024\ttotal: 1.47s\tremaining: 7.7s\n",
      "16:\tlearn: 0.5810199\ttotal: 1.54s\tremaining: 7.55s\n",
      "17:\tlearn: 0.5745064\ttotal: 1.63s\tremaining: 7.42s\n",
      "18:\tlearn: 0.5639842\ttotal: 1.71s\tremaining: 7.29s\n",
      "19:\tlearn: 0.5574174\ttotal: 1.78s\tremaining: 7.12s\n",
      "20:\tlearn: 0.5497371\ttotal: 1.87s\tremaining: 7.04s\n",
      "21:\tlearn: 0.5425708\ttotal: 1.96s\tremaining: 6.93s\n",
      "22:\tlearn: 0.5337820\ttotal: 2.05s\tremaining: 6.87s\n",
      "23:\tlearn: 0.5266947\ttotal: 2.14s\tremaining: 6.79s\n",
      "24:\tlearn: 0.5237619\ttotal: 2.21s\tremaining: 6.64s\n",
      "25:\tlearn: 0.5190033\ttotal: 2.29s\tremaining: 6.53s\n",
      "26:\tlearn: 0.5069624\ttotal: 2.39s\tremaining: 6.46s\n",
      "27:\tlearn: 0.4995519\ttotal: 2.47s\tremaining: 6.35s\n",
      "28:\tlearn: 0.4931026\ttotal: 2.55s\tremaining: 6.25s\n",
      "29:\tlearn: 0.4884657\ttotal: 2.64s\tremaining: 6.16s\n",
      "30:\tlearn: 0.4831926\ttotal: 2.72s\tremaining: 6.05s\n",
      "31:\tlearn: 0.4802191\ttotal: 2.79s\tremaining: 5.94s\n",
      "32:\tlearn: 0.4751489\ttotal: 2.88s\tremaining: 5.84s\n",
      "33:\tlearn: 0.4708665\ttotal: 2.96s\tremaining: 5.74s\n",
      "34:\tlearn: 0.4677607\ttotal: 3.02s\tremaining: 5.61s\n",
      "35:\tlearn: 0.4648248\ttotal: 3.08s\tremaining: 5.47s\n",
      "36:\tlearn: 0.4616323\ttotal: 3.16s\tremaining: 5.38s\n",
      "37:\tlearn: 0.4592780\ttotal: 3.23s\tremaining: 5.27s\n",
      "38:\tlearn: 0.4561741\ttotal: 3.31s\tremaining: 5.18s\n",
      "39:\tlearn: 0.4527649\ttotal: 3.38s\tremaining: 5.08s\n",
      "40:\tlearn: 0.4513067\ttotal: 3.44s\tremaining: 4.96s\n",
      "41:\tlearn: 0.4477085\ttotal: 3.53s\tremaining: 4.88s\n",
      "42:\tlearn: 0.4443095\ttotal: 3.62s\tremaining: 4.8s\n",
      "43:\tlearn: 0.4395263\ttotal: 3.71s\tremaining: 4.72s\n",
      "44:\tlearn: 0.4380757\ttotal: 3.77s\tremaining: 4.61s\n",
      "45:\tlearn: 0.4362752\ttotal: 3.85s\tremaining: 4.52s\n",
      "46:\tlearn: 0.4341125\ttotal: 3.92s\tremaining: 4.42s\n",
      "47:\tlearn: 0.4320587\ttotal: 3.98s\tremaining: 4.31s\n",
      "48:\tlearn: 0.4306897\ttotal: 4.05s\tremaining: 4.21s\n",
      "49:\tlearn: 0.4294855\ttotal: 4.11s\tremaining: 4.11s\n",
      "50:\tlearn: 0.4274904\ttotal: 4.18s\tremaining: 4.02s\n",
      "51:\tlearn: 0.4257132\ttotal: 4.25s\tremaining: 3.92s\n",
      "52:\tlearn: 0.4214884\ttotal: 4.34s\tremaining: 3.85s\n",
      "53:\tlearn: 0.4174723\ttotal: 4.43s\tremaining: 3.77s\n",
      "54:\tlearn: 0.4163801\ttotal: 4.49s\tremaining: 3.67s\n",
      "55:\tlearn: 0.4142550\ttotal: 4.58s\tremaining: 3.59s\n",
      "56:\tlearn: 0.4134076\ttotal: 4.63s\tremaining: 3.5s\n",
      "57:\tlearn: 0.4113617\ttotal: 4.71s\tremaining: 3.41s\n",
      "58:\tlearn: 0.4108066\ttotal: 4.76s\tremaining: 3.31s\n",
      "59:\tlearn: 0.4085016\ttotal: 4.84s\tremaining: 3.23s\n",
      "60:\tlearn: 0.4073017\ttotal: 4.9s\tremaining: 3.13s\n",
      "61:\tlearn: 0.4062390\ttotal: 4.96s\tremaining: 3.04s\n",
      "62:\tlearn: 0.4039149\ttotal: 5.04s\tremaining: 2.96s\n",
      "63:\tlearn: 0.4019155\ttotal: 5.11s\tremaining: 2.88s\n",
      "64:\tlearn: 0.4005652\ttotal: 5.18s\tremaining: 2.79s\n",
      "65:\tlearn: 0.3996807\ttotal: 5.25s\tremaining: 2.7s\n",
      "66:\tlearn: 0.3972966\ttotal: 5.32s\tremaining: 2.62s\n",
      "67:\tlearn: 0.3953121\ttotal: 5.39s\tremaining: 2.54s\n",
      "68:\tlearn: 0.3934742\ttotal: 5.46s\tremaining: 2.45s\n",
      "69:\tlearn: 0.3923550\ttotal: 5.55s\tremaining: 2.38s\n",
      "70:\tlearn: 0.3909220\ttotal: 5.63s\tremaining: 2.3s\n",
      "71:\tlearn: 0.3903483\ttotal: 5.69s\tremaining: 2.21s\n",
      "72:\tlearn: 0.3871856\ttotal: 5.79s\tremaining: 2.14s\n",
      "73:\tlearn: 0.3856429\ttotal: 5.87s\tremaining: 2.06s\n",
      "74:\tlearn: 0.3840158\ttotal: 5.95s\tremaining: 1.98s\n",
      "75:\tlearn: 0.3810120\ttotal: 6.04s\tremaining: 1.91s\n",
      "76:\tlearn: 0.3795487\ttotal: 6.12s\tremaining: 1.83s\n",
      "77:\tlearn: 0.3783966\ttotal: 6.19s\tremaining: 1.75s\n",
      "78:\tlearn: 0.3760602\ttotal: 6.28s\tremaining: 1.67s\n",
      "79:\tlearn: 0.3749928\ttotal: 6.36s\tremaining: 1.59s\n",
      "80:\tlearn: 0.3733500\ttotal: 6.44s\tremaining: 1.51s\n",
      "81:\tlearn: 0.3725951\ttotal: 6.51s\tremaining: 1.43s\n",
      "82:\tlearn: 0.3706516\ttotal: 6.59s\tremaining: 1.35s\n",
      "83:\tlearn: 0.3697940\ttotal: 6.67s\tremaining: 1.27s\n",
      "84:\tlearn: 0.3683332\ttotal: 6.76s\tremaining: 1.19s\n",
      "85:\tlearn: 0.3676896\ttotal: 6.84s\tremaining: 1.11s\n",
      "86:\tlearn: 0.3663464\ttotal: 6.93s\tremaining: 1.03s\n",
      "87:\tlearn: 0.3647272\ttotal: 7.01s\tremaining: 957ms\n",
      "88:\tlearn: 0.3630142\ttotal: 7.1s\tremaining: 878ms\n",
      "89:\tlearn: 0.3623167\ttotal: 7.17s\tremaining: 797ms\n",
      "90:\tlearn: 0.3619433\ttotal: 7.23s\tremaining: 715ms\n",
      "91:\tlearn: 0.3613805\ttotal: 7.3s\tremaining: 635ms\n",
      "92:\tlearn: 0.3605591\ttotal: 7.37s\tremaining: 555ms\n",
      "93:\tlearn: 0.3591521\ttotal: 7.46s\tremaining: 476ms\n",
      "94:\tlearn: 0.3584714\ttotal: 7.52s\tremaining: 396ms\n",
      "95:\tlearn: 0.3567881\ttotal: 7.63s\tremaining: 318ms\n",
      "96:\tlearn: 0.3551175\ttotal: 7.7s\tremaining: 238ms\n",
      "97:\tlearn: 0.3542241\ttotal: 7.77s\tremaining: 159ms\n",
      "98:\tlearn: 0.3530303\ttotal: 7.86s\tremaining: 79.4ms\n",
      "99:\tlearn: 0.3524106\ttotal: 7.92s\tremaining: 0us\n",
      "0:\tlearn: 1.4859815\ttotal: 199ms\tremaining: 19.7s\n",
      "1:\tlearn: 1.2176614\ttotal: 287ms\tremaining: 14.1s\n",
      "2:\tlearn: 1.0582276\ttotal: 376ms\tremaining: 12.2s\n",
      "3:\tlearn: 0.9526077\ttotal: 489ms\tremaining: 11.7s\n",
      "4:\tlearn: 0.8951146\ttotal: 579ms\tremaining: 11s\n",
      "5:\tlearn: 0.8491664\ttotal: 666ms\tremaining: 10.4s\n",
      "6:\tlearn: 0.7857463\ttotal: 760ms\tremaining: 10.1s\n",
      "7:\tlearn: 0.7441137\ttotal: 845ms\tremaining: 9.72s\n",
      "8:\tlearn: 0.7092327\ttotal: 942ms\tremaining: 9.53s\n",
      "9:\tlearn: 0.6835149\ttotal: 1.03s\tremaining: 9.32s\n",
      "10:\tlearn: 0.6589470\ttotal: 1.12s\tremaining: 9.08s\n",
      "11:\tlearn: 0.6448432\ttotal: 1.2s\tremaining: 8.83s\n",
      "12:\tlearn: 0.6294034\ttotal: 1.28s\tremaining: 8.58s\n",
      "13:\tlearn: 0.6155853\ttotal: 1.36s\tremaining: 8.36s\n",
      "14:\tlearn: 0.6034235\ttotal: 1.45s\tremaining: 8.21s\n",
      "15:\tlearn: 0.5910996\ttotal: 1.53s\tremaining: 8.06s\n",
      "16:\tlearn: 0.5806671\ttotal: 1.62s\tremaining: 7.91s\n",
      "17:\tlearn: 0.5714467\ttotal: 1.71s\tremaining: 7.79s\n",
      "18:\tlearn: 0.5585376\ttotal: 1.8s\tremaining: 7.67s\n",
      "19:\tlearn: 0.5527907\ttotal: 1.87s\tremaining: 7.49s\n",
      "20:\tlearn: 0.5475708\ttotal: 1.95s\tremaining: 7.34s\n",
      "21:\tlearn: 0.5379247\ttotal: 2.05s\tremaining: 7.25s\n",
      "22:\tlearn: 0.5324436\ttotal: 2.12s\tremaining: 7.1s\n",
      "23:\tlearn: 0.5261746\ttotal: 2.19s\tremaining: 6.94s\n",
      "24:\tlearn: 0.5202973\ttotal: 2.27s\tremaining: 6.8s\n",
      "25:\tlearn: 0.5148082\ttotal: 2.35s\tremaining: 6.7s\n",
      "26:\tlearn: 0.5122796\ttotal: 2.42s\tremaining: 6.56s\n",
      "27:\tlearn: 0.5075930\ttotal: 2.52s\tremaining: 6.49s\n",
      "28:\tlearn: 0.5005131\ttotal: 2.6s\tremaining: 6.38s\n",
      "29:\tlearn: 0.4968232\ttotal: 2.69s\tremaining: 6.28s\n",
      "30:\tlearn: 0.4908081\ttotal: 2.78s\tremaining: 6.19s\n",
      "31:\tlearn: 0.4865722\ttotal: 2.89s\tremaining: 6.14s\n",
      "32:\tlearn: 0.4816390\ttotal: 2.97s\tremaining: 6.04s\n",
      "33:\tlearn: 0.4773866\ttotal: 3.04s\tremaining: 5.91s\n",
      "34:\tlearn: 0.4726524\ttotal: 3.11s\tremaining: 5.78s\n",
      "35:\tlearn: 0.4695806\ttotal: 3.18s\tremaining: 5.66s\n",
      "36:\tlearn: 0.4632039\ttotal: 3.29s\tremaining: 5.59s\n",
      "37:\tlearn: 0.4605342\ttotal: 3.37s\tremaining: 5.5s\n",
      "38:\tlearn: 0.4557980\ttotal: 3.46s\tremaining: 5.42s\n",
      "39:\tlearn: 0.4505694\ttotal: 3.55s\tremaining: 5.33s\n",
      "40:\tlearn: 0.4489074\ttotal: 3.63s\tremaining: 5.22s\n",
      "41:\tlearn: 0.4477119\ttotal: 3.69s\tremaining: 5.1s\n",
      "42:\tlearn: 0.4435602\ttotal: 3.78s\tremaining: 5.01s\n",
      "43:\tlearn: 0.4412110\ttotal: 3.85s\tremaining: 4.91s\n",
      "44:\tlearn: 0.4377220\ttotal: 3.95s\tremaining: 4.83s\n",
      "45:\tlearn: 0.4348937\ttotal: 4.04s\tremaining: 4.74s\n",
      "46:\tlearn: 0.4328495\ttotal: 4.12s\tremaining: 4.65s\n",
      "47:\tlearn: 0.4304757\ttotal: 4.2s\tremaining: 4.55s\n",
      "48:\tlearn: 0.4284822\ttotal: 4.28s\tremaining: 4.45s\n",
      "49:\tlearn: 0.4270062\ttotal: 4.38s\tremaining: 4.38s\n",
      "50:\tlearn: 0.4232900\ttotal: 4.48s\tremaining: 4.3s\n",
      "51:\tlearn: 0.4215509\ttotal: 4.58s\tremaining: 4.22s\n",
      "52:\tlearn: 0.4182100\ttotal: 4.67s\tremaining: 4.14s\n",
      "53:\tlearn: 0.4169422\ttotal: 4.74s\tremaining: 4.04s\n",
      "54:\tlearn: 0.4150295\ttotal: 4.82s\tremaining: 3.94s\n",
      "55:\tlearn: 0.4132789\ttotal: 4.88s\tremaining: 3.84s\n",
      "56:\tlearn: 0.4122254\ttotal: 4.96s\tremaining: 3.74s\n",
      "57:\tlearn: 0.4098072\ttotal: 5.06s\tremaining: 3.67s\n",
      "58:\tlearn: 0.4085210\ttotal: 5.13s\tremaining: 3.56s\n",
      "59:\tlearn: 0.4067656\ttotal: 5.24s\tremaining: 3.49s\n",
      "60:\tlearn: 0.4046218\ttotal: 5.33s\tremaining: 3.41s\n",
      "61:\tlearn: 0.4033299\ttotal: 5.4s\tremaining: 3.31s\n",
      "62:\tlearn: 0.4004702\ttotal: 5.48s\tremaining: 3.22s\n",
      "63:\tlearn: 0.3985317\ttotal: 5.56s\tremaining: 3.13s\n",
      "64:\tlearn: 0.3978064\ttotal: 5.63s\tremaining: 3.03s\n",
      "65:\tlearn: 0.3961136\ttotal: 5.7s\tremaining: 2.94s\n",
      "66:\tlearn: 0.3949128\ttotal: 5.77s\tremaining: 2.84s\n",
      "67:\tlearn: 0.3937287\ttotal: 5.85s\tremaining: 2.75s\n",
      "68:\tlearn: 0.3920779\ttotal: 5.94s\tremaining: 2.67s\n",
      "69:\tlearn: 0.3910104\ttotal: 6.02s\tremaining: 2.58s\n",
      "70:\tlearn: 0.3891036\ttotal: 6.1s\tremaining: 2.49s\n",
      "71:\tlearn: 0.3876099\ttotal: 6.17s\tremaining: 2.4s\n",
      "72:\tlearn: 0.3847370\ttotal: 6.28s\tremaining: 2.32s\n",
      "73:\tlearn: 0.3837370\ttotal: 6.36s\tremaining: 2.23s\n",
      "74:\tlearn: 0.3828301\ttotal: 6.43s\tremaining: 2.14s\n",
      "75:\tlearn: 0.3797198\ttotal: 6.52s\tremaining: 2.06s\n",
      "76:\tlearn: 0.3784738\ttotal: 6.6s\tremaining: 1.97s\n",
      "77:\tlearn: 0.3776456\ttotal: 6.68s\tremaining: 1.89s\n",
      "78:\tlearn: 0.3763202\ttotal: 6.78s\tremaining: 1.8s\n",
      "79:\tlearn: 0.3754699\ttotal: 6.86s\tremaining: 1.71s\n",
      "80:\tlearn: 0.3748298\ttotal: 6.93s\tremaining: 1.63s\n",
      "81:\tlearn: 0.3731780\ttotal: 7.05s\tremaining: 1.55s\n",
      "82:\tlearn: 0.3721084\ttotal: 7.14s\tremaining: 1.46s\n",
      "83:\tlearn: 0.3711244\ttotal: 7.22s\tremaining: 1.37s\n",
      "84:\tlearn: 0.3698381\ttotal: 7.29s\tremaining: 1.29s\n",
      "85:\tlearn: 0.3684900\ttotal: 7.37s\tremaining: 1.2s\n",
      "86:\tlearn: 0.3671153\ttotal: 7.45s\tremaining: 1.11s\n",
      "87:\tlearn: 0.3650246\ttotal: 7.55s\tremaining: 1.03s\n",
      "88:\tlearn: 0.3645133\ttotal: 7.62s\tremaining: 942ms\n",
      "89:\tlearn: 0.3630552\ttotal: 7.71s\tremaining: 857ms\n",
      "90:\tlearn: 0.3623580\ttotal: 7.78s\tremaining: 770ms\n",
      "91:\tlearn: 0.3615709\ttotal: 7.85s\tremaining: 683ms\n",
      "92:\tlearn: 0.3596388\ttotal: 7.94s\tremaining: 597ms\n",
      "93:\tlearn: 0.3588449\ttotal: 8.03s\tremaining: 513ms\n",
      "94:\tlearn: 0.3583695\ttotal: 8.1s\tremaining: 426ms\n",
      "95:\tlearn: 0.3566998\ttotal: 8.19s\tremaining: 341ms\n",
      "96:\tlearn: 0.3558989\ttotal: 8.26s\tremaining: 255ms\n",
      "97:\tlearn: 0.3548867\ttotal: 8.33s\tremaining: 170ms\n",
      "98:\tlearn: 0.3541446\ttotal: 8.39s\tremaining: 84.8ms\n",
      "99:\tlearn: 0.3535313\ttotal: 8.47s\tremaining: 0us\n",
      "0:\tlearn: 1.4907512\ttotal: 85.5ms\tremaining: 8.46s\n",
      "1:\tlearn: 1.2237881\ttotal: 147ms\tremaining: 7.21s\n",
      "2:\tlearn: 1.0670628\ttotal: 237ms\tremaining: 7.66s\n",
      "3:\tlearn: 0.9617266\ttotal: 323ms\tremaining: 7.75s\n",
      "4:\tlearn: 0.8981958\ttotal: 399ms\tremaining: 7.59s\n",
      "5:\tlearn: 0.8317747\ttotal: 497ms\tremaining: 7.79s\n",
      "6:\tlearn: 0.7881228\ttotal: 584ms\tremaining: 7.76s\n",
      "7:\tlearn: 0.7520878\ttotal: 668ms\tremaining: 7.69s\n",
      "8:\tlearn: 0.7235711\ttotal: 752ms\tremaining: 7.6s\n",
      "9:\tlearn: 0.6974600\ttotal: 842ms\tremaining: 7.57s\n",
      "10:\tlearn: 0.6723062\ttotal: 933ms\tremaining: 7.55s\n",
      "11:\tlearn: 0.6546348\ttotal: 1.01s\tremaining: 7.42s\n",
      "12:\tlearn: 0.6438483\ttotal: 1.07s\tremaining: 7.2s\n",
      "13:\tlearn: 0.6264111\ttotal: 1.17s\tremaining: 7.16s\n",
      "14:\tlearn: 0.6102708\ttotal: 1.26s\tremaining: 7.17s\n",
      "15:\tlearn: 0.5980970\ttotal: 1.34s\tremaining: 7.04s\n",
      "16:\tlearn: 0.5837638\ttotal: 1.43s\tremaining: 6.97s\n",
      "17:\tlearn: 0.5779625\ttotal: 1.5s\tremaining: 6.85s\n",
      "18:\tlearn: 0.5675015\ttotal: 1.6s\tremaining: 6.8s\n",
      "19:\tlearn: 0.5581601\ttotal: 1.67s\tremaining: 6.69s\n",
      "20:\tlearn: 0.5510124\ttotal: 1.75s\tremaining: 6.57s\n",
      "21:\tlearn: 0.5433212\ttotal: 1.85s\tremaining: 6.55s\n",
      "22:\tlearn: 0.5270742\ttotal: 1.95s\tremaining: 6.53s\n",
      "23:\tlearn: 0.5193950\ttotal: 2.04s\tremaining: 6.46s\n",
      "24:\tlearn: 0.5132939\ttotal: 2.13s\tremaining: 6.38s\n",
      "25:\tlearn: 0.5058294\ttotal: 2.21s\tremaining: 6.3s\n",
      "26:\tlearn: 0.5022085\ttotal: 2.28s\tremaining: 6.17s\n",
      "27:\tlearn: 0.4993424\ttotal: 2.36s\tremaining: 6.07s\n",
      "28:\tlearn: 0.4950145\ttotal: 2.45s\tremaining: 6s\n",
      "29:\tlearn: 0.4911516\ttotal: 2.53s\tremaining: 5.91s\n",
      "30:\tlearn: 0.4871259\ttotal: 2.61s\tremaining: 5.81s\n",
      "31:\tlearn: 0.4829130\ttotal: 2.7s\tremaining: 5.74s\n",
      "32:\tlearn: 0.4767003\ttotal: 2.79s\tremaining: 5.66s\n",
      "33:\tlearn: 0.4723086\ttotal: 2.89s\tremaining: 5.6s\n",
      "34:\tlearn: 0.4694545\ttotal: 2.96s\tremaining: 5.5s\n",
      "35:\tlearn: 0.4647552\ttotal: 3.05s\tremaining: 5.42s\n",
      "36:\tlearn: 0.4610493\ttotal: 3.14s\tremaining: 5.34s\n",
      "37:\tlearn: 0.4582854\ttotal: 3.22s\tremaining: 5.26s\n",
      "38:\tlearn: 0.4560894\ttotal: 3.29s\tremaining: 5.15s\n",
      "39:\tlearn: 0.4508372\ttotal: 3.38s\tremaining: 5.07s\n",
      "40:\tlearn: 0.4481908\ttotal: 3.44s\tremaining: 4.96s\n",
      "41:\tlearn: 0.4447618\ttotal: 3.52s\tremaining: 4.86s\n",
      "42:\tlearn: 0.4408313\ttotal: 3.61s\tremaining: 4.79s\n",
      "43:\tlearn: 0.4391245\ttotal: 3.69s\tremaining: 4.69s\n",
      "44:\tlearn: 0.4371992\ttotal: 3.77s\tremaining: 4.61s\n",
      "45:\tlearn: 0.4359221\ttotal: 3.84s\tremaining: 4.51s\n",
      "46:\tlearn: 0.4313744\ttotal: 3.92s\tremaining: 4.42s\n",
      "47:\tlearn: 0.4273621\ttotal: 4.01s\tremaining: 4.34s\n",
      "48:\tlearn: 0.4264564\ttotal: 4.07s\tremaining: 4.23s\n",
      "49:\tlearn: 0.4242933\ttotal: 4.16s\tremaining: 4.16s\n",
      "50:\tlearn: 0.4214815\ttotal: 4.25s\tremaining: 4.08s\n",
      "51:\tlearn: 0.4198107\ttotal: 4.32s\tremaining: 3.98s\n",
      "52:\tlearn: 0.4180829\ttotal: 4.39s\tremaining: 3.89s\n",
      "53:\tlearn: 0.4159313\ttotal: 4.47s\tremaining: 3.81s\n",
      "54:\tlearn: 0.4124209\ttotal: 4.56s\tremaining: 3.73s\n",
      "55:\tlearn: 0.4104526\ttotal: 4.63s\tremaining: 3.64s\n",
      "56:\tlearn: 0.4093732\ttotal: 4.7s\tremaining: 3.54s\n",
      "57:\tlearn: 0.4081288\ttotal: 4.78s\tremaining: 3.46s\n",
      "58:\tlearn: 0.4051574\ttotal: 4.86s\tremaining: 3.38s\n",
      "59:\tlearn: 0.4036264\ttotal: 4.93s\tremaining: 3.29s\n",
      "60:\tlearn: 0.4009670\ttotal: 5.01s\tremaining: 3.2s\n",
      "61:\tlearn: 0.3995641\ttotal: 5.08s\tremaining: 3.12s\n",
      "62:\tlearn: 0.3980417\ttotal: 5.16s\tremaining: 3.03s\n",
      "63:\tlearn: 0.3972020\ttotal: 5.23s\tremaining: 2.94s\n",
      "64:\tlearn: 0.3957488\ttotal: 5.31s\tremaining: 2.86s\n",
      "65:\tlearn: 0.3942898\ttotal: 5.39s\tremaining: 2.77s\n",
      "66:\tlearn: 0.3934997\ttotal: 5.46s\tremaining: 2.69s\n",
      "67:\tlearn: 0.3928217\ttotal: 5.52s\tremaining: 2.6s\n",
      "68:\tlearn: 0.3916877\ttotal: 5.59s\tremaining: 2.51s\n",
      "69:\tlearn: 0.3905785\ttotal: 5.67s\tremaining: 2.43s\n",
      "70:\tlearn: 0.3864332\ttotal: 5.76s\tremaining: 2.35s\n",
      "71:\tlearn: 0.3852361\ttotal: 5.84s\tremaining: 2.27s\n",
      "72:\tlearn: 0.3837784\ttotal: 5.93s\tremaining: 2.19s\n",
      "73:\tlearn: 0.3816554\ttotal: 6.01s\tremaining: 2.11s\n",
      "74:\tlearn: 0.3802245\ttotal: 6.09s\tremaining: 2.03s\n",
      "75:\tlearn: 0.3791960\ttotal: 6.17s\tremaining: 1.95s\n",
      "76:\tlearn: 0.3777156\ttotal: 6.26s\tremaining: 1.87s\n",
      "77:\tlearn: 0.3770128\ttotal: 6.33s\tremaining: 1.78s\n",
      "78:\tlearn: 0.3758724\ttotal: 6.39s\tremaining: 1.7s\n",
      "79:\tlearn: 0.3754347\ttotal: 6.45s\tremaining: 1.61s\n",
      "80:\tlearn: 0.3736664\ttotal: 6.53s\tremaining: 1.53s\n",
      "81:\tlearn: 0.3724179\ttotal: 6.6s\tremaining: 1.45s\n",
      "82:\tlearn: 0.3710947\ttotal: 6.67s\tremaining: 1.37s\n",
      "83:\tlearn: 0.3703181\ttotal: 6.74s\tremaining: 1.28s\n",
      "84:\tlearn: 0.3699182\ttotal: 6.8s\tremaining: 1.2s\n",
      "85:\tlearn: 0.3690987\ttotal: 6.87s\tremaining: 1.12s\n",
      "86:\tlearn: 0.3681020\ttotal: 6.96s\tremaining: 1.04s\n",
      "87:\tlearn: 0.3670172\ttotal: 7.03s\tremaining: 959ms\n",
      "88:\tlearn: 0.3661810\ttotal: 7.1s\tremaining: 877ms\n",
      "89:\tlearn: 0.3655278\ttotal: 7.18s\tremaining: 798ms\n",
      "90:\tlearn: 0.3649142\ttotal: 7.25s\tremaining: 717ms\n",
      "91:\tlearn: 0.3638909\ttotal: 7.33s\tremaining: 637ms\n",
      "92:\tlearn: 0.3631336\ttotal: 7.4s\tremaining: 557ms\n",
      "93:\tlearn: 0.3619788\ttotal: 7.49s\tremaining: 478ms\n",
      "94:\tlearn: 0.3601250\ttotal: 7.58s\tremaining: 399ms\n",
      "95:\tlearn: 0.3592443\ttotal: 7.66s\tremaining: 319ms\n",
      "96:\tlearn: 0.3572383\ttotal: 7.74s\tremaining: 239ms\n",
      "97:\tlearn: 0.3563187\ttotal: 7.82s\tremaining: 160ms\n",
      "98:\tlearn: 0.3552931\ttotal: 7.93s\tremaining: 80.1ms\n",
      "99:\tlearn: 0.3545994\ttotal: 8.02s\tremaining: 0us\n",
      "0:\tlearn: 1.6173405\ttotal: 84.7ms\tremaining: 8.39s\n",
      "1:\tlearn: 1.3610505\ttotal: 151ms\tremaining: 7.39s\n",
      "2:\tlearn: 1.2383489\ttotal: 240ms\tremaining: 7.75s\n",
      "3:\tlearn: 1.0831542\ttotal: 324ms\tremaining: 7.78s\n",
      "4:\tlearn: 0.9829870\ttotal: 412ms\tremaining: 7.82s\n",
      "5:\tlearn: 0.9397884\ttotal: 491ms\tremaining: 7.69s\n",
      "6:\tlearn: 0.8998009\ttotal: 572ms\tremaining: 7.59s\n",
      "7:\tlearn: 0.8514544\ttotal: 656ms\tremaining: 7.54s\n",
      "8:\tlearn: 0.7994444\ttotal: 743ms\tremaining: 7.51s\n",
      "9:\tlearn: 0.7756806\ttotal: 829ms\tremaining: 7.46s\n",
      "10:\tlearn: 0.7457416\ttotal: 917ms\tremaining: 7.42s\n",
      "11:\tlearn: 0.7209276\ttotal: 1.01s\tremaining: 7.39s\n",
      "12:\tlearn: 0.7026217\ttotal: 1.09s\tremaining: 7.3s\n",
      "13:\tlearn: 0.6855301\ttotal: 1.16s\tremaining: 7.15s\n",
      "14:\tlearn: 0.6617941\ttotal: 1.25s\tremaining: 7.1s\n",
      "15:\tlearn: 0.6409414\ttotal: 1.34s\tremaining: 7.03s\n",
      "16:\tlearn: 0.6303556\ttotal: 1.43s\tremaining: 6.97s\n",
      "17:\tlearn: 0.6178826\ttotal: 1.51s\tremaining: 6.9s\n",
      "18:\tlearn: 0.6091777\ttotal: 1.6s\tremaining: 6.84s\n",
      "19:\tlearn: 0.6042056\ttotal: 1.69s\tremaining: 6.75s\n",
      "20:\tlearn: 0.6010288\ttotal: 1.77s\tremaining: 6.65s\n",
      "21:\tlearn: 0.5943810\ttotal: 1.85s\tremaining: 6.55s\n",
      "22:\tlearn: 0.5873646\ttotal: 1.94s\tremaining: 6.5s\n",
      "23:\tlearn: 0.5805283\ttotal: 2.02s\tremaining: 6.4s\n",
      "24:\tlearn: 0.5749564\ttotal: 2.09s\tremaining: 6.27s\n",
      "25:\tlearn: 0.5637090\ttotal: 2.19s\tremaining: 6.22s\n",
      "26:\tlearn: 0.5571651\ttotal: 2.27s\tremaining: 6.13s\n",
      "27:\tlearn: 0.5538908\ttotal: 2.33s\tremaining: 6s\n",
      "28:\tlearn: 0.5477294\ttotal: 2.42s\tremaining: 5.92s\n",
      "29:\tlearn: 0.5397188\ttotal: 2.51s\tremaining: 5.86s\n",
      "30:\tlearn: 0.5311299\ttotal: 2.61s\tremaining: 5.81s\n",
      "31:\tlearn: 0.5258997\ttotal: 2.7s\tremaining: 5.74s\n",
      "32:\tlearn: 0.5233370\ttotal: 2.77s\tremaining: 5.62s\n",
      "33:\tlearn: 0.5200332\ttotal: 2.84s\tremaining: 5.52s\n",
      "34:\tlearn: 0.5187748\ttotal: 2.91s\tremaining: 5.4s\n",
      "35:\tlearn: 0.5157007\ttotal: 2.97s\tremaining: 5.29s\n",
      "36:\tlearn: 0.5123004\ttotal: 3.04s\tremaining: 5.17s\n",
      "37:\tlearn: 0.5110807\ttotal: 3.11s\tremaining: 5.07s\n",
      "38:\tlearn: 0.5086228\ttotal: 3.18s\tremaining: 4.98s\n",
      "39:\tlearn: 0.5054616\ttotal: 3.27s\tremaining: 4.9s\n",
      "40:\tlearn: 0.5012277\ttotal: 3.34s\tremaining: 4.81s\n",
      "41:\tlearn: 0.4981952\ttotal: 3.42s\tremaining: 4.72s\n",
      "42:\tlearn: 0.4957518\ttotal: 3.49s\tremaining: 4.63s\n",
      "43:\tlearn: 0.4878490\ttotal: 3.59s\tremaining: 4.58s\n",
      "44:\tlearn: 0.4825031\ttotal: 3.67s\tremaining: 4.49s\n",
      "45:\tlearn: 0.4808215\ttotal: 3.75s\tremaining: 4.4s\n",
      "46:\tlearn: 0.4757149\ttotal: 3.85s\tremaining: 4.34s\n",
      "47:\tlearn: 0.4718580\ttotal: 3.95s\tremaining: 4.28s\n",
      "48:\tlearn: 0.4670354\ttotal: 4.04s\tremaining: 4.2s\n",
      "49:\tlearn: 0.4632454\ttotal: 4.11s\tremaining: 4.11s\n",
      "50:\tlearn: 0.4598018\ttotal: 4.19s\tremaining: 4.03s\n",
      "51:\tlearn: 0.4577851\ttotal: 4.26s\tremaining: 3.93s\n",
      "52:\tlearn: 0.4549552\ttotal: 4.33s\tremaining: 3.84s\n",
      "53:\tlearn: 0.4507283\ttotal: 4.41s\tremaining: 3.76s\n",
      "54:\tlearn: 0.4468803\ttotal: 4.48s\tremaining: 3.66s\n",
      "55:\tlearn: 0.4459019\ttotal: 4.62s\tremaining: 3.63s\n",
      "56:\tlearn: 0.4422079\ttotal: 4.7s\tremaining: 3.55s\n",
      "57:\tlearn: 0.4374824\ttotal: 4.78s\tremaining: 3.46s\n",
      "58:\tlearn: 0.4361327\ttotal: 4.85s\tremaining: 3.37s\n",
      "59:\tlearn: 0.4353758\ttotal: 4.92s\tremaining: 3.28s\n",
      "60:\tlearn: 0.4326344\ttotal: 5.01s\tremaining: 3.2s\n",
      "61:\tlearn: 0.4304454\ttotal: 5.09s\tremaining: 3.12s\n",
      "62:\tlearn: 0.4294918\ttotal: 5.15s\tremaining: 3.02s\n",
      "63:\tlearn: 0.4274290\ttotal: 5.24s\tremaining: 2.95s\n",
      "64:\tlearn: 0.4231578\ttotal: 5.33s\tremaining: 2.87s\n",
      "65:\tlearn: 0.4222745\ttotal: 5.4s\tremaining: 2.78s\n",
      "66:\tlearn: 0.4207156\ttotal: 5.47s\tremaining: 2.69s\n",
      "67:\tlearn: 0.4185707\ttotal: 5.55s\tremaining: 2.61s\n",
      "68:\tlearn: 0.4177817\ttotal: 5.61s\tremaining: 2.52s\n",
      "69:\tlearn: 0.4160779\ttotal: 5.68s\tremaining: 2.44s\n",
      "70:\tlearn: 0.4138596\ttotal: 5.75s\tremaining: 2.35s\n",
      "71:\tlearn: 0.4085856\ttotal: 5.84s\tremaining: 2.27s\n",
      "72:\tlearn: 0.4058153\ttotal: 5.93s\tremaining: 2.19s\n",
      "73:\tlearn: 0.4044909\ttotal: 6s\tremaining: 2.11s\n",
      "74:\tlearn: 0.4030956\ttotal: 6.08s\tremaining: 2.03s\n",
      "75:\tlearn: 0.4014586\ttotal: 6.16s\tremaining: 1.95s\n",
      "76:\tlearn: 0.4000662\ttotal: 6.23s\tremaining: 1.86s\n",
      "77:\tlearn: 0.3991963\ttotal: 6.29s\tremaining: 1.77s\n",
      "78:\tlearn: 0.3971996\ttotal: 6.36s\tremaining: 1.69s\n",
      "79:\tlearn: 0.3948918\ttotal: 6.44s\tremaining: 1.61s\n",
      "80:\tlearn: 0.3929727\ttotal: 6.51s\tremaining: 1.53s\n",
      "81:\tlearn: 0.3922508\ttotal: 6.58s\tremaining: 1.44s\n",
      "82:\tlearn: 0.3899716\ttotal: 6.65s\tremaining: 1.36s\n",
      "83:\tlearn: 0.3886225\ttotal: 6.73s\tremaining: 1.28s\n",
      "84:\tlearn: 0.3878956\ttotal: 6.8s\tremaining: 1.2s\n",
      "85:\tlearn: 0.3850922\ttotal: 6.88s\tremaining: 1.12s\n",
      "86:\tlearn: 0.3829834\ttotal: 6.97s\tremaining: 1.04s\n",
      "87:\tlearn: 0.3814759\ttotal: 7.06s\tremaining: 962ms\n",
      "88:\tlearn: 0.3807215\ttotal: 7.12s\tremaining: 880ms\n",
      "89:\tlearn: 0.3787528\ttotal: 7.2s\tremaining: 800ms\n",
      "90:\tlearn: 0.3767801\ttotal: 7.26s\tremaining: 718ms\n",
      "91:\tlearn: 0.3756875\ttotal: 7.33s\tremaining: 637ms\n",
      "92:\tlearn: 0.3742325\ttotal: 7.41s\tremaining: 558ms\n",
      "93:\tlearn: 0.3727364\ttotal: 7.47s\tremaining: 477ms\n",
      "94:\tlearn: 0.3702874\ttotal: 7.57s\tremaining: 398ms\n",
      "95:\tlearn: 0.3687914\ttotal: 7.64s\tremaining: 318ms\n",
      "96:\tlearn: 0.3673528\ttotal: 7.71s\tremaining: 239ms\n",
      "97:\tlearn: 0.3664333\ttotal: 7.79s\tremaining: 159ms\n",
      "98:\tlearn: 0.3651102\ttotal: 7.86s\tremaining: 79.4ms\n",
      "99:\tlearn: 0.3629544\ttotal: 7.94s\tremaining: 0us\n",
      "0:\tlearn: 1.5904964\ttotal: 92.6ms\tremaining: 9.17s\n",
      "1:\tlearn: 1.2868761\ttotal: 162ms\tremaining: 7.94s\n",
      "2:\tlearn: 1.2069274\ttotal: 246ms\tremaining: 7.94s\n",
      "3:\tlearn: 1.2591811\ttotal: 359ms\tremaining: 8.61s\n",
      "4:\tlearn: 1.2358491\ttotal: 474ms\tremaining: 9.01s\n",
      "5:\tlearn: 1.1135678\ttotal: 568ms\tremaining: 8.9s\n",
      "6:\tlearn: 1.2131935\ttotal: 668ms\tremaining: 8.88s\n",
      "7:\tlearn: 1.0560568\ttotal: 771ms\tremaining: 8.87s\n",
      "8:\tlearn: 0.9978661\ttotal: 865ms\tremaining: 8.75s\n",
      "9:\tlearn: 0.9668202\ttotal: 949ms\tremaining: 8.54s\n",
      "10:\tlearn: 0.9282470\ttotal: 1.05s\tremaining: 8.48s\n",
      "11:\tlearn: 0.8936989\ttotal: 1.14s\tremaining: 8.37s\n",
      "12:\tlearn: 0.8631421\ttotal: 1.23s\tremaining: 8.24s\n",
      "13:\tlearn: 0.8320332\ttotal: 1.32s\tremaining: 8.12s\n",
      "14:\tlearn: 0.8719433\ttotal: 1.41s\tremaining: 7.97s\n",
      "15:\tlearn: 0.8270734\ttotal: 1.49s\tremaining: 7.8s\n",
      "16:\tlearn: 0.8129897\ttotal: 1.56s\tremaining: 7.63s\n",
      "17:\tlearn: 0.7952248\ttotal: 1.66s\tremaining: 7.54s\n",
      "18:\tlearn: 0.7811221\ttotal: 1.75s\tremaining: 7.45s\n",
      "19:\tlearn: 0.7727428\ttotal: 1.83s\tremaining: 7.32s\n",
      "20:\tlearn: 0.7676297\ttotal: 1.9s\tremaining: 7.13s\n",
      "21:\tlearn: 0.7569438\ttotal: 1.98s\tremaining: 7.02s\n",
      "22:\tlearn: 0.7502177\ttotal: 2.04s\tremaining: 6.84s\n",
      "23:\tlearn: 0.7322262\ttotal: 2.15s\tremaining: 6.79s\n",
      "24:\tlearn: 0.7260848\ttotal: 2.22s\tremaining: 6.67s\n",
      "25:\tlearn: 0.7219858\ttotal: 2.29s\tremaining: 6.51s\n",
      "26:\tlearn: 0.7177420\ttotal: 2.35s\tremaining: 6.36s\n",
      "27:\tlearn: 0.7119295\ttotal: 2.42s\tremaining: 6.22s\n",
      "28:\tlearn: 0.6964787\ttotal: 2.51s\tremaining: 6.15s\n",
      "29:\tlearn: 0.6917295\ttotal: 2.59s\tremaining: 6.05s\n",
      "30:\tlearn: 0.6885751\ttotal: 2.66s\tremaining: 5.91s\n",
      "31:\tlearn: 0.6796224\ttotal: 2.74s\tremaining: 5.82s\n",
      "32:\tlearn: 0.6753834\ttotal: 2.81s\tremaining: 5.71s\n",
      "33:\tlearn: 0.6666199\ttotal: 2.91s\tremaining: 5.64s\n",
      "34:\tlearn: 0.6633736\ttotal: 2.97s\tremaining: 5.51s\n",
      "35:\tlearn: 0.6609227\ttotal: 3.03s\tremaining: 5.39s\n",
      "36:\tlearn: 0.6581662\ttotal: 3.1s\tremaining: 5.28s\n",
      "37:\tlearn: 0.6381378\ttotal: 3.17s\tremaining: 5.17s\n",
      "38:\tlearn: 0.6323538\ttotal: 3.24s\tremaining: 5.06s\n",
      "39:\tlearn: 0.6263121\ttotal: 3.3s\tremaining: 4.96s\n",
      "40:\tlearn: 0.6246289\ttotal: 3.37s\tremaining: 4.84s\n",
      "41:\tlearn: 0.6228307\ttotal: 3.43s\tremaining: 4.74s\n",
      "42:\tlearn: 0.6192888\ttotal: 3.49s\tremaining: 4.63s\n",
      "43:\tlearn: 0.6153719\ttotal: 3.57s\tremaining: 4.54s\n",
      "44:\tlearn: 0.6116215\ttotal: 3.64s\tremaining: 4.45s\n",
      "45:\tlearn: 0.6094971\ttotal: 3.71s\tremaining: 4.35s\n",
      "46:\tlearn: 0.6021314\ttotal: 3.81s\tremaining: 4.29s\n",
      "47:\tlearn: 0.5999093\ttotal: 3.87s\tremaining: 4.2s\n",
      "48:\tlearn: 0.5961066\ttotal: 3.95s\tremaining: 4.12s\n",
      "49:\tlearn: 0.5944487\ttotal: 4.02s\tremaining: 4.02s\n",
      "50:\tlearn: 0.5898753\ttotal: 4.09s\tremaining: 3.93s\n",
      "51:\tlearn: 0.5875276\ttotal: 4.17s\tremaining: 3.85s\n",
      "52:\tlearn: 0.5807612\ttotal: 4.26s\tremaining: 3.78s\n",
      "53:\tlearn: 0.5784218\ttotal: 4.32s\tremaining: 3.68s\n",
      "54:\tlearn: 0.5741661\ttotal: 4.42s\tremaining: 3.62s\n",
      "55:\tlearn: 0.5719413\ttotal: 4.49s\tremaining: 3.53s\n",
      "56:\tlearn: 0.5692398\ttotal: 4.58s\tremaining: 3.45s\n",
      "57:\tlearn: 0.5659760\ttotal: 4.67s\tremaining: 3.38s\n",
      "58:\tlearn: 0.5642367\ttotal: 4.73s\tremaining: 3.29s\n",
      "59:\tlearn: 0.5618699\ttotal: 4.79s\tremaining: 3.19s\n",
      "60:\tlearn: 0.5599464\ttotal: 4.87s\tremaining: 3.11s\n",
      "61:\tlearn: 0.5573931\ttotal: 4.94s\tremaining: 3.02s\n",
      "62:\tlearn: 0.5543340\ttotal: 5.05s\tremaining: 2.96s\n",
      "63:\tlearn: 0.5531849\ttotal: 5.12s\tremaining: 2.88s\n",
      "64:\tlearn: 0.5510241\ttotal: 5.2s\tremaining: 2.8s\n",
      "65:\tlearn: 0.5478365\ttotal: 5.27s\tremaining: 2.71s\n",
      "66:\tlearn: 0.5458885\ttotal: 5.35s\tremaining: 2.63s\n",
      "67:\tlearn: 0.5445070\ttotal: 5.41s\tremaining: 2.55s\n",
      "68:\tlearn: 0.5404689\ttotal: 5.5s\tremaining: 2.47s\n",
      "69:\tlearn: 0.5391264\ttotal: 5.58s\tremaining: 2.39s\n",
      "70:\tlearn: 0.5291583\ttotal: 5.66s\tremaining: 2.31s\n",
      "71:\tlearn: 0.5283203\ttotal: 5.72s\tremaining: 2.22s\n",
      "72:\tlearn: 0.5270240\ttotal: 5.78s\tremaining: 2.14s\n",
      "73:\tlearn: 0.5245043\ttotal: 5.86s\tremaining: 2.06s\n",
      "74:\tlearn: 0.5205631\ttotal: 5.94s\tremaining: 1.98s\n",
      "75:\tlearn: 0.5188635\ttotal: 6.02s\tremaining: 1.9s\n",
      "76:\tlearn: 0.5161578\ttotal: 6.09s\tremaining: 1.82s\n",
      "77:\tlearn: 0.5141368\ttotal: 6.17s\tremaining: 1.74s\n",
      "78:\tlearn: 0.5117138\ttotal: 6.26s\tremaining: 1.67s\n",
      "79:\tlearn: 0.5096479\ttotal: 6.37s\tremaining: 1.59s\n",
      "80:\tlearn: 0.5084591\ttotal: 6.45s\tremaining: 1.51s\n",
      "81:\tlearn: 0.5044370\ttotal: 6.53s\tremaining: 1.43s\n",
      "82:\tlearn: 0.5019635\ttotal: 6.59s\tremaining: 1.35s\n",
      "83:\tlearn: 0.5003890\ttotal: 6.66s\tremaining: 1.27s\n",
      "84:\tlearn: 0.4982664\ttotal: 6.73s\tremaining: 1.19s\n",
      "85:\tlearn: 0.4966947\ttotal: 6.81s\tremaining: 1.11s\n",
      "86:\tlearn: 0.4949121\ttotal: 6.88s\tremaining: 1.03s\n",
      "87:\tlearn: 0.4922088\ttotal: 6.96s\tremaining: 949ms\n",
      "88:\tlearn: 0.4906836\ttotal: 7.03s\tremaining: 869ms\n",
      "89:\tlearn: 0.4884153\ttotal: 7.1s\tremaining: 789ms\n",
      "90:\tlearn: 0.4874611\ttotal: 7.17s\tremaining: 709ms\n",
      "91:\tlearn: 0.4851514\ttotal: 7.26s\tremaining: 631ms\n",
      "92:\tlearn: 0.4844748\ttotal: 7.32s\tremaining: 551ms\n",
      "93:\tlearn: 0.4830030\ttotal: 7.39s\tremaining: 472ms\n",
      "94:\tlearn: 0.4810366\ttotal: 7.48s\tremaining: 394ms\n",
      "95:\tlearn: 0.4795148\ttotal: 7.55s\tremaining: 314ms\n",
      "96:\tlearn: 0.4775018\ttotal: 7.63s\tremaining: 236ms\n",
      "97:\tlearn: 0.4750804\ttotal: 7.7s\tremaining: 157ms\n",
      "98:\tlearn: 0.4742152\ttotal: 7.76s\tremaining: 78.4ms\n",
      "99:\tlearn: 0.4724026\ttotal: 7.84s\tremaining: 0us\n",
      "0:\tlearn: 1.5969118\ttotal: 278ms\tremaining: 27.6s\n",
      "1:\tlearn: 1.3103836\ttotal: 387ms\tremaining: 19s\n",
      "2:\tlearn: 1.2129746\ttotal: 482ms\tremaining: 15.6s\n",
      "3:\tlearn: 1.0905230\ttotal: 627ms\tremaining: 15.1s\n",
      "4:\tlearn: 0.9797581\ttotal: 726ms\tremaining: 13.8s\n",
      "5:\tlearn: 0.9616224\ttotal: 830ms\tremaining: 13s\n",
      "6:\tlearn: 0.8911732\ttotal: 923ms\tremaining: 12.3s\n",
      "7:\tlearn: 0.8292906\ttotal: 1.01s\tremaining: 11.6s\n",
      "8:\tlearn: 0.7856031\ttotal: 1.11s\tremaining: 11.2s\n",
      "9:\tlearn: 0.7552508\ttotal: 1.2s\tremaining: 10.8s\n",
      "10:\tlearn: 0.7170867\ttotal: 1.29s\tremaining: 10.5s\n",
      "11:\tlearn: 0.6883282\ttotal: 1.38s\tremaining: 10.1s\n",
      "12:\tlearn: 0.6652474\ttotal: 1.46s\tremaining: 9.8s\n",
      "13:\tlearn: 0.6484559\ttotal: 1.55s\tremaining: 9.51s\n",
      "14:\tlearn: 0.6320572\ttotal: 1.64s\tremaining: 9.28s\n",
      "15:\tlearn: 0.6170387\ttotal: 1.72s\tremaining: 9.02s\n",
      "16:\tlearn: 0.6065463\ttotal: 1.8s\tremaining: 8.77s\n",
      "17:\tlearn: 0.5939297\ttotal: 1.88s\tremaining: 8.58s\n",
      "18:\tlearn: 0.5826200\ttotal: 1.97s\tremaining: 8.38s\n",
      "19:\tlearn: 0.5760293\ttotal: 2.05s\tremaining: 8.2s\n",
      "20:\tlearn: 0.5689355\ttotal: 2.13s\tremaining: 8.01s\n",
      "21:\tlearn: 0.5646152\ttotal: 2.19s\tremaining: 7.76s\n",
      "22:\tlearn: 0.5624195\ttotal: 2.25s\tremaining: 7.53s\n",
      "23:\tlearn: 0.5588198\ttotal: 2.32s\tremaining: 7.36s\n",
      "24:\tlearn: 0.5494935\ttotal: 2.42s\tremaining: 7.27s\n",
      "25:\tlearn: 0.5401635\ttotal: 2.51s\tremaining: 7.14s\n",
      "26:\tlearn: 0.5361847\ttotal: 2.58s\tremaining: 6.97s\n",
      "27:\tlearn: 0.5325413\ttotal: 2.66s\tremaining: 6.84s\n",
      "28:\tlearn: 0.5285964\ttotal: 2.73s\tremaining: 6.7s\n",
      "29:\tlearn: 0.5254682\ttotal: 2.81s\tremaining: 6.57s\n",
      "30:\tlearn: 0.5203986\ttotal: 2.9s\tremaining: 6.45s\n",
      "31:\tlearn: 0.5172851\ttotal: 2.97s\tremaining: 6.32s\n",
      "32:\tlearn: 0.5128248\ttotal: 3.04s\tremaining: 6.18s\n",
      "33:\tlearn: 0.5101976\ttotal: 3.12s\tremaining: 6.06s\n",
      "34:\tlearn: 0.5077774\ttotal: 3.2s\tremaining: 5.94s\n",
      "35:\tlearn: 0.5011240\ttotal: 3.27s\tremaining: 5.81s\n",
      "36:\tlearn: 0.4971370\ttotal: 3.36s\tremaining: 5.72s\n",
      "37:\tlearn: 0.4934769\ttotal: 3.44s\tremaining: 5.61s\n",
      "38:\tlearn: 0.4889136\ttotal: 3.52s\tremaining: 5.5s\n",
      "39:\tlearn: 0.4842181\ttotal: 3.59s\tremaining: 5.38s\n",
      "40:\tlearn: 0.4790665\ttotal: 3.69s\tremaining: 5.3s\n",
      "41:\tlearn: 0.4764736\ttotal: 3.77s\tremaining: 5.2s\n",
      "42:\tlearn: 0.4718285\ttotal: 3.85s\tremaining: 5.1s\n",
      "43:\tlearn: 0.4703387\ttotal: 3.91s\tremaining: 4.97s\n",
      "44:\tlearn: 0.4694928\ttotal: 3.97s\tremaining: 4.86s\n",
      "45:\tlearn: 0.4681639\ttotal: 4.04s\tremaining: 4.74s\n",
      "46:\tlearn: 0.4664499\ttotal: 4.11s\tremaining: 4.63s\n",
      "47:\tlearn: 0.4632181\ttotal: 4.19s\tremaining: 4.54s\n",
      "48:\tlearn: 0.4602233\ttotal: 4.27s\tremaining: 4.44s\n",
      "49:\tlearn: 0.4582348\ttotal: 4.36s\tremaining: 4.36s\n",
      "50:\tlearn: 0.4559021\ttotal: 4.42s\tremaining: 4.24s\n",
      "51:\tlearn: 0.4549857\ttotal: 4.47s\tremaining: 4.13s\n",
      "52:\tlearn: 0.4520478\ttotal: 4.55s\tremaining: 4.03s\n",
      "53:\tlearn: 0.4490601\ttotal: 4.61s\tremaining: 3.93s\n",
      "54:\tlearn: 0.4454392\ttotal: 4.7s\tremaining: 3.84s\n",
      "55:\tlearn: 0.4413480\ttotal: 4.79s\tremaining: 3.76s\n",
      "56:\tlearn: 0.4384300\ttotal: 4.87s\tremaining: 3.67s\n",
      "57:\tlearn: 0.4376817\ttotal: 4.94s\tremaining: 3.58s\n",
      "58:\tlearn: 0.4365586\ttotal: 5.01s\tremaining: 3.48s\n",
      "59:\tlearn: 0.4340429\ttotal: 5.09s\tremaining: 3.39s\n",
      "60:\tlearn: 0.4313606\ttotal: 5.17s\tremaining: 3.31s\n",
      "61:\tlearn: 0.4300838\ttotal: 5.24s\tremaining: 3.21s\n",
      "62:\tlearn: 0.4283808\ttotal: 5.31s\tremaining: 3.12s\n",
      "63:\tlearn: 0.4263738\ttotal: 5.38s\tremaining: 3.03s\n",
      "64:\tlearn: 0.4239440\ttotal: 5.46s\tremaining: 2.94s\n",
      "65:\tlearn: 0.4220507\ttotal: 5.54s\tremaining: 2.85s\n",
      "66:\tlearn: 0.4206254\ttotal: 5.6s\tremaining: 2.76s\n",
      "67:\tlearn: 0.4178763\ttotal: 5.67s\tremaining: 2.67s\n",
      "68:\tlearn: 0.4144001\ttotal: 5.74s\tremaining: 2.58s\n",
      "69:\tlearn: 0.4126655\ttotal: 5.81s\tremaining: 2.49s\n",
      "70:\tlearn: 0.4111394\ttotal: 5.89s\tremaining: 2.4s\n",
      "71:\tlearn: 0.4095449\ttotal: 5.96s\tremaining: 2.32s\n",
      "72:\tlearn: 0.4074473\ttotal: 6.04s\tremaining: 2.23s\n",
      "73:\tlearn: 0.4060748\ttotal: 6.11s\tremaining: 2.15s\n",
      "74:\tlearn: 0.4043475\ttotal: 6.19s\tremaining: 2.06s\n",
      "75:\tlearn: 0.4010022\ttotal: 6.28s\tremaining: 1.98s\n",
      "76:\tlearn: 0.3960465\ttotal: 6.35s\tremaining: 1.9s\n",
      "77:\tlearn: 0.3944974\ttotal: 6.43s\tremaining: 1.81s\n",
      "78:\tlearn: 0.3922190\ttotal: 6.5s\tremaining: 1.73s\n",
      "79:\tlearn: 0.3910673\ttotal: 6.58s\tremaining: 1.64s\n",
      "80:\tlearn: 0.3901708\ttotal: 6.65s\tremaining: 1.56s\n",
      "81:\tlearn: 0.3885115\ttotal: 6.73s\tremaining: 1.48s\n",
      "82:\tlearn: 0.3861109\ttotal: 6.82s\tremaining: 1.4s\n",
      "83:\tlearn: 0.3846853\ttotal: 6.89s\tremaining: 1.31s\n",
      "84:\tlearn: 0.3841106\ttotal: 6.96s\tremaining: 1.23s\n",
      "85:\tlearn: 0.3823269\ttotal: 7.04s\tremaining: 1.15s\n",
      "86:\tlearn: 0.3806169\ttotal: 7.12s\tremaining: 1.06s\n",
      "87:\tlearn: 0.3794520\ttotal: 7.19s\tremaining: 980ms\n",
      "88:\tlearn: 0.3785163\ttotal: 7.25s\tremaining: 897ms\n",
      "89:\tlearn: 0.3759243\ttotal: 7.34s\tremaining: 815ms\n",
      "90:\tlearn: 0.3742317\ttotal: 7.41s\tremaining: 733ms\n",
      "91:\tlearn: 0.3736935\ttotal: 7.47s\tremaining: 650ms\n",
      "92:\tlearn: 0.3721104\ttotal: 7.55s\tremaining: 568ms\n",
      "93:\tlearn: 0.3715273\ttotal: 7.62s\tremaining: 486ms\n",
      "94:\tlearn: 0.3709885\ttotal: 7.68s\tremaining: 404ms\n",
      "95:\tlearn: 0.3693382\ttotal: 7.76s\tremaining: 323ms\n",
      "96:\tlearn: 0.3668557\ttotal: 7.84s\tremaining: 243ms\n",
      "97:\tlearn: 0.3651128\ttotal: 7.93s\tremaining: 162ms\n",
      "98:\tlearn: 0.3644351\ttotal: 7.99s\tremaining: 80.7ms\n",
      "99:\tlearn: 0.3633399\ttotal: 8.05s\tremaining: 0us\n",
      "0:\tlearn: 2.2756282\ttotal: 102ms\tremaining: 20.3s\n",
      "1:\tlearn: 2.2504542\ttotal: 196ms\tremaining: 19.4s\n",
      "2:\tlearn: 2.2268848\ttotal: 268ms\tremaining: 17.6s\n",
      "3:\tlearn: 2.2034461\ttotal: 342ms\tremaining: 16.8s\n",
      "4:\tlearn: 2.1800353\ttotal: 422ms\tremaining: 16.4s\n",
      "5:\tlearn: 2.1589622\ttotal: 497ms\tremaining: 16.1s\n",
      "6:\tlearn: 2.1387904\ttotal: 572ms\tremaining: 15.8s\n",
      "7:\tlearn: 2.1194893\ttotal: 655ms\tremaining: 15.7s\n",
      "8:\tlearn: 2.0991401\ttotal: 740ms\tremaining: 15.7s\n",
      "9:\tlearn: 2.0797159\ttotal: 839ms\tremaining: 15.9s\n",
      "10:\tlearn: 2.0624048\ttotal: 928ms\tremaining: 15.9s\n",
      "11:\tlearn: 2.0458741\ttotal: 1.01s\tremaining: 15.9s\n",
      "12:\tlearn: 2.0302765\ttotal: 1.1s\tremaining: 15.8s\n",
      "13:\tlearn: 2.0134852\ttotal: 1.18s\tremaining: 15.7s\n",
      "14:\tlearn: 1.9974696\ttotal: 1.26s\tremaining: 15.5s\n",
      "15:\tlearn: 1.9801576\ttotal: 1.35s\tremaining: 15.5s\n",
      "16:\tlearn: 1.9631199\ttotal: 1.44s\tremaining: 15.4s\n",
      "17:\tlearn: 1.9483252\ttotal: 1.52s\tremaining: 15.4s\n",
      "18:\tlearn: 1.9349998\ttotal: 1.61s\tremaining: 15.3s\n",
      "19:\tlearn: 1.9200673\ttotal: 1.7s\tremaining: 15.3s\n",
      "20:\tlearn: 1.9058736\ttotal: 1.78s\tremaining: 15.2s\n",
      "21:\tlearn: 1.8915828\ttotal: 1.88s\tremaining: 15.2s\n",
      "22:\tlearn: 1.8769847\ttotal: 1.96s\tremaining: 15.1s\n",
      "23:\tlearn: 1.8648099\ttotal: 2.04s\tremaining: 14.9s\n",
      "24:\tlearn: 1.8519857\ttotal: 2.13s\tremaining: 14.9s\n",
      "25:\tlearn: 1.8381391\ttotal: 2.22s\tremaining: 14.8s\n",
      "26:\tlearn: 1.8262921\ttotal: 2.31s\tremaining: 14.8s\n",
      "27:\tlearn: 1.8137760\ttotal: 2.39s\tremaining: 14.7s\n",
      "28:\tlearn: 1.8021825\ttotal: 2.48s\tremaining: 14.6s\n",
      "29:\tlearn: 1.7909263\ttotal: 2.56s\tremaining: 14.5s\n",
      "30:\tlearn: 1.7796770\ttotal: 2.65s\tremaining: 14.5s\n",
      "31:\tlearn: 1.7666104\ttotal: 2.74s\tremaining: 14.4s\n",
      "32:\tlearn: 1.7547963\ttotal: 2.82s\tremaining: 14.3s\n",
      "33:\tlearn: 1.7459996\ttotal: 2.9s\tremaining: 14.1s\n",
      "34:\tlearn: 1.7339920\ttotal: 2.99s\tremaining: 14.1s\n",
      "35:\tlearn: 1.7223199\ttotal: 3.09s\tremaining: 14.1s\n",
      "36:\tlearn: 1.7120850\ttotal: 3.17s\tremaining: 14s\n",
      "37:\tlearn: 1.7019442\ttotal: 3.26s\tremaining: 13.9s\n",
      "38:\tlearn: 1.6924788\ttotal: 3.35s\tremaining: 13.8s\n",
      "39:\tlearn: 1.6819899\ttotal: 3.44s\tremaining: 13.7s\n",
      "40:\tlearn: 1.6728333\ttotal: 3.52s\tremaining: 13.7s\n",
      "41:\tlearn: 1.6630244\ttotal: 3.61s\tremaining: 13.6s\n",
      "42:\tlearn: 1.6547669\ttotal: 3.69s\tremaining: 13.5s\n",
      "43:\tlearn: 1.6452349\ttotal: 3.78s\tremaining: 13.4s\n",
      "44:\tlearn: 1.6370997\ttotal: 3.85s\tremaining: 13.3s\n",
      "45:\tlearn: 1.6285728\ttotal: 3.93s\tremaining: 13.2s\n",
      "46:\tlearn: 1.6190982\ttotal: 4.02s\tremaining: 13.1s\n",
      "47:\tlearn: 1.6104807\ttotal: 4.1s\tremaining: 13s\n",
      "48:\tlearn: 1.6020463\ttotal: 4.18s\tremaining: 12.9s\n",
      "49:\tlearn: 1.5928468\ttotal: 4.27s\tremaining: 12.8s\n",
      "50:\tlearn: 1.5844217\ttotal: 4.35s\tremaining: 12.7s\n",
      "51:\tlearn: 1.5766308\ttotal: 4.43s\tremaining: 12.6s\n",
      "52:\tlearn: 1.5673758\ttotal: 4.52s\tremaining: 12.5s\n",
      "53:\tlearn: 1.5588601\ttotal: 4.6s\tremaining: 12.4s\n",
      "54:\tlearn: 1.5516005\ttotal: 4.68s\tremaining: 12.3s\n",
      "55:\tlearn: 1.5433873\ttotal: 4.77s\tremaining: 12.3s\n",
      "56:\tlearn: 1.5360875\ttotal: 4.84s\tremaining: 12.2s\n",
      "57:\tlearn: 1.5287793\ttotal: 4.92s\tremaining: 12.1s\n",
      "58:\tlearn: 1.5211384\ttotal: 5.01s\tremaining: 12s\n",
      "59:\tlearn: 1.5132376\ttotal: 5.1s\tremaining: 11.9s\n",
      "60:\tlearn: 1.5065747\ttotal: 5.18s\tremaining: 11.8s\n",
      "61:\tlearn: 1.4990832\ttotal: 5.27s\tremaining: 11.7s\n",
      "62:\tlearn: 1.4921304\ttotal: 5.36s\tremaining: 11.7s\n",
      "63:\tlearn: 1.4848171\ttotal: 5.45s\tremaining: 11.6s\n",
      "64:\tlearn: 1.4778031\ttotal: 5.53s\tremaining: 11.5s\n",
      "65:\tlearn: 1.4701706\ttotal: 5.62s\tremaining: 11.4s\n",
      "66:\tlearn: 1.4634391\ttotal: 5.71s\tremaining: 11.3s\n",
      "67:\tlearn: 1.4560855\ttotal: 5.8s\tremaining: 11.3s\n",
      "68:\tlearn: 1.4499583\ttotal: 5.93s\tremaining: 11.3s\n",
      "69:\tlearn: 1.4434459\ttotal: 6.03s\tremaining: 11.2s\n",
      "70:\tlearn: 1.4378745\ttotal: 6.14s\tremaining: 11.2s\n",
      "71:\tlearn: 1.4314756\ttotal: 6.22s\tremaining: 11.1s\n",
      "72:\tlearn: 1.4254876\ttotal: 6.29s\tremaining: 11s\n",
      "73:\tlearn: 1.4188693\ttotal: 6.38s\tremaining: 10.9s\n",
      "74:\tlearn: 1.4126911\ttotal: 6.47s\tremaining: 10.8s\n",
      "75:\tlearn: 1.4074864\ttotal: 6.56s\tremaining: 10.7s\n",
      "76:\tlearn: 1.4018986\ttotal: 6.63s\tremaining: 10.6s\n",
      "77:\tlearn: 1.3955521\ttotal: 6.72s\tremaining: 10.5s\n",
      "78:\tlearn: 1.3903655\ttotal: 6.8s\tremaining: 10.4s\n",
      "79:\tlearn: 1.3857381\ttotal: 6.87s\tremaining: 10.3s\n",
      "80:\tlearn: 1.3806541\ttotal: 6.95s\tremaining: 10.2s\n",
      "81:\tlearn: 1.3748759\ttotal: 7.04s\tremaining: 10.1s\n",
      "82:\tlearn: 1.3689754\ttotal: 7.11s\tremaining: 10s\n",
      "83:\tlearn: 1.3630267\ttotal: 7.2s\tremaining: 9.94s\n",
      "84:\tlearn: 1.3570733\ttotal: 7.29s\tremaining: 9.86s\n",
      "85:\tlearn: 1.3516045\ttotal: 7.4s\tremaining: 9.81s\n",
      "86:\tlearn: 1.3458217\ttotal: 7.49s\tremaining: 9.73s\n",
      "87:\tlearn: 1.3403653\ttotal: 7.57s\tremaining: 9.63s\n",
      "88:\tlearn: 1.3358159\ttotal: 7.63s\tremaining: 9.52s\n",
      "89:\tlearn: 1.3313733\ttotal: 7.71s\tremaining: 9.42s\n",
      "90:\tlearn: 1.3268484\ttotal: 7.79s\tremaining: 9.33s\n",
      "91:\tlearn: 1.3221128\ttotal: 7.87s\tremaining: 9.23s\n",
      "92:\tlearn: 1.3179038\ttotal: 7.93s\tremaining: 9.12s\n",
      "93:\tlearn: 1.3131651\ttotal: 8.01s\tremaining: 9.03s\n",
      "94:\tlearn: 1.3092564\ttotal: 8.07s\tremaining: 8.92s\n",
      "95:\tlearn: 1.3048717\ttotal: 8.16s\tremaining: 8.84s\n",
      "96:\tlearn: 1.3005995\ttotal: 8.25s\tremaining: 8.77s\n",
      "97:\tlearn: 1.2966938\ttotal: 8.38s\tremaining: 8.72s\n",
      "98:\tlearn: 1.2922096\ttotal: 8.47s\tremaining: 8.64s\n",
      "99:\tlearn: 1.2877058\ttotal: 8.54s\tremaining: 8.54s\n",
      "100:\tlearn: 1.2830093\ttotal: 8.62s\tremaining: 8.45s\n",
      "101:\tlearn: 1.2783961\ttotal: 8.7s\tremaining: 8.36s\n",
      "102:\tlearn: 1.2745566\ttotal: 8.78s\tremaining: 8.27s\n",
      "103:\tlearn: 1.2707010\ttotal: 8.86s\tremaining: 8.18s\n",
      "104:\tlearn: 1.2672195\ttotal: 8.93s\tremaining: 8.08s\n",
      "105:\tlearn: 1.2632025\ttotal: 9.01s\tremaining: 7.99s\n",
      "106:\tlearn: 1.2589646\ttotal: 9.08s\tremaining: 7.89s\n",
      "107:\tlearn: 1.2552646\ttotal: 9.17s\tremaining: 7.81s\n",
      "108:\tlearn: 1.2512656\ttotal: 9.25s\tremaining: 7.72s\n",
      "109:\tlearn: 1.2467182\ttotal: 9.34s\tremaining: 7.64s\n",
      "110:\tlearn: 1.2429148\ttotal: 9.41s\tremaining: 7.55s\n",
      "111:\tlearn: 1.2395959\ttotal: 9.51s\tremaining: 7.47s\n",
      "112:\tlearn: 1.2360591\ttotal: 9.6s\tremaining: 7.39s\n",
      "113:\tlearn: 1.2321882\ttotal: 9.68s\tremaining: 7.3s\n",
      "114:\tlearn: 1.2293806\ttotal: 9.75s\tremaining: 7.2s\n",
      "115:\tlearn: 1.2254155\ttotal: 9.83s\tremaining: 7.12s\n",
      "116:\tlearn: 1.2216913\ttotal: 9.91s\tremaining: 7.03s\n",
      "117:\tlearn: 1.2191852\ttotal: 9.97s\tremaining: 6.93s\n",
      "118:\tlearn: 1.2161929\ttotal: 10s\tremaining: 6.84s\n",
      "119:\tlearn: 1.2126719\ttotal: 10.1s\tremaining: 6.75s\n",
      "120:\tlearn: 1.2100263\ttotal: 10.2s\tremaining: 6.65s\n",
      "121:\tlearn: 1.2060141\ttotal: 10.3s\tremaining: 6.57s\n",
      "122:\tlearn: 1.2027549\ttotal: 10.4s\tremaining: 6.49s\n",
      "123:\tlearn: 1.1994536\ttotal: 10.4s\tremaining: 6.4s\n",
      "124:\tlearn: 1.1960627\ttotal: 10.5s\tremaining: 6.31s\n",
      "125:\tlearn: 1.1931584\ttotal: 10.6s\tremaining: 6.22s\n",
      "126:\tlearn: 1.1897248\ttotal: 10.7s\tremaining: 6.14s\n",
      "127:\tlearn: 1.1866077\ttotal: 10.8s\tremaining: 6.06s\n",
      "128:\tlearn: 1.1836388\ttotal: 10.9s\tremaining: 5.98s\n",
      "129:\tlearn: 1.1797773\ttotal: 11s\tremaining: 5.9s\n",
      "130:\tlearn: 1.1763556\ttotal: 11s\tremaining: 5.82s\n",
      "131:\tlearn: 1.1734133\ttotal: 11.1s\tremaining: 5.72s\n",
      "132:\tlearn: 1.1702814\ttotal: 11.2s\tremaining: 5.64s\n",
      "133:\tlearn: 1.1676601\ttotal: 11.3s\tremaining: 5.55s\n",
      "134:\tlearn: 1.1647492\ttotal: 11.4s\tremaining: 5.46s\n",
      "135:\tlearn: 1.1619577\ttotal: 11.4s\tremaining: 5.38s\n",
      "136:\tlearn: 1.1584490\ttotal: 11.6s\tremaining: 5.31s\n",
      "137:\tlearn: 1.1557453\ttotal: 11.6s\tremaining: 5.23s\n",
      "138:\tlearn: 1.1528716\ttotal: 11.7s\tremaining: 5.15s\n",
      "139:\tlearn: 1.1502593\ttotal: 11.8s\tremaining: 5.07s\n",
      "140:\tlearn: 1.1475512\ttotal: 11.9s\tremaining: 4.99s\n",
      "141:\tlearn: 1.1446665\ttotal: 12s\tremaining: 4.91s\n",
      "142:\tlearn: 1.1419055\ttotal: 12.1s\tremaining: 4.83s\n",
      "143:\tlearn: 1.1388804\ttotal: 12.2s\tremaining: 4.74s\n",
      "144:\tlearn: 1.1357311\ttotal: 12.3s\tremaining: 4.67s\n",
      "145:\tlearn: 1.1330698\ttotal: 12.4s\tremaining: 4.58s\n",
      "146:\tlearn: 1.1304794\ttotal: 12.5s\tremaining: 4.49s\n",
      "147:\tlearn: 1.1277402\ttotal: 12.6s\tremaining: 4.41s\n",
      "148:\tlearn: 1.1247223\ttotal: 12.7s\tremaining: 4.33s\n",
      "149:\tlearn: 1.1219349\ttotal: 12.7s\tremaining: 4.25s\n",
      "150:\tlearn: 1.1193907\ttotal: 12.8s\tremaining: 4.16s\n",
      "151:\tlearn: 1.1162695\ttotal: 12.9s\tremaining: 4.08s\n",
      "152:\tlearn: 1.1138503\ttotal: 13s\tremaining: 4s\n",
      "153:\tlearn: 1.1113445\ttotal: 13.1s\tremaining: 3.91s\n",
      "154:\tlearn: 1.1088320\ttotal: 13.2s\tremaining: 3.82s\n",
      "155:\tlearn: 1.1060981\ttotal: 13.2s\tremaining: 3.74s\n",
      "156:\tlearn: 1.1035521\ttotal: 13.3s\tremaining: 3.66s\n",
      "157:\tlearn: 1.1007211\ttotal: 13.4s\tremaining: 3.57s\n",
      "158:\tlearn: 1.0984435\ttotal: 13.5s\tremaining: 3.48s\n",
      "159:\tlearn: 1.0959854\ttotal: 13.6s\tremaining: 3.4s\n",
      "160:\tlearn: 1.0933616\ttotal: 13.7s\tremaining: 3.31s\n",
      "161:\tlearn: 1.0909571\ttotal: 13.8s\tremaining: 3.23s\n",
      "162:\tlearn: 1.0884936\ttotal: 13.9s\tremaining: 3.15s\n",
      "163:\tlearn: 1.0863320\ttotal: 13.9s\tremaining: 3.06s\n",
      "164:\tlearn: 1.0839790\ttotal: 14s\tremaining: 2.97s\n",
      "165:\tlearn: 1.0816713\ttotal: 14.1s\tremaining: 2.89s\n",
      "166:\tlearn: 1.0792009\ttotal: 14.2s\tremaining: 2.81s\n",
      "167:\tlearn: 1.0771626\ttotal: 14.3s\tremaining: 2.72s\n",
      "168:\tlearn: 1.0743473\ttotal: 14.4s\tremaining: 2.64s\n",
      "169:\tlearn: 1.0721164\ttotal: 14.5s\tremaining: 2.56s\n",
      "170:\tlearn: 1.0693195\ttotal: 14.6s\tremaining: 2.47s\n",
      "171:\tlearn: 1.0668277\ttotal: 14.7s\tremaining: 2.39s\n",
      "172:\tlearn: 1.0643669\ttotal: 14.8s\tremaining: 2.31s\n",
      "173:\tlearn: 1.0612558\ttotal: 14.9s\tremaining: 2.23s\n",
      "174:\tlearn: 1.0587535\ttotal: 15s\tremaining: 2.14s\n",
      "175:\tlearn: 1.0564050\ttotal: 15.1s\tremaining: 2.06s\n",
      "176:\tlearn: 1.0540303\ttotal: 15.2s\tremaining: 1.97s\n",
      "177:\tlearn: 1.0515928\ttotal: 15.3s\tremaining: 1.89s\n",
      "178:\tlearn: 1.0495769\ttotal: 15.4s\tremaining: 1.8s\n",
      "179:\tlearn: 1.0474665\ttotal: 15.4s\tremaining: 1.72s\n",
      "180:\tlearn: 1.0453434\ttotal: 15.5s\tremaining: 1.63s\n",
      "181:\tlearn: 1.0430524\ttotal: 15.6s\tremaining: 1.54s\n",
      "182:\tlearn: 1.0404471\ttotal: 15.7s\tremaining: 1.46s\n",
      "183:\tlearn: 1.0384276\ttotal: 15.8s\tremaining: 1.37s\n",
      "184:\tlearn: 1.0360518\ttotal: 15.9s\tremaining: 1.29s\n",
      "185:\tlearn: 1.0339795\ttotal: 16s\tremaining: 1.2s\n",
      "186:\tlearn: 1.0321370\ttotal: 16s\tremaining: 1.11s\n",
      "187:\tlearn: 1.0297204\ttotal: 16.1s\tremaining: 1.03s\n",
      "188:\tlearn: 1.0276976\ttotal: 16.2s\tremaining: 943ms\n",
      "189:\tlearn: 1.0257718\ttotal: 16.3s\tremaining: 857ms\n",
      "190:\tlearn: 1.0233752\ttotal: 16.4s\tremaining: 771ms\n",
      "191:\tlearn: 1.0209837\ttotal: 16.5s\tremaining: 686ms\n",
      "192:\tlearn: 1.0191620\ttotal: 16.6s\tremaining: 600ms\n",
      "193:\tlearn: 1.0170923\ttotal: 16.7s\tremaining: 516ms\n",
      "194:\tlearn: 1.0147857\ttotal: 16.8s\tremaining: 430ms\n",
      "195:\tlearn: 1.0128909\ttotal: 16.8s\tremaining: 343ms\n",
      "196:\tlearn: 1.0104265\ttotal: 16.9s\tremaining: 258ms\n",
      "197:\tlearn: 1.0085367\ttotal: 17s\tremaining: 172ms\n",
      "198:\tlearn: 1.0061525\ttotal: 17.1s\tremaining: 85.8ms\n",
      "199:\tlearn: 1.0040809\ttotal: 17.2s\tremaining: 0us\n",
      "0:\tlearn: 2.2745478\ttotal: 89.3ms\tremaining: 17.8s\n",
      "1:\tlearn: 2.2491091\ttotal: 163ms\tremaining: 16.1s\n",
      "2:\tlearn: 2.2248687\ttotal: 235ms\tremaining: 15.4s\n",
      "3:\tlearn: 2.2015363\ttotal: 309ms\tremaining: 15.2s\n",
      "4:\tlearn: 2.1793654\ttotal: 386ms\tremaining: 15.1s\n",
      "5:\tlearn: 2.1570508\ttotal: 467ms\tremaining: 15.1s\n",
      "6:\tlearn: 2.1369424\ttotal: 541ms\tremaining: 14.9s\n",
      "7:\tlearn: 2.1163147\ttotal: 619ms\tremaining: 14.9s\n",
      "8:\tlearn: 2.0974866\ttotal: 695ms\tremaining: 14.7s\n",
      "9:\tlearn: 2.0770918\ttotal: 780ms\tremaining: 14.8s\n",
      "10:\tlearn: 2.0572351\ttotal: 861ms\tremaining: 14.8s\n",
      "11:\tlearn: 2.0405087\ttotal: 937ms\tremaining: 14.7s\n",
      "12:\tlearn: 2.0249213\ttotal: 1.01s\tremaining: 14.6s\n",
      "13:\tlearn: 2.0082455\ttotal: 1.09s\tremaining: 14.5s\n",
      "14:\tlearn: 1.9921855\ttotal: 1.17s\tremaining: 14.4s\n",
      "15:\tlearn: 1.9761503\ttotal: 1.25s\tremaining: 14.4s\n",
      "16:\tlearn: 1.9615636\ttotal: 1.33s\tremaining: 14.3s\n",
      "17:\tlearn: 1.9466888\ttotal: 1.41s\tremaining: 14.3s\n",
      "18:\tlearn: 1.9333366\ttotal: 1.49s\tremaining: 14.2s\n",
      "19:\tlearn: 1.9183910\ttotal: 1.57s\tremaining: 14.2s\n",
      "20:\tlearn: 1.9047091\ttotal: 1.65s\tremaining: 14.1s\n",
      "21:\tlearn: 1.8929217\ttotal: 1.73s\tremaining: 14s\n",
      "22:\tlearn: 1.8793373\ttotal: 1.82s\tremaining: 14s\n",
      "23:\tlearn: 1.8643355\ttotal: 1.91s\tremaining: 14s\n",
      "24:\tlearn: 1.8511005\ttotal: 1.99s\tremaining: 13.9s\n",
      "25:\tlearn: 1.8379911\ttotal: 2.07s\tremaining: 13.9s\n",
      "26:\tlearn: 1.8261560\ttotal: 2.15s\tremaining: 13.8s\n",
      "27:\tlearn: 1.8134640\ttotal: 2.23s\tremaining: 13.7s\n",
      "28:\tlearn: 1.8017106\ttotal: 2.32s\tremaining: 13.7s\n",
      "29:\tlearn: 1.7889316\ttotal: 2.41s\tremaining: 13.7s\n",
      "30:\tlearn: 1.7776919\ttotal: 2.5s\tremaining: 13.6s\n",
      "31:\tlearn: 1.7647214\ttotal: 2.58s\tremaining: 13.5s\n",
      "32:\tlearn: 1.7524029\ttotal: 2.67s\tremaining: 13.5s\n",
      "33:\tlearn: 1.7420787\ttotal: 2.75s\tremaining: 13.4s\n",
      "34:\tlearn: 1.7304279\ttotal: 2.84s\tremaining: 13.4s\n",
      "35:\tlearn: 1.7191754\ttotal: 2.94s\tremaining: 13.4s\n",
      "36:\tlearn: 1.7084387\ttotal: 3.02s\tremaining: 13.3s\n",
      "37:\tlearn: 1.6967500\ttotal: 3.11s\tremaining: 13.2s\n",
      "38:\tlearn: 1.6872836\ttotal: 3.19s\tremaining: 13.2s\n",
      "39:\tlearn: 1.6769896\ttotal: 3.27s\tremaining: 13.1s\n",
      "40:\tlearn: 1.6677922\ttotal: 3.36s\tremaining: 13s\n",
      "41:\tlearn: 1.6580497\ttotal: 3.44s\tremaining: 13s\n",
      "42:\tlearn: 1.6485962\ttotal: 3.53s\tremaining: 12.9s\n",
      "43:\tlearn: 1.6400718\ttotal: 3.61s\tremaining: 12.8s\n",
      "44:\tlearn: 1.6316004\ttotal: 3.69s\tremaining: 12.7s\n",
      "45:\tlearn: 1.6220881\ttotal: 3.78s\tremaining: 12.7s\n",
      "46:\tlearn: 1.6128068\ttotal: 3.87s\tremaining: 12.6s\n",
      "47:\tlearn: 1.6036514\ttotal: 3.95s\tremaining: 12.5s\n",
      "48:\tlearn: 1.5953113\ttotal: 4.03s\tremaining: 12.4s\n",
      "49:\tlearn: 1.5863937\ttotal: 4.11s\tremaining: 12.3s\n",
      "50:\tlearn: 1.5777035\ttotal: 4.19s\tremaining: 12.2s\n",
      "51:\tlearn: 1.5700545\ttotal: 4.27s\tremaining: 12.1s\n",
      "52:\tlearn: 1.5609995\ttotal: 4.35s\tremaining: 12.1s\n",
      "53:\tlearn: 1.5529153\ttotal: 4.44s\tremaining: 12s\n",
      "54:\tlearn: 1.5455154\ttotal: 4.51s\tremaining: 11.9s\n",
      "55:\tlearn: 1.5373922\ttotal: 4.6s\tremaining: 11.8s\n",
      "56:\tlearn: 1.5300767\ttotal: 4.67s\tremaining: 11.7s\n",
      "57:\tlearn: 1.5227784\ttotal: 4.75s\tremaining: 11.6s\n",
      "58:\tlearn: 1.5153023\ttotal: 4.83s\tremaining: 11.6s\n",
      "59:\tlearn: 1.5077675\ttotal: 4.92s\tremaining: 11.5s\n",
      "60:\tlearn: 1.5011833\ttotal: 5s\tremaining: 11.4s\n",
      "61:\tlearn: 1.4941243\ttotal: 5.08s\tremaining: 11.3s\n",
      "62:\tlearn: 1.4869275\ttotal: 5.17s\tremaining: 11.2s\n",
      "63:\tlearn: 1.4797484\ttotal: 5.26s\tremaining: 11.2s\n",
      "64:\tlearn: 1.4730172\ttotal: 5.35s\tremaining: 11.1s\n",
      "65:\tlearn: 1.4655454\ttotal: 5.43s\tremaining: 11s\n",
      "66:\tlearn: 1.4595652\ttotal: 5.51s\tremaining: 10.9s\n",
      "67:\tlearn: 1.4523818\ttotal: 5.6s\tremaining: 10.9s\n",
      "68:\tlearn: 1.4457170\ttotal: 5.68s\tremaining: 10.8s\n",
      "69:\tlearn: 1.4397227\ttotal: 5.75s\tremaining: 10.7s\n",
      "70:\tlearn: 1.4338370\ttotal: 5.83s\tremaining: 10.6s\n",
      "71:\tlearn: 1.4273352\ttotal: 5.92s\tremaining: 10.5s\n",
      "72:\tlearn: 1.4208947\ttotal: 6.01s\tremaining: 10.5s\n",
      "73:\tlearn: 1.4153907\ttotal: 6.09s\tremaining: 10.4s\n",
      "74:\tlearn: 1.4095525\ttotal: 6.17s\tremaining: 10.3s\n",
      "75:\tlearn: 1.4043894\ttotal: 6.25s\tremaining: 10.2s\n",
      "76:\tlearn: 1.3989861\ttotal: 6.33s\tremaining: 10.1s\n",
      "77:\tlearn: 1.3924319\ttotal: 6.43s\tremaining: 10.1s\n",
      "78:\tlearn: 1.3873662\ttotal: 6.5s\tremaining: 9.96s\n",
      "79:\tlearn: 1.3823791\ttotal: 6.58s\tremaining: 9.87s\n",
      "80:\tlearn: 1.3773625\ttotal: 6.66s\tremaining: 9.78s\n",
      "81:\tlearn: 1.3715460\ttotal: 6.75s\tremaining: 9.71s\n",
      "82:\tlearn: 1.3658593\ttotal: 6.82s\tremaining: 9.61s\n",
      "83:\tlearn: 1.3599959\ttotal: 6.9s\tremaining: 9.53s\n",
      "84:\tlearn: 1.3549072\ttotal: 6.99s\tremaining: 9.45s\n",
      "85:\tlearn: 1.3494997\ttotal: 7.09s\tremaining: 9.4s\n",
      "86:\tlearn: 1.3442854\ttotal: 7.17s\tremaining: 9.31s\n",
      "87:\tlearn: 1.3389186\ttotal: 7.24s\tremaining: 9.22s\n",
      "88:\tlearn: 1.3342402\ttotal: 7.3s\tremaining: 9.11s\n",
      "89:\tlearn: 1.3296371\ttotal: 7.38s\tremaining: 9.02s\n",
      "90:\tlearn: 1.3251353\ttotal: 7.45s\tremaining: 8.93s\n",
      "91:\tlearn: 1.3200123\ttotal: 7.53s\tremaining: 8.84s\n",
      "92:\tlearn: 1.3159329\ttotal: 7.59s\tremaining: 8.74s\n",
      "93:\tlearn: 1.3112317\ttotal: 7.67s\tremaining: 8.65s\n",
      "94:\tlearn: 1.3072548\ttotal: 7.74s\tremaining: 8.56s\n",
      "95:\tlearn: 1.3028852\ttotal: 7.82s\tremaining: 8.47s\n",
      "96:\tlearn: 1.2986706\ttotal: 7.89s\tremaining: 8.38s\n",
      "97:\tlearn: 1.2943526\ttotal: 7.97s\tremaining: 8.29s\n",
      "98:\tlearn: 1.2901212\ttotal: 8.04s\tremaining: 8.2s\n",
      "99:\tlearn: 1.2851408\ttotal: 8.13s\tremaining: 8.13s\n",
      "100:\tlearn: 1.2803359\ttotal: 8.21s\tremaining: 8.04s\n",
      "101:\tlearn: 1.2752512\ttotal: 8.3s\tremaining: 7.97s\n",
      "102:\tlearn: 1.2714532\ttotal: 8.37s\tremaining: 7.88s\n",
      "103:\tlearn: 1.2676127\ttotal: 8.45s\tremaining: 7.8s\n",
      "104:\tlearn: 1.2632595\ttotal: 8.53s\tremaining: 7.71s\n",
      "105:\tlearn: 1.2594061\ttotal: 8.59s\tremaining: 7.62s\n",
      "106:\tlearn: 1.2551693\ttotal: 8.67s\tremaining: 7.53s\n",
      "107:\tlearn: 1.2515231\ttotal: 8.74s\tremaining: 7.45s\n",
      "108:\tlearn: 1.2476531\ttotal: 8.82s\tremaining: 7.37s\n",
      "109:\tlearn: 1.2430843\ttotal: 8.9s\tremaining: 7.28s\n",
      "110:\tlearn: 1.2393227\ttotal: 8.97s\tremaining: 7.19s\n",
      "111:\tlearn: 1.2348887\ttotal: 9.05s\tremaining: 7.11s\n",
      "112:\tlearn: 1.2314779\ttotal: 9.12s\tremaining: 7.02s\n",
      "113:\tlearn: 1.2275756\ttotal: 9.2s\tremaining: 6.94s\n",
      "114:\tlearn: 1.2247904\ttotal: 9.26s\tremaining: 6.85s\n",
      "115:\tlearn: 1.2208660\ttotal: 9.35s\tremaining: 6.77s\n",
      "116:\tlearn: 1.2175537\ttotal: 9.42s\tremaining: 6.68s\n",
      "117:\tlearn: 1.2146204\ttotal: 9.49s\tremaining: 6.6s\n",
      "118:\tlearn: 1.2116097\ttotal: 9.56s\tremaining: 6.51s\n",
      "119:\tlearn: 1.2087681\ttotal: 9.62s\tremaining: 6.41s\n",
      "120:\tlearn: 1.2057163\ttotal: 9.69s\tremaining: 6.33s\n",
      "121:\tlearn: 1.2017532\ttotal: 9.77s\tremaining: 6.25s\n",
      "122:\tlearn: 1.1980132\ttotal: 9.86s\tremaining: 6.17s\n",
      "123:\tlearn: 1.1947221\ttotal: 9.93s\tremaining: 6.09s\n",
      "124:\tlearn: 1.1911978\ttotal: 10s\tremaining: 6s\n",
      "125:\tlearn: 1.1882998\ttotal: 10.1s\tremaining: 5.92s\n",
      "126:\tlearn: 1.1849203\ttotal: 10.1s\tremaining: 5.83s\n",
      "127:\tlearn: 1.1818687\ttotal: 10.2s\tremaining: 5.75s\n",
      "128:\tlearn: 1.1789346\ttotal: 10.3s\tremaining: 5.67s\n",
      "129:\tlearn: 1.1752922\ttotal: 10.4s\tremaining: 5.59s\n",
      "130:\tlearn: 1.1722847\ttotal: 10.5s\tremaining: 5.51s\n",
      "131:\tlearn: 1.1694592\ttotal: 10.5s\tremaining: 5.42s\n",
      "132:\tlearn: 1.1666763\ttotal: 10.6s\tremaining: 5.33s\n",
      "133:\tlearn: 1.1641212\ttotal: 10.7s\tremaining: 5.25s\n",
      "134:\tlearn: 1.1611655\ttotal: 10.7s\tremaining: 5.17s\n",
      "135:\tlearn: 1.1584183\ttotal: 10.8s\tremaining: 5.08s\n",
      "136:\tlearn: 1.1549469\ttotal: 10.9s\tremaining: 5.01s\n",
      "137:\tlearn: 1.1522635\ttotal: 11s\tremaining: 4.93s\n",
      "138:\tlearn: 1.1488167\ttotal: 11s\tremaining: 4.85s\n",
      "139:\tlearn: 1.1462877\ttotal: 11.1s\tremaining: 4.76s\n",
      "140:\tlearn: 1.1437716\ttotal: 11.2s\tremaining: 4.68s\n",
      "141:\tlearn: 1.1414713\ttotal: 11.2s\tremaining: 4.59s\n",
      "142:\tlearn: 1.1383468\ttotal: 11.3s\tremaining: 4.52s\n",
      "143:\tlearn: 1.1352761\ttotal: 11.4s\tremaining: 4.44s\n",
      "144:\tlearn: 1.1321170\ttotal: 11.5s\tremaining: 4.36s\n",
      "145:\tlearn: 1.1294614\ttotal: 11.6s\tremaining: 4.28s\n",
      "146:\tlearn: 1.1269169\ttotal: 11.6s\tremaining: 4.2s\n",
      "147:\tlearn: 1.1243142\ttotal: 11.7s\tremaining: 4.12s\n",
      "148:\tlearn: 1.1216157\ttotal: 11.8s\tremaining: 4.04s\n",
      "149:\tlearn: 1.1188587\ttotal: 11.9s\tremaining: 3.95s\n",
      "150:\tlearn: 1.1159869\ttotal: 11.9s\tremaining: 3.88s\n",
      "151:\tlearn: 1.1131095\ttotal: 12s\tremaining: 3.8s\n",
      "152:\tlearn: 1.1105505\ttotal: 12.1s\tremaining: 3.72s\n",
      "153:\tlearn: 1.1077762\ttotal: 12.2s\tremaining: 3.64s\n",
      "154:\tlearn: 1.1051758\ttotal: 12.3s\tremaining: 3.56s\n",
      "155:\tlearn: 1.1024262\ttotal: 12.3s\tremaining: 3.48s\n",
      "156:\tlearn: 1.1000311\ttotal: 12.4s\tremaining: 3.4s\n",
      "157:\tlearn: 1.0973290\ttotal: 12.5s\tremaining: 3.32s\n",
      "158:\tlearn: 1.0950446\ttotal: 12.6s\tremaining: 3.24s\n",
      "159:\tlearn: 1.0924530\ttotal: 12.6s\tremaining: 3.16s\n",
      "160:\tlearn: 1.0898949\ttotal: 12.7s\tremaining: 3.08s\n",
      "161:\tlearn: 1.0873283\ttotal: 12.8s\tremaining: 3s\n",
      "162:\tlearn: 1.0845171\ttotal: 12.9s\tremaining: 2.92s\n",
      "163:\tlearn: 1.0823816\ttotal: 12.9s\tremaining: 2.84s\n",
      "164:\tlearn: 1.0800732\ttotal: 13s\tremaining: 2.76s\n",
      "165:\tlearn: 1.0776679\ttotal: 13.1s\tremaining: 2.68s\n",
      "166:\tlearn: 1.0747318\ttotal: 13.2s\tremaining: 2.61s\n",
      "167:\tlearn: 1.0725341\ttotal: 13.3s\tremaining: 2.53s\n",
      "168:\tlearn: 1.0702443\ttotal: 13.3s\tremaining: 2.45s\n",
      "169:\tlearn: 1.0680913\ttotal: 13.4s\tremaining: 2.37s\n",
      "170:\tlearn: 1.0650994\ttotal: 13.5s\tremaining: 2.29s\n",
      "171:\tlearn: 1.0626982\ttotal: 13.6s\tremaining: 2.21s\n",
      "172:\tlearn: 1.0605676\ttotal: 13.7s\tremaining: 2.13s\n",
      "173:\tlearn: 1.0576271\ttotal: 13.8s\tremaining: 2.06s\n",
      "174:\tlearn: 1.0551580\ttotal: 13.8s\tremaining: 1.98s\n",
      "175:\tlearn: 1.0528212\ttotal: 13.9s\tremaining: 1.9s\n",
      "176:\tlearn: 1.0503629\ttotal: 14s\tremaining: 1.82s\n",
      "177:\tlearn: 1.0475083\ttotal: 14.1s\tremaining: 1.74s\n",
      "178:\tlearn: 1.0455530\ttotal: 14.2s\tremaining: 1.66s\n",
      "179:\tlearn: 1.0434579\ttotal: 14.2s\tremaining: 1.58s\n",
      "180:\tlearn: 1.0415099\ttotal: 14.3s\tremaining: 1.5s\n",
      "181:\tlearn: 1.0395186\ttotal: 14.4s\tremaining: 1.42s\n",
      "182:\tlearn: 1.0369294\ttotal: 14.5s\tremaining: 1.34s\n",
      "183:\tlearn: 1.0347725\ttotal: 14.5s\tremaining: 1.26s\n",
      "184:\tlearn: 1.0323997\ttotal: 14.6s\tremaining: 1.19s\n",
      "185:\tlearn: 1.0304513\ttotal: 14.7s\tremaining: 1.11s\n",
      "186:\tlearn: 1.0284956\ttotal: 14.8s\tremaining: 1.03s\n",
      "187:\tlearn: 1.0265116\ttotal: 14.8s\tremaining: 947ms\n",
      "188:\tlearn: 1.0246482\ttotal: 14.9s\tremaining: 868ms\n",
      "189:\tlearn: 1.0228958\ttotal: 15s\tremaining: 790ms\n",
      "190:\tlearn: 1.0202642\ttotal: 15.1s\tremaining: 711ms\n",
      "191:\tlearn: 1.0181460\ttotal: 15.2s\tremaining: 632ms\n",
      "192:\tlearn: 1.0158712\ttotal: 15.2s\tremaining: 553ms\n",
      "193:\tlearn: 1.0138385\ttotal: 15.3s\tremaining: 474ms\n",
      "194:\tlearn: 1.0119984\ttotal: 15.4s\tremaining: 395ms\n",
      "195:\tlearn: 1.0101253\ttotal: 15.5s\tremaining: 316ms\n",
      "196:\tlearn: 1.0076642\ttotal: 15.6s\tremaining: 237ms\n",
      "197:\tlearn: 1.0058745\ttotal: 15.7s\tremaining: 158ms\n",
      "198:\tlearn: 1.0036246\ttotal: 15.7s\tremaining: 79.1ms\n",
      "199:\tlearn: 1.0015956\ttotal: 15.8s\tremaining: 0us\n",
      "0:\tlearn: 2.2745527\ttotal: 85.2ms\tremaining: 17s\n",
      "1:\tlearn: 2.2483020\ttotal: 170ms\tremaining: 16.8s\n",
      "2:\tlearn: 2.2237348\ttotal: 243ms\tremaining: 16s\n",
      "3:\tlearn: 2.2001446\ttotal: 318ms\tremaining: 15.6s\n",
      "4:\tlearn: 2.1779610\ttotal: 395ms\tremaining: 15.4s\n",
      "5:\tlearn: 2.1567463\ttotal: 470ms\tremaining: 15.2s\n",
      "6:\tlearn: 2.1368141\ttotal: 544ms\tremaining: 15s\n",
      "7:\tlearn: 2.1159693\ttotal: 622ms\tremaining: 14.9s\n",
      "8:\tlearn: 2.0955090\ttotal: 702ms\tremaining: 14.9s\n",
      "9:\tlearn: 2.0752417\ttotal: 786ms\tremaining: 14.9s\n",
      "10:\tlearn: 2.0578462\ttotal: 863ms\tremaining: 14.8s\n",
      "11:\tlearn: 2.0411178\ttotal: 938ms\tremaining: 14.7s\n",
      "12:\tlearn: 2.0255488\ttotal: 1.01s\tremaining: 14.6s\n",
      "13:\tlearn: 2.0090437\ttotal: 1.09s\tremaining: 14.5s\n",
      "14:\tlearn: 1.9930720\ttotal: 1.17s\tremaining: 14.4s\n",
      "15:\tlearn: 1.9786468\ttotal: 1.24s\tremaining: 14.3s\n",
      "16:\tlearn: 1.9635703\ttotal: 1.32s\tremaining: 14.2s\n",
      "17:\tlearn: 1.9486229\ttotal: 1.4s\tremaining: 14.2s\n",
      "18:\tlearn: 1.9352437\ttotal: 1.48s\tremaining: 14.1s\n",
      "19:\tlearn: 1.9202594\ttotal: 1.56s\tremaining: 14.1s\n",
      "20:\tlearn: 1.9061861\ttotal: 1.64s\tremaining: 14s\n",
      "21:\tlearn: 1.8938795\ttotal: 1.72s\tremaining: 13.9s\n",
      "22:\tlearn: 1.8790681\ttotal: 1.8s\tremaining: 13.9s\n",
      "23:\tlearn: 1.8642363\ttotal: 1.88s\tremaining: 13.8s\n",
      "24:\tlearn: 1.8515717\ttotal: 1.97s\tremaining: 13.8s\n",
      "25:\tlearn: 1.8385113\ttotal: 2.06s\tremaining: 13.8s\n",
      "26:\tlearn: 1.8266342\ttotal: 2.15s\tremaining: 13.7s\n",
      "27:\tlearn: 1.8141225\ttotal: 2.23s\tremaining: 13.7s\n",
      "28:\tlearn: 1.8010874\ttotal: 2.31s\tremaining: 13.6s\n",
      "29:\tlearn: 1.7885986\ttotal: 2.39s\tremaining: 13.6s\n",
      "30:\tlearn: 1.7772518\ttotal: 2.48s\tremaining: 13.5s\n",
      "31:\tlearn: 1.7649699\ttotal: 2.56s\tremaining: 13.5s\n",
      "32:\tlearn: 1.7526377\ttotal: 2.65s\tremaining: 13.4s\n",
      "33:\tlearn: 1.7411382\ttotal: 2.74s\tremaining: 13.4s\n",
      "34:\tlearn: 1.7293323\ttotal: 2.83s\tremaining: 13.4s\n",
      "35:\tlearn: 1.7179613\ttotal: 2.93s\tremaining: 13.3s\n",
      "36:\tlearn: 1.7070240\ttotal: 3.02s\tremaining: 13.3s\n",
      "37:\tlearn: 1.6959472\ttotal: 3.1s\tremaining: 13.2s\n",
      "38:\tlearn: 1.6864904\ttotal: 3.19s\tremaining: 13.2s\n",
      "39:\tlearn: 1.6761457\ttotal: 3.27s\tremaining: 13.1s\n",
      "40:\tlearn: 1.6671505\ttotal: 3.35s\tremaining: 13s\n",
      "41:\tlearn: 1.6574689\ttotal: 3.44s\tremaining: 12.9s\n",
      "42:\tlearn: 1.6476955\ttotal: 3.52s\tremaining: 12.9s\n",
      "43:\tlearn: 1.6389069\ttotal: 3.6s\tremaining: 12.8s\n",
      "44:\tlearn: 1.6295991\ttotal: 3.69s\tremaining: 12.7s\n",
      "45:\tlearn: 1.6202857\ttotal: 3.77s\tremaining: 12.6s\n",
      "46:\tlearn: 1.6114148\ttotal: 3.85s\tremaining: 12.5s\n",
      "47:\tlearn: 1.6023835\ttotal: 3.93s\tremaining: 12.5s\n",
      "48:\tlearn: 1.5941333\ttotal: 4.01s\tremaining: 12.4s\n",
      "49:\tlearn: 1.5854408\ttotal: 4.1s\tremaining: 12.3s\n",
      "50:\tlearn: 1.5766516\ttotal: 4.18s\tremaining: 12.2s\n",
      "51:\tlearn: 1.5688339\ttotal: 4.27s\tremaining: 12.2s\n",
      "52:\tlearn: 1.5605270\ttotal: 4.35s\tremaining: 12.1s\n",
      "53:\tlearn: 1.5524747\ttotal: 4.44s\tremaining: 12s\n",
      "54:\tlearn: 1.5449691\ttotal: 4.51s\tremaining: 11.9s\n",
      "55:\tlearn: 1.5372823\ttotal: 4.59s\tremaining: 11.8s\n",
      "56:\tlearn: 1.5304021\ttotal: 4.67s\tremaining: 11.7s\n",
      "57:\tlearn: 1.5232046\ttotal: 4.75s\tremaining: 11.6s\n",
      "58:\tlearn: 1.5158143\ttotal: 4.83s\tremaining: 11.5s\n",
      "59:\tlearn: 1.5085726\ttotal: 4.91s\tremaining: 11.5s\n",
      "60:\tlearn: 1.5019107\ttotal: 4.99s\tremaining: 11.4s\n",
      "61:\tlearn: 1.4951393\ttotal: 5.07s\tremaining: 11.3s\n",
      "62:\tlearn: 1.4880399\ttotal: 5.15s\tremaining: 11.2s\n",
      "63:\tlearn: 1.4808903\ttotal: 5.24s\tremaining: 11.1s\n",
      "64:\tlearn: 1.4750400\ttotal: 5.32s\tremaining: 11s\n",
      "65:\tlearn: 1.4676540\ttotal: 5.4s\tremaining: 11s\n",
      "66:\tlearn: 1.4616303\ttotal: 5.48s\tremaining: 10.9s\n",
      "67:\tlearn: 1.4543717\ttotal: 5.57s\tremaining: 10.8s\n",
      "68:\tlearn: 1.4478419\ttotal: 5.65s\tremaining: 10.7s\n",
      "69:\tlearn: 1.4412956\ttotal: 5.72s\tremaining: 10.6s\n",
      "70:\tlearn: 1.4354530\ttotal: 5.8s\tremaining: 10.5s\n",
      "71:\tlearn: 1.4298563\ttotal: 5.87s\tremaining: 10.4s\n",
      "72:\tlearn: 1.4249559\ttotal: 5.94s\tremaining: 10.3s\n",
      "73:\tlearn: 1.4194738\ttotal: 6.03s\tremaining: 10.3s\n",
      "74:\tlearn: 1.4135270\ttotal: 6.11s\tremaining: 10.2s\n",
      "75:\tlearn: 1.4080210\ttotal: 6.18s\tremaining: 10.1s\n",
      "76:\tlearn: 1.4021731\ttotal: 6.26s\tremaining: 10s\n",
      "77:\tlearn: 1.3976484\ttotal: 6.33s\tremaining: 9.9s\n",
      "78:\tlearn: 1.3921583\ttotal: 6.42s\tremaining: 9.84s\n",
      "79:\tlearn: 1.3863840\ttotal: 6.5s\tremaining: 9.76s\n",
      "80:\tlearn: 1.3811652\ttotal: 6.6s\tremaining: 9.7s\n",
      "81:\tlearn: 1.3753716\ttotal: 6.72s\tremaining: 9.67s\n",
      "82:\tlearn: 1.3705142\ttotal: 6.81s\tremaining: 9.6s\n",
      "83:\tlearn: 1.3645548\ttotal: 6.89s\tremaining: 9.52s\n",
      "84:\tlearn: 1.3591780\ttotal: 6.99s\tremaining: 9.45s\n",
      "85:\tlearn: 1.3537475\ttotal: 7.08s\tremaining: 9.38s\n",
      "86:\tlearn: 1.3479344\ttotal: 7.17s\tremaining: 9.31s\n",
      "87:\tlearn: 1.3425274\ttotal: 7.25s\tremaining: 9.22s\n",
      "88:\tlearn: 1.3383691\ttotal: 7.32s\tremaining: 9.13s\n",
      "89:\tlearn: 1.3332631\ttotal: 7.39s\tremaining: 9.04s\n",
      "90:\tlearn: 1.3283747\ttotal: 7.54s\tremaining: 9.03s\n",
      "91:\tlearn: 1.3240460\ttotal: 7.81s\tremaining: 9.17s\n",
      "92:\tlearn: 1.3199267\ttotal: 7.88s\tremaining: 9.06s\n",
      "93:\tlearn: 1.3151783\ttotal: 7.96s\tremaining: 8.98s\n",
      "94:\tlearn: 1.3111637\ttotal: 8.03s\tremaining: 8.88s\n",
      "95:\tlearn: 1.3068112\ttotal: 8.11s\tremaining: 8.78s\n",
      "96:\tlearn: 1.3030133\ttotal: 8.18s\tremaining: 8.69s\n",
      "97:\tlearn: 1.2986118\ttotal: 8.26s\tremaining: 8.59s\n",
      "98:\tlearn: 1.2943707\ttotal: 8.32s\tremaining: 8.49s\n",
      "99:\tlearn: 1.2898878\ttotal: 8.4s\tremaining: 8.4s\n",
      "100:\tlearn: 1.2850392\ttotal: 8.48s\tremaining: 8.31s\n",
      "101:\tlearn: 1.2799024\ttotal: 8.58s\tremaining: 8.24s\n",
      "102:\tlearn: 1.2760345\ttotal: 8.66s\tremaining: 8.15s\n",
      "103:\tlearn: 1.2714205\ttotal: 8.73s\tremaining: 8.06s\n",
      "104:\tlearn: 1.2678712\ttotal: 8.79s\tremaining: 7.96s\n",
      "105:\tlearn: 1.2636280\ttotal: 8.87s\tremaining: 7.87s\n",
      "106:\tlearn: 1.2598047\ttotal: 8.94s\tremaining: 7.77s\n",
      "107:\tlearn: 1.2561187\ttotal: 9.02s\tremaining: 7.68s\n",
      "108:\tlearn: 1.2515508\ttotal: 9.11s\tremaining: 7.6s\n",
      "109:\tlearn: 1.2469663\ttotal: 9.19s\tremaining: 7.52s\n",
      "110:\tlearn: 1.2430060\ttotal: 9.27s\tremaining: 7.43s\n",
      "111:\tlearn: 1.2389389\ttotal: 9.35s\tremaining: 7.34s\n",
      "112:\tlearn: 1.2352509\ttotal: 9.43s\tremaining: 7.26s\n",
      "113:\tlearn: 1.2314130\ttotal: 9.5s\tremaining: 7.17s\n",
      "114:\tlearn: 1.2286706\ttotal: 9.57s\tremaining: 7.07s\n",
      "115:\tlearn: 1.2244254\ttotal: 9.65s\tremaining: 6.99s\n",
      "116:\tlearn: 1.2201393\ttotal: 9.73s\tremaining: 6.9s\n",
      "117:\tlearn: 1.2167379\ttotal: 9.81s\tremaining: 6.82s\n",
      "118:\tlearn: 1.2134516\ttotal: 9.89s\tremaining: 6.73s\n",
      "119:\tlearn: 1.2092726\ttotal: 9.98s\tremaining: 6.65s\n",
      "120:\tlearn: 1.2060228\ttotal: 10.1s\tremaining: 6.56s\n",
      "121:\tlearn: 1.2028738\ttotal: 10.1s\tremaining: 6.47s\n",
      "122:\tlearn: 1.1996296\ttotal: 10.2s\tremaining: 6.39s\n",
      "123:\tlearn: 1.1963446\ttotal: 10.3s\tremaining: 6.3s\n",
      "124:\tlearn: 1.1929750\ttotal: 10.4s\tremaining: 6.21s\n",
      "125:\tlearn: 1.1892291\ttotal: 10.4s\tremaining: 6.13s\n",
      "126:\tlearn: 1.1862253\ttotal: 10.5s\tremaining: 6.04s\n",
      "127:\tlearn: 1.1831725\ttotal: 10.6s\tremaining: 5.95s\n",
      "128:\tlearn: 1.1803658\ttotal: 10.6s\tremaining: 5.86s\n",
      "129:\tlearn: 1.1770047\ttotal: 10.7s\tremaining: 5.78s\n",
      "130:\tlearn: 1.1739318\ttotal: 10.8s\tremaining: 5.7s\n",
      "131:\tlearn: 1.1710799\ttotal: 10.9s\tremaining: 5.6s\n",
      "132:\tlearn: 1.1683747\ttotal: 10.9s\tremaining: 5.51s\n",
      "133:\tlearn: 1.1657286\ttotal: 11s\tremaining: 5.42s\n",
      "134:\tlearn: 1.1634788\ttotal: 11.1s\tremaining: 5.33s\n",
      "135:\tlearn: 1.1607841\ttotal: 11.1s\tremaining: 5.25s\n",
      "136:\tlearn: 1.1571612\ttotal: 11.2s\tremaining: 5.17s\n",
      "137:\tlearn: 1.1544556\ttotal: 11.3s\tremaining: 5.08s\n",
      "138:\tlearn: 1.1516151\ttotal: 11.4s\tremaining: 5s\n",
      "139:\tlearn: 1.1490725\ttotal: 11.5s\tremaining: 4.91s\n",
      "140:\tlearn: 1.1463768\ttotal: 11.5s\tremaining: 4.82s\n",
      "141:\tlearn: 1.1435437\ttotal: 11.6s\tremaining: 4.74s\n",
      "142:\tlearn: 1.1405313\ttotal: 11.7s\tremaining: 4.66s\n",
      "143:\tlearn: 1.1380089\ttotal: 11.8s\tremaining: 4.58s\n",
      "144:\tlearn: 1.1350935\ttotal: 11.9s\tremaining: 4.5s\n",
      "145:\tlearn: 1.1325198\ttotal: 11.9s\tremaining: 4.41s\n",
      "146:\tlearn: 1.1299420\ttotal: 12s\tremaining: 4.33s\n",
      "147:\tlearn: 1.1272862\ttotal: 12.1s\tremaining: 4.24s\n",
      "148:\tlearn: 1.1245396\ttotal: 12.2s\tremaining: 4.16s\n",
      "149:\tlearn: 1.1218019\ttotal: 12.2s\tremaining: 4.08s\n",
      "150:\tlearn: 1.1182258\ttotal: 12.3s\tremaining: 4s\n",
      "151:\tlearn: 1.1151181\ttotal: 12.4s\tremaining: 3.92s\n",
      "152:\tlearn: 1.1125512\ttotal: 12.5s\tremaining: 3.84s\n",
      "153:\tlearn: 1.1100599\ttotal: 12.6s\tremaining: 3.76s\n",
      "154:\tlearn: 1.1076915\ttotal: 12.7s\tremaining: 3.67s\n",
      "155:\tlearn: 1.1049818\ttotal: 12.7s\tremaining: 3.59s\n",
      "156:\tlearn: 1.1021209\ttotal: 12.8s\tremaining: 3.51s\n",
      "157:\tlearn: 1.0990270\ttotal: 12.9s\tremaining: 3.43s\n",
      "158:\tlearn: 1.0974272\ttotal: 13s\tremaining: 3.34s\n",
      "159:\tlearn: 1.0950869\ttotal: 13s\tremaining: 3.26s\n",
      "160:\tlearn: 1.0925386\ttotal: 13.1s\tremaining: 3.18s\n",
      "161:\tlearn: 1.0897419\ttotal: 13.2s\tremaining: 3.1s\n",
      "162:\tlearn: 1.0871332\ttotal: 13.3s\tremaining: 3.01s\n",
      "163:\tlearn: 1.0845582\ttotal: 13.4s\tremaining: 2.93s\n",
      "164:\tlearn: 1.0822548\ttotal: 13.4s\tremaining: 2.85s\n",
      "165:\tlearn: 1.0800511\ttotal: 13.5s\tremaining: 2.77s\n",
      "166:\tlearn: 1.0775954\ttotal: 13.6s\tremaining: 2.69s\n",
      "167:\tlearn: 1.0753102\ttotal: 13.7s\tremaining: 2.6s\n",
      "168:\tlearn: 1.0725175\ttotal: 13.8s\tremaining: 2.52s\n",
      "169:\tlearn: 1.0703379\ttotal: 13.8s\tremaining: 2.44s\n",
      "170:\tlearn: 1.0674244\ttotal: 13.9s\tremaining: 2.36s\n",
      "171:\tlearn: 1.0648660\ttotal: 14s\tremaining: 2.28s\n",
      "172:\tlearn: 1.0627908\ttotal: 14.1s\tremaining: 2.2s\n",
      "173:\tlearn: 1.0603107\ttotal: 14.2s\tremaining: 2.12s\n",
      "174:\tlearn: 1.0577968\ttotal: 14.3s\tremaining: 2.04s\n",
      "175:\tlearn: 1.0549042\ttotal: 14.3s\tremaining: 1.96s\n",
      "176:\tlearn: 1.0524192\ttotal: 14.4s\tremaining: 1.87s\n",
      "177:\tlearn: 1.0496274\ttotal: 14.5s\tremaining: 1.79s\n",
      "178:\tlearn: 1.0480559\ttotal: 14.6s\tremaining: 1.71s\n",
      "179:\tlearn: 1.0453823\ttotal: 14.7s\tremaining: 1.63s\n",
      "180:\tlearn: 1.0431476\ttotal: 14.7s\tremaining: 1.55s\n",
      "181:\tlearn: 1.0411343\ttotal: 14.8s\tremaining: 1.47s\n",
      "182:\tlearn: 1.0388292\ttotal: 14.9s\tremaining: 1.38s\n",
      "183:\tlearn: 1.0367858\ttotal: 15s\tremaining: 1.3s\n",
      "184:\tlearn: 1.0343761\ttotal: 15.1s\tremaining: 1.22s\n",
      "185:\tlearn: 1.0325714\ttotal: 15.1s\tremaining: 1.14s\n",
      "186:\tlearn: 1.0304411\ttotal: 15.2s\tremaining: 1.06s\n",
      "187:\tlearn: 1.0282448\ttotal: 15.3s\tremaining: 977ms\n",
      "188:\tlearn: 1.0262220\ttotal: 15.4s\tremaining: 895ms\n",
      "189:\tlearn: 1.0240440\ttotal: 15.5s\tremaining: 814ms\n",
      "190:\tlearn: 1.0219189\ttotal: 15.5s\tremaining: 732ms\n",
      "191:\tlearn: 1.0196230\ttotal: 15.6s\tremaining: 651ms\n",
      "192:\tlearn: 1.0178767\ttotal: 15.7s\tremaining: 569ms\n",
      "193:\tlearn: 1.0153646\ttotal: 15.8s\tremaining: 488ms\n",
      "194:\tlearn: 1.0130765\ttotal: 15.9s\tremaining: 407ms\n",
      "195:\tlearn: 1.0113192\ttotal: 15.9s\tremaining: 325ms\n",
      "196:\tlearn: 1.0087363\ttotal: 16s\tremaining: 244ms\n",
      "197:\tlearn: 1.0063181\ttotal: 16.1s\tremaining: 163ms\n",
      "198:\tlearn: 1.0040464\ttotal: 16.2s\tremaining: 81.5ms\n",
      "199:\tlearn: 1.0019714\ttotal: 16.3s\tremaining: 0us\n",
      "0:\tlearn: 1.5161069\ttotal: 87.6ms\tremaining: 17.4s\n",
      "1:\tlearn: 1.2497339\ttotal: 152ms\tremaining: 15s\n",
      "2:\tlearn: 1.1053270\ttotal: 234ms\tremaining: 15.4s\n",
      "3:\tlearn: 0.9531728\ttotal: 330ms\tremaining: 16.2s\n",
      "4:\tlearn: 0.8881169\ttotal: 408ms\tremaining: 15.9s\n",
      "5:\tlearn: 0.8357729\ttotal: 497ms\tremaining: 16.1s\n",
      "6:\tlearn: 0.7875413\ttotal: 591ms\tremaining: 16.3s\n",
      "7:\tlearn: 0.7571742\ttotal: 670ms\tremaining: 16.1s\n",
      "8:\tlearn: 0.7293294\ttotal: 747ms\tremaining: 15.8s\n",
      "9:\tlearn: 0.6921629\ttotal: 842ms\tremaining: 16s\n",
      "10:\tlearn: 0.6620651\ttotal: 933ms\tremaining: 16s\n",
      "11:\tlearn: 0.6408625\ttotal: 1.02s\tremaining: 16s\n",
      "12:\tlearn: 0.6257649\ttotal: 1.1s\tremaining: 15.8s\n",
      "13:\tlearn: 0.6142029\ttotal: 1.18s\tremaining: 15.7s\n",
      "14:\tlearn: 0.6019845\ttotal: 1.26s\tremaining: 15.5s\n",
      "15:\tlearn: 0.5943024\ttotal: 1.33s\tremaining: 15.3s\n",
      "16:\tlearn: 0.5810199\ttotal: 1.41s\tremaining: 15.2s\n",
      "17:\tlearn: 0.5745064\ttotal: 1.49s\tremaining: 15s\n",
      "18:\tlearn: 0.5639842\ttotal: 1.57s\tremaining: 14.9s\n",
      "19:\tlearn: 0.5574174\ttotal: 1.64s\tremaining: 14.7s\n",
      "20:\tlearn: 0.5497371\ttotal: 1.73s\tremaining: 14.7s\n",
      "21:\tlearn: 0.5425708\ttotal: 1.81s\tremaining: 14.7s\n",
      "22:\tlearn: 0.5337820\ttotal: 1.9s\tremaining: 14.6s\n",
      "23:\tlearn: 0.5266947\ttotal: 1.99s\tremaining: 14.6s\n",
      "24:\tlearn: 0.5237619\ttotal: 2.06s\tremaining: 14.4s\n",
      "25:\tlearn: 0.5190033\ttotal: 2.14s\tremaining: 14.3s\n",
      "26:\tlearn: 0.5069624\ttotal: 2.23s\tremaining: 14.3s\n",
      "27:\tlearn: 0.4995519\ttotal: 2.3s\tremaining: 14.1s\n",
      "28:\tlearn: 0.4931026\ttotal: 2.38s\tremaining: 14s\n",
      "29:\tlearn: 0.4884657\ttotal: 2.46s\tremaining: 13.9s\n",
      "30:\tlearn: 0.4831926\ttotal: 2.54s\tremaining: 13.8s\n",
      "31:\tlearn: 0.4802191\ttotal: 2.61s\tremaining: 13.7s\n",
      "32:\tlearn: 0.4751489\ttotal: 2.69s\tremaining: 13.6s\n",
      "33:\tlearn: 0.4708665\ttotal: 2.77s\tremaining: 13.5s\n",
      "34:\tlearn: 0.4677607\ttotal: 2.83s\tremaining: 13.4s\n",
      "35:\tlearn: 0.4648248\ttotal: 2.89s\tremaining: 13.2s\n",
      "36:\tlearn: 0.4616323\ttotal: 2.97s\tremaining: 13.1s\n",
      "37:\tlearn: 0.4592780\ttotal: 3.04s\tremaining: 13s\n",
      "38:\tlearn: 0.4561741\ttotal: 3.12s\tremaining: 12.9s\n",
      "39:\tlearn: 0.4527649\ttotal: 3.19s\tremaining: 12.8s\n",
      "40:\tlearn: 0.4513067\ttotal: 3.25s\tremaining: 12.6s\n",
      "41:\tlearn: 0.4477085\ttotal: 3.34s\tremaining: 12.6s\n",
      "42:\tlearn: 0.4443095\ttotal: 3.42s\tremaining: 12.5s\n",
      "43:\tlearn: 0.4395263\ttotal: 3.51s\tremaining: 12.5s\n",
      "44:\tlearn: 0.4380757\ttotal: 3.57s\tremaining: 12.3s\n",
      "45:\tlearn: 0.4362752\ttotal: 3.64s\tremaining: 12.2s\n",
      "46:\tlearn: 0.4341125\ttotal: 3.71s\tremaining: 12.1s\n",
      "47:\tlearn: 0.4320587\ttotal: 3.77s\tremaining: 12s\n",
      "48:\tlearn: 0.4306897\ttotal: 3.84s\tremaining: 11.8s\n",
      "49:\tlearn: 0.4294855\ttotal: 3.9s\tremaining: 11.7s\n",
      "50:\tlearn: 0.4274904\ttotal: 3.97s\tremaining: 11.6s\n",
      "51:\tlearn: 0.4257132\ttotal: 4.04s\tremaining: 11.5s\n",
      "52:\tlearn: 0.4214884\ttotal: 4.12s\tremaining: 11.4s\n",
      "53:\tlearn: 0.4174723\ttotal: 4.22s\tremaining: 11.4s\n",
      "54:\tlearn: 0.4163801\ttotal: 4.28s\tremaining: 11.3s\n",
      "55:\tlearn: 0.4142550\ttotal: 4.36s\tremaining: 11.2s\n",
      "56:\tlearn: 0.4134076\ttotal: 4.42s\tremaining: 11.1s\n",
      "57:\tlearn: 0.4113617\ttotal: 4.49s\tremaining: 11s\n",
      "58:\tlearn: 0.4108066\ttotal: 4.55s\tremaining: 10.9s\n",
      "59:\tlearn: 0.4085016\ttotal: 4.62s\tremaining: 10.8s\n",
      "60:\tlearn: 0.4073017\ttotal: 4.68s\tremaining: 10.7s\n",
      "61:\tlearn: 0.4062390\ttotal: 4.74s\tremaining: 10.6s\n",
      "62:\tlearn: 0.4039149\ttotal: 4.82s\tremaining: 10.5s\n",
      "63:\tlearn: 0.4019155\ttotal: 4.89s\tremaining: 10.4s\n",
      "64:\tlearn: 0.4005652\ttotal: 4.96s\tremaining: 10.3s\n",
      "65:\tlearn: 0.3996807\ttotal: 5.03s\tremaining: 10.2s\n",
      "66:\tlearn: 0.3972966\ttotal: 5.1s\tremaining: 10.1s\n",
      "67:\tlearn: 0.3953121\ttotal: 5.17s\tremaining: 10s\n",
      "68:\tlearn: 0.3934742\ttotal: 5.24s\tremaining: 9.94s\n",
      "69:\tlearn: 0.3923550\ttotal: 5.31s\tremaining: 9.86s\n",
      "70:\tlearn: 0.3909220\ttotal: 5.38s\tremaining: 9.78s\n",
      "71:\tlearn: 0.3903483\ttotal: 5.44s\tremaining: 9.67s\n",
      "72:\tlearn: 0.3871856\ttotal: 5.54s\tremaining: 9.64s\n",
      "73:\tlearn: 0.3856429\ttotal: 5.61s\tremaining: 9.56s\n",
      "74:\tlearn: 0.3840158\ttotal: 5.68s\tremaining: 9.48s\n",
      "75:\tlearn: 0.3810120\ttotal: 5.78s\tremaining: 9.43s\n",
      "76:\tlearn: 0.3795487\ttotal: 5.85s\tremaining: 9.34s\n",
      "77:\tlearn: 0.3783966\ttotal: 5.91s\tremaining: 9.24s\n",
      "78:\tlearn: 0.3760602\ttotal: 5.99s\tremaining: 9.17s\n",
      "79:\tlearn: 0.3749928\ttotal: 6.07s\tremaining: 9.1s\n",
      "80:\tlearn: 0.3733500\ttotal: 6.13s\tremaining: 9.01s\n",
      "81:\tlearn: 0.3725951\ttotal: 6.2s\tremaining: 8.92s\n",
      "82:\tlearn: 0.3706516\ttotal: 6.28s\tremaining: 8.85s\n",
      "83:\tlearn: 0.3697940\ttotal: 6.34s\tremaining: 8.76s\n",
      "84:\tlearn: 0.3683332\ttotal: 6.42s\tremaining: 8.68s\n",
      "85:\tlearn: 0.3676896\ttotal: 6.49s\tremaining: 8.6s\n",
      "86:\tlearn: 0.3663464\ttotal: 6.57s\tremaining: 8.53s\n",
      "87:\tlearn: 0.3647272\ttotal: 6.65s\tremaining: 8.47s\n",
      "88:\tlearn: 0.3630142\ttotal: 6.74s\tremaining: 8.4s\n",
      "89:\tlearn: 0.3623167\ttotal: 6.8s\tremaining: 8.31s\n",
      "90:\tlearn: 0.3619433\ttotal: 6.86s\tremaining: 8.22s\n",
      "91:\tlearn: 0.3613805\ttotal: 6.92s\tremaining: 8.13s\n",
      "92:\tlearn: 0.3605591\ttotal: 6.99s\tremaining: 8.04s\n",
      "93:\tlearn: 0.3591521\ttotal: 7.07s\tremaining: 7.97s\n",
      "94:\tlearn: 0.3584714\ttotal: 7.13s\tremaining: 7.88s\n",
      "95:\tlearn: 0.3567881\ttotal: 7.23s\tremaining: 7.83s\n",
      "96:\tlearn: 0.3551175\ttotal: 7.29s\tremaining: 7.75s\n",
      "97:\tlearn: 0.3542241\ttotal: 7.37s\tremaining: 7.67s\n",
      "98:\tlearn: 0.3530303\ttotal: 7.45s\tremaining: 7.6s\n",
      "99:\tlearn: 0.3524106\ttotal: 7.51s\tremaining: 7.51s\n",
      "100:\tlearn: 0.3507782\ttotal: 7.6s\tremaining: 7.45s\n",
      "101:\tlearn: 0.3490622\ttotal: 7.68s\tremaining: 7.38s\n",
      "102:\tlearn: 0.3476472\ttotal: 7.76s\tremaining: 7.31s\n",
      "103:\tlearn: 0.3473553\ttotal: 7.82s\tremaining: 7.22s\n",
      "104:\tlearn: 0.3459835\ttotal: 7.89s\tremaining: 7.14s\n",
      "105:\tlearn: 0.3449514\ttotal: 7.96s\tremaining: 7.06s\n",
      "106:\tlearn: 0.3436669\ttotal: 8.03s\tremaining: 6.98s\n",
      "107:\tlearn: 0.3426542\ttotal: 8.1s\tremaining: 6.89s\n",
      "108:\tlearn: 0.3422492\ttotal: 8.15s\tremaining: 6.81s\n",
      "109:\tlearn: 0.3417941\ttotal: 8.21s\tremaining: 6.72s\n",
      "110:\tlearn: 0.3413782\ttotal: 8.27s\tremaining: 6.63s\n",
      "111:\tlearn: 0.3406302\ttotal: 8.34s\tremaining: 6.55s\n",
      "112:\tlearn: 0.3403359\ttotal: 8.39s\tremaining: 6.46s\n",
      "113:\tlearn: 0.3385819\ttotal: 8.48s\tremaining: 6.4s\n",
      "114:\tlearn: 0.3376021\ttotal: 8.55s\tremaining: 6.32s\n",
      "115:\tlearn: 0.3360857\ttotal: 8.63s\tremaining: 6.25s\n",
      "116:\tlearn: 0.3356839\ttotal: 8.69s\tremaining: 6.16s\n",
      "117:\tlearn: 0.3343383\ttotal: 8.76s\tremaining: 6.09s\n",
      "118:\tlearn: 0.3330978\ttotal: 8.85s\tremaining: 6.02s\n",
      "119:\tlearn: 0.3325695\ttotal: 8.91s\tremaining: 5.94s\n",
      "120:\tlearn: 0.3315191\ttotal: 8.98s\tremaining: 5.86s\n",
      "121:\tlearn: 0.3304235\ttotal: 9.06s\tremaining: 5.79s\n",
      "122:\tlearn: 0.3294511\ttotal: 9.13s\tremaining: 5.72s\n",
      "123:\tlearn: 0.3283675\ttotal: 9.21s\tremaining: 5.65s\n",
      "124:\tlearn: 0.3274505\ttotal: 9.28s\tremaining: 5.57s\n",
      "125:\tlearn: 0.3266395\ttotal: 9.35s\tremaining: 5.49s\n",
      "126:\tlearn: 0.3256204\ttotal: 9.42s\tremaining: 5.42s\n",
      "127:\tlearn: 0.3251875\ttotal: 9.49s\tremaining: 5.34s\n",
      "128:\tlearn: 0.3248408\ttotal: 9.55s\tremaining: 5.26s\n",
      "129:\tlearn: 0.3240183\ttotal: 9.64s\tremaining: 5.19s\n",
      "130:\tlearn: 0.3235424\ttotal: 9.7s\tremaining: 5.11s\n",
      "131:\tlearn: 0.3229461\ttotal: 9.76s\tremaining: 5.03s\n",
      "132:\tlearn: 0.3219331\ttotal: 9.85s\tremaining: 4.96s\n",
      "133:\tlearn: 0.3211841\ttotal: 9.91s\tremaining: 4.88s\n",
      "134:\tlearn: 0.3206073\ttotal: 9.98s\tremaining: 4.8s\n",
      "135:\tlearn: 0.3196423\ttotal: 10.1s\tremaining: 4.73s\n",
      "136:\tlearn: 0.3189613\ttotal: 10.1s\tremaining: 4.66s\n",
      "137:\tlearn: 0.3181618\ttotal: 10.2s\tremaining: 4.58s\n",
      "138:\tlearn: 0.3176328\ttotal: 10.3s\tremaining: 4.51s\n",
      "139:\tlearn: 0.3170670\ttotal: 10.4s\tremaining: 4.44s\n",
      "140:\tlearn: 0.3164153\ttotal: 10.4s\tremaining: 4.37s\n",
      "141:\tlearn: 0.3151536\ttotal: 10.5s\tremaining: 4.29s\n",
      "142:\tlearn: 0.3138493\ttotal: 10.6s\tremaining: 4.22s\n",
      "143:\tlearn: 0.3127964\ttotal: 10.7s\tremaining: 4.15s\n",
      "144:\tlearn: 0.3118311\ttotal: 10.7s\tremaining: 4.07s\n",
      "145:\tlearn: 0.3110454\ttotal: 10.8s\tremaining: 4s\n",
      "146:\tlearn: 0.3099757\ttotal: 10.9s\tremaining: 3.92s\n",
      "147:\tlearn: 0.3091240\ttotal: 11s\tremaining: 3.85s\n",
      "148:\tlearn: 0.3088328\ttotal: 11s\tremaining: 3.77s\n",
      "149:\tlearn: 0.3084724\ttotal: 11.1s\tremaining: 3.69s\n",
      "150:\tlearn: 0.3080394\ttotal: 11.1s\tremaining: 3.61s\n",
      "151:\tlearn: 0.3075786\ttotal: 11.2s\tremaining: 3.53s\n",
      "152:\tlearn: 0.3071063\ttotal: 11.3s\tremaining: 3.46s\n",
      "153:\tlearn: 0.3064452\ttotal: 11.3s\tremaining: 3.38s\n",
      "154:\tlearn: 0.3062368\ttotal: 11.4s\tremaining: 3.3s\n",
      "155:\tlearn: 0.3050954\ttotal: 11.5s\tremaining: 3.23s\n",
      "156:\tlearn: 0.3041750\ttotal: 11.5s\tremaining: 3.16s\n",
      "157:\tlearn: 0.3033892\ttotal: 11.6s\tremaining: 3.08s\n",
      "158:\tlearn: 0.3024921\ttotal: 11.7s\tremaining: 3.01s\n",
      "159:\tlearn: 0.3014221\ttotal: 11.7s\tremaining: 2.94s\n",
      "160:\tlearn: 0.3006242\ttotal: 11.8s\tremaining: 2.86s\n",
      "161:\tlearn: 0.3002408\ttotal: 11.9s\tremaining: 2.78s\n",
      "162:\tlearn: 0.2994598\ttotal: 11.9s\tremaining: 2.71s\n",
      "163:\tlearn: 0.2989674\ttotal: 12s\tremaining: 2.63s\n",
      "164:\tlearn: 0.2984704\ttotal: 12.1s\tremaining: 2.56s\n",
      "165:\tlearn: 0.2980125\ttotal: 12.1s\tremaining: 2.48s\n",
      "166:\tlearn: 0.2968159\ttotal: 12.2s\tremaining: 2.41s\n",
      "167:\tlearn: 0.2964903\ttotal: 12.3s\tremaining: 2.33s\n",
      "168:\tlearn: 0.2950450\ttotal: 12.3s\tremaining: 2.26s\n",
      "169:\tlearn: 0.2944771\ttotal: 12.4s\tremaining: 2.19s\n",
      "170:\tlearn: 0.2937457\ttotal: 12.5s\tremaining: 2.12s\n",
      "171:\tlearn: 0.2930703\ttotal: 12.6s\tremaining: 2.04s\n",
      "172:\tlearn: 0.2928492\ttotal: 12.6s\tremaining: 1.97s\n",
      "173:\tlearn: 0.2920472\ttotal: 12.7s\tremaining: 1.9s\n",
      "174:\tlearn: 0.2912526\ttotal: 12.8s\tremaining: 1.82s\n",
      "175:\tlearn: 0.2901043\ttotal: 12.8s\tremaining: 1.75s\n",
      "176:\tlearn: 0.2895466\ttotal: 12.9s\tremaining: 1.68s\n",
      "177:\tlearn: 0.2887947\ttotal: 13s\tremaining: 1.6s\n",
      "178:\tlearn: 0.2881933\ttotal: 13.1s\tremaining: 1.53s\n",
      "179:\tlearn: 0.2873189\ttotal: 13.1s\tremaining: 1.46s\n",
      "180:\tlearn: 0.2863697\ttotal: 13.2s\tremaining: 1.39s\n",
      "181:\tlearn: 0.2859598\ttotal: 13.3s\tremaining: 1.31s\n",
      "182:\tlearn: 0.2854346\ttotal: 13.3s\tremaining: 1.24s\n",
      "183:\tlearn: 0.2846353\ttotal: 13.4s\tremaining: 1.17s\n",
      "184:\tlearn: 0.2840024\ttotal: 13.5s\tremaining: 1.09s\n",
      "185:\tlearn: 0.2833388\ttotal: 13.6s\tremaining: 1.02s\n",
      "186:\tlearn: 0.2827500\ttotal: 13.6s\tremaining: 947ms\n",
      "187:\tlearn: 0.2821906\ttotal: 13.7s\tremaining: 874ms\n",
      "188:\tlearn: 0.2817216\ttotal: 13.8s\tremaining: 801ms\n",
      "189:\tlearn: 0.2810585\ttotal: 13.8s\tremaining: 728ms\n",
      "190:\tlearn: 0.2805880\ttotal: 13.9s\tremaining: 654ms\n",
      "191:\tlearn: 0.2798183\ttotal: 14s\tremaining: 583ms\n",
      "192:\tlearn: 0.2791645\ttotal: 14.1s\tremaining: 510ms\n",
      "193:\tlearn: 0.2785671\ttotal: 14.2s\tremaining: 438ms\n",
      "194:\tlearn: 0.2778484\ttotal: 14.2s\tremaining: 365ms\n",
      "195:\tlearn: 0.2771363\ttotal: 14.3s\tremaining: 292ms\n",
      "196:\tlearn: 0.2761592\ttotal: 14.4s\tremaining: 219ms\n",
      "197:\tlearn: 0.2752440\ttotal: 14.4s\tremaining: 146ms\n",
      "198:\tlearn: 0.2748796\ttotal: 14.5s\tremaining: 72.8ms\n",
      "199:\tlearn: 0.2743096\ttotal: 14.6s\tremaining: 0us\n",
      "0:\tlearn: 1.4859815\ttotal: 88.3ms\tremaining: 17.6s\n",
      "1:\tlearn: 1.2176614\ttotal: 152ms\tremaining: 15.1s\n",
      "2:\tlearn: 1.0582276\ttotal: 237ms\tremaining: 15.5s\n",
      "3:\tlearn: 0.9526077\ttotal: 331ms\tremaining: 16.2s\n",
      "4:\tlearn: 0.8951146\ttotal: 415ms\tremaining: 16.2s\n",
      "5:\tlearn: 0.8491664\ttotal: 499ms\tremaining: 16.1s\n",
      "6:\tlearn: 0.7857463\ttotal: 591ms\tremaining: 16.3s\n",
      "7:\tlearn: 0.7441137\ttotal: 673ms\tremaining: 16.2s\n",
      "8:\tlearn: 0.7092327\ttotal: 764ms\tremaining: 16.2s\n",
      "9:\tlearn: 0.6835149\ttotal: 849ms\tremaining: 16.1s\n",
      "10:\tlearn: 0.6589470\ttotal: 924ms\tremaining: 15.9s\n",
      "11:\tlearn: 0.6448432\ttotal: 1s\tremaining: 15.7s\n",
      "12:\tlearn: 0.6294034\ttotal: 1.08s\tremaining: 15.5s\n",
      "13:\tlearn: 0.6155853\ttotal: 1.16s\tremaining: 15.4s\n",
      "14:\tlearn: 0.6034235\ttotal: 1.24s\tremaining: 15.3s\n",
      "15:\tlearn: 0.5910996\ttotal: 1.32s\tremaining: 15.2s\n",
      "16:\tlearn: 0.5806671\ttotal: 1.4s\tremaining: 15.1s\n",
      "17:\tlearn: 0.5714467\ttotal: 1.48s\tremaining: 15s\n",
      "18:\tlearn: 0.5585376\ttotal: 1.56s\tremaining: 14.9s\n",
      "19:\tlearn: 0.5527907\ttotal: 1.63s\tremaining: 14.7s\n",
      "20:\tlearn: 0.5475708\ttotal: 1.71s\tremaining: 14.6s\n",
      "21:\tlearn: 0.5379247\ttotal: 1.8s\tremaining: 14.6s\n",
      "22:\tlearn: 0.5324436\ttotal: 1.87s\tremaining: 14.4s\n",
      "23:\tlearn: 0.5261746\ttotal: 1.93s\tremaining: 14.2s\n",
      "24:\tlearn: 0.5202973\ttotal: 2.01s\tremaining: 14.1s\n",
      "25:\tlearn: 0.5148082\ttotal: 2.08s\tremaining: 13.9s\n",
      "26:\tlearn: 0.5122796\ttotal: 2.14s\tremaining: 13.7s\n",
      "27:\tlearn: 0.5075930\ttotal: 2.23s\tremaining: 13.7s\n",
      "28:\tlearn: 0.5005131\ttotal: 2.31s\tremaining: 13.7s\n",
      "29:\tlearn: 0.4968232\ttotal: 2.4s\tremaining: 13.6s\n",
      "30:\tlearn: 0.4908081\ttotal: 2.48s\tremaining: 13.5s\n",
      "31:\tlearn: 0.4865722\ttotal: 2.55s\tremaining: 13.4s\n",
      "32:\tlearn: 0.4816390\ttotal: 2.62s\tremaining: 13.3s\n",
      "33:\tlearn: 0.4773866\ttotal: 2.69s\tremaining: 13.1s\n",
      "34:\tlearn: 0.4726524\ttotal: 2.75s\tremaining: 13s\n",
      "35:\tlearn: 0.4695806\ttotal: 2.82s\tremaining: 12.8s\n",
      "36:\tlearn: 0.4632039\ttotal: 2.91s\tremaining: 12.8s\n",
      "37:\tlearn: 0.4605342\ttotal: 2.99s\tremaining: 12.7s\n",
      "38:\tlearn: 0.4557980\ttotal: 3.07s\tremaining: 12.7s\n",
      "39:\tlearn: 0.4505694\ttotal: 3.15s\tremaining: 12.6s\n",
      "40:\tlearn: 0.4489074\ttotal: 3.22s\tremaining: 12.5s\n",
      "41:\tlearn: 0.4477119\ttotal: 3.28s\tremaining: 12.3s\n",
      "42:\tlearn: 0.4435602\ttotal: 3.35s\tremaining: 12.3s\n",
      "43:\tlearn: 0.4412110\ttotal: 3.43s\tremaining: 12.2s\n",
      "44:\tlearn: 0.4377220\ttotal: 3.51s\tremaining: 12.1s\n",
      "45:\tlearn: 0.4348937\ttotal: 3.59s\tremaining: 12s\n",
      "46:\tlearn: 0.4328495\ttotal: 3.66s\tremaining: 11.9s\n",
      "47:\tlearn: 0.4304757\ttotal: 3.73s\tremaining: 11.8s\n",
      "48:\tlearn: 0.4284822\ttotal: 3.8s\tremaining: 11.7s\n",
      "49:\tlearn: 0.4270062\ttotal: 3.86s\tremaining: 11.6s\n",
      "50:\tlearn: 0.4232900\ttotal: 3.93s\tremaining: 11.5s\n",
      "51:\tlearn: 0.4215509\ttotal: 3.99s\tremaining: 11.4s\n",
      "52:\tlearn: 0.4182100\ttotal: 4.07s\tremaining: 11.3s\n",
      "53:\tlearn: 0.4169422\ttotal: 4.13s\tremaining: 11.2s\n",
      "54:\tlearn: 0.4150295\ttotal: 4.2s\tremaining: 11.1s\n",
      "55:\tlearn: 0.4132789\ttotal: 4.26s\tremaining: 11s\n",
      "56:\tlearn: 0.4122254\ttotal: 4.32s\tremaining: 10.8s\n",
      "57:\tlearn: 0.4098072\ttotal: 4.41s\tremaining: 10.8s\n",
      "58:\tlearn: 0.4085210\ttotal: 4.46s\tremaining: 10.7s\n",
      "59:\tlearn: 0.4067656\ttotal: 4.55s\tremaining: 10.6s\n",
      "60:\tlearn: 0.4046218\ttotal: 4.64s\tremaining: 10.6s\n",
      "61:\tlearn: 0.4033299\ttotal: 4.7s\tremaining: 10.5s\n",
      "62:\tlearn: 0.4004702\ttotal: 4.78s\tremaining: 10.4s\n",
      "63:\tlearn: 0.3985317\ttotal: 4.85s\tremaining: 10.3s\n",
      "64:\tlearn: 0.3978064\ttotal: 4.92s\tremaining: 10.2s\n",
      "65:\tlearn: 0.3961136\ttotal: 4.98s\tremaining: 10.1s\n",
      "66:\tlearn: 0.3949128\ttotal: 5.05s\tremaining: 10s\n",
      "67:\tlearn: 0.3937287\ttotal: 5.12s\tremaining: 9.93s\n",
      "68:\tlearn: 0.3920779\ttotal: 5.19s\tremaining: 9.86s\n",
      "69:\tlearn: 0.3910104\ttotal: 5.26s\tremaining: 9.77s\n",
      "70:\tlearn: 0.3891036\ttotal: 5.34s\tremaining: 9.7s\n",
      "71:\tlearn: 0.3876099\ttotal: 5.4s\tremaining: 9.6s\n",
      "72:\tlearn: 0.3847370\ttotal: 5.49s\tremaining: 9.55s\n",
      "73:\tlearn: 0.3837370\ttotal: 5.55s\tremaining: 9.45s\n",
      "74:\tlearn: 0.3828301\ttotal: 5.61s\tremaining: 9.35s\n",
      "75:\tlearn: 0.3797198\ttotal: 5.69s\tremaining: 9.29s\n",
      "76:\tlearn: 0.3784738\ttotal: 5.76s\tremaining: 9.2s\n",
      "77:\tlearn: 0.3776456\ttotal: 5.83s\tremaining: 9.12s\n",
      "78:\tlearn: 0.3763202\ttotal: 5.9s\tremaining: 9.04s\n",
      "79:\tlearn: 0.3754699\ttotal: 5.97s\tremaining: 8.96s\n",
      "80:\tlearn: 0.3748298\ttotal: 6.03s\tremaining: 8.86s\n",
      "81:\tlearn: 0.3731780\ttotal: 6.11s\tremaining: 8.79s\n",
      "82:\tlearn: 0.3721084\ttotal: 6.21s\tremaining: 8.75s\n",
      "83:\tlearn: 0.3711244\ttotal: 6.27s\tremaining: 8.66s\n",
      "84:\tlearn: 0.3698381\ttotal: 6.34s\tremaining: 8.58s\n",
      "85:\tlearn: 0.3684900\ttotal: 6.41s\tremaining: 8.49s\n",
      "86:\tlearn: 0.3671153\ttotal: 6.48s\tremaining: 8.41s\n",
      "87:\tlearn: 0.3650246\ttotal: 6.56s\tremaining: 8.35s\n",
      "88:\tlearn: 0.3645133\ttotal: 6.63s\tremaining: 8.27s\n",
      "89:\tlearn: 0.3630552\ttotal: 6.71s\tremaining: 8.2s\n",
      "90:\tlearn: 0.3623580\ttotal: 6.77s\tremaining: 8.11s\n",
      "91:\tlearn: 0.3615709\ttotal: 6.83s\tremaining: 8.02s\n",
      "92:\tlearn: 0.3596388\ttotal: 6.91s\tremaining: 7.95s\n",
      "93:\tlearn: 0.3588449\ttotal: 6.98s\tremaining: 7.88s\n",
      "94:\tlearn: 0.3583695\ttotal: 7.04s\tremaining: 7.78s\n",
      "95:\tlearn: 0.3566998\ttotal: 7.13s\tremaining: 7.72s\n",
      "96:\tlearn: 0.3558989\ttotal: 7.19s\tremaining: 7.63s\n",
      "97:\tlearn: 0.3548867\ttotal: 7.26s\tremaining: 7.55s\n",
      "98:\tlearn: 0.3541446\ttotal: 7.32s\tremaining: 7.46s\n",
      "99:\tlearn: 0.3535313\ttotal: 7.38s\tremaining: 7.38s\n",
      "100:\tlearn: 0.3521270\ttotal: 7.45s\tremaining: 7.3s\n",
      "101:\tlearn: 0.3505918\ttotal: 7.53s\tremaining: 7.24s\n",
      "102:\tlearn: 0.3498171\ttotal: 7.59s\tremaining: 7.15s\n",
      "103:\tlearn: 0.3490117\ttotal: 7.66s\tremaining: 7.07s\n",
      "104:\tlearn: 0.3488045\ttotal: 7.72s\tremaining: 6.99s\n",
      "105:\tlearn: 0.3464732\ttotal: 7.8s\tremaining: 6.92s\n",
      "106:\tlearn: 0.3459250\ttotal: 7.86s\tremaining: 6.83s\n",
      "107:\tlearn: 0.3451223\ttotal: 7.93s\tremaining: 6.75s\n",
      "108:\tlearn: 0.3443163\ttotal: 7.99s\tremaining: 6.67s\n",
      "109:\tlearn: 0.3435041\ttotal: 8.06s\tremaining: 6.59s\n",
      "110:\tlearn: 0.3428533\ttotal: 8.13s\tremaining: 6.52s\n",
      "111:\tlearn: 0.3419604\ttotal: 8.2s\tremaining: 6.44s\n",
      "112:\tlearn: 0.3406428\ttotal: 8.26s\tremaining: 6.36s\n",
      "113:\tlearn: 0.3398411\ttotal: 8.34s\tremaining: 6.29s\n",
      "114:\tlearn: 0.3394199\ttotal: 8.4s\tremaining: 6.21s\n",
      "115:\tlearn: 0.3386586\ttotal: 8.46s\tremaining: 6.13s\n",
      "116:\tlearn: 0.3383283\ttotal: 8.52s\tremaining: 6.04s\n",
      "117:\tlearn: 0.3372965\ttotal: 8.6s\tremaining: 5.98s\n",
      "118:\tlearn: 0.3361848\ttotal: 8.67s\tremaining: 5.9s\n",
      "119:\tlearn: 0.3355776\ttotal: 8.74s\tremaining: 5.83s\n",
      "120:\tlearn: 0.3347330\ttotal: 8.83s\tremaining: 5.76s\n",
      "121:\tlearn: 0.3333456\ttotal: 8.9s\tremaining: 5.69s\n",
      "122:\tlearn: 0.3320373\ttotal: 8.97s\tremaining: 5.62s\n",
      "123:\tlearn: 0.3311572\ttotal: 9.04s\tremaining: 5.54s\n",
      "124:\tlearn: 0.3300471\ttotal: 9.11s\tremaining: 5.47s\n",
      "125:\tlearn: 0.3295000\ttotal: 9.17s\tremaining: 5.39s\n",
      "126:\tlearn: 0.3288872\ttotal: 9.24s\tremaining: 5.31s\n",
      "127:\tlearn: 0.3279421\ttotal: 9.32s\tremaining: 5.24s\n",
      "128:\tlearn: 0.3271748\ttotal: 9.4s\tremaining: 5.17s\n",
      "129:\tlearn: 0.3258205\ttotal: 9.48s\tremaining: 5.11s\n",
      "130:\tlearn: 0.3246031\ttotal: 9.57s\tremaining: 5.04s\n",
      "131:\tlearn: 0.3243588\ttotal: 9.63s\tremaining: 4.96s\n",
      "132:\tlearn: 0.3236361\ttotal: 9.7s\tremaining: 4.89s\n",
      "133:\tlearn: 0.3230938\ttotal: 9.77s\tremaining: 4.81s\n",
      "134:\tlearn: 0.3224452\ttotal: 9.83s\tremaining: 4.73s\n",
      "135:\tlearn: 0.3217724\ttotal: 9.9s\tremaining: 4.66s\n",
      "136:\tlearn: 0.3214826\ttotal: 9.96s\tremaining: 4.58s\n",
      "137:\tlearn: 0.3206632\ttotal: 10s\tremaining: 4.5s\n",
      "138:\tlearn: 0.3199954\ttotal: 10.1s\tremaining: 4.43s\n",
      "139:\tlearn: 0.3193347\ttotal: 10.1s\tremaining: 4.35s\n",
      "140:\tlearn: 0.3185499\ttotal: 10.2s\tremaining: 4.28s\n",
      "141:\tlearn: 0.3178801\ttotal: 10.3s\tremaining: 4.21s\n",
      "142:\tlearn: 0.3159814\ttotal: 10.4s\tremaining: 4.14s\n",
      "143:\tlearn: 0.3153204\ttotal: 10.4s\tremaining: 4.06s\n",
      "144:\tlearn: 0.3147471\ttotal: 10.5s\tremaining: 3.98s\n",
      "145:\tlearn: 0.3124097\ttotal: 10.6s\tremaining: 3.92s\n",
      "146:\tlearn: 0.3119251\ttotal: 10.7s\tremaining: 3.85s\n",
      "147:\tlearn: 0.3111275\ttotal: 10.7s\tremaining: 3.77s\n",
      "148:\tlearn: 0.3103541\ttotal: 10.8s\tremaining: 3.7s\n",
      "149:\tlearn: 0.3093033\ttotal: 10.9s\tremaining: 3.63s\n",
      "150:\tlearn: 0.3076539\ttotal: 11s\tremaining: 3.56s\n",
      "151:\tlearn: 0.3069557\ttotal: 11s\tremaining: 3.48s\n",
      "152:\tlearn: 0.3060438\ttotal: 11.1s\tremaining: 3.41s\n",
      "153:\tlearn: 0.3051667\ttotal: 11.2s\tremaining: 3.34s\n",
      "154:\tlearn: 0.3049629\ttotal: 11.3s\tremaining: 3.27s\n",
      "155:\tlearn: 0.3037019\ttotal: 11.3s\tremaining: 3.19s\n",
      "156:\tlearn: 0.3031688\ttotal: 11.4s\tremaining: 3.12s\n",
      "157:\tlearn: 0.3020677\ttotal: 11.5s\tremaining: 3.05s\n",
      "158:\tlearn: 0.3016193\ttotal: 11.6s\tremaining: 2.98s\n",
      "159:\tlearn: 0.3008867\ttotal: 11.6s\tremaining: 2.91s\n",
      "160:\tlearn: 0.3004711\ttotal: 11.7s\tremaining: 2.83s\n",
      "161:\tlearn: 0.3002246\ttotal: 11.7s\tremaining: 2.75s\n",
      "162:\tlearn: 0.2998629\ttotal: 11.8s\tremaining: 2.68s\n",
      "163:\tlearn: 0.2991237\ttotal: 11.9s\tremaining: 2.61s\n",
      "164:\tlearn: 0.2978053\ttotal: 12s\tremaining: 2.54s\n",
      "165:\tlearn: 0.2972333\ttotal: 12s\tremaining: 2.46s\n",
      "166:\tlearn: 0.2961853\ttotal: 12.1s\tremaining: 2.39s\n",
      "167:\tlearn: 0.2951295\ttotal: 12.2s\tremaining: 2.32s\n",
      "168:\tlearn: 0.2946726\ttotal: 12.3s\tremaining: 2.25s\n",
      "169:\tlearn: 0.2941472\ttotal: 12.3s\tremaining: 2.17s\n",
      "170:\tlearn: 0.2931882\ttotal: 12.4s\tremaining: 2.1s\n",
      "171:\tlearn: 0.2929311\ttotal: 12.4s\tremaining: 2.03s\n",
      "172:\tlearn: 0.2925483\ttotal: 12.5s\tremaining: 1.95s\n",
      "173:\tlearn: 0.2919050\ttotal: 12.6s\tremaining: 1.88s\n",
      "174:\tlearn: 0.2915566\ttotal: 12.6s\tremaining: 1.8s\n",
      "175:\tlearn: 0.2906357\ttotal: 12.7s\tremaining: 1.73s\n",
      "176:\tlearn: 0.2901971\ttotal: 12.8s\tremaining: 1.66s\n",
      "177:\tlearn: 0.2893559\ttotal: 12.9s\tremaining: 1.59s\n",
      "178:\tlearn: 0.2889839\ttotal: 12.9s\tremaining: 1.51s\n",
      "179:\tlearn: 0.2877580\ttotal: 13s\tremaining: 1.44s\n",
      "180:\tlearn: 0.2873548\ttotal: 13.1s\tremaining: 1.37s\n",
      "181:\tlearn: 0.2867741\ttotal: 13.1s\tremaining: 1.3s\n",
      "182:\tlearn: 0.2860735\ttotal: 13.2s\tremaining: 1.23s\n",
      "183:\tlearn: 0.2855628\ttotal: 13.3s\tremaining: 1.15s\n",
      "184:\tlearn: 0.2849040\ttotal: 13.4s\tremaining: 1.08s\n",
      "185:\tlearn: 0.2839775\ttotal: 13.4s\tremaining: 1.01s\n",
      "186:\tlearn: 0.2835651\ttotal: 13.5s\tremaining: 939ms\n",
      "187:\tlearn: 0.2824336\ttotal: 13.6s\tremaining: 866ms\n",
      "188:\tlearn: 0.2813556\ttotal: 13.6s\tremaining: 794ms\n",
      "189:\tlearn: 0.2801056\ttotal: 13.7s\tremaining: 722ms\n",
      "190:\tlearn: 0.2792334\ttotal: 13.8s\tremaining: 650ms\n",
      "191:\tlearn: 0.2789576\ttotal: 13.9s\tremaining: 577ms\n",
      "192:\tlearn: 0.2781441\ttotal: 13.9s\tremaining: 505ms\n",
      "193:\tlearn: 0.2774318\ttotal: 14s\tremaining: 433ms\n",
      "194:\tlearn: 0.2766288\ttotal: 14.1s\tremaining: 361ms\n",
      "195:\tlearn: 0.2760540\ttotal: 14.1s\tremaining: 289ms\n",
      "196:\tlearn: 0.2755890\ttotal: 14.2s\tremaining: 216ms\n",
      "197:\tlearn: 0.2749118\ttotal: 14.3s\tremaining: 144ms\n",
      "198:\tlearn: 0.2743971\ttotal: 14.3s\tremaining: 72ms\n",
      "199:\tlearn: 0.2738146\ttotal: 14.4s\tremaining: 0us\n",
      "0:\tlearn: 1.4907512\ttotal: 86.7ms\tremaining: 17.3s\n",
      "1:\tlearn: 1.2237881\ttotal: 150ms\tremaining: 14.8s\n",
      "2:\tlearn: 1.0670628\ttotal: 241ms\tremaining: 15.8s\n",
      "3:\tlearn: 0.9617266\ttotal: 330ms\tremaining: 16.2s\n",
      "4:\tlearn: 0.8981958\ttotal: 406ms\tremaining: 15.9s\n",
      "5:\tlearn: 0.8317747\ttotal: 502ms\tremaining: 16.2s\n",
      "6:\tlearn: 0.7881228\ttotal: 588ms\tremaining: 16.2s\n",
      "7:\tlearn: 0.7520878\ttotal: 671ms\tremaining: 16.1s\n",
      "8:\tlearn: 0.7235711\ttotal: 753ms\tremaining: 16s\n",
      "9:\tlearn: 0.6974600\ttotal: 838ms\tremaining: 15.9s\n",
      "10:\tlearn: 0.6723062\ttotal: 928ms\tremaining: 15.9s\n",
      "11:\tlearn: 0.6546348\ttotal: 1.01s\tremaining: 15.8s\n",
      "12:\tlearn: 0.6438483\ttotal: 1.08s\tremaining: 15.5s\n",
      "13:\tlearn: 0.6264111\ttotal: 1.18s\tremaining: 15.7s\n",
      "14:\tlearn: 0.6102708\ttotal: 1.27s\tremaining: 15.7s\n",
      "15:\tlearn: 0.5980970\ttotal: 1.34s\tremaining: 15.5s\n",
      "16:\tlearn: 0.5837638\ttotal: 1.43s\tremaining: 15.4s\n",
      "17:\tlearn: 0.5779625\ttotal: 1.5s\tremaining: 15.2s\n",
      "18:\tlearn: 0.5675015\ttotal: 1.6s\tremaining: 15.3s\n",
      "19:\tlearn: 0.5581601\ttotal: 1.68s\tremaining: 15.1s\n",
      "20:\tlearn: 0.5510124\ttotal: 1.76s\tremaining: 15s\n",
      "21:\tlearn: 0.5433212\ttotal: 1.84s\tremaining: 14.9s\n",
      "22:\tlearn: 0.5270742\ttotal: 1.93s\tremaining: 14.8s\n",
      "23:\tlearn: 0.5193950\ttotal: 2.01s\tremaining: 14.8s\n",
      "24:\tlearn: 0.5132939\ttotal: 2.09s\tremaining: 14.6s\n",
      "25:\tlearn: 0.5058294\ttotal: 2.17s\tremaining: 14.5s\n",
      "26:\tlearn: 0.5022085\ttotal: 2.23s\tremaining: 14.3s\n",
      "27:\tlearn: 0.4993424\ttotal: 2.3s\tremaining: 14.2s\n",
      "28:\tlearn: 0.4950145\ttotal: 2.39s\tremaining: 14.1s\n",
      "29:\tlearn: 0.4911516\ttotal: 2.46s\tremaining: 14s\n",
      "30:\tlearn: 0.4871259\ttotal: 2.54s\tremaining: 13.8s\n",
      "31:\tlearn: 0.4829130\ttotal: 2.62s\tremaining: 13.7s\n",
      "32:\tlearn: 0.4767003\ttotal: 2.69s\tremaining: 13.6s\n",
      "33:\tlearn: 0.4723086\ttotal: 2.79s\tremaining: 13.6s\n",
      "34:\tlearn: 0.4694545\ttotal: 2.86s\tremaining: 13.5s\n",
      "35:\tlearn: 0.4647552\ttotal: 2.93s\tremaining: 13.4s\n",
      "36:\tlearn: 0.4610493\ttotal: 3.02s\tremaining: 13.3s\n",
      "37:\tlearn: 0.4582854\ttotal: 3.09s\tremaining: 13.2s\n",
      "38:\tlearn: 0.4560894\ttotal: 3.15s\tremaining: 13s\n",
      "39:\tlearn: 0.4508372\ttotal: 3.23s\tremaining: 12.9s\n",
      "40:\tlearn: 0.4481908\ttotal: 3.3s\tremaining: 12.8s\n",
      "41:\tlearn: 0.4447618\ttotal: 3.37s\tremaining: 12.7s\n",
      "42:\tlearn: 0.4408313\ttotal: 3.45s\tremaining: 12.6s\n",
      "43:\tlearn: 0.4391245\ttotal: 3.52s\tremaining: 12.5s\n",
      "44:\tlearn: 0.4371992\ttotal: 3.59s\tremaining: 12.4s\n",
      "45:\tlearn: 0.4359221\ttotal: 3.65s\tremaining: 12.2s\n",
      "46:\tlearn: 0.4313744\ttotal: 3.73s\tremaining: 12.1s\n",
      "47:\tlearn: 0.4273621\ttotal: 3.81s\tremaining: 12.1s\n",
      "48:\tlearn: 0.4264564\ttotal: 3.87s\tremaining: 11.9s\n",
      "49:\tlearn: 0.4242933\ttotal: 3.96s\tremaining: 11.9s\n",
      "50:\tlearn: 0.4214815\ttotal: 4.04s\tremaining: 11.8s\n",
      "51:\tlearn: 0.4198107\ttotal: 4.09s\tremaining: 11.7s\n",
      "52:\tlearn: 0.4180829\ttotal: 4.16s\tremaining: 11.5s\n",
      "53:\tlearn: 0.4159313\ttotal: 4.24s\tremaining: 11.5s\n",
      "54:\tlearn: 0.4124209\ttotal: 4.32s\tremaining: 11.4s\n",
      "55:\tlearn: 0.4104526\ttotal: 4.38s\tremaining: 11.3s\n",
      "56:\tlearn: 0.4093732\ttotal: 4.44s\tremaining: 11.1s\n",
      "57:\tlearn: 0.4081288\ttotal: 4.52s\tremaining: 11.1s\n",
      "58:\tlearn: 0.4051574\ttotal: 4.59s\tremaining: 11s\n",
      "59:\tlearn: 0.4036264\ttotal: 4.66s\tremaining: 10.9s\n",
      "60:\tlearn: 0.4009670\ttotal: 4.73s\tremaining: 10.8s\n",
      "61:\tlearn: 0.3995641\ttotal: 4.8s\tremaining: 10.7s\n",
      "62:\tlearn: 0.3980417\ttotal: 4.88s\tremaining: 10.6s\n",
      "63:\tlearn: 0.3972020\ttotal: 4.93s\tremaining: 10.5s\n",
      "64:\tlearn: 0.3957488\ttotal: 5s\tremaining: 10.4s\n",
      "65:\tlearn: 0.3942898\ttotal: 5.07s\tremaining: 10.3s\n",
      "66:\tlearn: 0.3934997\ttotal: 5.13s\tremaining: 10.2s\n",
      "67:\tlearn: 0.3928217\ttotal: 5.19s\tremaining: 10.1s\n",
      "68:\tlearn: 0.3916877\ttotal: 5.26s\tremaining: 9.98s\n",
      "69:\tlearn: 0.3905785\ttotal: 5.33s\tremaining: 9.89s\n",
      "70:\tlearn: 0.3864332\ttotal: 5.42s\tremaining: 9.84s\n",
      "71:\tlearn: 0.3852361\ttotal: 5.49s\tremaining: 9.75s\n",
      "72:\tlearn: 0.3837784\ttotal: 5.56s\tremaining: 9.68s\n",
      "73:\tlearn: 0.3816554\ttotal: 5.63s\tremaining: 9.6s\n",
      "74:\tlearn: 0.3802245\ttotal: 5.7s\tremaining: 9.5s\n",
      "75:\tlearn: 0.3791960\ttotal: 5.76s\tremaining: 9.4s\n",
      "76:\tlearn: 0.3777156\ttotal: 5.84s\tremaining: 9.33s\n",
      "77:\tlearn: 0.3770128\ttotal: 5.9s\tremaining: 9.23s\n",
      "78:\tlearn: 0.3758724\ttotal: 5.96s\tremaining: 9.12s\n",
      "79:\tlearn: 0.3754347\ttotal: 6.01s\tremaining: 9.02s\n",
      "80:\tlearn: 0.3736664\ttotal: 6.08s\tremaining: 8.94s\n",
      "81:\tlearn: 0.3724179\ttotal: 6.15s\tremaining: 8.86s\n",
      "82:\tlearn: 0.3710947\ttotal: 6.22s\tremaining: 8.77s\n",
      "83:\tlearn: 0.3703181\ttotal: 6.29s\tremaining: 8.69s\n",
      "84:\tlearn: 0.3699182\ttotal: 6.35s\tremaining: 8.59s\n",
      "85:\tlearn: 0.3690987\ttotal: 6.42s\tremaining: 8.5s\n",
      "86:\tlearn: 0.3681020\ttotal: 6.49s\tremaining: 8.44s\n",
      "87:\tlearn: 0.3670172\ttotal: 6.56s\tremaining: 8.34s\n",
      "88:\tlearn: 0.3661810\ttotal: 6.61s\tremaining: 8.25s\n",
      "89:\tlearn: 0.3655278\ttotal: 6.68s\tremaining: 8.17s\n",
      "90:\tlearn: 0.3649142\ttotal: 6.74s\tremaining: 8.08s\n",
      "91:\tlearn: 0.3638909\ttotal: 6.81s\tremaining: 8s\n",
      "92:\tlearn: 0.3631336\ttotal: 6.87s\tremaining: 7.9s\n",
      "93:\tlearn: 0.3619788\ttotal: 6.95s\tremaining: 7.84s\n",
      "94:\tlearn: 0.3601250\ttotal: 7.04s\tremaining: 7.78s\n",
      "95:\tlearn: 0.3592443\ttotal: 7.11s\tremaining: 7.71s\n",
      "96:\tlearn: 0.3572383\ttotal: 7.19s\tremaining: 7.63s\n",
      "97:\tlearn: 0.3563187\ttotal: 7.26s\tremaining: 7.56s\n",
      "98:\tlearn: 0.3552931\ttotal: 7.33s\tremaining: 7.48s\n",
      "99:\tlearn: 0.3545994\ttotal: 7.39s\tremaining: 7.39s\n",
      "100:\tlearn: 0.3540307\ttotal: 7.45s\tremaining: 7.3s\n",
      "101:\tlearn: 0.3536275\ttotal: 7.51s\tremaining: 7.21s\n",
      "102:\tlearn: 0.3524213\ttotal: 7.6s\tremaining: 7.16s\n",
      "103:\tlearn: 0.3514703\ttotal: 7.67s\tremaining: 7.08s\n",
      "104:\tlearn: 0.3506247\ttotal: 7.74s\tremaining: 7.01s\n",
      "105:\tlearn: 0.3497277\ttotal: 7.81s\tremaining: 6.93s\n",
      "106:\tlearn: 0.3482838\ttotal: 7.88s\tremaining: 6.85s\n",
      "107:\tlearn: 0.3471152\ttotal: 7.95s\tremaining: 6.77s\n",
      "108:\tlearn: 0.3464169\ttotal: 8.02s\tremaining: 6.69s\n",
      "109:\tlearn: 0.3454734\ttotal: 8.09s\tremaining: 6.62s\n",
      "110:\tlearn: 0.3446746\ttotal: 8.16s\tremaining: 6.54s\n",
      "111:\tlearn: 0.3438258\ttotal: 8.23s\tremaining: 6.46s\n",
      "112:\tlearn: 0.3427172\ttotal: 8.33s\tremaining: 6.41s\n",
      "113:\tlearn: 0.3410788\ttotal: 8.4s\tremaining: 6.34s\n",
      "114:\tlearn: 0.3404384\ttotal: 8.48s\tremaining: 6.27s\n",
      "115:\tlearn: 0.3390627\ttotal: 8.55s\tremaining: 6.19s\n",
      "116:\tlearn: 0.3387780\ttotal: 8.61s\tremaining: 6.11s\n",
      "117:\tlearn: 0.3380062\ttotal: 8.68s\tremaining: 6.03s\n",
      "118:\tlearn: 0.3366322\ttotal: 8.75s\tremaining: 5.96s\n",
      "119:\tlearn: 0.3357072\ttotal: 8.82s\tremaining: 5.88s\n",
      "120:\tlearn: 0.3347003\ttotal: 8.88s\tremaining: 5.8s\n",
      "121:\tlearn: 0.3341035\ttotal: 8.95s\tremaining: 5.72s\n",
      "122:\tlearn: 0.3334333\ttotal: 9.01s\tremaining: 5.64s\n",
      "123:\tlearn: 0.3325230\ttotal: 9.09s\tremaining: 5.57s\n",
      "124:\tlearn: 0.3317818\ttotal: 9.15s\tremaining: 5.49s\n",
      "125:\tlearn: 0.3309059\ttotal: 9.22s\tremaining: 5.42s\n",
      "126:\tlearn: 0.3293103\ttotal: 9.29s\tremaining: 5.34s\n",
      "127:\tlearn: 0.3280742\ttotal: 9.35s\tremaining: 5.26s\n",
      "128:\tlearn: 0.3271543\ttotal: 9.41s\tremaining: 5.18s\n",
      "129:\tlearn: 0.3265936\ttotal: 9.49s\tremaining: 5.11s\n",
      "130:\tlearn: 0.3257297\ttotal: 9.55s\tremaining: 5.03s\n",
      "131:\tlearn: 0.3245007\ttotal: 9.63s\tremaining: 4.96s\n",
      "132:\tlearn: 0.3236996\ttotal: 9.69s\tremaining: 4.88s\n",
      "133:\tlearn: 0.3233560\ttotal: 9.77s\tremaining: 4.81s\n",
      "134:\tlearn: 0.3230001\ttotal: 9.83s\tremaining: 4.73s\n",
      "135:\tlearn: 0.3221156\ttotal: 9.9s\tremaining: 4.66s\n",
      "136:\tlearn: 0.3211523\ttotal: 9.99s\tremaining: 4.59s\n",
      "137:\tlearn: 0.3200864\ttotal: 10.1s\tremaining: 4.52s\n",
      "138:\tlearn: 0.3190460\ttotal: 10.1s\tremaining: 4.44s\n",
      "139:\tlearn: 0.3179427\ttotal: 10.2s\tremaining: 4.37s\n",
      "140:\tlearn: 0.3172671\ttotal: 10.3s\tremaining: 4.3s\n",
      "141:\tlearn: 0.3160305\ttotal: 10.3s\tremaining: 4.22s\n",
      "142:\tlearn: 0.3150668\ttotal: 10.4s\tremaining: 4.16s\n",
      "143:\tlearn: 0.3143144\ttotal: 10.5s\tremaining: 4.08s\n",
      "144:\tlearn: 0.3134400\ttotal: 10.6s\tremaining: 4.01s\n",
      "145:\tlearn: 0.3124892\ttotal: 10.6s\tremaining: 3.94s\n",
      "146:\tlearn: 0.3115086\ttotal: 10.7s\tremaining: 3.87s\n",
      "147:\tlearn: 0.3103175\ttotal: 10.8s\tremaining: 3.79s\n",
      "148:\tlearn: 0.3083720\ttotal: 10.9s\tremaining: 3.72s\n",
      "149:\tlearn: 0.3073569\ttotal: 10.9s\tremaining: 3.65s\n",
      "150:\tlearn: 0.3068226\ttotal: 11s\tremaining: 3.58s\n",
      "151:\tlearn: 0.3061698\ttotal: 11.1s\tremaining: 3.5s\n",
      "152:\tlearn: 0.3048703\ttotal: 11.2s\tremaining: 3.43s\n",
      "153:\tlearn: 0.3042925\ttotal: 11.2s\tremaining: 3.36s\n",
      "154:\tlearn: 0.3035058\ttotal: 11.3s\tremaining: 3.28s\n",
      "155:\tlearn: 0.3028521\ttotal: 11.4s\tremaining: 3.21s\n",
      "156:\tlearn: 0.3011653\ttotal: 11.5s\tremaining: 3.14s\n",
      "157:\tlearn: 0.3003197\ttotal: 11.5s\tremaining: 3.06s\n",
      "158:\tlearn: 0.2995486\ttotal: 11.6s\tremaining: 2.99s\n",
      "159:\tlearn: 0.2991719\ttotal: 11.7s\tremaining: 2.91s\n",
      "160:\tlearn: 0.2985839\ttotal: 11.7s\tremaining: 2.84s\n",
      "161:\tlearn: 0.2982321\ttotal: 11.8s\tremaining: 2.76s\n",
      "162:\tlearn: 0.2972459\ttotal: 11.9s\tremaining: 2.69s\n",
      "163:\tlearn: 0.2965588\ttotal: 11.9s\tremaining: 2.62s\n",
      "164:\tlearn: 0.2962019\ttotal: 12s\tremaining: 2.54s\n",
      "165:\tlearn: 0.2959661\ttotal: 12s\tremaining: 2.46s\n",
      "166:\tlearn: 0.2953197\ttotal: 12.1s\tremaining: 2.39s\n",
      "167:\tlearn: 0.2948497\ttotal: 12.2s\tremaining: 2.32s\n",
      "168:\tlearn: 0.2935897\ttotal: 12.3s\tremaining: 2.25s\n",
      "169:\tlearn: 0.2928974\ttotal: 12.3s\tremaining: 2.17s\n",
      "170:\tlearn: 0.2924805\ttotal: 12.4s\tremaining: 2.1s\n",
      "171:\tlearn: 0.2919261\ttotal: 12.5s\tremaining: 2.03s\n",
      "172:\tlearn: 0.2917016\ttotal: 12.5s\tremaining: 1.95s\n",
      "173:\tlearn: 0.2907886\ttotal: 12.6s\tremaining: 1.88s\n",
      "174:\tlearn: 0.2901059\ttotal: 12.7s\tremaining: 1.81s\n",
      "175:\tlearn: 0.2896465\ttotal: 12.7s\tremaining: 1.74s\n",
      "176:\tlearn: 0.2885279\ttotal: 12.8s\tremaining: 1.67s\n",
      "177:\tlearn: 0.2879697\ttotal: 12.9s\tremaining: 1.59s\n",
      "178:\tlearn: 0.2872535\ttotal: 12.9s\tremaining: 1.52s\n",
      "179:\tlearn: 0.2865699\ttotal: 13s\tremaining: 1.45s\n",
      "180:\tlearn: 0.2860291\ttotal: 13.1s\tremaining: 1.37s\n",
      "181:\tlearn: 0.2853103\ttotal: 13.2s\tremaining: 1.3s\n",
      "182:\tlearn: 0.2845278\ttotal: 13.2s\tremaining: 1.23s\n",
      "183:\tlearn: 0.2842194\ttotal: 13.3s\tremaining: 1.16s\n",
      "184:\tlearn: 0.2830958\ttotal: 13.4s\tremaining: 1.08s\n",
      "185:\tlearn: 0.2828998\ttotal: 13.4s\tremaining: 1.01s\n",
      "186:\tlearn: 0.2826197\ttotal: 13.5s\tremaining: 938ms\n",
      "187:\tlearn: 0.2825073\ttotal: 13.6s\tremaining: 865ms\n",
      "188:\tlearn: 0.2817276\ttotal: 13.6s\tremaining: 792ms\n",
      "189:\tlearn: 0.2814711\ttotal: 13.7s\tremaining: 720ms\n",
      "190:\tlearn: 0.2811318\ttotal: 13.7s\tremaining: 647ms\n",
      "191:\tlearn: 0.2807290\ttotal: 13.8s\tremaining: 575ms\n",
      "192:\tlearn: 0.2803809\ttotal: 13.9s\tremaining: 503ms\n",
      "193:\tlearn: 0.2802504\ttotal: 13.9s\tremaining: 430ms\n",
      "194:\tlearn: 0.2798027\ttotal: 14s\tremaining: 358ms\n",
      "195:\tlearn: 0.2793118\ttotal: 14.1s\tremaining: 287ms\n",
      "196:\tlearn: 0.2786725\ttotal: 14.1s\tremaining: 215ms\n",
      "197:\tlearn: 0.2778413\ttotal: 14.2s\tremaining: 143ms\n",
      "198:\tlearn: 0.2774638\ttotal: 14.3s\tremaining: 71.7ms\n",
      "199:\tlearn: 0.2768499\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 1.6173405\ttotal: 85.3ms\tremaining: 17s\n",
      "1:\tlearn: 1.3610505\ttotal: 147ms\tremaining: 14.6s\n",
      "2:\tlearn: 1.2383489\ttotal: 231ms\tremaining: 15.1s\n",
      "3:\tlearn: 1.0831542\ttotal: 312ms\tremaining: 15.3s\n",
      "4:\tlearn: 0.9829870\ttotal: 401ms\tremaining: 15.6s\n",
      "5:\tlearn: 0.9397884\ttotal: 478ms\tremaining: 15.4s\n",
      "6:\tlearn: 0.8998009\ttotal: 555ms\tremaining: 15.3s\n",
      "7:\tlearn: 0.8514544\ttotal: 633ms\tremaining: 15.2s\n",
      "8:\tlearn: 0.7994444\ttotal: 714ms\tremaining: 15.2s\n",
      "9:\tlearn: 0.7756806\ttotal: 809ms\tremaining: 15.4s\n",
      "10:\tlearn: 0.7457416\ttotal: 901ms\tremaining: 15.5s\n",
      "11:\tlearn: 0.7209276\ttotal: 977ms\tremaining: 15.3s\n",
      "12:\tlearn: 0.7026217\ttotal: 1.06s\tremaining: 15.2s\n",
      "13:\tlearn: 0.6855301\ttotal: 1.13s\tremaining: 15s\n",
      "14:\tlearn: 0.6617941\ttotal: 1.21s\tremaining: 15s\n",
      "15:\tlearn: 0.6409414\ttotal: 1.3s\tremaining: 14.9s\n",
      "16:\tlearn: 0.6303556\ttotal: 1.38s\tremaining: 14.8s\n",
      "17:\tlearn: 0.6178826\ttotal: 1.46s\tremaining: 14.7s\n",
      "18:\tlearn: 0.6091777\ttotal: 1.54s\tremaining: 14.7s\n",
      "19:\tlearn: 0.6042056\ttotal: 1.61s\tremaining: 14.5s\n",
      "20:\tlearn: 0.6010288\ttotal: 1.68s\tremaining: 14.3s\n",
      "21:\tlearn: 0.5943810\ttotal: 1.75s\tremaining: 14.2s\n",
      "22:\tlearn: 0.5873646\ttotal: 1.82s\tremaining: 14.1s\n",
      "23:\tlearn: 0.5805283\ttotal: 1.9s\tremaining: 13.9s\n",
      "24:\tlearn: 0.5749564\ttotal: 1.96s\tremaining: 13.7s\n",
      "25:\tlearn: 0.5637090\ttotal: 2.05s\tremaining: 13.7s\n",
      "26:\tlearn: 0.5571651\ttotal: 2.12s\tremaining: 13.6s\n",
      "27:\tlearn: 0.5538908\ttotal: 2.18s\tremaining: 13.4s\n",
      "28:\tlearn: 0.5477294\ttotal: 2.26s\tremaining: 13.3s\n",
      "29:\tlearn: 0.5397188\ttotal: 2.34s\tremaining: 13.3s\n",
      "30:\tlearn: 0.5311299\ttotal: 2.44s\tremaining: 13.3s\n",
      "31:\tlearn: 0.5258997\ttotal: 2.52s\tremaining: 13.2s\n",
      "32:\tlearn: 0.5233370\ttotal: 2.58s\tremaining: 13.1s\n",
      "33:\tlearn: 0.5200332\ttotal: 2.65s\tremaining: 12.9s\n",
      "34:\tlearn: 0.5187748\ttotal: 2.71s\tremaining: 12.8s\n",
      "35:\tlearn: 0.5157007\ttotal: 2.77s\tremaining: 12.6s\n",
      "36:\tlearn: 0.5123004\ttotal: 2.83s\tremaining: 12.5s\n",
      "37:\tlearn: 0.5110807\ttotal: 2.89s\tremaining: 12.3s\n",
      "38:\tlearn: 0.5086228\ttotal: 2.95s\tremaining: 12.2s\n",
      "39:\tlearn: 0.5054616\ttotal: 3.03s\tremaining: 12.1s\n",
      "40:\tlearn: 0.5012277\ttotal: 3.1s\tremaining: 12s\n",
      "41:\tlearn: 0.4981952\ttotal: 3.17s\tremaining: 11.9s\n",
      "42:\tlearn: 0.4957518\ttotal: 3.24s\tremaining: 11.8s\n",
      "43:\tlearn: 0.4878490\ttotal: 3.32s\tremaining: 11.8s\n",
      "44:\tlearn: 0.4825031\ttotal: 3.39s\tremaining: 11.7s\n",
      "45:\tlearn: 0.4808215\ttotal: 3.46s\tremaining: 11.6s\n",
      "46:\tlearn: 0.4757149\ttotal: 3.54s\tremaining: 11.5s\n",
      "47:\tlearn: 0.4718580\ttotal: 3.62s\tremaining: 11.5s\n",
      "48:\tlearn: 0.4670354\ttotal: 3.71s\tremaining: 11.4s\n",
      "49:\tlearn: 0.4632454\ttotal: 3.78s\tremaining: 11.3s\n",
      "50:\tlearn: 0.4598018\ttotal: 3.86s\tremaining: 11.3s\n",
      "51:\tlearn: 0.4577851\ttotal: 3.92s\tremaining: 11.2s\n",
      "52:\tlearn: 0.4549552\ttotal: 4s\tremaining: 11.1s\n",
      "53:\tlearn: 0.4507283\ttotal: 4.07s\tremaining: 11s\n",
      "54:\tlearn: 0.4468803\ttotal: 4.13s\tremaining: 10.9s\n",
      "55:\tlearn: 0.4459019\ttotal: 4.19s\tremaining: 10.8s\n",
      "56:\tlearn: 0.4422079\ttotal: 4.27s\tremaining: 10.7s\n",
      "57:\tlearn: 0.4374824\ttotal: 4.35s\tremaining: 10.7s\n",
      "58:\tlearn: 0.4361327\ttotal: 4.41s\tremaining: 10.5s\n",
      "59:\tlearn: 0.4353758\ttotal: 4.47s\tremaining: 10.4s\n",
      "60:\tlearn: 0.4326344\ttotal: 4.55s\tremaining: 10.4s\n",
      "61:\tlearn: 0.4304454\ttotal: 4.63s\tremaining: 10.3s\n",
      "62:\tlearn: 0.4294918\ttotal: 4.69s\tremaining: 10.2s\n",
      "63:\tlearn: 0.4274290\ttotal: 4.77s\tremaining: 10.1s\n",
      "64:\tlearn: 0.4231578\ttotal: 4.85s\tremaining: 10.1s\n",
      "65:\tlearn: 0.4222745\ttotal: 4.91s\tremaining: 9.97s\n",
      "66:\tlearn: 0.4207156\ttotal: 4.98s\tremaining: 9.88s\n",
      "67:\tlearn: 0.4185707\ttotal: 5.05s\tremaining: 9.79s\n",
      "68:\tlearn: 0.4177817\ttotal: 5.1s\tremaining: 9.69s\n",
      "69:\tlearn: 0.4160779\ttotal: 5.16s\tremaining: 9.59s\n",
      "70:\tlearn: 0.4138596\ttotal: 5.24s\tremaining: 9.52s\n",
      "71:\tlearn: 0.4085856\ttotal: 5.33s\tremaining: 9.47s\n",
      "72:\tlearn: 0.4058153\ttotal: 5.4s\tremaining: 9.39s\n",
      "73:\tlearn: 0.4044909\ttotal: 5.47s\tremaining: 9.31s\n",
      "74:\tlearn: 0.4030956\ttotal: 5.54s\tremaining: 9.24s\n",
      "75:\tlearn: 0.4014586\ttotal: 5.62s\tremaining: 9.17s\n",
      "76:\tlearn: 0.4000662\ttotal: 5.68s\tremaining: 9.07s\n",
      "77:\tlearn: 0.3991963\ttotal: 5.74s\tremaining: 8.97s\n",
      "78:\tlearn: 0.3971996\ttotal: 5.8s\tremaining: 8.89s\n",
      "79:\tlearn: 0.3948918\ttotal: 5.88s\tremaining: 8.82s\n",
      "80:\tlearn: 0.3929727\ttotal: 5.95s\tremaining: 8.74s\n",
      "81:\tlearn: 0.3922508\ttotal: 6.01s\tremaining: 8.65s\n",
      "82:\tlearn: 0.3899716\ttotal: 6.08s\tremaining: 8.57s\n",
      "83:\tlearn: 0.3886225\ttotal: 6.14s\tremaining: 8.48s\n",
      "84:\tlearn: 0.3878956\ttotal: 6.21s\tremaining: 8.4s\n",
      "85:\tlearn: 0.3850922\ttotal: 6.28s\tremaining: 8.33s\n",
      "86:\tlearn: 0.3829834\ttotal: 6.37s\tremaining: 8.27s\n",
      "87:\tlearn: 0.3814759\ttotal: 6.44s\tremaining: 8.2s\n",
      "88:\tlearn: 0.3807215\ttotal: 6.5s\tremaining: 8.1s\n",
      "89:\tlearn: 0.3787528\ttotal: 6.57s\tremaining: 8.03s\n",
      "90:\tlearn: 0.3767801\ttotal: 6.64s\tremaining: 7.95s\n",
      "91:\tlearn: 0.3756875\ttotal: 6.71s\tremaining: 7.88s\n",
      "92:\tlearn: 0.3742325\ttotal: 6.78s\tremaining: 7.8s\n",
      "93:\tlearn: 0.3727364\ttotal: 6.85s\tremaining: 7.72s\n",
      "94:\tlearn: 0.3702874\ttotal: 6.94s\tremaining: 7.67s\n",
      "95:\tlearn: 0.3687914\ttotal: 7s\tremaining: 7.58s\n",
      "96:\tlearn: 0.3673528\ttotal: 7.07s\tremaining: 7.51s\n",
      "97:\tlearn: 0.3664333\ttotal: 7.14s\tremaining: 7.44s\n",
      "98:\tlearn: 0.3651102\ttotal: 7.21s\tremaining: 7.36s\n",
      "99:\tlearn: 0.3629544\ttotal: 7.28s\tremaining: 7.28s\n",
      "100:\tlearn: 0.3620260\ttotal: 7.35s\tremaining: 7.2s\n",
      "101:\tlearn: 0.3614259\ttotal: 7.41s\tremaining: 7.12s\n",
      "102:\tlearn: 0.3600045\ttotal: 7.47s\tremaining: 7.04s\n",
      "103:\tlearn: 0.3582633\ttotal: 7.55s\tremaining: 6.97s\n",
      "104:\tlearn: 0.3566802\ttotal: 7.62s\tremaining: 6.89s\n",
      "105:\tlearn: 0.3558527\ttotal: 7.68s\tremaining: 6.81s\n",
      "106:\tlearn: 0.3545484\ttotal: 7.75s\tremaining: 6.73s\n",
      "107:\tlearn: 0.3529319\ttotal: 7.81s\tremaining: 6.66s\n",
      "108:\tlearn: 0.3507065\ttotal: 7.88s\tremaining: 6.58s\n",
      "109:\tlearn: 0.3493082\ttotal: 7.95s\tremaining: 6.5s\n",
      "110:\tlearn: 0.3482153\ttotal: 8.02s\tremaining: 6.43s\n",
      "111:\tlearn: 0.3472302\ttotal: 8.08s\tremaining: 6.35s\n",
      "112:\tlearn: 0.3461948\ttotal: 8.14s\tremaining: 6.27s\n",
      "113:\tlearn: 0.3443519\ttotal: 8.22s\tremaining: 6.2s\n",
      "114:\tlearn: 0.3429308\ttotal: 8.3s\tremaining: 6.13s\n",
      "115:\tlearn: 0.3422004\ttotal: 8.36s\tremaining: 6.05s\n",
      "116:\tlearn: 0.3416746\ttotal: 8.42s\tremaining: 5.97s\n",
      "117:\tlearn: 0.3404022\ttotal: 8.48s\tremaining: 5.89s\n",
      "118:\tlearn: 0.3392983\ttotal: 8.56s\tremaining: 5.83s\n",
      "119:\tlearn: 0.3377338\ttotal: 8.63s\tremaining: 5.76s\n",
      "120:\tlearn: 0.3362043\ttotal: 8.71s\tremaining: 5.68s\n",
      "121:\tlearn: 0.3353798\ttotal: 8.77s\tremaining: 5.61s\n",
      "122:\tlearn: 0.3342871\ttotal: 8.84s\tremaining: 5.53s\n",
      "123:\tlearn: 0.3323548\ttotal: 8.91s\tremaining: 5.46s\n",
      "124:\tlearn: 0.3313445\ttotal: 8.98s\tremaining: 5.39s\n",
      "125:\tlearn: 0.3300307\ttotal: 9.05s\tremaining: 5.32s\n",
      "126:\tlearn: 0.3281246\ttotal: 9.12s\tremaining: 5.24s\n",
      "127:\tlearn: 0.3276333\ttotal: 9.18s\tremaining: 5.16s\n",
      "128:\tlearn: 0.3260951\ttotal: 9.25s\tremaining: 5.09s\n",
      "129:\tlearn: 0.3254202\ttotal: 9.32s\tremaining: 5.02s\n",
      "130:\tlearn: 0.3247326\ttotal: 9.38s\tremaining: 4.94s\n",
      "131:\tlearn: 0.3237435\ttotal: 9.44s\tremaining: 4.87s\n",
      "132:\tlearn: 0.3227423\ttotal: 9.52s\tremaining: 4.8s\n",
      "133:\tlearn: 0.3206731\ttotal: 9.61s\tremaining: 4.74s\n",
      "134:\tlearn: 0.3200313\ttotal: 9.67s\tremaining: 4.66s\n",
      "135:\tlearn: 0.3187656\ttotal: 9.74s\tremaining: 4.58s\n",
      "136:\tlearn: 0.3155173\ttotal: 9.82s\tremaining: 4.52s\n",
      "137:\tlearn: 0.3139450\ttotal: 9.9s\tremaining: 4.45s\n",
      "138:\tlearn: 0.3134187\ttotal: 9.96s\tremaining: 4.37s\n",
      "139:\tlearn: 0.3128283\ttotal: 10s\tremaining: 4.3s\n",
      "140:\tlearn: 0.3120676\ttotal: 10.1s\tremaining: 4.22s\n",
      "141:\tlearn: 0.3108403\ttotal: 10.2s\tremaining: 4.15s\n",
      "142:\tlearn: 0.3088957\ttotal: 10.2s\tremaining: 4.08s\n",
      "143:\tlearn: 0.3078067\ttotal: 10.3s\tremaining: 4s\n",
      "144:\tlearn: 0.3063946\ttotal: 10.4s\tremaining: 3.93s\n",
      "145:\tlearn: 0.3056039\ttotal: 10.4s\tremaining: 3.86s\n",
      "146:\tlearn: 0.3047042\ttotal: 10.5s\tremaining: 3.79s\n",
      "147:\tlearn: 0.3031033\ttotal: 10.6s\tremaining: 3.72s\n",
      "148:\tlearn: 0.3018309\ttotal: 10.7s\tremaining: 3.65s\n",
      "149:\tlearn: 0.3007020\ttotal: 10.7s\tremaining: 3.58s\n",
      "150:\tlearn: 0.2997052\ttotal: 10.8s\tremaining: 3.5s\n",
      "151:\tlearn: 0.2989160\ttotal: 10.9s\tremaining: 3.43s\n",
      "152:\tlearn: 0.2981535\ttotal: 10.9s\tremaining: 3.36s\n",
      "153:\tlearn: 0.2969038\ttotal: 11s\tremaining: 3.29s\n",
      "154:\tlearn: 0.2961651\ttotal: 11.1s\tremaining: 3.21s\n",
      "155:\tlearn: 0.2949250\ttotal: 11.1s\tremaining: 3.14s\n",
      "156:\tlearn: 0.2944694\ttotal: 11.2s\tremaining: 3.07s\n",
      "157:\tlearn: 0.2927731\ttotal: 11.3s\tremaining: 3s\n",
      "158:\tlearn: 0.2916416\ttotal: 11.3s\tremaining: 2.92s\n",
      "159:\tlearn: 0.2910899\ttotal: 11.4s\tremaining: 2.85s\n",
      "160:\tlearn: 0.2897849\ttotal: 11.5s\tremaining: 2.78s\n",
      "161:\tlearn: 0.2891113\ttotal: 11.5s\tremaining: 2.71s\n",
      "162:\tlearn: 0.2884903\ttotal: 11.6s\tremaining: 2.63s\n",
      "163:\tlearn: 0.2872093\ttotal: 11.7s\tremaining: 2.56s\n",
      "164:\tlearn: 0.2858354\ttotal: 11.7s\tremaining: 2.49s\n",
      "165:\tlearn: 0.2846987\ttotal: 11.8s\tremaining: 2.42s\n",
      "166:\tlearn: 0.2841494\ttotal: 11.9s\tremaining: 2.35s\n",
      "167:\tlearn: 0.2836111\ttotal: 12s\tremaining: 2.28s\n",
      "168:\tlearn: 0.2826850\ttotal: 12s\tremaining: 2.21s\n",
      "169:\tlearn: 0.2819824\ttotal: 12.1s\tremaining: 2.14s\n",
      "170:\tlearn: 0.2813827\ttotal: 12.2s\tremaining: 2.06s\n",
      "171:\tlearn: 0.2803828\ttotal: 12.2s\tremaining: 1.99s\n",
      "172:\tlearn: 0.2795737\ttotal: 12.3s\tremaining: 1.92s\n",
      "173:\tlearn: 0.2774372\ttotal: 12.4s\tremaining: 1.85s\n",
      "174:\tlearn: 0.2769987\ttotal: 12.5s\tremaining: 1.78s\n",
      "175:\tlearn: 0.2761480\ttotal: 12.5s\tremaining: 1.71s\n",
      "176:\tlearn: 0.2756332\ttotal: 12.6s\tremaining: 1.64s\n",
      "177:\tlearn: 0.2743603\ttotal: 12.7s\tremaining: 1.57s\n",
      "178:\tlearn: 0.2723615\ttotal: 12.8s\tremaining: 1.5s\n",
      "179:\tlearn: 0.2718423\ttotal: 12.8s\tremaining: 1.43s\n",
      "180:\tlearn: 0.2708660\ttotal: 12.9s\tremaining: 1.35s\n",
      "181:\tlearn: 0.2699190\ttotal: 13s\tremaining: 1.28s\n",
      "182:\tlearn: 0.2688820\ttotal: 13s\tremaining: 1.21s\n",
      "183:\tlearn: 0.2673247\ttotal: 13.1s\tremaining: 1.14s\n",
      "184:\tlearn: 0.2671187\ttotal: 13.2s\tremaining: 1.07s\n",
      "185:\tlearn: 0.2668336\ttotal: 13.2s\tremaining: 996ms\n",
      "186:\tlearn: 0.2661729\ttotal: 13.3s\tremaining: 924ms\n",
      "187:\tlearn: 0.2646314\ttotal: 13.4s\tremaining: 854ms\n",
      "188:\tlearn: 0.2638999\ttotal: 13.4s\tremaining: 782ms\n",
      "189:\tlearn: 0.2627521\ttotal: 13.5s\tremaining: 711ms\n",
      "190:\tlearn: 0.2621785\ttotal: 13.6s\tremaining: 640ms\n",
      "191:\tlearn: 0.2618882\ttotal: 13.6s\tremaining: 568ms\n",
      "192:\tlearn: 0.2608913\ttotal: 13.7s\tremaining: 497ms\n",
      "193:\tlearn: 0.2602223\ttotal: 13.8s\tremaining: 425ms\n",
      "194:\tlearn: 0.2595157\ttotal: 13.8s\tremaining: 354ms\n",
      "195:\tlearn: 0.2589855\ttotal: 13.9s\tremaining: 283ms\n",
      "196:\tlearn: 0.2581400\ttotal: 13.9s\tremaining: 212ms\n",
      "197:\tlearn: 0.2570058\ttotal: 14s\tremaining: 142ms\n",
      "198:\tlearn: 0.2566882\ttotal: 14.1s\tremaining: 70.7ms\n",
      "199:\tlearn: 0.2560633\ttotal: 14.1s\tremaining: 0us\n",
      "0:\tlearn: 1.5904964\ttotal: 87.8ms\tremaining: 17.5s\n",
      "1:\tlearn: 1.2868761\ttotal: 150ms\tremaining: 14.8s\n",
      "2:\tlearn: 1.2069274\ttotal: 228ms\tremaining: 14.9s\n",
      "3:\tlearn: 1.2591811\ttotal: 316ms\tremaining: 15.5s\n",
      "4:\tlearn: 1.2358491\ttotal: 391ms\tremaining: 15.2s\n",
      "5:\tlearn: 1.1135678\ttotal: 470ms\tremaining: 15.2s\n",
      "6:\tlearn: 1.2131935\ttotal: 566ms\tremaining: 15.6s\n",
      "7:\tlearn: 1.0560568\ttotal: 680ms\tremaining: 16.3s\n",
      "8:\tlearn: 0.9978661\ttotal: 765ms\tremaining: 16.2s\n",
      "9:\tlearn: 0.9668202\ttotal: 851ms\tremaining: 16.2s\n",
      "10:\tlearn: 0.9282470\ttotal: 936ms\tremaining: 16.1s\n",
      "11:\tlearn: 0.8936989\ttotal: 1.02s\tremaining: 16s\n",
      "12:\tlearn: 0.8631421\ttotal: 1.1s\tremaining: 15.9s\n",
      "13:\tlearn: 0.8320332\ttotal: 1.19s\tremaining: 15.9s\n",
      "14:\tlearn: 0.8719433\ttotal: 1.27s\tremaining: 15.7s\n",
      "15:\tlearn: 0.8270734\ttotal: 1.35s\tremaining: 15.5s\n",
      "16:\tlearn: 0.8129897\ttotal: 1.42s\tremaining: 15.3s\n",
      "17:\tlearn: 0.7952248\ttotal: 1.5s\tremaining: 15.2s\n",
      "18:\tlearn: 0.7811221\ttotal: 1.59s\tremaining: 15.2s\n",
      "19:\tlearn: 0.7727428\ttotal: 1.67s\tremaining: 15s\n",
      "20:\tlearn: 0.7676297\ttotal: 1.73s\tremaining: 14.8s\n",
      "21:\tlearn: 0.7569438\ttotal: 1.81s\tremaining: 14.7s\n",
      "22:\tlearn: 0.7502177\ttotal: 1.87s\tremaining: 14.4s\n",
      "23:\tlearn: 0.7322262\ttotal: 1.96s\tremaining: 14.4s\n",
      "24:\tlearn: 0.7260848\ttotal: 2.04s\tremaining: 14.3s\n",
      "25:\tlearn: 0.7219858\ttotal: 2.1s\tremaining: 14s\n",
      "26:\tlearn: 0.7177420\ttotal: 2.16s\tremaining: 13.8s\n",
      "27:\tlearn: 0.7119295\ttotal: 2.22s\tremaining: 13.7s\n",
      "28:\tlearn: 0.6964787\ttotal: 2.32s\tremaining: 13.7s\n",
      "29:\tlearn: 0.6917295\ttotal: 2.4s\tremaining: 13.6s\n",
      "30:\tlearn: 0.6885751\ttotal: 2.45s\tremaining: 13.4s\n",
      "31:\tlearn: 0.6796224\ttotal: 2.53s\tremaining: 13.3s\n",
      "32:\tlearn: 0.6753834\ttotal: 2.6s\tremaining: 13.2s\n",
      "33:\tlearn: 0.6666199\ttotal: 2.69s\tremaining: 13.2s\n",
      "34:\tlearn: 0.6633736\ttotal: 2.75s\tremaining: 13s\n",
      "35:\tlearn: 0.6609227\ttotal: 2.82s\tremaining: 12.8s\n",
      "36:\tlearn: 0.6581662\ttotal: 2.88s\tremaining: 12.7s\n",
      "37:\tlearn: 0.6381378\ttotal: 2.95s\tremaining: 12.6s\n",
      "38:\tlearn: 0.6323538\ttotal: 3.02s\tremaining: 12.5s\n",
      "39:\tlearn: 0.6263121\ttotal: 3.08s\tremaining: 12.3s\n",
      "40:\tlearn: 0.6246289\ttotal: 3.14s\tremaining: 12.2s\n",
      "41:\tlearn: 0.6228307\ttotal: 3.2s\tremaining: 12s\n",
      "42:\tlearn: 0.6192888\ttotal: 3.27s\tremaining: 11.9s\n",
      "43:\tlearn: 0.6153719\ttotal: 3.33s\tremaining: 11.8s\n",
      "44:\tlearn: 0.6116215\ttotal: 3.4s\tremaining: 11.7s\n",
      "45:\tlearn: 0.6094971\ttotal: 3.47s\tremaining: 11.6s\n",
      "46:\tlearn: 0.6021314\ttotal: 3.55s\tremaining: 11.6s\n",
      "47:\tlearn: 0.5999093\ttotal: 3.61s\tremaining: 11.4s\n",
      "48:\tlearn: 0.5961066\ttotal: 3.69s\tremaining: 11.4s\n",
      "49:\tlearn: 0.5944487\ttotal: 3.75s\tremaining: 11.3s\n",
      "50:\tlearn: 0.5898753\ttotal: 3.82s\tremaining: 11.2s\n",
      "51:\tlearn: 0.5875276\ttotal: 3.89s\tremaining: 11.1s\n",
      "52:\tlearn: 0.5807612\ttotal: 3.98s\tremaining: 11s\n",
      "53:\tlearn: 0.5784218\ttotal: 4.04s\tremaining: 10.9s\n",
      "54:\tlearn: 0.5741661\ttotal: 4.12s\tremaining: 10.9s\n",
      "55:\tlearn: 0.5719413\ttotal: 4.19s\tremaining: 10.8s\n",
      "56:\tlearn: 0.5692398\ttotal: 4.26s\tremaining: 10.7s\n",
      "57:\tlearn: 0.5659760\ttotal: 4.34s\tremaining: 10.6s\n",
      "58:\tlearn: 0.5642367\ttotal: 4.4s\tremaining: 10.5s\n",
      "59:\tlearn: 0.5618699\ttotal: 4.46s\tremaining: 10.4s\n",
      "60:\tlearn: 0.5599464\ttotal: 4.53s\tremaining: 10.3s\n",
      "61:\tlearn: 0.5573931\ttotal: 4.59s\tremaining: 10.2s\n",
      "62:\tlearn: 0.5543340\ttotal: 4.67s\tremaining: 10.2s\n",
      "63:\tlearn: 0.5531849\ttotal: 4.73s\tremaining: 10s\n",
      "64:\tlearn: 0.5510241\ttotal: 4.78s\tremaining: 9.94s\n",
      "65:\tlearn: 0.5478365\ttotal: 4.85s\tremaining: 9.85s\n",
      "66:\tlearn: 0.5458885\ttotal: 4.91s\tremaining: 9.75s\n",
      "67:\tlearn: 0.5445070\ttotal: 4.97s\tremaining: 9.64s\n",
      "68:\tlearn: 0.5404689\ttotal: 5.05s\tremaining: 9.59s\n",
      "69:\tlearn: 0.5391264\ttotal: 5.12s\tremaining: 9.5s\n",
      "70:\tlearn: 0.5291583\ttotal: 5.19s\tremaining: 9.44s\n",
      "71:\tlearn: 0.5283203\ttotal: 5.25s\tremaining: 9.33s\n",
      "72:\tlearn: 0.5270240\ttotal: 5.31s\tremaining: 9.23s\n",
      "73:\tlearn: 0.5245043\ttotal: 5.38s\tremaining: 9.15s\n",
      "74:\tlearn: 0.5205631\ttotal: 5.46s\tremaining: 9.09s\n",
      "75:\tlearn: 0.5188635\ttotal: 5.53s\tremaining: 9.02s\n",
      "76:\tlearn: 0.5161578\ttotal: 5.59s\tremaining: 8.94s\n",
      "77:\tlearn: 0.5141368\ttotal: 5.67s\tremaining: 8.87s\n",
      "78:\tlearn: 0.5117138\ttotal: 5.74s\tremaining: 8.79s\n",
      "79:\tlearn: 0.5096479\ttotal: 5.8s\tremaining: 8.71s\n",
      "80:\tlearn: 0.5084591\ttotal: 5.87s\tremaining: 8.63s\n",
      "81:\tlearn: 0.5044370\ttotal: 5.93s\tremaining: 8.54s\n",
      "82:\tlearn: 0.5019635\ttotal: 5.99s\tremaining: 8.45s\n",
      "83:\tlearn: 0.5003890\ttotal: 6.05s\tremaining: 8.36s\n",
      "84:\tlearn: 0.4982664\ttotal: 6.12s\tremaining: 8.27s\n",
      "85:\tlearn: 0.4966947\ttotal: 6.19s\tremaining: 8.2s\n",
      "86:\tlearn: 0.4949121\ttotal: 6.26s\tremaining: 8.13s\n",
      "87:\tlearn: 0.4922088\ttotal: 6.33s\tremaining: 8.06s\n",
      "88:\tlearn: 0.4906836\ttotal: 6.39s\tremaining: 7.97s\n",
      "89:\tlearn: 0.4884153\ttotal: 6.46s\tremaining: 7.89s\n",
      "90:\tlearn: 0.4874611\ttotal: 6.52s\tremaining: 7.81s\n",
      "91:\tlearn: 0.4851514\ttotal: 6.6s\tremaining: 7.75s\n",
      "92:\tlearn: 0.4844748\ttotal: 6.66s\tremaining: 7.66s\n",
      "93:\tlearn: 0.4830030\ttotal: 6.72s\tremaining: 7.58s\n",
      "94:\tlearn: 0.4810366\ttotal: 6.8s\tremaining: 7.51s\n",
      "95:\tlearn: 0.4795148\ttotal: 6.86s\tremaining: 7.43s\n",
      "96:\tlearn: 0.4775018\ttotal: 6.93s\tremaining: 7.36s\n",
      "97:\tlearn: 0.4750804\ttotal: 7s\tremaining: 7.29s\n",
      "98:\tlearn: 0.4742152\ttotal: 7.06s\tremaining: 7.2s\n",
      "99:\tlearn: 0.4724026\ttotal: 7.14s\tremaining: 7.14s\n",
      "100:\tlearn: 0.4703963\ttotal: 7.22s\tremaining: 7.07s\n",
      "101:\tlearn: 0.4691964\ttotal: 7.28s\tremaining: 7s\n",
      "102:\tlearn: 0.4677430\ttotal: 7.34s\tremaining: 6.92s\n",
      "103:\tlearn: 0.4662578\ttotal: 7.42s\tremaining: 6.85s\n",
      "104:\tlearn: 0.4651410\ttotal: 7.48s\tremaining: 6.77s\n",
      "105:\tlearn: 0.4642058\ttotal: 7.55s\tremaining: 6.7s\n",
      "106:\tlearn: 0.4623442\ttotal: 7.68s\tremaining: 6.67s\n",
      "107:\tlearn: 0.4591740\ttotal: 7.79s\tremaining: 6.64s\n",
      "108:\tlearn: 0.4570554\ttotal: 7.89s\tremaining: 6.58s\n",
      "109:\tlearn: 0.4555159\ttotal: 7.96s\tremaining: 6.52s\n",
      "110:\tlearn: 0.4549524\ttotal: 8.03s\tremaining: 6.43s\n",
      "111:\tlearn: 0.4545310\ttotal: 8.09s\tremaining: 6.35s\n",
      "112:\tlearn: 0.4538704\ttotal: 8.14s\tremaining: 6.27s\n",
      "113:\tlearn: 0.4522432\ttotal: 8.21s\tremaining: 6.19s\n",
      "114:\tlearn: 0.4510936\ttotal: 8.27s\tremaining: 6.11s\n",
      "115:\tlearn: 0.4484243\ttotal: 8.35s\tremaining: 6.05s\n",
      "116:\tlearn: 0.4464775\ttotal: 8.42s\tremaining: 5.97s\n",
      "117:\tlearn: 0.4438034\ttotal: 8.5s\tremaining: 5.91s\n",
      "118:\tlearn: 0.4424400\ttotal: 8.57s\tremaining: 5.83s\n",
      "119:\tlearn: 0.4403081\ttotal: 8.64s\tremaining: 5.76s\n",
      "120:\tlearn: 0.4386851\ttotal: 8.72s\tremaining: 5.69s\n",
      "121:\tlearn: 0.4377637\ttotal: 8.79s\tremaining: 5.62s\n",
      "122:\tlearn: 0.4360399\ttotal: 8.86s\tremaining: 5.55s\n",
      "123:\tlearn: 0.4348882\ttotal: 8.94s\tremaining: 5.48s\n",
      "124:\tlearn: 0.4343833\ttotal: 8.99s\tremaining: 5.4s\n",
      "125:\tlearn: 0.4335493\ttotal: 9.05s\tremaining: 5.32s\n",
      "126:\tlearn: 0.4320863\ttotal: 9.12s\tremaining: 5.24s\n",
      "127:\tlearn: 0.4302723\ttotal: 9.2s\tremaining: 5.17s\n",
      "128:\tlearn: 0.4290845\ttotal: 9.26s\tremaining: 5.1s\n",
      "129:\tlearn: 0.4264265\ttotal: 9.34s\tremaining: 5.03s\n",
      "130:\tlearn: 0.4244212\ttotal: 9.42s\tremaining: 4.96s\n",
      "131:\tlearn: 0.4227405\ttotal: 9.49s\tremaining: 4.89s\n",
      "132:\tlearn: 0.4217767\ttotal: 9.55s\tremaining: 4.81s\n",
      "133:\tlearn: 0.4210432\ttotal: 9.61s\tremaining: 4.73s\n",
      "134:\tlearn: 0.4194771\ttotal: 9.68s\tremaining: 4.66s\n",
      "135:\tlearn: 0.4186912\ttotal: 9.73s\tremaining: 4.58s\n",
      "136:\tlearn: 0.4176008\ttotal: 9.8s\tremaining: 4.51s\n",
      "137:\tlearn: 0.4166733\ttotal: 9.87s\tremaining: 4.43s\n",
      "138:\tlearn: 0.4148617\ttotal: 9.94s\tremaining: 4.36s\n",
      "139:\tlearn: 0.4139880\ttotal: 10s\tremaining: 4.29s\n",
      "140:\tlearn: 0.4132246\ttotal: 10.1s\tremaining: 4.21s\n",
      "141:\tlearn: 0.4089655\ttotal: 10.1s\tremaining: 4.14s\n",
      "142:\tlearn: 0.4078707\ttotal: 10.2s\tremaining: 4.07s\n",
      "143:\tlearn: 0.4062710\ttotal: 10.3s\tremaining: 4s\n",
      "144:\tlearn: 0.4053735\ttotal: 10.3s\tremaining: 3.92s\n",
      "145:\tlearn: 0.4041493\ttotal: 10.4s\tremaining: 3.85s\n",
      "146:\tlearn: 0.4024437\ttotal: 10.5s\tremaining: 3.78s\n",
      "147:\tlearn: 0.4002937\ttotal: 10.6s\tremaining: 3.71s\n",
      "148:\tlearn: 0.3991471\ttotal: 10.6s\tremaining: 3.64s\n",
      "149:\tlearn: 0.3968882\ttotal: 10.7s\tremaining: 3.58s\n",
      "150:\tlearn: 0.3955831\ttotal: 10.8s\tremaining: 3.5s\n",
      "151:\tlearn: 0.3944013\ttotal: 10.9s\tremaining: 3.43s\n",
      "152:\tlearn: 0.3931780\ttotal: 10.9s\tremaining: 3.36s\n",
      "153:\tlearn: 0.3920621\ttotal: 11s\tremaining: 3.29s\n",
      "154:\tlearn: 0.3908517\ttotal: 11.1s\tremaining: 3.21s\n",
      "155:\tlearn: 0.3895211\ttotal: 11.1s\tremaining: 3.14s\n",
      "156:\tlearn: 0.3880542\ttotal: 11.2s\tremaining: 3.08s\n",
      "157:\tlearn: 0.3865021\ttotal: 11.3s\tremaining: 3s\n",
      "158:\tlearn: 0.3840622\ttotal: 11.4s\tremaining: 2.93s\n",
      "159:\tlearn: 0.3830402\ttotal: 11.4s\tremaining: 2.86s\n",
      "160:\tlearn: 0.3820464\ttotal: 11.5s\tremaining: 2.79s\n",
      "161:\tlearn: 0.3813721\ttotal: 11.6s\tremaining: 2.71s\n",
      "162:\tlearn: 0.3801465\ttotal: 11.6s\tremaining: 2.64s\n",
      "163:\tlearn: 0.3790978\ttotal: 11.7s\tremaining: 2.57s\n",
      "164:\tlearn: 0.3776448\ttotal: 11.8s\tremaining: 2.5s\n",
      "165:\tlearn: 0.3769575\ttotal: 11.8s\tremaining: 2.42s\n",
      "166:\tlearn: 0.3762056\ttotal: 11.9s\tremaining: 2.35s\n",
      "167:\tlearn: 0.3749567\ttotal: 12s\tremaining: 2.28s\n",
      "168:\tlearn: 0.3736965\ttotal: 12s\tremaining: 2.21s\n",
      "169:\tlearn: 0.3717329\ttotal: 12.1s\tremaining: 2.14s\n",
      "170:\tlearn: 0.3708425\ttotal: 12.2s\tremaining: 2.06s\n",
      "171:\tlearn: 0.3678928\ttotal: 12.3s\tremaining: 2s\n",
      "172:\tlearn: 0.3674607\ttotal: 12.3s\tremaining: 1.92s\n",
      "173:\tlearn: 0.3670701\ttotal: 12.4s\tremaining: 1.85s\n",
      "174:\tlearn: 0.3664816\ttotal: 12.4s\tremaining: 1.78s\n",
      "175:\tlearn: 0.3650001\ttotal: 12.5s\tremaining: 1.71s\n",
      "176:\tlearn: 0.3637655\ttotal: 12.6s\tremaining: 1.63s\n",
      "177:\tlearn: 0.3626315\ttotal: 12.6s\tremaining: 1.56s\n",
      "178:\tlearn: 0.3618810\ttotal: 12.7s\tremaining: 1.49s\n",
      "179:\tlearn: 0.3607968\ttotal: 12.8s\tremaining: 1.42s\n",
      "180:\tlearn: 0.3594448\ttotal: 12.8s\tremaining: 1.35s\n",
      "181:\tlearn: 0.3584207\ttotal: 12.9s\tremaining: 1.28s\n",
      "182:\tlearn: 0.3575423\ttotal: 13s\tremaining: 1.21s\n",
      "183:\tlearn: 0.3570383\ttotal: 13s\tremaining: 1.13s\n",
      "184:\tlearn: 0.3559116\ttotal: 13.1s\tremaining: 1.06s\n",
      "185:\tlearn: 0.3553303\ttotal: 13.2s\tremaining: 991ms\n",
      "186:\tlearn: 0.3541204\ttotal: 13.2s\tremaining: 920ms\n",
      "187:\tlearn: 0.3533159\ttotal: 13.3s\tremaining: 849ms\n",
      "188:\tlearn: 0.3526317\ttotal: 13.4s\tremaining: 778ms\n",
      "189:\tlearn: 0.3506019\ttotal: 13.5s\tremaining: 708ms\n",
      "190:\tlearn: 0.3488218\ttotal: 13.5s\tremaining: 638ms\n",
      "191:\tlearn: 0.3476563\ttotal: 13.6s\tremaining: 567ms\n",
      "192:\tlearn: 0.3463897\ttotal: 13.7s\tremaining: 496ms\n",
      "193:\tlearn: 0.3455623\ttotal: 13.7s\tremaining: 425ms\n",
      "194:\tlearn: 0.3446074\ttotal: 13.8s\tremaining: 354ms\n",
      "195:\tlearn: 0.3442670\ttotal: 13.9s\tremaining: 283ms\n",
      "196:\tlearn: 0.3431864\ttotal: 13.9s\tremaining: 212ms\n",
      "197:\tlearn: 0.3409727\ttotal: 14s\tremaining: 142ms\n",
      "198:\tlearn: 0.3400497\ttotal: 14.1s\tremaining: 70.8ms\n",
      "199:\tlearn: 0.3392426\ttotal: 14.1s\tremaining: 0us\n",
      "0:\tlearn: 1.5969118\ttotal: 85.9ms\tremaining: 17.1s\n",
      "1:\tlearn: 1.3103836\ttotal: 149ms\tremaining: 14.7s\n",
      "2:\tlearn: 1.2129746\ttotal: 226ms\tremaining: 14.8s\n",
      "3:\tlearn: 1.0905230\ttotal: 304ms\tremaining: 14.9s\n",
      "4:\tlearn: 0.9797581\ttotal: 394ms\tremaining: 15.4s\n",
      "5:\tlearn: 0.9616224\ttotal: 481ms\tremaining: 15.5s\n",
      "6:\tlearn: 0.8911732\ttotal: 567ms\tremaining: 15.6s\n",
      "7:\tlearn: 0.8292906\ttotal: 651ms\tremaining: 15.6s\n",
      "8:\tlearn: 0.7856031\ttotal: 740ms\tremaining: 15.7s\n",
      "9:\tlearn: 0.7552508\ttotal: 829ms\tremaining: 15.8s\n",
      "10:\tlearn: 0.7170867\ttotal: 911ms\tremaining: 15.7s\n",
      "11:\tlearn: 0.6883282\ttotal: 991ms\tremaining: 15.5s\n",
      "12:\tlearn: 0.6652474\ttotal: 1.07s\tremaining: 15.4s\n",
      "13:\tlearn: 0.6484559\ttotal: 1.14s\tremaining: 15.2s\n",
      "14:\tlearn: 0.6320572\ttotal: 1.22s\tremaining: 15.1s\n",
      "15:\tlearn: 0.6170387\ttotal: 1.3s\tremaining: 15s\n",
      "16:\tlearn: 0.6065463\ttotal: 1.37s\tremaining: 14.8s\n",
      "17:\tlearn: 0.5939297\ttotal: 1.45s\tremaining: 14.7s\n",
      "18:\tlearn: 0.5826200\ttotal: 1.53s\tremaining: 14.6s\n",
      "19:\tlearn: 0.5760293\ttotal: 1.6s\tremaining: 14.4s\n",
      "20:\tlearn: 0.5689355\ttotal: 1.68s\tremaining: 14.3s\n",
      "21:\tlearn: 0.5646152\ttotal: 1.74s\tremaining: 14.1s\n",
      "22:\tlearn: 0.5624195\ttotal: 1.8s\tremaining: 13.9s\n",
      "23:\tlearn: 0.5588198\ttotal: 1.87s\tremaining: 13.7s\n",
      "24:\tlearn: 0.5494935\ttotal: 1.96s\tremaining: 13.7s\n",
      "25:\tlearn: 0.5401635\ttotal: 2.04s\tremaining: 13.6s\n",
      "26:\tlearn: 0.5361847\ttotal: 2.11s\tremaining: 13.5s\n",
      "27:\tlearn: 0.5325413\ttotal: 2.18s\tremaining: 13.4s\n",
      "28:\tlearn: 0.5285964\ttotal: 2.25s\tremaining: 13.3s\n",
      "29:\tlearn: 0.5254682\ttotal: 2.32s\tremaining: 13.2s\n",
      "30:\tlearn: 0.5203986\ttotal: 2.4s\tremaining: 13.1s\n",
      "31:\tlearn: 0.5172851\ttotal: 2.47s\tremaining: 13s\n",
      "32:\tlearn: 0.5128248\ttotal: 2.54s\tremaining: 12.8s\n",
      "33:\tlearn: 0.5101976\ttotal: 2.6s\tremaining: 12.7s\n",
      "34:\tlearn: 0.5077774\ttotal: 2.68s\tremaining: 12.6s\n",
      "35:\tlearn: 0.5011240\ttotal: 2.74s\tremaining: 12.5s\n",
      "36:\tlearn: 0.4971370\ttotal: 2.82s\tremaining: 12.4s\n",
      "37:\tlearn: 0.4934769\ttotal: 2.89s\tremaining: 12.3s\n",
      "38:\tlearn: 0.4889136\ttotal: 2.96s\tremaining: 12.2s\n",
      "39:\tlearn: 0.4842181\ttotal: 3.03s\tremaining: 12.1s\n",
      "40:\tlearn: 0.4790665\ttotal: 3.12s\tremaining: 12.1s\n",
      "41:\tlearn: 0.4764736\ttotal: 3.19s\tremaining: 12s\n",
      "42:\tlearn: 0.4718285\ttotal: 3.28s\tremaining: 12s\n",
      "43:\tlearn: 0.4703387\ttotal: 3.34s\tremaining: 11.9s\n",
      "44:\tlearn: 0.4694928\ttotal: 3.4s\tremaining: 11.7s\n",
      "45:\tlearn: 0.4681639\ttotal: 3.46s\tremaining: 11.6s\n",
      "46:\tlearn: 0.4664499\ttotal: 3.52s\tremaining: 11.5s\n",
      "47:\tlearn: 0.4632181\ttotal: 3.6s\tremaining: 11.4s\n",
      "48:\tlearn: 0.4602233\ttotal: 3.67s\tremaining: 11.3s\n",
      "49:\tlearn: 0.4582348\ttotal: 3.75s\tremaining: 11.3s\n",
      "50:\tlearn: 0.4559021\ttotal: 3.81s\tremaining: 11.1s\n",
      "51:\tlearn: 0.4549857\ttotal: 3.87s\tremaining: 11s\n",
      "52:\tlearn: 0.4520478\ttotal: 3.94s\tremaining: 10.9s\n",
      "53:\tlearn: 0.4490601\ttotal: 4.01s\tremaining: 10.8s\n",
      "54:\tlearn: 0.4454392\ttotal: 4.09s\tremaining: 10.8s\n",
      "55:\tlearn: 0.4413480\ttotal: 4.18s\tremaining: 10.7s\n",
      "56:\tlearn: 0.4384300\ttotal: 4.26s\tremaining: 10.7s\n",
      "57:\tlearn: 0.4376817\ttotal: 4.32s\tremaining: 10.6s\n",
      "58:\tlearn: 0.4365586\ttotal: 4.38s\tremaining: 10.5s\n",
      "59:\tlearn: 0.4340429\ttotal: 4.46s\tremaining: 10.4s\n",
      "60:\tlearn: 0.4313606\ttotal: 4.53s\tremaining: 10.3s\n",
      "61:\tlearn: 0.4300838\ttotal: 4.59s\tremaining: 10.2s\n",
      "62:\tlearn: 0.4283808\ttotal: 4.66s\tremaining: 10.1s\n",
      "63:\tlearn: 0.4263738\ttotal: 4.72s\tremaining: 10s\n",
      "64:\tlearn: 0.4239440\ttotal: 4.8s\tremaining: 9.96s\n",
      "65:\tlearn: 0.4220507\ttotal: 4.86s\tremaining: 9.88s\n",
      "66:\tlearn: 0.4206254\ttotal: 4.92s\tremaining: 9.78s\n",
      "67:\tlearn: 0.4178763\ttotal: 4.99s\tremaining: 9.69s\n",
      "68:\tlearn: 0.4144001\ttotal: 5.06s\tremaining: 9.61s\n",
      "69:\tlearn: 0.4126655\ttotal: 5.13s\tremaining: 9.53s\n",
      "70:\tlearn: 0.4111394\ttotal: 5.2s\tremaining: 9.45s\n",
      "71:\tlearn: 0.4095449\ttotal: 5.27s\tremaining: 9.37s\n",
      "72:\tlearn: 0.4074473\ttotal: 5.34s\tremaining: 9.29s\n",
      "73:\tlearn: 0.4060748\ttotal: 5.4s\tremaining: 9.19s\n",
      "74:\tlearn: 0.4043475\ttotal: 5.47s\tremaining: 9.11s\n",
      "75:\tlearn: 0.4010022\ttotal: 5.55s\tremaining: 9.05s\n",
      "76:\tlearn: 0.3960465\ttotal: 5.62s\tremaining: 8.97s\n",
      "77:\tlearn: 0.3944974\ttotal: 5.68s\tremaining: 8.89s\n",
      "78:\tlearn: 0.3922190\ttotal: 5.75s\tremaining: 8.81s\n",
      "79:\tlearn: 0.3910673\ttotal: 5.82s\tremaining: 8.72s\n",
      "80:\tlearn: 0.3901708\ttotal: 5.88s\tremaining: 8.63s\n",
      "81:\tlearn: 0.3885115\ttotal: 5.95s\tremaining: 8.57s\n",
      "82:\tlearn: 0.3861109\ttotal: 6.03s\tremaining: 8.5s\n",
      "83:\tlearn: 0.3846853\ttotal: 6.1s\tremaining: 8.42s\n",
      "84:\tlearn: 0.3841106\ttotal: 6.16s\tremaining: 8.33s\n",
      "85:\tlearn: 0.3823269\ttotal: 6.24s\tremaining: 8.27s\n",
      "86:\tlearn: 0.3806169\ttotal: 6.3s\tremaining: 8.19s\n",
      "87:\tlearn: 0.3794520\ttotal: 6.36s\tremaining: 8.1s\n",
      "88:\tlearn: 0.3785163\ttotal: 6.43s\tremaining: 8.02s\n",
      "89:\tlearn: 0.3759243\ttotal: 6.5s\tremaining: 7.95s\n",
      "90:\tlearn: 0.3742317\ttotal: 6.57s\tremaining: 7.87s\n",
      "91:\tlearn: 0.3736935\ttotal: 6.63s\tremaining: 7.78s\n",
      "92:\tlearn: 0.3721104\ttotal: 6.69s\tremaining: 7.7s\n",
      "93:\tlearn: 0.3715273\ttotal: 6.75s\tremaining: 7.62s\n",
      "94:\tlearn: 0.3709885\ttotal: 6.81s\tremaining: 7.53s\n",
      "95:\tlearn: 0.3693382\ttotal: 6.88s\tremaining: 7.46s\n",
      "96:\tlearn: 0.3668557\ttotal: 6.96s\tremaining: 7.38s\n",
      "97:\tlearn: 0.3651128\ttotal: 7.02s\tremaining: 7.3s\n",
      "98:\tlearn: 0.3644351\ttotal: 7.08s\tremaining: 7.22s\n",
      "99:\tlearn: 0.3633399\ttotal: 7.13s\tremaining: 7.13s\n",
      "100:\tlearn: 0.3621716\ttotal: 7.19s\tremaining: 7.05s\n",
      "101:\tlearn: 0.3609095\ttotal: 7.26s\tremaining: 6.97s\n",
      "102:\tlearn: 0.3586754\ttotal: 7.34s\tremaining: 6.91s\n",
      "103:\tlearn: 0.3569965\ttotal: 7.41s\tremaining: 6.84s\n",
      "104:\tlearn: 0.3549492\ttotal: 7.5s\tremaining: 6.79s\n",
      "105:\tlearn: 0.3539260\ttotal: 7.57s\tremaining: 6.71s\n",
      "106:\tlearn: 0.3534286\ttotal: 7.63s\tremaining: 6.63s\n",
      "107:\tlearn: 0.3526284\ttotal: 7.68s\tremaining: 6.54s\n",
      "108:\tlearn: 0.3515748\ttotal: 7.74s\tremaining: 6.46s\n",
      "109:\tlearn: 0.3500952\ttotal: 7.82s\tremaining: 6.4s\n",
      "110:\tlearn: 0.3483996\ttotal: 7.88s\tremaining: 6.32s\n",
      "111:\tlearn: 0.3473840\ttotal: 7.95s\tremaining: 6.25s\n",
      "112:\tlearn: 0.3457150\ttotal: 8.02s\tremaining: 6.17s\n",
      "113:\tlearn: 0.3438444\ttotal: 8.09s\tremaining: 6.1s\n",
      "114:\tlearn: 0.3428713\ttotal: 8.16s\tremaining: 6.03s\n",
      "115:\tlearn: 0.3415080\ttotal: 8.22s\tremaining: 5.96s\n",
      "116:\tlearn: 0.3402657\ttotal: 8.29s\tremaining: 5.88s\n",
      "117:\tlearn: 0.3390081\ttotal: 8.36s\tremaining: 5.81s\n",
      "118:\tlearn: 0.3381480\ttotal: 8.43s\tremaining: 5.74s\n",
      "119:\tlearn: 0.3371025\ttotal: 8.49s\tremaining: 5.66s\n",
      "120:\tlearn: 0.3364194\ttotal: 8.55s\tremaining: 5.58s\n",
      "121:\tlearn: 0.3353641\ttotal: 8.63s\tremaining: 5.51s\n",
      "122:\tlearn: 0.3337622\ttotal: 8.71s\tremaining: 5.45s\n",
      "123:\tlearn: 0.3323091\ttotal: 8.78s\tremaining: 5.38s\n",
      "124:\tlearn: 0.3311668\ttotal: 8.84s\tremaining: 5.3s\n",
      "125:\tlearn: 0.3297235\ttotal: 8.92s\tremaining: 5.24s\n",
      "126:\tlearn: 0.3278310\ttotal: 8.99s\tremaining: 5.17s\n",
      "127:\tlearn: 0.3258310\ttotal: 9.07s\tremaining: 5.1s\n",
      "128:\tlearn: 0.3251218\ttotal: 9.13s\tremaining: 5.03s\n",
      "129:\tlearn: 0.3235254\ttotal: 9.2s\tremaining: 4.96s\n",
      "130:\tlearn: 0.3219537\ttotal: 9.27s\tremaining: 4.88s\n",
      "131:\tlearn: 0.3209182\ttotal: 9.34s\tremaining: 4.81s\n",
      "132:\tlearn: 0.3190900\ttotal: 9.41s\tremaining: 4.74s\n",
      "133:\tlearn: 0.3183238\ttotal: 9.47s\tremaining: 4.66s\n",
      "134:\tlearn: 0.3179151\ttotal: 9.52s\tremaining: 4.58s\n",
      "135:\tlearn: 0.3165758\ttotal: 9.6s\tremaining: 4.52s\n",
      "136:\tlearn: 0.3150339\ttotal: 9.68s\tremaining: 4.45s\n",
      "137:\tlearn: 0.3146867\ttotal: 9.73s\tremaining: 4.37s\n",
      "138:\tlearn: 0.3142802\ttotal: 9.79s\tremaining: 4.3s\n",
      "139:\tlearn: 0.3129849\ttotal: 9.87s\tremaining: 4.23s\n",
      "140:\tlearn: 0.3114993\ttotal: 9.94s\tremaining: 4.16s\n",
      "141:\tlearn: 0.3109316\ttotal: 10s\tremaining: 4.09s\n",
      "142:\tlearn: 0.3101015\ttotal: 10.1s\tremaining: 4.01s\n",
      "143:\tlearn: 0.3093006\ttotal: 10.1s\tremaining: 3.94s\n",
      "144:\tlearn: 0.3084976\ttotal: 10.2s\tremaining: 3.87s\n",
      "145:\tlearn: 0.3072117\ttotal: 10.3s\tremaining: 3.8s\n",
      "146:\tlearn: 0.3054922\ttotal: 10.3s\tremaining: 3.73s\n",
      "147:\tlearn: 0.3039150\ttotal: 10.4s\tremaining: 3.66s\n",
      "148:\tlearn: 0.3027012\ttotal: 10.5s\tremaining: 3.59s\n",
      "149:\tlearn: 0.3017372\ttotal: 10.5s\tremaining: 3.52s\n",
      "150:\tlearn: 0.2999868\ttotal: 10.6s\tremaining: 3.44s\n",
      "151:\tlearn: 0.2987846\ttotal: 10.7s\tremaining: 3.37s\n",
      "152:\tlearn: 0.2980998\ttotal: 10.7s\tremaining: 3.3s\n",
      "153:\tlearn: 0.2968359\ttotal: 10.8s\tremaining: 3.23s\n",
      "154:\tlearn: 0.2963747\ttotal: 10.9s\tremaining: 3.16s\n",
      "155:\tlearn: 0.2957532\ttotal: 10.9s\tremaining: 3.08s\n",
      "156:\tlearn: 0.2949661\ttotal: 11s\tremaining: 3.01s\n",
      "157:\tlearn: 0.2940873\ttotal: 11.1s\tremaining: 2.94s\n",
      "158:\tlearn: 0.2936339\ttotal: 11.1s\tremaining: 2.87s\n",
      "159:\tlearn: 0.2925582\ttotal: 11.2s\tremaining: 2.8s\n",
      "160:\tlearn: 0.2920553\ttotal: 11.2s\tremaining: 2.72s\n",
      "161:\tlearn: 0.2910946\ttotal: 11.3s\tremaining: 2.65s\n",
      "162:\tlearn: 0.2896364\ttotal: 11.4s\tremaining: 2.59s\n",
      "163:\tlearn: 0.2879716\ttotal: 11.5s\tremaining: 2.52s\n",
      "164:\tlearn: 0.2867214\ttotal: 11.6s\tremaining: 2.45s\n",
      "165:\tlearn: 0.2854454\ttotal: 11.6s\tremaining: 2.38s\n",
      "166:\tlearn: 0.2841843\ttotal: 11.7s\tremaining: 2.31s\n",
      "167:\tlearn: 0.2823275\ttotal: 11.8s\tremaining: 2.24s\n",
      "168:\tlearn: 0.2817161\ttotal: 11.8s\tremaining: 2.17s\n",
      "169:\tlearn: 0.2802220\ttotal: 11.9s\tremaining: 2.1s\n",
      "170:\tlearn: 0.2783079\ttotal: 12s\tremaining: 2.03s\n",
      "171:\tlearn: 0.2774202\ttotal: 12.1s\tremaining: 1.96s\n",
      "172:\tlearn: 0.2754915\ttotal: 12.1s\tremaining: 1.89s\n",
      "173:\tlearn: 0.2746518\ttotal: 12.2s\tremaining: 1.82s\n",
      "174:\tlearn: 0.2735334\ttotal: 12.3s\tremaining: 1.75s\n",
      "175:\tlearn: 0.2729706\ttotal: 12.3s\tremaining: 1.68s\n",
      "176:\tlearn: 0.2715397\ttotal: 12.4s\tremaining: 1.61s\n",
      "177:\tlearn: 0.2696785\ttotal: 12.5s\tremaining: 1.54s\n",
      "178:\tlearn: 0.2687472\ttotal: 12.6s\tremaining: 1.47s\n",
      "179:\tlearn: 0.2679588\ttotal: 12.6s\tremaining: 1.4s\n",
      "180:\tlearn: 0.2652362\ttotal: 12.7s\tremaining: 1.33s\n",
      "181:\tlearn: 0.2643137\ttotal: 12.8s\tremaining: 1.26s\n",
      "182:\tlearn: 0.2638296\ttotal: 12.8s\tremaining: 1.19s\n",
      "183:\tlearn: 0.2627927\ttotal: 12.9s\tremaining: 1.12s\n",
      "184:\tlearn: 0.2618254\ttotal: 13s\tremaining: 1.05s\n",
      "185:\tlearn: 0.2615224\ttotal: 13s\tremaining: 981ms\n",
      "186:\tlearn: 0.2601623\ttotal: 13.1s\tremaining: 912ms\n",
      "187:\tlearn: 0.2588497\ttotal: 13.2s\tremaining: 843ms\n",
      "188:\tlearn: 0.2583114\ttotal: 13.3s\tremaining: 772ms\n",
      "189:\tlearn: 0.2573653\ttotal: 13.3s\tremaining: 701ms\n",
      "190:\tlearn: 0.2554569\ttotal: 13.4s\tremaining: 632ms\n",
      "191:\tlearn: 0.2550725\ttotal: 13.5s\tremaining: 561ms\n",
      "192:\tlearn: 0.2545906\ttotal: 13.5s\tremaining: 491ms\n",
      "193:\tlearn: 0.2538698\ttotal: 13.6s\tremaining: 420ms\n",
      "194:\tlearn: 0.2524481\ttotal: 13.7s\tremaining: 351ms\n",
      "195:\tlearn: 0.2518537\ttotal: 13.7s\tremaining: 280ms\n",
      "196:\tlearn: 0.2512907\ttotal: 13.8s\tremaining: 210ms\n",
      "197:\tlearn: 0.2505970\ttotal: 13.9s\tremaining: 140ms\n",
      "198:\tlearn: 0.2488402\ttotal: 13.9s\tremaining: 70ms\n",
      "199:\tlearn: 0.2481790\ttotal: 14s\tremaining: 0us\n",
      "0:\tlearn: 2.2673938\ttotal: 271ms\tremaining: 13.3s\n",
      "1:\tlearn: 2.2333218\ttotal: 546ms\tremaining: 13.1s\n",
      "2:\tlearn: 2.2011205\ttotal: 825ms\tremaining: 12.9s\n",
      "3:\tlearn: 2.1712990\ttotal: 1.1s\tremaining: 12.7s\n",
      "4:\tlearn: 2.1409528\ttotal: 1.38s\tremaining: 12.5s\n",
      "5:\tlearn: 2.1136404\ttotal: 1.65s\tremaining: 12.1s\n",
      "6:\tlearn: 2.0870102\ttotal: 1.93s\tremaining: 11.9s\n",
      "7:\tlearn: 2.0612172\ttotal: 2.21s\tremaining: 11.6s\n",
      "8:\tlearn: 2.0345898\ttotal: 2.51s\tremaining: 11.4s\n",
      "9:\tlearn: 2.0107693\ttotal: 2.79s\tremaining: 11.1s\n",
      "10:\tlearn: 1.9885799\ttotal: 3.07s\tremaining: 10.9s\n",
      "11:\tlearn: 1.9672853\ttotal: 3.36s\tremaining: 10.6s\n",
      "12:\tlearn: 1.9465835\ttotal: 3.64s\tremaining: 10.4s\n",
      "13:\tlearn: 1.9267541\ttotal: 3.92s\tremaining: 10.1s\n",
      "14:\tlearn: 1.9073327\ttotal: 4.2s\tremaining: 9.8s\n",
      "15:\tlearn: 1.8879555\ttotal: 4.49s\tremaining: 9.53s\n",
      "16:\tlearn: 1.8698446\ttotal: 4.76s\tremaining: 9.25s\n",
      "17:\tlearn: 1.8524154\ttotal: 5.04s\tremaining: 8.96s\n",
      "18:\tlearn: 1.8348135\ttotal: 5.32s\tremaining: 8.69s\n",
      "19:\tlearn: 1.8167583\ttotal: 5.61s\tremaining: 8.41s\n",
      "20:\tlearn: 1.8005195\ttotal: 5.89s\tremaining: 8.13s\n",
      "21:\tlearn: 1.7830541\ttotal: 6.17s\tremaining: 7.86s\n",
      "22:\tlearn: 1.7660927\ttotal: 6.47s\tremaining: 7.59s\n",
      "23:\tlearn: 1.7505340\ttotal: 6.75s\tremaining: 7.31s\n",
      "24:\tlearn: 1.7350243\ttotal: 7.03s\tremaining: 7.03s\n",
      "25:\tlearn: 1.7204197\ttotal: 7.32s\tremaining: 6.76s\n",
      "26:\tlearn: 1.7061317\ttotal: 7.61s\tremaining: 6.48s\n",
      "27:\tlearn: 1.6930708\ttotal: 7.89s\tremaining: 6.2s\n",
      "28:\tlearn: 1.6789393\ttotal: 8.19s\tremaining: 5.93s\n",
      "29:\tlearn: 1.6655962\ttotal: 8.47s\tremaining: 5.65s\n",
      "30:\tlearn: 1.6530749\ttotal: 8.75s\tremaining: 5.36s\n",
      "31:\tlearn: 1.6399162\ttotal: 9.04s\tremaining: 5.08s\n",
      "32:\tlearn: 1.6271479\ttotal: 9.33s\tremaining: 4.8s\n",
      "33:\tlearn: 1.6142222\ttotal: 9.62s\tremaining: 4.53s\n",
      "34:\tlearn: 1.6019316\ttotal: 9.9s\tremaining: 4.24s\n",
      "35:\tlearn: 1.5899986\ttotal: 10.2s\tremaining: 3.97s\n",
      "36:\tlearn: 1.5791980\ttotal: 10.5s\tremaining: 3.69s\n",
      "37:\tlearn: 1.5670542\ttotal: 10.8s\tremaining: 3.4s\n",
      "38:\tlearn: 1.5558176\ttotal: 11.1s\tremaining: 3.12s\n",
      "39:\tlearn: 1.5452011\ttotal: 11.4s\tremaining: 2.84s\n",
      "40:\tlearn: 1.5348511\ttotal: 11.6s\tremaining: 2.56s\n",
      "41:\tlearn: 1.5240529\ttotal: 11.9s\tremaining: 2.27s\n",
      "42:\tlearn: 1.5140522\ttotal: 12.2s\tremaining: 1.99s\n",
      "43:\tlearn: 1.5042739\ttotal: 12.5s\tremaining: 1.7s\n",
      "44:\tlearn: 1.4947875\ttotal: 12.8s\tremaining: 1.42s\n",
      "45:\tlearn: 1.4850110\ttotal: 13.1s\tremaining: 1.14s\n",
      "46:\tlearn: 1.4754400\ttotal: 13.4s\tremaining: 852ms\n",
      "47:\tlearn: 1.4653980\ttotal: 13.6s\tremaining: 568ms\n",
      "48:\tlearn: 1.4557138\ttotal: 13.9s\tremaining: 284ms\n",
      "49:\tlearn: 1.4463370\ttotal: 14.2s\tremaining: 0us\n",
      "0:\tlearn: 2.2658662\ttotal: 278ms\tremaining: 13.6s\n",
      "1:\tlearn: 2.2321196\ttotal: 559ms\tremaining: 13.4s\n",
      "2:\tlearn: 2.2000769\ttotal: 834ms\tremaining: 13.1s\n",
      "3:\tlearn: 2.1700152\ttotal: 1.11s\tremaining: 12.8s\n",
      "4:\tlearn: 2.1397933\ttotal: 1.39s\tremaining: 12.5s\n",
      "5:\tlearn: 2.1124022\ttotal: 1.67s\tremaining: 12.2s\n",
      "6:\tlearn: 2.0870195\ttotal: 1.94s\tremaining: 11.9s\n",
      "7:\tlearn: 2.0610816\ttotal: 2.23s\tremaining: 11.7s\n",
      "8:\tlearn: 2.0346797\ttotal: 2.52s\tremaining: 11.5s\n",
      "9:\tlearn: 2.0112394\ttotal: 2.8s\tremaining: 11.2s\n",
      "10:\tlearn: 1.9891258\ttotal: 3.08s\tremaining: 10.9s\n",
      "11:\tlearn: 1.9665233\ttotal: 3.37s\tremaining: 10.7s\n",
      "12:\tlearn: 1.9459449\ttotal: 3.64s\tremaining: 10.4s\n",
      "13:\tlearn: 1.9262198\ttotal: 3.92s\tremaining: 10.1s\n",
      "14:\tlearn: 1.9072866\ttotal: 4.2s\tremaining: 9.81s\n",
      "15:\tlearn: 1.8882567\ttotal: 4.49s\tremaining: 9.54s\n",
      "16:\tlearn: 1.8700881\ttotal: 4.77s\tremaining: 9.25s\n",
      "17:\tlearn: 1.8518151\ttotal: 5.05s\tremaining: 8.98s\n",
      "18:\tlearn: 1.8338730\ttotal: 5.33s\tremaining: 8.7s\n",
      "19:\tlearn: 1.8169242\ttotal: 5.62s\tremaining: 8.44s\n",
      "20:\tlearn: 1.8007661\ttotal: 5.9s\tremaining: 8.15s\n",
      "21:\tlearn: 1.7840747\ttotal: 6.19s\tremaining: 7.88s\n",
      "22:\tlearn: 1.7674244\ttotal: 6.49s\tremaining: 7.62s\n",
      "23:\tlearn: 1.7525202\ttotal: 6.77s\tremaining: 7.34s\n",
      "24:\tlearn: 1.7367955\ttotal: 7.06s\tremaining: 7.06s\n",
      "25:\tlearn: 1.7220128\ttotal: 7.36s\tremaining: 6.79s\n",
      "26:\tlearn: 1.7070051\ttotal: 7.65s\tremaining: 6.52s\n",
      "27:\tlearn: 1.6936101\ttotal: 7.93s\tremaining: 6.23s\n",
      "28:\tlearn: 1.6795383\ttotal: 8.22s\tremaining: 5.95s\n",
      "29:\tlearn: 1.6664890\ttotal: 8.5s\tremaining: 5.67s\n",
      "30:\tlearn: 1.6540412\ttotal: 8.78s\tremaining: 5.38s\n",
      "31:\tlearn: 1.6420332\ttotal: 9.06s\tremaining: 5.1s\n",
      "32:\tlearn: 1.6293734\ttotal: 9.35s\tremaining: 4.82s\n",
      "33:\tlearn: 1.6165076\ttotal: 9.63s\tremaining: 4.53s\n",
      "34:\tlearn: 1.6048963\ttotal: 9.92s\tremaining: 4.25s\n",
      "35:\tlearn: 1.5930459\ttotal: 10.2s\tremaining: 3.97s\n",
      "36:\tlearn: 1.5823790\ttotal: 10.5s\tremaining: 3.69s\n",
      "37:\tlearn: 1.5704712\ttotal: 10.8s\tremaining: 3.4s\n",
      "38:\tlearn: 1.5594392\ttotal: 11.1s\tremaining: 3.12s\n",
      "39:\tlearn: 1.5488511\ttotal: 11.3s\tremaining: 2.84s\n",
      "40:\tlearn: 1.5383351\ttotal: 11.6s\tremaining: 2.55s\n",
      "41:\tlearn: 1.5277579\ttotal: 12s\tremaining: 2.28s\n",
      "42:\tlearn: 1.5174808\ttotal: 12.2s\tremaining: 1.99s\n",
      "43:\tlearn: 1.5077700\ttotal: 12.5s\tremaining: 1.71s\n",
      "44:\tlearn: 1.4981677\ttotal: 12.8s\tremaining: 1.42s\n",
      "45:\tlearn: 1.4882478\ttotal: 13.1s\tremaining: 1.14s\n",
      "46:\tlearn: 1.4786084\ttotal: 13.4s\tremaining: 855ms\n",
      "47:\tlearn: 1.4697465\ttotal: 13.7s\tremaining: 570ms\n",
      "48:\tlearn: 1.4600768\ttotal: 14s\tremaining: 285ms\n",
      "49:\tlearn: 1.4508920\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 2.2658348\ttotal: 275ms\tremaining: 13.5s\n",
      "1:\tlearn: 2.2318670\ttotal: 555ms\tremaining: 13.3s\n",
      "2:\tlearn: 2.1995876\ttotal: 833ms\tremaining: 13s\n",
      "3:\tlearn: 2.1694404\ttotal: 1.11s\tremaining: 12.7s\n",
      "4:\tlearn: 2.1391886\ttotal: 1.39s\tremaining: 12.5s\n",
      "5:\tlearn: 2.1122518\ttotal: 1.67s\tremaining: 12.3s\n",
      "6:\tlearn: 2.0866065\ttotal: 1.95s\tremaining: 12s\n",
      "7:\tlearn: 2.0604940\ttotal: 2.23s\tremaining: 11.7s\n",
      "8:\tlearn: 2.0342440\ttotal: 2.52s\tremaining: 11.5s\n",
      "9:\tlearn: 2.0108247\ttotal: 2.8s\tremaining: 11.2s\n",
      "10:\tlearn: 1.9887644\ttotal: 3.08s\tremaining: 10.9s\n",
      "11:\tlearn: 1.9663554\ttotal: 3.38s\tremaining: 10.7s\n",
      "12:\tlearn: 1.9460161\ttotal: 3.66s\tremaining: 10.4s\n",
      "13:\tlearn: 1.9262526\ttotal: 3.94s\tremaining: 10.1s\n",
      "14:\tlearn: 1.9063746\ttotal: 4.22s\tremaining: 9.86s\n",
      "15:\tlearn: 1.8871857\ttotal: 4.53s\tremaining: 9.63s\n",
      "16:\tlearn: 1.8689453\ttotal: 4.81s\tremaining: 9.34s\n",
      "17:\tlearn: 1.8510906\ttotal: 5.1s\tremaining: 9.07s\n",
      "18:\tlearn: 1.8330862\ttotal: 5.39s\tremaining: 8.79s\n",
      "19:\tlearn: 1.8159929\ttotal: 5.67s\tremaining: 8.51s\n",
      "20:\tlearn: 1.7998444\ttotal: 5.95s\tremaining: 8.21s\n",
      "21:\tlearn: 1.7832012\ttotal: 6.24s\tremaining: 7.93s\n",
      "22:\tlearn: 1.7672822\ttotal: 6.52s\tremaining: 7.65s\n",
      "23:\tlearn: 1.7523322\ttotal: 6.81s\tremaining: 7.38s\n",
      "24:\tlearn: 1.7369720\ttotal: 7.1s\tremaining: 7.1s\n",
      "25:\tlearn: 1.7229644\ttotal: 7.38s\tremaining: 6.81s\n",
      "26:\tlearn: 1.7079435\ttotal: 7.67s\tremaining: 6.54s\n",
      "27:\tlearn: 1.6940111\ttotal: 7.96s\tremaining: 6.26s\n",
      "28:\tlearn: 1.6799941\ttotal: 8.25s\tremaining: 5.97s\n",
      "29:\tlearn: 1.6669424\ttotal: 8.53s\tremaining: 5.69s\n",
      "30:\tlearn: 1.6545551\ttotal: 8.81s\tremaining: 5.4s\n",
      "31:\tlearn: 1.6415428\ttotal: 9.1s\tremaining: 5.12s\n",
      "32:\tlearn: 1.6286692\ttotal: 9.39s\tremaining: 4.84s\n",
      "33:\tlearn: 1.6160027\ttotal: 9.68s\tremaining: 4.55s\n",
      "34:\tlearn: 1.6035782\ttotal: 9.97s\tremaining: 4.27s\n",
      "35:\tlearn: 1.5916527\ttotal: 10.3s\tremaining: 3.99s\n",
      "36:\tlearn: 1.5810683\ttotal: 10.5s\tremaining: 3.71s\n",
      "37:\tlearn: 1.5697625\ttotal: 10.8s\tremaining: 3.42s\n",
      "38:\tlearn: 1.5585202\ttotal: 11.1s\tremaining: 3.14s\n",
      "39:\tlearn: 1.5481518\ttotal: 11.4s\tremaining: 2.85s\n",
      "40:\tlearn: 1.5377913\ttotal: 11.7s\tremaining: 2.57s\n",
      "41:\tlearn: 1.5272234\ttotal: 12s\tremaining: 2.28s\n",
      "42:\tlearn: 1.5175372\ttotal: 12.3s\tremaining: 2s\n",
      "43:\tlearn: 1.5071924\ttotal: 12.6s\tremaining: 1.71s\n",
      "44:\tlearn: 1.4975511\ttotal: 12.9s\tremaining: 1.43s\n",
      "45:\tlearn: 1.4882345\ttotal: 13.1s\tremaining: 1.14s\n",
      "46:\tlearn: 1.4785427\ttotal: 13.4s\tremaining: 857ms\n",
      "47:\tlearn: 1.4693593\ttotal: 13.7s\tremaining: 572ms\n",
      "48:\tlearn: 1.4600600\ttotal: 14s\tremaining: 286ms\n",
      "49:\tlearn: 1.4509252\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 1.2891537\ttotal: 271ms\tremaining: 13.3s\n",
      "1:\tlearn: 1.0635618\ttotal: 557ms\tremaining: 13.4s\n",
      "2:\tlearn: 0.9281624\ttotal: 833ms\tremaining: 13.1s\n",
      "3:\tlearn: 0.8417570\ttotal: 1.13s\tremaining: 13s\n",
      "4:\tlearn: 0.7599713\ttotal: 1.43s\tremaining: 12.9s\n",
      "5:\tlearn: 0.7134519\ttotal: 1.73s\tremaining: 12.7s\n",
      "6:\tlearn: 0.6819323\ttotal: 2.01s\tremaining: 12.4s\n",
      "7:\tlearn: 0.6421344\ttotal: 2.3s\tremaining: 12.1s\n",
      "8:\tlearn: 0.6131799\ttotal: 2.58s\tremaining: 11.8s\n",
      "9:\tlearn: 0.5855527\ttotal: 2.87s\tremaining: 11.5s\n",
      "10:\tlearn: 0.5736969\ttotal: 3.14s\tremaining: 11.1s\n",
      "11:\tlearn: 0.5637071\ttotal: 3.42s\tremaining: 10.8s\n",
      "12:\tlearn: 0.5470339\ttotal: 3.72s\tremaining: 10.6s\n",
      "13:\tlearn: 0.5328172\ttotal: 3.99s\tremaining: 10.3s\n",
      "14:\tlearn: 0.5199291\ttotal: 4.28s\tremaining: 9.99s\n",
      "15:\tlearn: 0.5089275\ttotal: 4.56s\tremaining: 9.68s\n",
      "16:\tlearn: 0.5027604\ttotal: 4.84s\tremaining: 9.39s\n",
      "17:\tlearn: 0.4971283\ttotal: 5.12s\tremaining: 9.11s\n",
      "18:\tlearn: 0.4922164\ttotal: 5.39s\tremaining: 8.79s\n",
      "19:\tlearn: 0.4858211\ttotal: 5.66s\tremaining: 8.49s\n",
      "20:\tlearn: 0.4765633\ttotal: 5.94s\tremaining: 8.21s\n",
      "21:\tlearn: 0.4683197\ttotal: 6.23s\tremaining: 7.93s\n",
      "22:\tlearn: 0.4596810\ttotal: 6.5s\tremaining: 7.63s\n",
      "23:\tlearn: 0.4560721\ttotal: 6.77s\tremaining: 7.33s\n",
      "24:\tlearn: 0.4476011\ttotal: 7.05s\tremaining: 7.05s\n",
      "25:\tlearn: 0.4425884\ttotal: 7.32s\tremaining: 6.76s\n",
      "26:\tlearn: 0.4400161\ttotal: 7.58s\tremaining: 6.46s\n",
      "27:\tlearn: 0.4356819\ttotal: 7.86s\tremaining: 6.18s\n",
      "28:\tlearn: 0.4308022\ttotal: 8.14s\tremaining: 5.89s\n",
      "29:\tlearn: 0.4247129\ttotal: 8.42s\tremaining: 5.61s\n",
      "30:\tlearn: 0.4214119\ttotal: 8.69s\tremaining: 5.32s\n",
      "31:\tlearn: 0.4146935\ttotal: 8.97s\tremaining: 5.04s\n",
      "32:\tlearn: 0.4035699\ttotal: 9.26s\tremaining: 4.77s\n",
      "33:\tlearn: 0.3972906\ttotal: 9.53s\tremaining: 4.48s\n",
      "34:\tlearn: 0.3922274\ttotal: 9.8s\tremaining: 4.2s\n",
      "35:\tlearn: 0.3879774\ttotal: 10.1s\tremaining: 3.92s\n",
      "36:\tlearn: 0.3864630\ttotal: 10.3s\tremaining: 3.64s\n",
      "37:\tlearn: 0.3838449\ttotal: 10.6s\tremaining: 3.35s\n",
      "38:\tlearn: 0.3799694\ttotal: 10.9s\tremaining: 3.07s\n",
      "39:\tlearn: 0.3759426\ttotal: 11.2s\tremaining: 2.79s\n",
      "40:\tlearn: 0.3722526\ttotal: 11.4s\tremaining: 2.51s\n",
      "41:\tlearn: 0.3699576\ttotal: 11.7s\tremaining: 2.23s\n",
      "42:\tlearn: 0.3667690\ttotal: 12s\tremaining: 1.95s\n",
      "43:\tlearn: 0.3642207\ttotal: 12.3s\tremaining: 1.67s\n",
      "44:\tlearn: 0.3616298\ttotal: 12.5s\tremaining: 1.39s\n",
      "45:\tlearn: 0.3591593\ttotal: 12.8s\tremaining: 1.11s\n",
      "46:\tlearn: 0.3577433\ttotal: 13.1s\tremaining: 835ms\n",
      "47:\tlearn: 0.3549495\ttotal: 13.4s\tremaining: 556ms\n",
      "48:\tlearn: 0.3519899\ttotal: 13.6s\tremaining: 278ms\n",
      "49:\tlearn: 0.3509037\ttotal: 13.9s\tremaining: 0us\n",
      "0:\tlearn: 1.2453824\ttotal: 275ms\tremaining: 13.5s\n",
      "1:\tlearn: 1.0460857\ttotal: 550ms\tremaining: 13.2s\n",
      "2:\tlearn: 0.9075354\ttotal: 845ms\tremaining: 13.2s\n",
      "3:\tlearn: 0.8161234\ttotal: 1.13s\tremaining: 13s\n",
      "4:\tlearn: 0.7571292\ttotal: 1.42s\tremaining: 12.8s\n",
      "5:\tlearn: 0.7033798\ttotal: 1.71s\tremaining: 12.5s\n",
      "6:\tlearn: 0.6682388\ttotal: 1.99s\tremaining: 12.2s\n",
      "7:\tlearn: 0.6332849\ttotal: 2.27s\tremaining: 11.9s\n",
      "8:\tlearn: 0.6102045\ttotal: 2.55s\tremaining: 11.6s\n",
      "9:\tlearn: 0.5819260\ttotal: 2.84s\tremaining: 11.4s\n",
      "10:\tlearn: 0.5699302\ttotal: 3.12s\tremaining: 11.1s\n",
      "11:\tlearn: 0.5590179\ttotal: 3.4s\tremaining: 10.8s\n",
      "12:\tlearn: 0.5426648\ttotal: 3.68s\tremaining: 10.5s\n",
      "13:\tlearn: 0.5358060\ttotal: 3.95s\tremaining: 10.2s\n",
      "14:\tlearn: 0.5237043\ttotal: 4.25s\tremaining: 9.91s\n",
      "15:\tlearn: 0.5109553\ttotal: 4.54s\tremaining: 9.64s\n",
      "16:\tlearn: 0.5051187\ttotal: 4.82s\tremaining: 9.35s\n",
      "17:\tlearn: 0.4983362\ttotal: 5.1s\tremaining: 9.06s\n",
      "18:\tlearn: 0.4877593\ttotal: 5.38s\tremaining: 8.78s\n",
      "19:\tlearn: 0.4773902\ttotal: 5.67s\tremaining: 8.5s\n",
      "20:\tlearn: 0.4714455\ttotal: 5.94s\tremaining: 8.2s\n",
      "21:\tlearn: 0.4626222\ttotal: 6.22s\tremaining: 7.92s\n",
      "22:\tlearn: 0.4575152\ttotal: 6.49s\tremaining: 7.62s\n",
      "23:\tlearn: 0.4518861\ttotal: 6.78s\tremaining: 7.34s\n",
      "24:\tlearn: 0.4489304\ttotal: 7.05s\tremaining: 7.05s\n",
      "25:\tlearn: 0.4419995\ttotal: 7.32s\tremaining: 6.76s\n",
      "26:\tlearn: 0.4358793\ttotal: 7.61s\tremaining: 6.48s\n",
      "27:\tlearn: 0.4318121\ttotal: 7.88s\tremaining: 6.19s\n",
      "28:\tlearn: 0.4281226\ttotal: 8.16s\tremaining: 5.91s\n",
      "29:\tlearn: 0.4235008\ttotal: 8.44s\tremaining: 5.62s\n",
      "30:\tlearn: 0.4211903\ttotal: 8.71s\tremaining: 5.34s\n",
      "31:\tlearn: 0.4141696\ttotal: 8.99s\tremaining: 5.06s\n",
      "32:\tlearn: 0.4108934\ttotal: 9.26s\tremaining: 4.77s\n",
      "33:\tlearn: 0.4080736\ttotal: 9.52s\tremaining: 4.48s\n",
      "34:\tlearn: 0.4023072\ttotal: 9.79s\tremaining: 4.2s\n",
      "35:\tlearn: 0.3991582\ttotal: 10.1s\tremaining: 3.91s\n",
      "36:\tlearn: 0.3924196\ttotal: 10.3s\tremaining: 3.63s\n",
      "37:\tlearn: 0.3909637\ttotal: 10.6s\tremaining: 3.35s\n",
      "38:\tlearn: 0.3856940\ttotal: 10.9s\tremaining: 3.07s\n",
      "39:\tlearn: 0.3838430\ttotal: 11.1s\tremaining: 2.79s\n",
      "40:\tlearn: 0.3800581\ttotal: 11.4s\tremaining: 2.51s\n",
      "41:\tlearn: 0.3765109\ttotal: 11.7s\tremaining: 2.23s\n",
      "42:\tlearn: 0.3738568\ttotal: 12s\tremaining: 1.95s\n",
      "43:\tlearn: 0.3700673\ttotal: 12.2s\tremaining: 1.67s\n",
      "44:\tlearn: 0.3657037\ttotal: 12.5s\tremaining: 1.39s\n",
      "45:\tlearn: 0.3639628\ttotal: 12.8s\tremaining: 1.11s\n",
      "46:\tlearn: 0.3599310\ttotal: 13.1s\tremaining: 834ms\n",
      "47:\tlearn: 0.3582642\ttotal: 13.3s\tremaining: 556ms\n",
      "48:\tlearn: 0.3555223\ttotal: 13.6s\tremaining: 278ms\n",
      "49:\tlearn: 0.3515570\ttotal: 13.9s\tremaining: 0us\n",
      "0:\tlearn: 1.2503068\ttotal: 272ms\tremaining: 13.3s\n",
      "1:\tlearn: 1.0477035\ttotal: 546ms\tremaining: 13.1s\n",
      "2:\tlearn: 0.9116336\ttotal: 828ms\tremaining: 13s\n",
      "3:\tlearn: 0.8324993\ttotal: 1.12s\tremaining: 12.9s\n",
      "4:\tlearn: 0.7706255\ttotal: 1.39s\tremaining: 12.5s\n",
      "5:\tlearn: 0.7187089\ttotal: 1.67s\tremaining: 12.3s\n",
      "6:\tlearn: 0.6785269\ttotal: 1.95s\tremaining: 12s\n",
      "7:\tlearn: 0.6421193\ttotal: 2.24s\tremaining: 11.7s\n",
      "8:\tlearn: 0.6068233\ttotal: 2.54s\tremaining: 11.6s\n",
      "9:\tlearn: 0.5786453\ttotal: 2.83s\tremaining: 11.3s\n",
      "10:\tlearn: 0.5635693\ttotal: 3.11s\tremaining: 11s\n",
      "11:\tlearn: 0.5501816\ttotal: 3.4s\tremaining: 10.8s\n",
      "12:\tlearn: 0.5345276\ttotal: 3.69s\tremaining: 10.5s\n",
      "13:\tlearn: 0.5252909\ttotal: 3.97s\tremaining: 10.2s\n",
      "14:\tlearn: 0.5117636\ttotal: 4.25s\tremaining: 9.93s\n",
      "15:\tlearn: 0.5053637\ttotal: 4.53s\tremaining: 9.62s\n",
      "16:\tlearn: 0.4991372\ttotal: 4.8s\tremaining: 9.32s\n",
      "17:\tlearn: 0.4899824\ttotal: 5.1s\tremaining: 9.07s\n",
      "18:\tlearn: 0.4817277\ttotal: 5.38s\tremaining: 8.78s\n",
      "19:\tlearn: 0.4712011\ttotal: 5.68s\tremaining: 8.52s\n",
      "20:\tlearn: 0.4663543\ttotal: 5.96s\tremaining: 8.22s\n",
      "21:\tlearn: 0.4620317\ttotal: 6.23s\tremaining: 7.92s\n",
      "22:\tlearn: 0.4566709\ttotal: 6.51s\tremaining: 7.65s\n",
      "23:\tlearn: 0.4469512\ttotal: 6.8s\tremaining: 7.37s\n",
      "24:\tlearn: 0.4431239\ttotal: 7.07s\tremaining: 7.07s\n",
      "25:\tlearn: 0.4396459\ttotal: 7.34s\tremaining: 6.77s\n",
      "26:\tlearn: 0.4343429\ttotal: 7.6s\tremaining: 6.47s\n",
      "27:\tlearn: 0.4263729\ttotal: 7.88s\tremaining: 6.19s\n",
      "28:\tlearn: 0.4216622\ttotal: 8.16s\tremaining: 5.91s\n",
      "29:\tlearn: 0.4165220\ttotal: 8.44s\tremaining: 5.63s\n",
      "30:\tlearn: 0.4131043\ttotal: 8.7s\tremaining: 5.33s\n",
      "31:\tlearn: 0.4041856\ttotal: 9s\tremaining: 5.06s\n",
      "32:\tlearn: 0.4010008\ttotal: 9.27s\tremaining: 4.77s\n",
      "33:\tlearn: 0.3975883\ttotal: 9.55s\tremaining: 4.49s\n",
      "34:\tlearn: 0.3938106\ttotal: 9.82s\tremaining: 4.21s\n",
      "35:\tlearn: 0.3895686\ttotal: 10.1s\tremaining: 3.93s\n",
      "36:\tlearn: 0.3846725\ttotal: 10.4s\tremaining: 3.65s\n",
      "37:\tlearn: 0.3829916\ttotal: 10.7s\tremaining: 3.36s\n",
      "38:\tlearn: 0.3794315\ttotal: 10.9s\tremaining: 3.08s\n",
      "39:\tlearn: 0.3749970\ttotal: 11.2s\tremaining: 2.8s\n",
      "40:\tlearn: 0.3733725\ttotal: 11.5s\tremaining: 2.52s\n",
      "41:\tlearn: 0.3698827\ttotal: 11.7s\tremaining: 2.23s\n",
      "42:\tlearn: 0.3683926\ttotal: 12s\tremaining: 1.96s\n",
      "43:\tlearn: 0.3659456\ttotal: 12.3s\tremaining: 1.68s\n",
      "44:\tlearn: 0.3637099\ttotal: 12.6s\tremaining: 1.39s\n",
      "45:\tlearn: 0.3621563\ttotal: 12.8s\tremaining: 1.11s\n",
      "46:\tlearn: 0.3588678\ttotal: 13.1s\tremaining: 836ms\n",
      "47:\tlearn: 0.3566979\ttotal: 13.4s\tremaining: 557ms\n",
      "48:\tlearn: 0.3543719\ttotal: 13.6s\tremaining: 278ms\n",
      "49:\tlearn: 0.3523474\ttotal: 13.9s\tremaining: 0us\n",
      "0:\tlearn: 1.5304652\ttotal: 270ms\tremaining: 13.2s\n",
      "1:\tlearn: 3.9594276\ttotal: 561ms\tremaining: 13.5s\n",
      "2:\tlearn: 22.8090832\ttotal: 846ms\tremaining: 13.3s\n",
      "3:\tlearn: 14.1684297\ttotal: 1.14s\tremaining: 13.1s\n",
      "4:\tlearn: 13.4715753\ttotal: 1.42s\tremaining: 12.8s\n",
      "5:\tlearn: 12.1525011\ttotal: 1.72s\tremaining: 12.6s\n",
      "6:\tlearn: 10.9711181\ttotal: 2s\tremaining: 12.3s\n",
      "7:\tlearn: 10.3372942\ttotal: 2.3s\tremaining: 12.1s\n",
      "8:\tlearn: 10.3191299\ttotal: 2.59s\tremaining: 11.8s\n",
      "9:\tlearn: 9.2994778\ttotal: 2.88s\tremaining: 11.5s\n",
      "10:\tlearn: 8.9432314\ttotal: 3.17s\tremaining: 11.2s\n",
      "11:\tlearn: 8.7004866\ttotal: 3.46s\tremaining: 11s\n",
      "12:\tlearn: 8.5347425\ttotal: 3.76s\tremaining: 10.7s\n",
      "13:\tlearn: 8.3822425\ttotal: 4.03s\tremaining: 10.4s\n",
      "14:\tlearn: 8.1667093\ttotal: 4.31s\tremaining: 10.1s\n",
      "15:\tlearn: 8.0273147\ttotal: 4.59s\tremaining: 9.76s\n",
      "16:\tlearn: 7.8583587\ttotal: 4.88s\tremaining: 9.47s\n",
      "17:\tlearn: 7.7132111\ttotal: 5.16s\tremaining: 9.18s\n",
      "18:\tlearn: 7.4960955\ttotal: 5.45s\tremaining: 8.89s\n",
      "19:\tlearn: 7.4246610\ttotal: 5.71s\tremaining: 8.57s\n",
      "20:\tlearn: 7.3578026\ttotal: 5.99s\tremaining: 8.27s\n",
      "21:\tlearn: 7.2548322\ttotal: 6.28s\tremaining: 7.99s\n",
      "22:\tlearn: 7.2118065\ttotal: 6.54s\tremaining: 7.68s\n",
      "23:\tlearn: 7.1460010\ttotal: 6.82s\tremaining: 7.39s\n",
      "24:\tlearn: 7.0230654\ttotal: 7.09s\tremaining: 7.09s\n",
      "25:\tlearn: 6.8799874\ttotal: 7.38s\tremaining: 6.81s\n",
      "26:\tlearn: 6.6813121\ttotal: 7.67s\tremaining: 6.53s\n",
      "27:\tlearn: 6.6127516\ttotal: 7.93s\tremaining: 6.23s\n",
      "28:\tlearn: 6.5803724\ttotal: 8.21s\tremaining: 5.94s\n",
      "29:\tlearn: 6.5439883\ttotal: 8.46s\tremaining: 5.64s\n",
      "30:\tlearn: 6.5023767\ttotal: 8.72s\tremaining: 5.35s\n",
      "31:\tlearn: 6.4776322\ttotal: 9s\tremaining: 5.06s\n",
      "32:\tlearn: 6.3814886\ttotal: 9.28s\tremaining: 4.78s\n",
      "33:\tlearn: 6.3518612\ttotal: 9.55s\tremaining: 4.49s\n",
      "34:\tlearn: 6.3091767\ttotal: 9.82s\tremaining: 4.21s\n",
      "35:\tlearn: 6.2630024\ttotal: 10.1s\tremaining: 3.93s\n",
      "36:\tlearn: 6.2341382\ttotal: 10.4s\tremaining: 3.64s\n",
      "37:\tlearn: 6.2085123\ttotal: 10.6s\tremaining: 3.35s\n",
      "38:\tlearn: 6.1937622\ttotal: 10.9s\tremaining: 3.07s\n",
      "39:\tlearn: 6.1714935\ttotal: 11.2s\tremaining: 2.79s\n",
      "40:\tlearn: 6.1236106\ttotal: 11.4s\tremaining: 2.5s\n",
      "41:\tlearn: 6.1085439\ttotal: 11.7s\tremaining: 2.23s\n",
      "42:\tlearn: 6.0758630\ttotal: 12s\tremaining: 1.95s\n",
      "43:\tlearn: 6.0639140\ttotal: 12.2s\tremaining: 1.67s\n",
      "44:\tlearn: 5.9118809\ttotal: 12.5s\tremaining: 1.39s\n",
      "45:\tlearn: 5.8778706\ttotal: 12.8s\tremaining: 1.11s\n",
      "46:\tlearn: 5.8616648\ttotal: 13s\tremaining: 832ms\n",
      "47:\tlearn: 5.8408098\ttotal: 13.3s\tremaining: 554ms\n",
      "48:\tlearn: 5.8146740\ttotal: 13.6s\tremaining: 277ms\n",
      "49:\tlearn: 5.7920405\ttotal: 13.8s\tremaining: 0us\n",
      "0:\tlearn: 1.4178636\ttotal: 276ms\tremaining: 13.5s\n",
      "1:\tlearn: 4.2154843\ttotal: 557ms\tremaining: 13.4s\n",
      "2:\tlearn: 13.1777011\ttotal: 835ms\tremaining: 13.1s\n",
      "3:\tlearn: 14.2806637\ttotal: 1.11s\tremaining: 12.7s\n",
      "4:\tlearn: 16.4422268\ttotal: 1.39s\tremaining: 12.5s\n",
      "5:\tlearn: 27.6912923\ttotal: 1.68s\tremaining: 12.3s\n",
      "6:\tlearn: 25.8154626\ttotal: 1.99s\tremaining: 12.2s\n",
      "7:\tlearn: 30.0826418\ttotal: 2.29s\tremaining: 12s\n",
      "8:\tlearn: 27.7295839\ttotal: 2.57s\tremaining: 11.7s\n",
      "9:\tlearn: 26.5603629\ttotal: 2.85s\tremaining: 11.4s\n",
      "10:\tlearn: 25.4710872\ttotal: 3.13s\tremaining: 11.1s\n",
      "11:\tlearn: 24.5573572\ttotal: 3.42s\tremaining: 10.8s\n",
      "12:\tlearn: 23.3305677\ttotal: 3.72s\tremaining: 10.6s\n",
      "13:\tlearn: 22.3812545\ttotal: 4.01s\tremaining: 10.3s\n",
      "14:\tlearn: 21.7156230\ttotal: 4.3s\tremaining: 10s\n",
      "15:\tlearn: 21.2362963\ttotal: 4.59s\tremaining: 9.77s\n",
      "16:\tlearn: 20.9976871\ttotal: 4.88s\tremaining: 9.47s\n",
      "17:\tlearn: 20.5050044\ttotal: 5.13s\tremaining: 9.13s\n",
      "18:\tlearn: 20.2809683\ttotal: 5.44s\tremaining: 8.88s\n",
      "19:\tlearn: 19.4951735\ttotal: 5.72s\tremaining: 8.58s\n",
      "20:\tlearn: 19.2542500\ttotal: 6s\tremaining: 8.29s\n",
      "21:\tlearn: 18.8277794\ttotal: 6.3s\tremaining: 8.02s\n",
      "22:\tlearn: 18.6695371\ttotal: 6.57s\tremaining: 7.71s\n",
      "23:\tlearn: 18.5222050\ttotal: 6.84s\tremaining: 7.41s\n",
      "24:\tlearn: 18.2660869\ttotal: 7.13s\tremaining: 7.13s\n",
      "25:\tlearn: 17.9608755\ttotal: 7.41s\tremaining: 6.84s\n",
      "26:\tlearn: 17.8494076\ttotal: 7.68s\tremaining: 6.54s\n",
      "27:\tlearn: 17.7754424\ttotal: 7.95s\tremaining: 6.24s\n",
      "28:\tlearn: 17.5455198\ttotal: 8.24s\tremaining: 5.97s\n",
      "29:\tlearn: 17.5035272\ttotal: 8.51s\tremaining: 5.67s\n",
      "30:\tlearn: 17.4060362\ttotal: 8.78s\tremaining: 5.38s\n",
      "31:\tlearn: 17.3391421\ttotal: 9.04s\tremaining: 5.09s\n",
      "32:\tlearn: 16.6237532\ttotal: 9.36s\tremaining: 4.82s\n",
      "33:\tlearn: 16.4854877\ttotal: 9.64s\tremaining: 4.53s\n",
      "34:\tlearn: 15.9928585\ttotal: 9.93s\tremaining: 4.25s\n",
      "35:\tlearn: 15.7140192\ttotal: 10.2s\tremaining: 3.97s\n",
      "36:\tlearn: 15.6522244\ttotal: 10.5s\tremaining: 3.68s\n",
      "37:\tlearn: 15.2758985\ttotal: 10.8s\tremaining: 3.4s\n",
      "38:\tlearn: 15.1149175\ttotal: 11.1s\tremaining: 3.12s\n",
      "39:\tlearn: 14.9202555\ttotal: 11.3s\tremaining: 2.83s\n",
      "40:\tlearn: 14.3822511\ttotal: 11.6s\tremaining: 2.55s\n",
      "41:\tlearn: 14.2305127\ttotal: 11.9s\tremaining: 2.26s\n",
      "42:\tlearn: 13.9377907\ttotal: 12.2s\tremaining: 1.98s\n",
      "43:\tlearn: 13.4553489\ttotal: 12.5s\tremaining: 1.7s\n",
      "44:\tlearn: 13.4055203\ttotal: 12.7s\tremaining: 1.41s\n",
      "45:\tlearn: 13.3244871\ttotal: 13s\tremaining: 1.13s\n",
      "46:\tlearn: 13.0807672\ttotal: 13.3s\tremaining: 848ms\n",
      "47:\tlearn: 12.9843008\ttotal: 13.6s\tremaining: 565ms\n",
      "48:\tlearn: 12.9570908\ttotal: 13.8s\tremaining: 282ms\n",
      "49:\tlearn: 12.7634920\ttotal: 14.1s\tremaining: 0us\n",
      "0:\tlearn: 1.4243817\ttotal: 273ms\tremaining: 13.4s\n",
      "1:\tlearn: 2.4462211\ttotal: 554ms\tremaining: 13.3s\n",
      "2:\tlearn: 12.7209456\ttotal: 845ms\tremaining: 13.2s\n",
      "3:\tlearn: 10.8348138\ttotal: 1.12s\tremaining: 12.9s\n",
      "4:\tlearn: 10.3888988\ttotal: 1.42s\tremaining: 12.8s\n",
      "5:\tlearn: 10.1636458\ttotal: 1.7s\tremaining: 12.5s\n",
      "6:\tlearn: 8.8300284\ttotal: 1.98s\tremaining: 12.2s\n",
      "7:\tlearn: 10.4688496\ttotal: 2.29s\tremaining: 12s\n",
      "8:\tlearn: 9.4708793\ttotal: 2.57s\tremaining: 11.7s\n",
      "9:\tlearn: 8.9756507\ttotal: 2.86s\tremaining: 11.5s\n",
      "10:\tlearn: 9.1636987\ttotal: 3.16s\tremaining: 11.2s\n",
      "11:\tlearn: 8.5103581\ttotal: 3.44s\tremaining: 10.9s\n",
      "12:\tlearn: 7.7510597\ttotal: 3.74s\tremaining: 10.6s\n",
      "13:\tlearn: 7.3143430\ttotal: 4.03s\tremaining: 10.4s\n",
      "14:\tlearn: 6.7871872\ttotal: 4.32s\tremaining: 10.1s\n",
      "15:\tlearn: 6.6276053\ttotal: 4.6s\tremaining: 9.78s\n",
      "16:\tlearn: 6.4796052\ttotal: 4.9s\tremaining: 9.51s\n",
      "17:\tlearn: 6.1936373\ttotal: 5.2s\tremaining: 9.25s\n",
      "18:\tlearn: 6.0568934\ttotal: 5.49s\tremaining: 8.95s\n",
      "19:\tlearn: 5.9583625\ttotal: 5.77s\tremaining: 8.66s\n",
      "20:\tlearn: 5.8727198\ttotal: 6.05s\tremaining: 8.36s\n",
      "21:\tlearn: 5.7843573\ttotal: 6.34s\tremaining: 8.07s\n",
      "22:\tlearn: 5.7522106\ttotal: 6.62s\tremaining: 7.77s\n",
      "23:\tlearn: 5.7154066\ttotal: 6.88s\tremaining: 7.46s\n",
      "24:\tlearn: 5.6507107\ttotal: 7.16s\tremaining: 7.16s\n",
      "25:\tlearn: 5.5841829\ttotal: 7.45s\tremaining: 6.88s\n",
      "26:\tlearn: 5.5350633\ttotal: 7.72s\tremaining: 6.57s\n",
      "27:\tlearn: 5.3846441\ttotal: 7.99s\tremaining: 6.28s\n",
      "28:\tlearn: 5.3446222\ttotal: 8.26s\tremaining: 5.98s\n",
      "29:\tlearn: 5.3197164\ttotal: 8.52s\tremaining: 5.68s\n",
      "30:\tlearn: 5.2526150\ttotal: 8.8s\tremaining: 5.39s\n",
      "31:\tlearn: 5.2068206\ttotal: 9.08s\tremaining: 5.11s\n",
      "32:\tlearn: 5.1773428\ttotal: 9.35s\tremaining: 4.82s\n",
      "33:\tlearn: 5.1502752\ttotal: 9.62s\tremaining: 4.53s\n",
      "34:\tlearn: 5.1246120\ttotal: 9.88s\tremaining: 4.23s\n",
      "35:\tlearn: 5.0870947\ttotal: 10.2s\tremaining: 3.95s\n",
      "36:\tlearn: 5.0647698\ttotal: 10.4s\tremaining: 3.66s\n",
      "37:\tlearn: 4.9455085\ttotal: 10.7s\tremaining: 3.38s\n",
      "38:\tlearn: 4.9205463\ttotal: 11s\tremaining: 3.1s\n",
      "39:\tlearn: 4.9045241\ttotal: 11.2s\tremaining: 2.81s\n",
      "40:\tlearn: 4.8897192\ttotal: 11.5s\tremaining: 2.52s\n",
      "41:\tlearn: 4.8760849\ttotal: 11.8s\tremaining: 2.24s\n",
      "42:\tlearn: 4.8639433\ttotal: 12s\tremaining: 1.96s\n",
      "43:\tlearn: 4.8491512\ttotal: 12.3s\tremaining: 1.68s\n",
      "44:\tlearn: 4.8157987\ttotal: 12.6s\tremaining: 1.4s\n",
      "45:\tlearn: 4.8060961\ttotal: 12.8s\tremaining: 1.11s\n",
      "46:\tlearn: 4.7729003\ttotal: 13.1s\tremaining: 837ms\n",
      "47:\tlearn: 4.6833486\ttotal: 13.4s\tremaining: 558ms\n",
      "48:\tlearn: 4.6691795\ttotal: 13.7s\tremaining: 279ms\n",
      "49:\tlearn: 4.6634250\ttotal: 13.9s\tremaining: 0us\n",
      "0:\tlearn: 2.2673938\ttotal: 270ms\tremaining: 26.8s\n",
      "1:\tlearn: 2.2333218\ttotal: 547ms\tremaining: 26.8s\n",
      "2:\tlearn: 2.2011205\ttotal: 821ms\tremaining: 26.6s\n",
      "3:\tlearn: 2.1712990\ttotal: 1.1s\tremaining: 26.3s\n",
      "4:\tlearn: 2.1409528\ttotal: 1.38s\tremaining: 26.2s\n",
      "5:\tlearn: 2.1136404\ttotal: 1.65s\tremaining: 25.9s\n",
      "6:\tlearn: 2.0870102\ttotal: 1.93s\tremaining: 25.6s\n",
      "7:\tlearn: 2.0612172\ttotal: 2.21s\tremaining: 25.4s\n",
      "8:\tlearn: 2.0345898\ttotal: 2.5s\tremaining: 25.3s\n",
      "9:\tlearn: 2.0107693\ttotal: 2.78s\tremaining: 25s\n",
      "10:\tlearn: 1.9885799\ttotal: 3.06s\tremaining: 24.7s\n",
      "11:\tlearn: 1.9672853\ttotal: 3.33s\tremaining: 24.4s\n",
      "12:\tlearn: 1.9465835\ttotal: 3.61s\tremaining: 24.2s\n",
      "13:\tlearn: 1.9267541\ttotal: 3.89s\tremaining: 23.9s\n",
      "14:\tlearn: 1.9073327\ttotal: 4.17s\tremaining: 23.6s\n",
      "15:\tlearn: 1.8879555\ttotal: 4.45s\tremaining: 23.4s\n",
      "16:\tlearn: 1.8698446\ttotal: 4.73s\tremaining: 23.1s\n",
      "17:\tlearn: 1.8524154\ttotal: 5s\tremaining: 22.8s\n",
      "18:\tlearn: 1.8348135\ttotal: 5.28s\tremaining: 22.5s\n",
      "19:\tlearn: 1.8167583\ttotal: 5.59s\tremaining: 22.4s\n",
      "20:\tlearn: 1.8005195\ttotal: 5.86s\tremaining: 22.1s\n",
      "21:\tlearn: 1.7830541\ttotal: 6.14s\tremaining: 21.8s\n",
      "22:\tlearn: 1.7660927\ttotal: 6.44s\tremaining: 21.5s\n",
      "23:\tlearn: 1.7505340\ttotal: 6.71s\tremaining: 21.3s\n",
      "24:\tlearn: 1.7350243\ttotal: 7s\tremaining: 21s\n",
      "25:\tlearn: 1.7204197\ttotal: 7.29s\tremaining: 20.7s\n",
      "26:\tlearn: 1.7061317\ttotal: 7.57s\tremaining: 20.5s\n",
      "27:\tlearn: 1.6930708\ttotal: 7.85s\tremaining: 20.2s\n",
      "28:\tlearn: 1.6789393\ttotal: 8.13s\tremaining: 19.9s\n",
      "29:\tlearn: 1.6655962\ttotal: 8.41s\tremaining: 19.6s\n",
      "30:\tlearn: 1.6530749\ttotal: 8.69s\tremaining: 19.3s\n",
      "31:\tlearn: 1.6399162\ttotal: 8.98s\tremaining: 19.1s\n",
      "32:\tlearn: 1.6271479\ttotal: 9.26s\tremaining: 18.8s\n",
      "33:\tlearn: 1.6142222\ttotal: 9.55s\tremaining: 18.5s\n",
      "34:\tlearn: 1.6019316\ttotal: 9.83s\tremaining: 18.3s\n",
      "35:\tlearn: 1.5899986\ttotal: 10.1s\tremaining: 18s\n",
      "36:\tlearn: 1.5791980\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 1.5670542\ttotal: 10.7s\tremaining: 17.4s\n",
      "38:\tlearn: 1.5558176\ttotal: 11s\tremaining: 17.2s\n",
      "39:\tlearn: 1.5452011\ttotal: 11.3s\tremaining: 16.9s\n",
      "40:\tlearn: 1.5348511\ttotal: 11.5s\tremaining: 16.6s\n",
      "41:\tlearn: 1.5240529\ttotal: 11.8s\tremaining: 16.3s\n",
      "42:\tlearn: 1.5140522\ttotal: 12.1s\tremaining: 16s\n",
      "43:\tlearn: 1.5042739\ttotal: 12.4s\tremaining: 15.8s\n",
      "44:\tlearn: 1.4947875\ttotal: 12.7s\tremaining: 15.5s\n",
      "45:\tlearn: 1.4850110\ttotal: 12.9s\tremaining: 15.2s\n",
      "46:\tlearn: 1.4754400\ttotal: 13.2s\tremaining: 14.9s\n",
      "47:\tlearn: 1.4653980\ttotal: 13.5s\tremaining: 14.6s\n",
      "48:\tlearn: 1.4557138\ttotal: 13.8s\tremaining: 14.4s\n",
      "49:\tlearn: 1.4463370\ttotal: 14.1s\tremaining: 14.1s\n",
      "50:\tlearn: 1.4380509\ttotal: 14.4s\tremaining: 13.8s\n",
      "51:\tlearn: 1.4287553\ttotal: 14.7s\tremaining: 13.5s\n",
      "52:\tlearn: 1.4201901\ttotal: 14.9s\tremaining: 13.3s\n",
      "53:\tlearn: 1.4115870\ttotal: 15.2s\tremaining: 13s\n",
      "54:\tlearn: 1.4029148\ttotal: 15.5s\tremaining: 12.7s\n",
      "55:\tlearn: 1.3943630\ttotal: 15.8s\tremaining: 12.4s\n",
      "56:\tlearn: 1.3866313\ttotal: 16.1s\tremaining: 12.1s\n",
      "57:\tlearn: 1.3788452\ttotal: 16.4s\tremaining: 11.9s\n",
      "58:\tlearn: 1.3713696\ttotal: 16.7s\tremaining: 11.6s\n",
      "59:\tlearn: 1.3635481\ttotal: 16.9s\tremaining: 11.3s\n",
      "60:\tlearn: 1.3559909\ttotal: 17.2s\tremaining: 11s\n",
      "61:\tlearn: 1.3483509\ttotal: 17.5s\tremaining: 10.8s\n",
      "62:\tlearn: 1.3408879\ttotal: 17.9s\tremaining: 10.5s\n",
      "63:\tlearn: 1.3343050\ttotal: 18.1s\tremaining: 10.2s\n",
      "64:\tlearn: 1.3266084\ttotal: 18.4s\tremaining: 9.92s\n",
      "65:\tlearn: 1.3192575\ttotal: 18.7s\tremaining: 9.64s\n",
      "66:\tlearn: 1.3118719\ttotal: 19s\tremaining: 9.37s\n",
      "67:\tlearn: 1.3054877\ttotal: 19.3s\tremaining: 9.09s\n",
      "68:\tlearn: 1.2989392\ttotal: 19.6s\tremaining: 8.8s\n",
      "69:\tlearn: 1.2925001\ttotal: 19.9s\tremaining: 8.53s\n",
      "70:\tlearn: 1.2857567\ttotal: 20.2s\tremaining: 8.24s\n",
      "71:\tlearn: 1.2791112\ttotal: 20.5s\tremaining: 7.96s\n",
      "72:\tlearn: 1.2726317\ttotal: 20.8s\tremaining: 7.67s\n",
      "73:\tlearn: 1.2656780\ttotal: 21s\tremaining: 7.39s\n",
      "74:\tlearn: 1.2592673\ttotal: 21.3s\tremaining: 7.11s\n",
      "75:\tlearn: 1.2529669\ttotal: 21.6s\tremaining: 6.83s\n",
      "76:\tlearn: 1.2463677\ttotal: 21.9s\tremaining: 6.55s\n",
      "77:\tlearn: 1.2400692\ttotal: 22.2s\tremaining: 6.26s\n",
      "78:\tlearn: 1.2344377\ttotal: 22.5s\tremaining: 5.98s\n",
      "79:\tlearn: 1.2289360\ttotal: 22.8s\tremaining: 5.7s\n",
      "80:\tlearn: 1.2226774\ttotal: 23.1s\tremaining: 5.41s\n",
      "81:\tlearn: 1.2172070\ttotal: 23.4s\tremaining: 5.13s\n",
      "82:\tlearn: 1.2117429\ttotal: 23.6s\tremaining: 4.84s\n",
      "83:\tlearn: 1.2064233\ttotal: 23.9s\tremaining: 4.56s\n",
      "84:\tlearn: 1.2010964\ttotal: 24.2s\tremaining: 4.27s\n",
      "85:\tlearn: 1.1953776\ttotal: 24.5s\tremaining: 3.99s\n",
      "86:\tlearn: 1.1901437\ttotal: 24.8s\tremaining: 3.71s\n",
      "87:\tlearn: 1.1853279\ttotal: 25.1s\tremaining: 3.42s\n",
      "88:\tlearn: 1.1802565\ttotal: 25.4s\tremaining: 3.13s\n",
      "89:\tlearn: 1.1745928\ttotal: 25.7s\tremaining: 2.85s\n",
      "90:\tlearn: 1.1695442\ttotal: 25.9s\tremaining: 2.57s\n",
      "91:\tlearn: 1.1642966\ttotal: 26.2s\tremaining: 2.28s\n",
      "92:\tlearn: 1.1590612\ttotal: 26.5s\tremaining: 2s\n",
      "93:\tlearn: 1.1536931\ttotal: 26.8s\tremaining: 1.71s\n",
      "94:\tlearn: 1.1491156\ttotal: 27.1s\tremaining: 1.43s\n",
      "95:\tlearn: 1.1440859\ttotal: 27.4s\tremaining: 1.14s\n",
      "96:\tlearn: 1.1391190\ttotal: 27.7s\tremaining: 857ms\n",
      "97:\tlearn: 1.1343866\ttotal: 28s\tremaining: 572ms\n",
      "98:\tlearn: 1.1300979\ttotal: 28.3s\tremaining: 286ms\n",
      "99:\tlearn: 1.1253022\ttotal: 28.6s\tremaining: 0us\n",
      "0:\tlearn: 2.2658662\ttotal: 276ms\tremaining: 27.3s\n",
      "1:\tlearn: 2.2321196\ttotal: 557ms\tremaining: 27.3s\n",
      "2:\tlearn: 2.2000769\ttotal: 834ms\tremaining: 27s\n",
      "3:\tlearn: 2.1700152\ttotal: 1.11s\tremaining: 26.7s\n",
      "4:\tlearn: 2.1397933\ttotal: 1.39s\tremaining: 26.5s\n",
      "5:\tlearn: 2.1124022\ttotal: 1.67s\tremaining: 26.2s\n",
      "6:\tlearn: 2.0870195\ttotal: 1.95s\tremaining: 26s\n",
      "7:\tlearn: 2.0610816\ttotal: 2.23s\tremaining: 25.7s\n",
      "8:\tlearn: 2.0346797\ttotal: 2.52s\tremaining: 25.5s\n",
      "9:\tlearn: 2.0112394\ttotal: 2.8s\tremaining: 25.2s\n",
      "10:\tlearn: 1.9891258\ttotal: 3.09s\tremaining: 25s\n",
      "11:\tlearn: 1.9665233\ttotal: 3.38s\tremaining: 24.8s\n",
      "12:\tlearn: 1.9459449\ttotal: 3.66s\tremaining: 24.5s\n",
      "13:\tlearn: 1.9262198\ttotal: 3.94s\tremaining: 24.2s\n",
      "14:\tlearn: 1.9072866\ttotal: 4.22s\tremaining: 23.9s\n",
      "15:\tlearn: 1.8882567\ttotal: 4.5s\tremaining: 23.6s\n",
      "16:\tlearn: 1.8700881\ttotal: 4.78s\tremaining: 23.4s\n",
      "17:\tlearn: 1.8518151\ttotal: 5.07s\tremaining: 23.1s\n",
      "18:\tlearn: 1.8338730\ttotal: 5.35s\tremaining: 22.8s\n",
      "19:\tlearn: 1.8169242\ttotal: 5.63s\tremaining: 22.5s\n",
      "20:\tlearn: 1.8007661\ttotal: 5.91s\tremaining: 22.2s\n",
      "21:\tlearn: 1.7840747\ttotal: 6.2s\tremaining: 22s\n",
      "22:\tlearn: 1.7674244\ttotal: 6.49s\tremaining: 21.7s\n",
      "23:\tlearn: 1.7525202\ttotal: 6.77s\tremaining: 21.4s\n",
      "24:\tlearn: 1.7367955\ttotal: 7.06s\tremaining: 21.2s\n",
      "25:\tlearn: 1.7220128\ttotal: 7.35s\tremaining: 20.9s\n",
      "26:\tlearn: 1.7070051\ttotal: 7.64s\tremaining: 20.7s\n",
      "27:\tlearn: 1.6936101\ttotal: 7.92s\tremaining: 20.4s\n",
      "28:\tlearn: 1.6795383\ttotal: 8.22s\tremaining: 20.1s\n",
      "29:\tlearn: 1.6664890\ttotal: 8.5s\tremaining: 19.8s\n",
      "30:\tlearn: 1.6540412\ttotal: 8.78s\tremaining: 19.5s\n",
      "31:\tlearn: 1.6420332\ttotal: 9.06s\tremaining: 19.3s\n",
      "32:\tlearn: 1.6293734\ttotal: 9.35s\tremaining: 19s\n",
      "33:\tlearn: 1.6165076\ttotal: 9.66s\tremaining: 18.7s\n",
      "34:\tlearn: 1.6048963\ttotal: 9.94s\tremaining: 18.5s\n",
      "35:\tlearn: 1.5930459\ttotal: 10.2s\tremaining: 18.2s\n",
      "36:\tlearn: 1.5823790\ttotal: 10.5s\tremaining: 17.9s\n",
      "37:\tlearn: 1.5704712\ttotal: 10.8s\tremaining: 17.6s\n",
      "38:\tlearn: 1.5594392\ttotal: 11.1s\tremaining: 17.3s\n",
      "39:\tlearn: 1.5488511\ttotal: 11.4s\tremaining: 17s\n",
      "40:\tlearn: 1.5383351\ttotal: 11.7s\tremaining: 16.8s\n",
      "41:\tlearn: 1.5277579\ttotal: 11.9s\tremaining: 16.5s\n",
      "42:\tlearn: 1.5174808\ttotal: 12.2s\tremaining: 16.2s\n",
      "43:\tlearn: 1.5077700\ttotal: 12.5s\tremaining: 15.9s\n",
      "44:\tlearn: 1.4981677\ttotal: 12.8s\tremaining: 15.7s\n",
      "45:\tlearn: 1.4882478\ttotal: 13.1s\tremaining: 15.4s\n",
      "46:\tlearn: 1.4786084\ttotal: 13.4s\tremaining: 15.1s\n",
      "47:\tlearn: 1.4697465\ttotal: 13.7s\tremaining: 14.8s\n",
      "48:\tlearn: 1.4600768\ttotal: 14s\tremaining: 14.5s\n",
      "49:\tlearn: 1.4508920\ttotal: 14.3s\tremaining: 14.3s\n",
      "50:\tlearn: 1.4420124\ttotal: 14.6s\tremaining: 14s\n",
      "51:\tlearn: 1.4325981\ttotal: 14.9s\tremaining: 13.7s\n",
      "52:\tlearn: 1.4239182\ttotal: 15.1s\tremaining: 13.4s\n",
      "53:\tlearn: 1.4152526\ttotal: 15.4s\tremaining: 13.1s\n",
      "54:\tlearn: 1.4067786\ttotal: 15.7s\tremaining: 12.9s\n",
      "55:\tlearn: 1.3986248\ttotal: 16s\tremaining: 12.6s\n",
      "56:\tlearn: 1.3905384\ttotal: 16.3s\tremaining: 12.3s\n",
      "57:\tlearn: 1.3825087\ttotal: 16.6s\tremaining: 12s\n",
      "58:\tlearn: 1.3750030\ttotal: 16.9s\tremaining: 11.7s\n",
      "59:\tlearn: 1.3668683\ttotal: 17.2s\tremaining: 11.4s\n",
      "60:\tlearn: 1.3594376\ttotal: 17.4s\tremaining: 11.1s\n",
      "61:\tlearn: 1.3518517\ttotal: 17.7s\tremaining: 10.9s\n",
      "62:\tlearn: 1.3440052\ttotal: 18s\tremaining: 10.6s\n",
      "63:\tlearn: 1.3374164\ttotal: 18.3s\tremaining: 10.3s\n",
      "64:\tlearn: 1.3300053\ttotal: 18.6s\tremaining: 10s\n",
      "65:\tlearn: 1.3226447\ttotal: 18.9s\tremaining: 9.75s\n",
      "66:\tlearn: 1.3153739\ttotal: 19.2s\tremaining: 9.47s\n",
      "67:\tlearn: 1.3090016\ttotal: 19.5s\tremaining: 9.18s\n",
      "68:\tlearn: 1.3022701\ttotal: 19.8s\tremaining: 8.89s\n",
      "69:\tlearn: 1.2957489\ttotal: 20.1s\tremaining: 8.62s\n",
      "70:\tlearn: 1.2885132\ttotal: 20.4s\tremaining: 8.34s\n",
      "71:\tlearn: 1.2824298\ttotal: 20.7s\tremaining: 8.05s\n",
      "72:\tlearn: 1.2762711\ttotal: 21s\tremaining: 7.76s\n",
      "73:\tlearn: 1.2694337\ttotal: 21.3s\tremaining: 7.47s\n",
      "74:\tlearn: 1.2628962\ttotal: 21.6s\tremaining: 7.19s\n",
      "75:\tlearn: 1.2571373\ttotal: 21.8s\tremaining: 6.9s\n",
      "76:\tlearn: 1.2507156\ttotal: 22.2s\tremaining: 6.62s\n",
      "77:\tlearn: 1.2444499\ttotal: 22.5s\tremaining: 6.34s\n",
      "78:\tlearn: 1.2388406\ttotal: 22.8s\tremaining: 6.05s\n",
      "79:\tlearn: 1.2334934\ttotal: 23s\tremaining: 5.76s\n",
      "80:\tlearn: 1.2271808\ttotal: 23.3s\tremaining: 5.47s\n",
      "81:\tlearn: 1.2217179\ttotal: 23.6s\tremaining: 5.19s\n",
      "82:\tlearn: 1.2162501\ttotal: 23.9s\tremaining: 4.9s\n",
      "83:\tlearn: 1.2103142\ttotal: 24.2s\tremaining: 4.61s\n",
      "84:\tlearn: 1.2042927\ttotal: 24.5s\tremaining: 4.33s\n",
      "85:\tlearn: 1.1985221\ttotal: 24.8s\tremaining: 4.04s\n",
      "86:\tlearn: 1.1933482\ttotal: 25.1s\tremaining: 3.75s\n",
      "87:\tlearn: 1.1885704\ttotal: 25.4s\tremaining: 3.46s\n",
      "88:\tlearn: 1.1829325\ttotal: 25.7s\tremaining: 3.17s\n",
      "89:\tlearn: 1.1773452\ttotal: 26s\tremaining: 2.89s\n",
      "90:\tlearn: 1.1724112\ttotal: 26.3s\tremaining: 2.6s\n",
      "91:\tlearn: 1.1671410\ttotal: 26.6s\tremaining: 2.31s\n",
      "92:\tlearn: 1.1617659\ttotal: 26.9s\tremaining: 2.02s\n",
      "93:\tlearn: 1.1568809\ttotal: 27.2s\tremaining: 1.73s\n",
      "94:\tlearn: 1.1519844\ttotal: 27.5s\tremaining: 1.45s\n",
      "95:\tlearn: 1.1469142\ttotal: 27.8s\tremaining: 1.16s\n",
      "96:\tlearn: 1.1419818\ttotal: 28.1s\tremaining: 868ms\n",
      "97:\tlearn: 1.1372831\ttotal: 28.4s\tremaining: 579ms\n",
      "98:\tlearn: 1.1326306\ttotal: 28.6s\tremaining: 289ms\n",
      "99:\tlearn: 1.1277865\ttotal: 28.9s\tremaining: 0us\n",
      "0:\tlearn: 2.2658348\ttotal: 276ms\tremaining: 27.3s\n",
      "1:\tlearn: 2.2318670\ttotal: 552ms\tremaining: 27.1s\n",
      "2:\tlearn: 2.1995876\ttotal: 833ms\tremaining: 26.9s\n",
      "3:\tlearn: 2.1694404\ttotal: 1.11s\tremaining: 26.6s\n",
      "4:\tlearn: 2.1391886\ttotal: 1.39s\tremaining: 26.4s\n",
      "5:\tlearn: 2.1122518\ttotal: 1.67s\tremaining: 26.1s\n",
      "6:\tlearn: 2.0866065\ttotal: 1.94s\tremaining: 25.8s\n",
      "7:\tlearn: 2.0604940\ttotal: 2.22s\tremaining: 25.6s\n",
      "8:\tlearn: 2.0342440\ttotal: 2.51s\tremaining: 25.4s\n",
      "9:\tlearn: 2.0108247\ttotal: 2.8s\tremaining: 25.2s\n",
      "10:\tlearn: 1.9887644\ttotal: 3.08s\tremaining: 24.9s\n",
      "11:\tlearn: 1.9663554\ttotal: 3.37s\tremaining: 24.7s\n",
      "12:\tlearn: 1.9460161\ttotal: 3.65s\tremaining: 24.4s\n",
      "13:\tlearn: 1.9262526\ttotal: 3.93s\tremaining: 24.1s\n",
      "14:\tlearn: 1.9063746\ttotal: 4.21s\tremaining: 23.9s\n",
      "15:\tlearn: 1.8871857\ttotal: 4.5s\tremaining: 23.6s\n",
      "16:\tlearn: 1.8689453\ttotal: 4.78s\tremaining: 23.3s\n",
      "17:\tlearn: 1.8510906\ttotal: 5.06s\tremaining: 23.1s\n",
      "18:\tlearn: 1.8330862\ttotal: 5.35s\tremaining: 22.8s\n",
      "19:\tlearn: 1.8159929\ttotal: 5.63s\tremaining: 22.5s\n",
      "20:\tlearn: 1.7998444\ttotal: 5.91s\tremaining: 22.2s\n",
      "21:\tlearn: 1.7832012\ttotal: 6.19s\tremaining: 22s\n",
      "22:\tlearn: 1.7672822\ttotal: 6.48s\tremaining: 21.7s\n",
      "23:\tlearn: 1.7523322\ttotal: 6.77s\tremaining: 21.4s\n",
      "24:\tlearn: 1.7369720\ttotal: 7.05s\tremaining: 21.2s\n",
      "25:\tlearn: 1.7229644\ttotal: 7.34s\tremaining: 20.9s\n",
      "26:\tlearn: 1.7079435\ttotal: 7.63s\tremaining: 20.6s\n",
      "27:\tlearn: 1.6940111\ttotal: 7.92s\tremaining: 20.4s\n",
      "28:\tlearn: 1.6799941\ttotal: 8.2s\tremaining: 20.1s\n",
      "29:\tlearn: 1.6669424\ttotal: 8.49s\tremaining: 19.8s\n",
      "30:\tlearn: 1.6545551\ttotal: 8.77s\tremaining: 19.5s\n",
      "31:\tlearn: 1.6415428\ttotal: 9.06s\tremaining: 19.2s\n",
      "32:\tlearn: 1.6286692\ttotal: 9.35s\tremaining: 19s\n",
      "33:\tlearn: 1.6160027\ttotal: 9.63s\tremaining: 18.7s\n",
      "34:\tlearn: 1.6035782\ttotal: 9.92s\tremaining: 18.4s\n",
      "35:\tlearn: 1.5916527\ttotal: 10.2s\tremaining: 18.1s\n",
      "36:\tlearn: 1.5810683\ttotal: 10.5s\tremaining: 17.9s\n",
      "37:\tlearn: 1.5697625\ttotal: 10.8s\tremaining: 17.6s\n",
      "38:\tlearn: 1.5585202\ttotal: 11.1s\tremaining: 17.3s\n",
      "39:\tlearn: 1.5481518\ttotal: 11.3s\tremaining: 17s\n",
      "40:\tlearn: 1.5377913\ttotal: 11.6s\tremaining: 16.7s\n",
      "41:\tlearn: 1.5272234\ttotal: 12s\tremaining: 16.5s\n",
      "42:\tlearn: 1.5175372\ttotal: 12.2s\tremaining: 16.2s\n",
      "43:\tlearn: 1.5071924\ttotal: 12.5s\tremaining: 15.9s\n",
      "44:\tlearn: 1.4975511\ttotal: 12.8s\tremaining: 15.7s\n",
      "45:\tlearn: 1.4882345\ttotal: 13.1s\tremaining: 15.4s\n",
      "46:\tlearn: 1.4785427\ttotal: 13.4s\tremaining: 15.1s\n",
      "47:\tlearn: 1.4693593\ttotal: 13.7s\tremaining: 14.8s\n",
      "48:\tlearn: 1.4600600\ttotal: 13.9s\tremaining: 14.5s\n",
      "49:\tlearn: 1.4509252\ttotal: 14.2s\tremaining: 14.2s\n",
      "50:\tlearn: 1.4426465\ttotal: 14.5s\tremaining: 13.9s\n",
      "51:\tlearn: 1.4331327\ttotal: 14.8s\tremaining: 13.7s\n",
      "52:\tlearn: 1.4246175\ttotal: 15.1s\tremaining: 13.4s\n",
      "53:\tlearn: 1.4159833\ttotal: 15.4s\tremaining: 13.1s\n",
      "54:\tlearn: 1.4075353\ttotal: 15.7s\tremaining: 12.8s\n",
      "55:\tlearn: 1.3983680\ttotal: 16s\tremaining: 12.5s\n",
      "56:\tlearn: 1.3905548\ttotal: 16.3s\tremaining: 12.3s\n",
      "57:\tlearn: 1.3824593\ttotal: 16.5s\tremaining: 12s\n",
      "58:\tlearn: 1.3750512\ttotal: 16.8s\tremaining: 11.7s\n",
      "59:\tlearn: 1.3675995\ttotal: 17.1s\tremaining: 11.4s\n",
      "60:\tlearn: 1.3601802\ttotal: 17.4s\tremaining: 11.1s\n",
      "61:\tlearn: 1.3526767\ttotal: 17.7s\tremaining: 10.8s\n",
      "62:\tlearn: 1.3445280\ttotal: 18s\tremaining: 10.6s\n",
      "63:\tlearn: 1.3371855\ttotal: 18.3s\tremaining: 10.3s\n",
      "64:\tlearn: 1.3294855\ttotal: 18.6s\tremaining: 9.99s\n",
      "65:\tlearn: 1.3220691\ttotal: 18.9s\tremaining: 9.71s\n",
      "66:\tlearn: 1.3147716\ttotal: 19.1s\tremaining: 9.43s\n",
      "67:\tlearn: 1.3083777\ttotal: 19.4s\tremaining: 9.15s\n",
      "68:\tlearn: 1.3015194\ttotal: 19.7s\tremaining: 8.86s\n",
      "69:\tlearn: 1.2955230\ttotal: 20s\tremaining: 8.58s\n",
      "70:\tlearn: 1.2881869\ttotal: 20.3s\tremaining: 8.3s\n",
      "71:\tlearn: 1.2821119\ttotal: 20.6s\tremaining: 8.02s\n",
      "72:\tlearn: 1.2753178\ttotal: 20.9s\tremaining: 7.74s\n",
      "73:\tlearn: 1.2684737\ttotal: 21.2s\tremaining: 7.46s\n",
      "74:\tlearn: 1.2623719\ttotal: 21.5s\tremaining: 7.17s\n",
      "75:\tlearn: 1.2564955\ttotal: 21.8s\tremaining: 6.88s\n",
      "76:\tlearn: 1.2499109\ttotal: 22.1s\tremaining: 6.6s\n",
      "77:\tlearn: 1.2439606\ttotal: 22.4s\tremaining: 6.31s\n",
      "78:\tlearn: 1.2384212\ttotal: 22.7s\tremaining: 6.03s\n",
      "79:\tlearn: 1.2330370\ttotal: 23s\tremaining: 5.74s\n",
      "80:\tlearn: 1.2270309\ttotal: 23.2s\tremaining: 5.45s\n",
      "81:\tlearn: 1.2218386\ttotal: 23.5s\tremaining: 5.17s\n",
      "82:\tlearn: 1.2164314\ttotal: 23.8s\tremaining: 4.88s\n",
      "83:\tlearn: 1.2109682\ttotal: 24.1s\tremaining: 4.59s\n",
      "84:\tlearn: 1.2053451\ttotal: 24.4s\tremaining: 4.3s\n",
      "85:\tlearn: 1.1996161\ttotal: 24.7s\tremaining: 4.02s\n",
      "86:\tlearn: 1.1941879\ttotal: 25s\tremaining: 3.73s\n",
      "87:\tlearn: 1.1891235\ttotal: 25.3s\tremaining: 3.45s\n",
      "88:\tlearn: 1.1842241\ttotal: 25.6s\tremaining: 3.16s\n",
      "89:\tlearn: 1.1785432\ttotal: 25.9s\tremaining: 2.87s\n",
      "90:\tlearn: 1.1733837\ttotal: 26.1s\tremaining: 2.58s\n",
      "91:\tlearn: 1.1682235\ttotal: 26.4s\tremaining: 2.3s\n",
      "92:\tlearn: 1.1631448\ttotal: 26.7s\tremaining: 2.01s\n",
      "93:\tlearn: 1.1576167\ttotal: 27s\tremaining: 1.72s\n",
      "94:\tlearn: 1.1526028\ttotal: 27.3s\tremaining: 1.44s\n",
      "95:\tlearn: 1.1476650\ttotal: 27.6s\tremaining: 1.15s\n",
      "96:\tlearn: 1.1427013\ttotal: 27.9s\tremaining: 863ms\n",
      "97:\tlearn: 1.1380165\ttotal: 28.2s\tremaining: 575ms\n",
      "98:\tlearn: 1.1334592\ttotal: 28.5s\tremaining: 288ms\n",
      "99:\tlearn: 1.1286791\ttotal: 28.8s\tremaining: 0us\n",
      "0:\tlearn: 1.2891537\ttotal: 271ms\tremaining: 26.8s\n",
      "1:\tlearn: 1.0635618\ttotal: 554ms\tremaining: 27.1s\n",
      "2:\tlearn: 0.9281624\ttotal: 831ms\tremaining: 26.9s\n",
      "3:\tlearn: 0.8417570\ttotal: 1.11s\tremaining: 26.7s\n",
      "4:\tlearn: 0.7599713\ttotal: 1.41s\tremaining: 26.7s\n",
      "5:\tlearn: 0.7134519\ttotal: 1.71s\tremaining: 26.7s\n",
      "6:\tlearn: 0.6819323\ttotal: 1.99s\tremaining: 26.4s\n",
      "7:\tlearn: 0.6421344\ttotal: 2.27s\tremaining: 26.1s\n",
      "8:\tlearn: 0.6131799\ttotal: 2.56s\tremaining: 25.9s\n",
      "9:\tlearn: 0.5855527\ttotal: 2.85s\tremaining: 25.6s\n",
      "10:\tlearn: 0.5736969\ttotal: 3.12s\tremaining: 25.3s\n",
      "11:\tlearn: 0.5637071\ttotal: 3.4s\tremaining: 25s\n",
      "12:\tlearn: 0.5470339\ttotal: 3.7s\tremaining: 24.8s\n",
      "13:\tlearn: 0.5328172\ttotal: 3.98s\tremaining: 24.4s\n",
      "14:\tlearn: 0.5199291\ttotal: 4.27s\tremaining: 24.2s\n",
      "15:\tlearn: 0.5089275\ttotal: 4.55s\tremaining: 23.9s\n",
      "16:\tlearn: 0.5027604\ttotal: 4.85s\tremaining: 23.7s\n",
      "17:\tlearn: 0.4971283\ttotal: 5.14s\tremaining: 23.4s\n",
      "18:\tlearn: 0.4922164\ttotal: 5.41s\tremaining: 23s\n",
      "19:\tlearn: 0.4858211\ttotal: 5.68s\tremaining: 22.7s\n",
      "20:\tlearn: 0.4765633\ttotal: 5.97s\tremaining: 22.5s\n",
      "21:\tlearn: 0.4683197\ttotal: 6.26s\tremaining: 22.2s\n",
      "22:\tlearn: 0.4596810\ttotal: 6.54s\tremaining: 21.9s\n",
      "23:\tlearn: 0.4560721\ttotal: 6.8s\tremaining: 21.6s\n",
      "24:\tlearn: 0.4476011\ttotal: 7.09s\tremaining: 21.3s\n",
      "25:\tlearn: 0.4425884\ttotal: 7.36s\tremaining: 21s\n",
      "26:\tlearn: 0.4400161\ttotal: 7.63s\tremaining: 20.6s\n",
      "27:\tlearn: 0.4356819\ttotal: 7.9s\tremaining: 20.3s\n",
      "28:\tlearn: 0.4308022\ttotal: 8.19s\tremaining: 20.1s\n",
      "29:\tlearn: 0.4247129\ttotal: 8.47s\tremaining: 19.8s\n",
      "30:\tlearn: 0.4214119\ttotal: 8.74s\tremaining: 19.5s\n",
      "31:\tlearn: 0.4146935\ttotal: 9.03s\tremaining: 19.2s\n",
      "32:\tlearn: 0.4035699\ttotal: 9.31s\tremaining: 18.9s\n",
      "33:\tlearn: 0.3972906\ttotal: 9.58s\tremaining: 18.6s\n",
      "34:\tlearn: 0.3922274\ttotal: 9.86s\tremaining: 18.3s\n",
      "35:\tlearn: 0.3879774\ttotal: 10.1s\tremaining: 18s\n",
      "36:\tlearn: 0.3864630\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 0.3838449\ttotal: 10.7s\tremaining: 17.4s\n",
      "38:\tlearn: 0.3799694\ttotal: 10.9s\tremaining: 17.1s\n",
      "39:\tlearn: 0.3759426\ttotal: 11.2s\tremaining: 16.8s\n",
      "40:\tlearn: 0.3722526\ttotal: 11.5s\tremaining: 16.6s\n",
      "41:\tlearn: 0.3699576\ttotal: 11.8s\tremaining: 16.2s\n",
      "42:\tlearn: 0.3667690\ttotal: 12s\tremaining: 16s\n",
      "43:\tlearn: 0.3642207\ttotal: 12.3s\tremaining: 15.7s\n",
      "44:\tlearn: 0.3616298\ttotal: 12.6s\tremaining: 15.4s\n",
      "45:\tlearn: 0.3591593\ttotal: 12.9s\tremaining: 15.1s\n",
      "46:\tlearn: 0.3577433\ttotal: 13.1s\tremaining: 14.8s\n",
      "47:\tlearn: 0.3549495\ttotal: 13.4s\tremaining: 14.5s\n",
      "48:\tlearn: 0.3519899\ttotal: 13.7s\tremaining: 14.2s\n",
      "49:\tlearn: 0.3509037\ttotal: 13.9s\tremaining: 13.9s\n",
      "50:\tlearn: 0.3500819\ttotal: 14.2s\tremaining: 13.6s\n",
      "51:\tlearn: 0.3479737\ttotal: 14.5s\tremaining: 13.3s\n",
      "52:\tlearn: 0.3457946\ttotal: 14.7s\tremaining: 13.1s\n",
      "53:\tlearn: 0.3430581\ttotal: 15s\tremaining: 12.8s\n",
      "54:\tlearn: 0.3406439\ttotal: 15.3s\tremaining: 12.5s\n",
      "55:\tlearn: 0.3377603\ttotal: 15.5s\tremaining: 12.2s\n",
      "56:\tlearn: 0.3362619\ttotal: 15.8s\tremaining: 11.9s\n",
      "57:\tlearn: 0.3301957\ttotal: 16.1s\tremaining: 11.7s\n",
      "58:\tlearn: 0.3275173\ttotal: 16.4s\tremaining: 11.4s\n",
      "59:\tlearn: 0.3259710\ttotal: 16.6s\tremaining: 11.1s\n",
      "60:\tlearn: 0.3238108\ttotal: 16.9s\tremaining: 10.8s\n",
      "61:\tlearn: 0.3216094\ttotal: 17.2s\tremaining: 10.5s\n",
      "62:\tlearn: 0.3183372\ttotal: 17.5s\tremaining: 10.3s\n",
      "63:\tlearn: 0.3160793\ttotal: 17.7s\tremaining: 9.97s\n",
      "64:\tlearn: 0.3140282\ttotal: 18s\tremaining: 9.7s\n",
      "65:\tlearn: 0.3126501\ttotal: 18.3s\tremaining: 9.42s\n",
      "66:\tlearn: 0.3112348\ttotal: 18.6s\tremaining: 9.14s\n",
      "67:\tlearn: 0.3103329\ttotal: 18.8s\tremaining: 8.86s\n",
      "68:\tlearn: 0.3084596\ttotal: 19.1s\tremaining: 8.58s\n",
      "69:\tlearn: 0.3051045\ttotal: 19.4s\tremaining: 8.31s\n",
      "70:\tlearn: 0.3029219\ttotal: 19.7s\tremaining: 8.03s\n",
      "71:\tlearn: 0.3016418\ttotal: 19.9s\tremaining: 7.75s\n",
      "72:\tlearn: 0.2993073\ttotal: 20.2s\tremaining: 7.48s\n",
      "73:\tlearn: 0.2976537\ttotal: 20.5s\tremaining: 7.2s\n",
      "74:\tlearn: 0.2966458\ttotal: 20.8s\tremaining: 6.92s\n",
      "75:\tlearn: 0.2958733\ttotal: 21s\tremaining: 6.64s\n",
      "76:\tlearn: 0.2930826\ttotal: 21.3s\tremaining: 6.37s\n",
      "77:\tlearn: 0.2923063\ttotal: 21.6s\tremaining: 6.09s\n",
      "78:\tlearn: 0.2915689\ttotal: 21.9s\tremaining: 5.81s\n",
      "79:\tlearn: 0.2896730\ttotal: 22.1s\tremaining: 5.53s\n",
      "80:\tlearn: 0.2884715\ttotal: 22.4s\tremaining: 5.25s\n",
      "81:\tlearn: 0.2865178\ttotal: 22.7s\tremaining: 4.98s\n",
      "82:\tlearn: 0.2851551\ttotal: 22.9s\tremaining: 4.7s\n",
      "83:\tlearn: 0.2839602\ttotal: 23.2s\tremaining: 4.42s\n",
      "84:\tlearn: 0.2828179\ttotal: 23.5s\tremaining: 4.14s\n",
      "85:\tlearn: 0.2809309\ttotal: 23.7s\tremaining: 3.86s\n",
      "86:\tlearn: 0.2802643\ttotal: 24s\tremaining: 3.59s\n",
      "87:\tlearn: 0.2784397\ttotal: 24.3s\tremaining: 3.31s\n",
      "88:\tlearn: 0.2765641\ttotal: 24.6s\tremaining: 3.03s\n",
      "89:\tlearn: 0.2749822\ttotal: 24.8s\tremaining: 2.76s\n",
      "90:\tlearn: 0.2741946\ttotal: 25.1s\tremaining: 2.48s\n",
      "91:\tlearn: 0.2733344\ttotal: 25.4s\tremaining: 2.21s\n",
      "92:\tlearn: 0.2727329\ttotal: 25.6s\tremaining: 1.93s\n",
      "93:\tlearn: 0.2714400\ttotal: 25.9s\tremaining: 1.65s\n",
      "94:\tlearn: 0.2703430\ttotal: 26.2s\tremaining: 1.38s\n",
      "95:\tlearn: 0.2689044\ttotal: 26.4s\tremaining: 1.1s\n",
      "96:\tlearn: 0.2677602\ttotal: 26.7s\tremaining: 826ms\n",
      "97:\tlearn: 0.2664236\ttotal: 27s\tremaining: 551ms\n",
      "98:\tlearn: 0.2637656\ttotal: 27.3s\tremaining: 276ms\n",
      "99:\tlearn: 0.2631655\ttotal: 27.5s\tremaining: 0us\n",
      "0:\tlearn: 1.2453824\ttotal: 275ms\tremaining: 27.2s\n",
      "1:\tlearn: 1.0460857\ttotal: 548ms\tremaining: 26.8s\n",
      "2:\tlearn: 0.9075354\ttotal: 845ms\tremaining: 27.3s\n",
      "3:\tlearn: 0.8161234\ttotal: 1.14s\tremaining: 27.2s\n",
      "4:\tlearn: 0.7571292\ttotal: 1.42s\tremaining: 27s\n",
      "5:\tlearn: 0.7033798\ttotal: 1.71s\tremaining: 26.8s\n",
      "6:\tlearn: 0.6682388\ttotal: 1.99s\tremaining: 26.5s\n",
      "7:\tlearn: 0.6332849\ttotal: 2.28s\tremaining: 26.3s\n",
      "8:\tlearn: 0.6102045\ttotal: 2.56s\tremaining: 25.9s\n",
      "9:\tlearn: 0.5819260\ttotal: 2.85s\tremaining: 25.7s\n",
      "10:\tlearn: 0.5699302\ttotal: 3.13s\tremaining: 25.3s\n",
      "11:\tlearn: 0.5590179\ttotal: 3.41s\tremaining: 25s\n",
      "12:\tlearn: 0.5426648\ttotal: 3.7s\tremaining: 24.8s\n",
      "13:\tlearn: 0.5358060\ttotal: 3.97s\tremaining: 24.4s\n",
      "14:\tlearn: 0.5237043\ttotal: 4.27s\tremaining: 24.2s\n",
      "15:\tlearn: 0.5109553\ttotal: 4.55s\tremaining: 23.9s\n",
      "16:\tlearn: 0.5051187\ttotal: 4.83s\tremaining: 23.6s\n",
      "17:\tlearn: 0.4983362\ttotal: 5.12s\tremaining: 23.3s\n",
      "18:\tlearn: 0.4877593\ttotal: 5.4s\tremaining: 23s\n",
      "19:\tlearn: 0.4773902\ttotal: 5.69s\tremaining: 22.7s\n",
      "20:\tlearn: 0.4714455\ttotal: 5.96s\tremaining: 22.4s\n",
      "21:\tlearn: 0.4626222\ttotal: 6.24s\tremaining: 22.1s\n",
      "22:\tlearn: 0.4575152\ttotal: 6.51s\tremaining: 21.8s\n",
      "23:\tlearn: 0.4518861\ttotal: 6.79s\tremaining: 21.5s\n",
      "24:\tlearn: 0.4489304\ttotal: 7.06s\tremaining: 21.2s\n",
      "25:\tlearn: 0.4419995\ttotal: 7.33s\tremaining: 20.9s\n",
      "26:\tlearn: 0.4358793\ttotal: 7.61s\tremaining: 20.6s\n",
      "27:\tlearn: 0.4318121\ttotal: 7.89s\tremaining: 20.3s\n",
      "28:\tlearn: 0.4281226\ttotal: 8.17s\tremaining: 20s\n",
      "29:\tlearn: 0.4235008\ttotal: 8.45s\tremaining: 19.7s\n",
      "30:\tlearn: 0.4211903\ttotal: 8.72s\tremaining: 19.4s\n",
      "31:\tlearn: 0.4141696\ttotal: 9s\tremaining: 19.1s\n",
      "32:\tlearn: 0.4108934\ttotal: 9.29s\tremaining: 18.9s\n",
      "33:\tlearn: 0.4080736\ttotal: 9.55s\tremaining: 18.5s\n",
      "34:\tlearn: 0.4023072\ttotal: 9.82s\tremaining: 18.2s\n",
      "35:\tlearn: 0.3991582\ttotal: 10.1s\tremaining: 17.9s\n",
      "36:\tlearn: 0.3924196\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 0.3909637\ttotal: 10.6s\tremaining: 17.3s\n",
      "38:\tlearn: 0.3856940\ttotal: 10.9s\tremaining: 17.1s\n",
      "39:\tlearn: 0.3838430\ttotal: 11.2s\tremaining: 16.8s\n",
      "40:\tlearn: 0.3800581\ttotal: 11.5s\tremaining: 16.5s\n",
      "41:\tlearn: 0.3765109\ttotal: 11.7s\tremaining: 16.2s\n",
      "42:\tlearn: 0.3738568\ttotal: 12s\tremaining: 15.9s\n",
      "43:\tlearn: 0.3700673\ttotal: 12.3s\tremaining: 15.6s\n",
      "44:\tlearn: 0.3657037\ttotal: 12.6s\tremaining: 15.3s\n",
      "45:\tlearn: 0.3639628\ttotal: 12.8s\tremaining: 15s\n",
      "46:\tlearn: 0.3599310\ttotal: 13.1s\tremaining: 14.8s\n",
      "47:\tlearn: 0.3582642\ttotal: 13.4s\tremaining: 14.5s\n",
      "48:\tlearn: 0.3555223\ttotal: 13.6s\tremaining: 14.2s\n",
      "49:\tlearn: 0.3515570\ttotal: 13.9s\tremaining: 13.9s\n",
      "50:\tlearn: 0.3501051\ttotal: 14.2s\tremaining: 13.6s\n",
      "51:\tlearn: 0.3464516\ttotal: 14.5s\tremaining: 13.4s\n",
      "52:\tlearn: 0.3443949\ttotal: 14.7s\tremaining: 13.1s\n",
      "53:\tlearn: 0.3431695\ttotal: 15s\tremaining: 12.8s\n",
      "54:\tlearn: 0.3405292\ttotal: 15.3s\tremaining: 12.5s\n",
      "55:\tlearn: 0.3382568\ttotal: 15.5s\tremaining: 12.2s\n",
      "56:\tlearn: 0.3369654\ttotal: 15.8s\tremaining: 11.9s\n",
      "57:\tlearn: 0.3349708\ttotal: 16.1s\tremaining: 11.6s\n",
      "58:\tlearn: 0.3310636\ttotal: 16.4s\tremaining: 11.4s\n",
      "59:\tlearn: 0.3292447\ttotal: 16.6s\tremaining: 11.1s\n",
      "60:\tlearn: 0.3264906\ttotal: 16.9s\tremaining: 10.8s\n",
      "61:\tlearn: 0.3244394\ttotal: 17.2s\tremaining: 10.5s\n",
      "62:\tlearn: 0.3225549\ttotal: 17.5s\tremaining: 10.3s\n",
      "63:\tlearn: 0.3198363\ttotal: 17.8s\tremaining: 9.99s\n",
      "64:\tlearn: 0.3193189\ttotal: 18s\tremaining: 9.7s\n",
      "65:\tlearn: 0.3160661\ttotal: 18.3s\tremaining: 9.43s\n",
      "66:\tlearn: 0.3148046\ttotal: 18.6s\tremaining: 9.15s\n",
      "67:\tlearn: 0.3105458\ttotal: 18.9s\tremaining: 8.87s\n",
      "68:\tlearn: 0.3080068\ttotal: 19.1s\tremaining: 8.6s\n",
      "69:\tlearn: 0.3054291\ttotal: 19.4s\tremaining: 8.32s\n",
      "70:\tlearn: 0.3036820\ttotal: 19.7s\tremaining: 8.05s\n",
      "71:\tlearn: 0.3028227\ttotal: 20s\tremaining: 7.77s\n",
      "72:\tlearn: 0.3013374\ttotal: 20.3s\tremaining: 7.49s\n",
      "73:\tlearn: 0.2993935\ttotal: 20.5s\tremaining: 7.21s\n",
      "74:\tlearn: 0.2977328\ttotal: 20.8s\tremaining: 6.93s\n",
      "75:\tlearn: 0.2963434\ttotal: 21.1s\tremaining: 6.65s\n",
      "76:\tlearn: 0.2934478\ttotal: 21.4s\tremaining: 6.38s\n",
      "77:\tlearn: 0.2915480\ttotal: 21.6s\tremaining: 6.1s\n",
      "78:\tlearn: 0.2895964\ttotal: 21.9s\tremaining: 5.82s\n",
      "79:\tlearn: 0.2876783\ttotal: 22.2s\tremaining: 5.54s\n",
      "80:\tlearn: 0.2864487\ttotal: 22.5s\tremaining: 5.27s\n",
      "81:\tlearn: 0.2849721\ttotal: 22.7s\tremaining: 4.99s\n",
      "82:\tlearn: 0.2838286\ttotal: 23s\tremaining: 4.71s\n",
      "83:\tlearn: 0.2832653\ttotal: 23.3s\tremaining: 4.43s\n",
      "84:\tlearn: 0.2812781\ttotal: 23.5s\tremaining: 4.15s\n",
      "85:\tlearn: 0.2802035\ttotal: 23.8s\tremaining: 3.87s\n",
      "86:\tlearn: 0.2791183\ttotal: 24.1s\tremaining: 3.6s\n",
      "87:\tlearn: 0.2776420\ttotal: 24.3s\tremaining: 3.32s\n",
      "88:\tlearn: 0.2760237\ttotal: 24.6s\tremaining: 3.04s\n",
      "89:\tlearn: 0.2749652\ttotal: 24.9s\tremaining: 2.77s\n",
      "90:\tlearn: 0.2736397\ttotal: 25.2s\tremaining: 2.49s\n",
      "91:\tlearn: 0.2726216\ttotal: 25.4s\tremaining: 2.21s\n",
      "92:\tlearn: 0.2719497\ttotal: 25.7s\tremaining: 1.93s\n",
      "93:\tlearn: 0.2710345\ttotal: 26s\tremaining: 1.66s\n",
      "94:\tlearn: 0.2698482\ttotal: 26.2s\tremaining: 1.38s\n",
      "95:\tlearn: 0.2681117\ttotal: 26.5s\tremaining: 1.1s\n",
      "96:\tlearn: 0.2670117\ttotal: 26.8s\tremaining: 828ms\n",
      "97:\tlearn: 0.2661162\ttotal: 27s\tremaining: 552ms\n",
      "98:\tlearn: 0.2650517\ttotal: 27.3s\tremaining: 276ms\n",
      "99:\tlearn: 0.2641167\ttotal: 27.6s\tremaining: 0us\n",
      "0:\tlearn: 1.2503068\ttotal: 275ms\tremaining: 27.2s\n",
      "1:\tlearn: 1.0477035\ttotal: 552ms\tremaining: 27.1s\n",
      "2:\tlearn: 0.9116336\ttotal: 843ms\tremaining: 27.2s\n",
      "3:\tlearn: 0.8324993\ttotal: 1.14s\tremaining: 27.3s\n",
      "4:\tlearn: 0.7706255\ttotal: 1.41s\tremaining: 26.8s\n",
      "5:\tlearn: 0.7187089\ttotal: 1.7s\tremaining: 26.6s\n",
      "6:\tlearn: 0.6785269\ttotal: 1.98s\tremaining: 26.3s\n",
      "7:\tlearn: 0.6421193\ttotal: 2.27s\tremaining: 26.1s\n",
      "8:\tlearn: 0.6068233\ttotal: 2.57s\tremaining: 26s\n",
      "9:\tlearn: 0.5786453\ttotal: 2.87s\tremaining: 25.8s\n",
      "10:\tlearn: 0.5635693\ttotal: 3.14s\tremaining: 25.4s\n",
      "11:\tlearn: 0.5501816\ttotal: 3.43s\tremaining: 25.1s\n",
      "12:\tlearn: 0.5345276\ttotal: 3.72s\tremaining: 24.9s\n",
      "13:\tlearn: 0.5252909\ttotal: 4s\tremaining: 24.6s\n",
      "14:\tlearn: 0.5117636\ttotal: 4.29s\tremaining: 24.3s\n",
      "15:\tlearn: 0.5053637\ttotal: 4.57s\tremaining: 24s\n",
      "16:\tlearn: 0.4991372\ttotal: 4.84s\tremaining: 23.6s\n",
      "17:\tlearn: 0.4899824\ttotal: 5.13s\tremaining: 23.4s\n",
      "18:\tlearn: 0.4817277\ttotal: 5.41s\tremaining: 23.1s\n",
      "19:\tlearn: 0.4712011\ttotal: 5.7s\tremaining: 22.8s\n",
      "20:\tlearn: 0.4663543\ttotal: 5.96s\tremaining: 22.4s\n",
      "21:\tlearn: 0.4620317\ttotal: 6.22s\tremaining: 22.1s\n",
      "22:\tlearn: 0.4566709\ttotal: 6.49s\tremaining: 21.7s\n",
      "23:\tlearn: 0.4469512\ttotal: 6.76s\tremaining: 21.4s\n",
      "24:\tlearn: 0.4431239\ttotal: 7.04s\tremaining: 21.1s\n",
      "25:\tlearn: 0.4396459\ttotal: 7.3s\tremaining: 20.8s\n",
      "26:\tlearn: 0.4343429\ttotal: 7.56s\tremaining: 20.4s\n",
      "27:\tlearn: 0.4263729\ttotal: 7.86s\tremaining: 20.2s\n",
      "28:\tlearn: 0.4216622\ttotal: 8.14s\tremaining: 19.9s\n",
      "29:\tlearn: 0.4165220\ttotal: 8.42s\tremaining: 19.6s\n",
      "30:\tlearn: 0.4131043\ttotal: 8.68s\tremaining: 19.3s\n",
      "31:\tlearn: 0.4041856\ttotal: 8.98s\tremaining: 19.1s\n",
      "32:\tlearn: 0.4010008\ttotal: 9.25s\tremaining: 18.8s\n",
      "33:\tlearn: 0.3975883\ttotal: 9.53s\tremaining: 18.5s\n",
      "34:\tlearn: 0.3938106\ttotal: 9.81s\tremaining: 18.2s\n",
      "35:\tlearn: 0.3895686\ttotal: 10.1s\tremaining: 17.9s\n",
      "36:\tlearn: 0.3846725\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 0.3829916\ttotal: 10.6s\tremaining: 17.3s\n",
      "38:\tlearn: 0.3794315\ttotal: 10.9s\tremaining: 17.1s\n",
      "39:\tlearn: 0.3749970\ttotal: 11.2s\tremaining: 16.8s\n",
      "40:\tlearn: 0.3733725\ttotal: 11.5s\tremaining: 16.5s\n",
      "41:\tlearn: 0.3698827\ttotal: 11.7s\tremaining: 16.2s\n",
      "42:\tlearn: 0.3683926\ttotal: 12s\tremaining: 15.9s\n",
      "43:\tlearn: 0.3659456\ttotal: 12.3s\tremaining: 15.6s\n",
      "44:\tlearn: 0.3637099\ttotal: 12.5s\tremaining: 15.3s\n",
      "45:\tlearn: 0.3621563\ttotal: 12.8s\tremaining: 15s\n",
      "46:\tlearn: 0.3588678\ttotal: 13.1s\tremaining: 14.8s\n",
      "47:\tlearn: 0.3566979\ttotal: 13.4s\tremaining: 14.5s\n",
      "48:\tlearn: 0.3543719\ttotal: 13.6s\tremaining: 14.2s\n",
      "49:\tlearn: 0.3523474\ttotal: 13.9s\tremaining: 13.9s\n",
      "50:\tlearn: 0.3504780\ttotal: 14.2s\tremaining: 13.6s\n",
      "51:\tlearn: 0.3485608\ttotal: 14.4s\tremaining: 13.3s\n",
      "52:\tlearn: 0.3459472\ttotal: 14.7s\tremaining: 13s\n",
      "53:\tlearn: 0.3423936\ttotal: 15s\tremaining: 12.8s\n",
      "54:\tlearn: 0.3408505\ttotal: 15.3s\tremaining: 12.5s\n",
      "55:\tlearn: 0.3387584\ttotal: 15.5s\tremaining: 12.2s\n",
      "56:\tlearn: 0.3375933\ttotal: 15.8s\tremaining: 11.9s\n",
      "57:\tlearn: 0.3360651\ttotal: 16.1s\tremaining: 11.6s\n",
      "58:\tlearn: 0.3339156\ttotal: 16.3s\tremaining: 11.4s\n",
      "59:\tlearn: 0.3304765\ttotal: 16.6s\tremaining: 11.1s\n",
      "60:\tlearn: 0.3286450\ttotal: 16.9s\tremaining: 10.8s\n",
      "61:\tlearn: 0.3265360\ttotal: 17.2s\tremaining: 10.5s\n",
      "62:\tlearn: 0.3255338\ttotal: 17.4s\tremaining: 10.2s\n",
      "63:\tlearn: 0.3227127\ttotal: 17.7s\tremaining: 9.98s\n",
      "64:\tlearn: 0.3198453\ttotal: 18s\tremaining: 9.71s\n",
      "65:\tlearn: 0.3192675\ttotal: 18.3s\tremaining: 9.42s\n",
      "66:\tlearn: 0.3179716\ttotal: 18.6s\tremaining: 9.14s\n",
      "67:\tlearn: 0.3159851\ttotal: 18.8s\tremaining: 8.86s\n",
      "68:\tlearn: 0.3149279\ttotal: 19.1s\tremaining: 8.58s\n",
      "69:\tlearn: 0.3140414\ttotal: 19.4s\tremaining: 8.3s\n",
      "70:\tlearn: 0.3133543\ttotal: 19.6s\tremaining: 8.02s\n",
      "71:\tlearn: 0.3120757\ttotal: 19.9s\tremaining: 7.74s\n",
      "72:\tlearn: 0.3109591\ttotal: 20.2s\tremaining: 7.46s\n",
      "73:\tlearn: 0.3081813\ttotal: 20.4s\tremaining: 7.18s\n",
      "74:\tlearn: 0.3065825\ttotal: 20.7s\tremaining: 6.9s\n",
      "75:\tlearn: 0.3042398\ttotal: 21s\tremaining: 6.63s\n",
      "76:\tlearn: 0.3021675\ttotal: 21.3s\tremaining: 6.35s\n",
      "77:\tlearn: 0.3006531\ttotal: 21.5s\tremaining: 6.08s\n",
      "78:\tlearn: 0.2968666\ttotal: 21.8s\tremaining: 5.8s\n",
      "79:\tlearn: 0.2946922\ttotal: 22.1s\tremaining: 5.53s\n",
      "80:\tlearn: 0.2936545\ttotal: 22.4s\tremaining: 5.25s\n",
      "81:\tlearn: 0.2926375\ttotal: 22.6s\tremaining: 4.97s\n",
      "82:\tlearn: 0.2900254\ttotal: 22.9s\tremaining: 4.69s\n",
      "83:\tlearn: 0.2876533\ttotal: 23.2s\tremaining: 4.42s\n",
      "84:\tlearn: 0.2861836\ttotal: 23.5s\tremaining: 4.14s\n",
      "85:\tlearn: 0.2849283\ttotal: 23.7s\tremaining: 3.87s\n",
      "86:\tlearn: 0.2831328\ttotal: 24s\tremaining: 3.59s\n",
      "87:\tlearn: 0.2826099\ttotal: 24.3s\tremaining: 3.31s\n",
      "88:\tlearn: 0.2811823\ttotal: 24.5s\tremaining: 3.03s\n",
      "89:\tlearn: 0.2801331\ttotal: 24.8s\tremaining: 2.76s\n",
      "90:\tlearn: 0.2794274\ttotal: 25.1s\tremaining: 2.48s\n",
      "91:\tlearn: 0.2786366\ttotal: 25.3s\tremaining: 2.2s\n",
      "92:\tlearn: 0.2780240\ttotal: 25.6s\tremaining: 1.93s\n",
      "93:\tlearn: 0.2768479\ttotal: 25.9s\tremaining: 1.65s\n",
      "94:\tlearn: 0.2760667\ttotal: 26.1s\tremaining: 1.38s\n",
      "95:\tlearn: 0.2748787\ttotal: 26.4s\tremaining: 1.1s\n",
      "96:\tlearn: 0.2734957\ttotal: 26.7s\tremaining: 825ms\n",
      "97:\tlearn: 0.2728759\ttotal: 26.9s\tremaining: 550ms\n",
      "98:\tlearn: 0.2711648\ttotal: 27.3s\tremaining: 275ms\n",
      "99:\tlearn: 0.2689142\ttotal: 27.5s\tremaining: 0us\n",
      "0:\tlearn: 1.5304652\ttotal: 271ms\tremaining: 26.9s\n",
      "1:\tlearn: 3.9594276\ttotal: 563ms\tremaining: 27.6s\n",
      "2:\tlearn: 22.8090832\ttotal: 845ms\tremaining: 27.3s\n",
      "3:\tlearn: 14.1684297\ttotal: 1.14s\tremaining: 27.3s\n",
      "4:\tlearn: 13.4715753\ttotal: 1.43s\tremaining: 27.1s\n",
      "5:\tlearn: 12.1525011\ttotal: 1.7s\tremaining: 26.7s\n",
      "6:\tlearn: 10.9711181\ttotal: 2s\tremaining: 26.6s\n",
      "7:\tlearn: 10.3372942\ttotal: 2.3s\tremaining: 26.4s\n",
      "8:\tlearn: 10.3191299\ttotal: 2.58s\tremaining: 26.1s\n",
      "9:\tlearn: 9.2994778\ttotal: 2.87s\tremaining: 25.8s\n",
      "10:\tlearn: 8.9432314\ttotal: 3.17s\tremaining: 25.6s\n",
      "11:\tlearn: 8.7004866\ttotal: 3.46s\tremaining: 25.4s\n",
      "12:\tlearn: 8.5347425\ttotal: 3.75s\tremaining: 25.1s\n",
      "13:\tlearn: 8.3822425\ttotal: 4.03s\tremaining: 24.7s\n",
      "14:\tlearn: 8.1667093\ttotal: 4.31s\tremaining: 24.4s\n",
      "15:\tlearn: 8.0273147\ttotal: 4.58s\tremaining: 24.1s\n",
      "16:\tlearn: 7.8583587\ttotal: 4.87s\tremaining: 23.8s\n",
      "17:\tlearn: 7.7132111\ttotal: 5.16s\tremaining: 23.5s\n",
      "18:\tlearn: 7.4960955\ttotal: 5.45s\tremaining: 23.2s\n",
      "19:\tlearn: 7.4246610\ttotal: 5.71s\tremaining: 22.8s\n",
      "20:\tlearn: 7.3578026\ttotal: 5.98s\tremaining: 22.5s\n",
      "21:\tlearn: 7.2548322\ttotal: 6.27s\tremaining: 22.2s\n",
      "22:\tlearn: 7.2118065\ttotal: 6.54s\tremaining: 21.9s\n",
      "23:\tlearn: 7.1460010\ttotal: 6.82s\tremaining: 21.6s\n",
      "24:\tlearn: 7.0230654\ttotal: 7.09s\tremaining: 21.3s\n",
      "25:\tlearn: 6.8799874\ttotal: 7.38s\tremaining: 21s\n",
      "26:\tlearn: 6.6813121\ttotal: 7.66s\tremaining: 20.7s\n",
      "27:\tlearn: 6.6127516\ttotal: 7.93s\tremaining: 20.4s\n",
      "28:\tlearn: 6.5803724\ttotal: 8.21s\tremaining: 20.1s\n",
      "29:\tlearn: 6.5439883\ttotal: 8.46s\tremaining: 19.8s\n",
      "30:\tlearn: 6.5023767\ttotal: 8.73s\tremaining: 19.4s\n",
      "31:\tlearn: 6.4776322\ttotal: 9.01s\tremaining: 19.1s\n",
      "32:\tlearn: 6.3814886\ttotal: 9.3s\tremaining: 18.9s\n",
      "33:\tlearn: 6.3518612\ttotal: 9.57s\tremaining: 18.6s\n",
      "34:\tlearn: 6.3091767\ttotal: 9.84s\tremaining: 18.3s\n",
      "35:\tlearn: 6.2630024\ttotal: 10.1s\tremaining: 18s\n",
      "36:\tlearn: 6.2341382\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 6.2085123\ttotal: 10.6s\tremaining: 17.4s\n",
      "38:\tlearn: 6.1937622\ttotal: 10.9s\tremaining: 17.1s\n",
      "39:\tlearn: 6.1714935\ttotal: 11.2s\tremaining: 16.8s\n",
      "40:\tlearn: 6.1236106\ttotal: 11.4s\tremaining: 16.5s\n",
      "41:\tlearn: 6.1085439\ttotal: 11.7s\tremaining: 16.2s\n",
      "42:\tlearn: 6.0758630\ttotal: 12s\tremaining: 15.9s\n",
      "43:\tlearn: 6.0639140\ttotal: 12.2s\tremaining: 15.6s\n",
      "44:\tlearn: 5.9118809\ttotal: 12.5s\tremaining: 15.3s\n",
      "45:\tlearn: 5.8778706\ttotal: 12.8s\tremaining: 15s\n",
      "46:\tlearn: 5.8616648\ttotal: 13s\tremaining: 14.7s\n",
      "47:\tlearn: 5.8408098\ttotal: 13.3s\tremaining: 14.4s\n",
      "48:\tlearn: 5.8146740\ttotal: 13.6s\tremaining: 14.1s\n",
      "49:\tlearn: 5.7920405\ttotal: 13.8s\tremaining: 13.8s\n",
      "50:\tlearn: 5.7650822\ttotal: 14.1s\tremaining: 13.5s\n",
      "51:\tlearn: 5.7270788\ttotal: 14.4s\tremaining: 13.3s\n",
      "52:\tlearn: 5.7032085\ttotal: 14.6s\tremaining: 13s\n",
      "53:\tlearn: 5.6944799\ttotal: 14.9s\tremaining: 12.7s\n",
      "54:\tlearn: 5.6786196\ttotal: 15.2s\tremaining: 12.4s\n",
      "55:\tlearn: 5.6582612\ttotal: 15.4s\tremaining: 12.1s\n",
      "56:\tlearn: 5.6442118\ttotal: 15.7s\tremaining: 11.8s\n",
      "57:\tlearn: 5.6212680\ttotal: 16s\tremaining: 11.6s\n",
      "58:\tlearn: 5.6027348\ttotal: 16.2s\tremaining: 11.3s\n",
      "59:\tlearn: 5.5937097\ttotal: 16.5s\tremaining: 11s\n",
      "60:\tlearn: 5.5385128\ttotal: 16.8s\tremaining: 10.7s\n",
      "61:\tlearn: 5.5326013\ttotal: 17s\tremaining: 10.4s\n",
      "62:\tlearn: 5.5131654\ttotal: 17.3s\tremaining: 10.2s\n",
      "63:\tlearn: 5.4495935\ttotal: 17.6s\tremaining: 9.88s\n",
      "64:\tlearn: 5.3717743\ttotal: 17.8s\tremaining: 9.61s\n",
      "65:\tlearn: 5.3473016\ttotal: 18.1s\tremaining: 9.33s\n",
      "66:\tlearn: 5.3402977\ttotal: 18.4s\tremaining: 9.05s\n",
      "67:\tlearn: 5.3338818\ttotal: 18.6s\tremaining: 8.77s\n",
      "68:\tlearn: 5.3229890\ttotal: 18.9s\tremaining: 8.49s\n",
      "69:\tlearn: 5.2994724\ttotal: 19.2s\tremaining: 8.21s\n",
      "70:\tlearn: 4.8953893\ttotal: 19.4s\tremaining: 7.94s\n",
      "71:\tlearn: 4.8475504\ttotal: 19.7s\tremaining: 7.67s\n",
      "72:\tlearn: 4.8417753\ttotal: 20s\tremaining: 7.4s\n",
      "73:\tlearn: 4.8135596\ttotal: 20.3s\tremaining: 7.13s\n",
      "74:\tlearn: 4.7704425\ttotal: 20.6s\tremaining: 6.85s\n",
      "75:\tlearn: 4.7533701\ttotal: 20.8s\tremaining: 6.58s\n",
      "76:\tlearn: 4.7056709\ttotal: 21.1s\tremaining: 6.31s\n",
      "77:\tlearn: 4.6941532\ttotal: 21.4s\tremaining: 6.03s\n",
      "78:\tlearn: 4.6899946\ttotal: 21.6s\tremaining: 5.75s\n",
      "79:\tlearn: 4.6733442\ttotal: 21.9s\tremaining: 5.48s\n",
      "80:\tlearn: 4.6557811\ttotal: 22.2s\tremaining: 5.2s\n",
      "81:\tlearn: 4.6368030\ttotal: 22.4s\tremaining: 4.93s\n",
      "82:\tlearn: 4.6306304\ttotal: 22.7s\tremaining: 4.65s\n",
      "83:\tlearn: 4.6196742\ttotal: 23s\tremaining: 4.38s\n",
      "84:\tlearn: 4.6019293\ttotal: 23.2s\tremaining: 4.1s\n",
      "85:\tlearn: 4.5959377\ttotal: 23.5s\tremaining: 3.83s\n",
      "86:\tlearn: 4.5534721\ttotal: 23.8s\tremaining: 3.55s\n",
      "87:\tlearn: 4.5445230\ttotal: 24s\tremaining: 3.28s\n",
      "88:\tlearn: 4.5210723\ttotal: 24.3s\tremaining: 3.01s\n",
      "89:\tlearn: 4.5031242\ttotal: 24.6s\tremaining: 2.73s\n",
      "90:\tlearn: 4.4889317\ttotal: 24.9s\tremaining: 2.46s\n",
      "91:\tlearn: 4.4821851\ttotal: 25.1s\tremaining: 2.18s\n",
      "92:\tlearn: 4.4708323\ttotal: 25.4s\tremaining: 1.91s\n",
      "93:\tlearn: 4.4446280\ttotal: 25.7s\tremaining: 1.64s\n",
      "94:\tlearn: 4.4387830\ttotal: 25.9s\tremaining: 1.36s\n",
      "95:\tlearn: 4.4325754\ttotal: 26.2s\tremaining: 1.09s\n",
      "96:\tlearn: 4.4099295\ttotal: 26.5s\tremaining: 818ms\n",
      "97:\tlearn: 4.3996484\ttotal: 26.7s\tremaining: 545ms\n",
      "98:\tlearn: 4.3804805\ttotal: 27s\tremaining: 273ms\n",
      "99:\tlearn: 4.3686009\ttotal: 27.3s\tremaining: 0us\n",
      "0:\tlearn: 1.4178636\ttotal: 275ms\tremaining: 27.3s\n",
      "1:\tlearn: 4.2154843\ttotal: 552ms\tremaining: 27.1s\n",
      "2:\tlearn: 13.1777011\ttotal: 833ms\tremaining: 26.9s\n",
      "3:\tlearn: 14.2806637\ttotal: 1.11s\tremaining: 26.7s\n",
      "4:\tlearn: 16.4422268\ttotal: 1.4s\tremaining: 26.6s\n",
      "5:\tlearn: 27.6912923\ttotal: 1.68s\tremaining: 26.4s\n",
      "6:\tlearn: 25.8154626\ttotal: 1.98s\tremaining: 26.3s\n",
      "7:\tlearn: 30.0826418\ttotal: 2.28s\tremaining: 26.2s\n",
      "8:\tlearn: 27.7295839\ttotal: 2.57s\tremaining: 26s\n",
      "9:\tlearn: 26.5603629\ttotal: 2.85s\tremaining: 25.7s\n",
      "10:\tlearn: 25.4710872\ttotal: 3.13s\tremaining: 25.4s\n",
      "11:\tlearn: 24.5573572\ttotal: 3.43s\tremaining: 25.2s\n",
      "12:\tlearn: 23.3305677\ttotal: 3.72s\tremaining: 24.9s\n",
      "13:\tlearn: 22.3812545\ttotal: 4.02s\tremaining: 24.7s\n",
      "14:\tlearn: 21.7156230\ttotal: 4.31s\tremaining: 24.4s\n",
      "15:\tlearn: 21.2362963\ttotal: 4.61s\tremaining: 24.2s\n",
      "16:\tlearn: 20.9976871\ttotal: 4.89s\tremaining: 23.9s\n",
      "17:\tlearn: 20.5050044\ttotal: 5.15s\tremaining: 23.5s\n",
      "18:\tlearn: 20.2809683\ttotal: 5.45s\tremaining: 23.2s\n",
      "19:\tlearn: 19.4951735\ttotal: 5.72s\tremaining: 22.9s\n",
      "20:\tlearn: 19.2542500\ttotal: 6.02s\tremaining: 22.7s\n",
      "21:\tlearn: 18.8277794\ttotal: 6.33s\tremaining: 22.4s\n",
      "22:\tlearn: 18.6695371\ttotal: 6.59s\tremaining: 22.1s\n",
      "23:\tlearn: 18.5222050\ttotal: 6.87s\tremaining: 21.7s\n",
      "24:\tlearn: 18.2660869\ttotal: 7.15s\tremaining: 21.4s\n",
      "25:\tlearn: 17.9608755\ttotal: 7.43s\tremaining: 21.2s\n",
      "26:\tlearn: 17.8494076\ttotal: 7.73s\tremaining: 20.9s\n",
      "27:\tlearn: 17.7754424\ttotal: 8s\tremaining: 20.6s\n",
      "28:\tlearn: 17.5455198\ttotal: 8.29s\tremaining: 20.3s\n",
      "29:\tlearn: 17.5035272\ttotal: 8.57s\tremaining: 20s\n",
      "30:\tlearn: 17.4060362\ttotal: 8.84s\tremaining: 19.7s\n",
      "31:\tlearn: 17.3391421\ttotal: 9.11s\tremaining: 19.4s\n",
      "32:\tlearn: 16.6237532\ttotal: 9.41s\tremaining: 19.1s\n",
      "33:\tlearn: 16.4854877\ttotal: 9.68s\tremaining: 18.8s\n",
      "34:\tlearn: 15.9928585\ttotal: 9.98s\tremaining: 18.5s\n",
      "35:\tlearn: 15.7140192\ttotal: 10.3s\tremaining: 18.2s\n",
      "36:\tlearn: 15.6522244\ttotal: 10.5s\tremaining: 17.9s\n",
      "37:\tlearn: 15.2758985\ttotal: 10.8s\tremaining: 17.6s\n",
      "38:\tlearn: 15.1149175\ttotal: 11.1s\tremaining: 17.4s\n",
      "39:\tlearn: 14.9202555\ttotal: 11.4s\tremaining: 17.1s\n",
      "40:\tlearn: 14.3822511\ttotal: 11.7s\tremaining: 16.8s\n",
      "41:\tlearn: 14.2305127\ttotal: 11.9s\tremaining: 16.5s\n",
      "42:\tlearn: 13.9377907\ttotal: 12.2s\tremaining: 16.2s\n",
      "43:\tlearn: 13.4553489\ttotal: 12.5s\tremaining: 15.9s\n",
      "44:\tlearn: 13.4055203\ttotal: 12.8s\tremaining: 15.6s\n",
      "45:\tlearn: 13.3244871\ttotal: 13.1s\tremaining: 15.3s\n",
      "46:\tlearn: 13.0807672\ttotal: 13.4s\tremaining: 15.1s\n",
      "47:\tlearn: 12.9843008\ttotal: 13.6s\tremaining: 14.8s\n",
      "48:\tlearn: 12.9570908\ttotal: 13.9s\tremaining: 14.5s\n",
      "49:\tlearn: 12.7634920\ttotal: 14.2s\tremaining: 14.2s\n",
      "50:\tlearn: 12.7360000\ttotal: 14.5s\tremaining: 13.9s\n",
      "51:\tlearn: 12.7028716\ttotal: 14.7s\tremaining: 13.6s\n",
      "52:\tlearn: 12.5823648\ttotal: 15s\tremaining: 13.3s\n",
      "53:\tlearn: 12.4886243\ttotal: 15.3s\tremaining: 13s\n",
      "54:\tlearn: 12.4677147\ttotal: 15.5s\tremaining: 12.7s\n",
      "55:\tlearn: 12.4020083\ttotal: 15.8s\tremaining: 12.4s\n",
      "56:\tlearn: 12.3602515\ttotal: 16.1s\tremaining: 12.1s\n",
      "57:\tlearn: 12.2757289\ttotal: 16.4s\tremaining: 11.8s\n",
      "58:\tlearn: 12.2385269\ttotal: 16.6s\tremaining: 11.6s\n",
      "59:\tlearn: 12.2104304\ttotal: 16.9s\tremaining: 11.3s\n",
      "60:\tlearn: 12.1923221\ttotal: 17.2s\tremaining: 11s\n",
      "61:\tlearn: 12.0051930\ttotal: 17.5s\tremaining: 10.7s\n",
      "62:\tlearn: 11.9225527\ttotal: 17.7s\tremaining: 10.4s\n",
      "63:\tlearn: 11.6560542\ttotal: 18s\tremaining: 10.1s\n",
      "64:\tlearn: 11.6188536\ttotal: 18.3s\tremaining: 9.85s\n",
      "65:\tlearn: 11.5909186\ttotal: 18.6s\tremaining: 9.56s\n",
      "66:\tlearn: 11.5499733\ttotal: 18.8s\tremaining: 9.28s\n",
      "67:\tlearn: 11.4047646\ttotal: 19.1s\tremaining: 9s\n",
      "68:\tlearn: 11.3666829\ttotal: 19.4s\tremaining: 8.71s\n",
      "69:\tlearn: 11.3245062\ttotal: 19.7s\tremaining: 8.43s\n",
      "70:\tlearn: 11.2673403\ttotal: 19.9s\tremaining: 8.15s\n",
      "71:\tlearn: 11.2544220\ttotal: 20.2s\tremaining: 7.86s\n",
      "72:\tlearn: 11.2318657\ttotal: 20.5s\tremaining: 7.57s\n",
      "73:\tlearn: 11.2182228\ttotal: 20.7s\tremaining: 7.29s\n",
      "74:\tlearn: 11.1511017\ttotal: 21s\tremaining: 7s\n",
      "75:\tlearn: 11.1197278\ttotal: 21.3s\tremaining: 6.72s\n",
      "76:\tlearn: 11.0983356\ttotal: 21.5s\tremaining: 6.43s\n",
      "77:\tlearn: 11.0537191\ttotal: 21.8s\tremaining: 6.15s\n",
      "78:\tlearn: 11.0237432\ttotal: 22.1s\tremaining: 5.87s\n",
      "79:\tlearn: 10.9730851\ttotal: 22.4s\tremaining: 5.59s\n",
      "80:\tlearn: 10.9180190\ttotal: 22.6s\tremaining: 5.31s\n",
      "81:\tlearn: 10.8988039\ttotal: 22.9s\tremaining: 5.03s\n",
      "82:\tlearn: 10.8534819\ttotal: 23.2s\tremaining: 4.75s\n",
      "83:\tlearn: 10.8468038\ttotal: 23.4s\tremaining: 4.47s\n",
      "84:\tlearn: 10.8315166\ttotal: 23.7s\tremaining: 4.18s\n",
      "85:\tlearn: 10.7792392\ttotal: 24s\tremaining: 3.91s\n",
      "86:\tlearn: 10.7324589\ttotal: 24.3s\tremaining: 3.63s\n",
      "87:\tlearn: 10.6985781\ttotal: 24.5s\tremaining: 3.35s\n",
      "88:\tlearn: 10.6869101\ttotal: 24.8s\tremaining: 3.06s\n",
      "89:\tlearn: 10.6405182\ttotal: 25.1s\tremaining: 2.79s\n",
      "90:\tlearn: 10.6060612\ttotal: 25.3s\tremaining: 2.51s\n",
      "91:\tlearn: 10.5796016\ttotal: 25.6s\tremaining: 2.23s\n",
      "92:\tlearn: 10.5570703\ttotal: 25.9s\tremaining: 1.95s\n",
      "93:\tlearn: 10.5004194\ttotal: 26.2s\tremaining: 1.67s\n",
      "94:\tlearn: 10.1794712\ttotal: 26.4s\tremaining: 1.39s\n",
      "95:\tlearn: 10.1560820\ttotal: 26.7s\tremaining: 1.11s\n",
      "96:\tlearn: 10.1489982\ttotal: 27s\tremaining: 835ms\n",
      "97:\tlearn: 10.0888890\ttotal: 27.3s\tremaining: 557ms\n",
      "98:\tlearn: 10.0776293\ttotal: 27.5s\tremaining: 278ms\n",
      "99:\tlearn: 10.0650861\ttotal: 27.8s\tremaining: 0us\n",
      "0:\tlearn: 1.4243817\ttotal: 271ms\tremaining: 26.8s\n",
      "1:\tlearn: 2.4462211\ttotal: 549ms\tremaining: 26.9s\n",
      "2:\tlearn: 12.7209456\ttotal: 844ms\tremaining: 27.3s\n",
      "3:\tlearn: 10.8348138\ttotal: 1.12s\tremaining: 27s\n",
      "4:\tlearn: 10.3888988\ttotal: 1.41s\tremaining: 26.7s\n",
      "5:\tlearn: 10.1636458\ttotal: 1.69s\tremaining: 26.6s\n",
      "6:\tlearn: 8.8300284\ttotal: 1.98s\tremaining: 26.3s\n",
      "7:\tlearn: 10.4688496\ttotal: 2.28s\tremaining: 26.2s\n",
      "8:\tlearn: 9.4708793\ttotal: 2.57s\tremaining: 26s\n",
      "9:\tlearn: 8.9756507\ttotal: 2.86s\tremaining: 25.7s\n",
      "10:\tlearn: 9.1636987\ttotal: 3.16s\tremaining: 25.6s\n",
      "11:\tlearn: 8.5103581\ttotal: 3.45s\tremaining: 25.3s\n",
      "12:\tlearn: 7.7510597\ttotal: 3.74s\tremaining: 25s\n",
      "13:\tlearn: 7.3143430\ttotal: 4.03s\tremaining: 24.8s\n",
      "14:\tlearn: 6.7871872\ttotal: 4.33s\tremaining: 24.5s\n",
      "15:\tlearn: 6.6276053\ttotal: 4.61s\tremaining: 24.2s\n",
      "16:\tlearn: 6.4796052\ttotal: 4.91s\tremaining: 24s\n",
      "17:\tlearn: 6.1936373\ttotal: 5.21s\tremaining: 23.7s\n",
      "18:\tlearn: 6.0568934\ttotal: 5.5s\tremaining: 23.4s\n",
      "19:\tlearn: 5.9583625\ttotal: 5.78s\tremaining: 23.1s\n",
      "20:\tlearn: 5.8727198\ttotal: 6.06s\tremaining: 22.8s\n",
      "21:\tlearn: 5.7843573\ttotal: 6.34s\tremaining: 22.5s\n",
      "22:\tlearn: 5.7522106\ttotal: 6.61s\tremaining: 22.1s\n",
      "23:\tlearn: 5.7154066\ttotal: 6.88s\tremaining: 21.8s\n",
      "24:\tlearn: 5.6507107\ttotal: 7.15s\tremaining: 21.4s\n",
      "25:\tlearn: 5.5841829\ttotal: 7.43s\tremaining: 21.1s\n",
      "26:\tlearn: 5.5350633\ttotal: 7.7s\tremaining: 20.8s\n",
      "27:\tlearn: 5.3846441\ttotal: 7.97s\tremaining: 20.5s\n",
      "28:\tlearn: 5.3446222\ttotal: 8.23s\tremaining: 20.2s\n",
      "29:\tlearn: 5.3197164\ttotal: 8.5s\tremaining: 19.8s\n",
      "30:\tlearn: 5.2526150\ttotal: 8.78s\tremaining: 19.5s\n",
      "31:\tlearn: 5.2068206\ttotal: 9.06s\tremaining: 19.2s\n",
      "32:\tlearn: 5.1773428\ttotal: 9.33s\tremaining: 18.9s\n",
      "33:\tlearn: 5.1502752\ttotal: 9.6s\tremaining: 18.6s\n",
      "34:\tlearn: 5.1246120\ttotal: 9.87s\tremaining: 18.3s\n",
      "35:\tlearn: 5.0870947\ttotal: 10.2s\tremaining: 18.1s\n",
      "36:\tlearn: 5.0647698\ttotal: 10.4s\tremaining: 17.7s\n",
      "37:\tlearn: 4.9455085\ttotal: 10.7s\tremaining: 17.5s\n",
      "38:\tlearn: 4.9205463\ttotal: 11s\tremaining: 17.2s\n",
      "39:\tlearn: 4.9045241\ttotal: 11.2s\tremaining: 16.9s\n",
      "40:\tlearn: 4.8897192\ttotal: 11.5s\tremaining: 16.6s\n",
      "41:\tlearn: 4.8760849\ttotal: 11.8s\tremaining: 16.3s\n",
      "42:\tlearn: 4.8639433\ttotal: 12.1s\tremaining: 16s\n",
      "43:\tlearn: 4.8491512\ttotal: 12.3s\tremaining: 15.7s\n",
      "44:\tlearn: 4.8157987\ttotal: 12.6s\tremaining: 15.4s\n",
      "45:\tlearn: 4.8060961\ttotal: 12.9s\tremaining: 15.1s\n",
      "46:\tlearn: 4.7729003\ttotal: 13.1s\tremaining: 14.8s\n",
      "47:\tlearn: 4.6833486\ttotal: 13.4s\tremaining: 14.5s\n",
      "48:\tlearn: 4.6691795\ttotal: 13.7s\tremaining: 14.2s\n",
      "49:\tlearn: 4.6634250\ttotal: 13.9s\tremaining: 13.9s\n",
      "50:\tlearn: 4.6417253\ttotal: 14.2s\tremaining: 13.7s\n",
      "51:\tlearn: 4.6261750\ttotal: 14.5s\tremaining: 13.4s\n",
      "52:\tlearn: 4.5131466\ttotal: 14.8s\tremaining: 13.1s\n",
      "53:\tlearn: 4.4997845\ttotal: 15s\tremaining: 12.8s\n",
      "54:\tlearn: 4.4872186\ttotal: 15.3s\tremaining: 12.5s\n",
      "55:\tlearn: 4.4308898\ttotal: 15.6s\tremaining: 12.3s\n",
      "56:\tlearn: 4.4214065\ttotal: 15.9s\tremaining: 12s\n",
      "57:\tlearn: 4.4150389\ttotal: 16.1s\tremaining: 11.7s\n",
      "58:\tlearn: 4.3861125\ttotal: 16.4s\tremaining: 11.4s\n",
      "59:\tlearn: 4.3172777\ttotal: 16.7s\tremaining: 11.1s\n",
      "60:\tlearn: 4.3072157\ttotal: 17s\tremaining: 10.8s\n",
      "61:\tlearn: 4.2919476\ttotal: 17.2s\tremaining: 10.6s\n",
      "62:\tlearn: 4.2113676\ttotal: 17.5s\tremaining: 10.3s\n",
      "63:\tlearn: 4.2035736\ttotal: 17.8s\tremaining: 10s\n",
      "64:\tlearn: 4.1949746\ttotal: 18s\tremaining: 9.72s\n",
      "65:\tlearn: 4.1879964\ttotal: 18.3s\tremaining: 9.43s\n",
      "66:\tlearn: 4.1759917\ttotal: 18.6s\tremaining: 9.15s\n",
      "67:\tlearn: 4.1634577\ttotal: 18.8s\tremaining: 8.87s\n",
      "68:\tlearn: 4.1501686\ttotal: 19.1s\tremaining: 8.59s\n",
      "69:\tlearn: 4.1409193\ttotal: 19.4s\tremaining: 8.3s\n",
      "70:\tlearn: 4.1309885\ttotal: 19.6s\tremaining: 8.02s\n",
      "71:\tlearn: 4.1167685\ttotal: 19.9s\tremaining: 7.75s\n",
      "72:\tlearn: 4.0962029\ttotal: 20.2s\tremaining: 7.47s\n",
      "73:\tlearn: 4.0880206\ttotal: 20.6s\tremaining: 7.24s\n",
      "74:\tlearn: 4.0797600\ttotal: 20.9s\tremaining: 6.97s\n",
      "75:\tlearn: 4.0650321\ttotal: 21.2s\tremaining: 6.69s\n",
      "76:\tlearn: 4.0553120\ttotal: 21.5s\tremaining: 6.41s\n",
      "77:\tlearn: 4.0453034\ttotal: 21.7s\tremaining: 6.13s\n",
      "78:\tlearn: 3.9845717\ttotal: 22s\tremaining: 5.86s\n",
      "79:\tlearn: 3.9782503\ttotal: 22.3s\tremaining: 5.57s\n",
      "80:\tlearn: 3.9661066\ttotal: 22.6s\tremaining: 5.29s\n",
      "81:\tlearn: 3.9561458\ttotal: 22.8s\tremaining: 5.01s\n",
      "82:\tlearn: 3.9429443\ttotal: 23.1s\tremaining: 4.73s\n",
      "83:\tlearn: 3.9333858\ttotal: 23.4s\tremaining: 4.45s\n",
      "84:\tlearn: 3.9168024\ttotal: 23.6s\tremaining: 4.17s\n",
      "85:\tlearn: 3.9111828\ttotal: 23.9s\tremaining: 3.89s\n",
      "86:\tlearn: 3.8993808\ttotal: 24.2s\tremaining: 3.61s\n",
      "87:\tlearn: 3.8903944\ttotal: 24.4s\tremaining: 3.33s\n",
      "88:\tlearn: 3.8809635\ttotal: 24.7s\tremaining: 3.05s\n",
      "89:\tlearn: 3.8672668\ttotal: 24.9s\tremaining: 2.77s\n",
      "90:\tlearn: 3.8616449\ttotal: 25.2s\tremaining: 2.49s\n",
      "91:\tlearn: 3.8455175\ttotal: 25.5s\tremaining: 2.22s\n",
      "92:\tlearn: 3.8375240\ttotal: 25.8s\tremaining: 1.94s\n",
      "93:\tlearn: 3.8253003\ttotal: 26s\tremaining: 1.66s\n",
      "94:\tlearn: 3.8203217\ttotal: 26.3s\tremaining: 1.38s\n",
      "95:\tlearn: 3.8173699\ttotal: 26.5s\tremaining: 1.1s\n",
      "96:\tlearn: 3.8084090\ttotal: 26.8s\tremaining: 829ms\n",
      "97:\tlearn: 3.8001314\ttotal: 27.3s\tremaining: 557ms\n",
      "98:\tlearn: 3.7883326\ttotal: 27.6s\tremaining: 279ms\n",
      "99:\tlearn: 3.7819997\ttotal: 27.9s\tremaining: 0us\n",
      "0:\tlearn: 2.2673938\ttotal: 268ms\tremaining: 53.3s\n",
      "1:\tlearn: 2.2333218\ttotal: 541ms\tremaining: 53.6s\n",
      "2:\tlearn: 2.2011205\ttotal: 815ms\tremaining: 53.5s\n",
      "3:\tlearn: 2.1712990\ttotal: 1.09s\tremaining: 53.6s\n",
      "4:\tlearn: 2.1409528\ttotal: 1.37s\tremaining: 53.4s\n",
      "5:\tlearn: 2.1136404\ttotal: 1.64s\tremaining: 53.1s\n",
      "6:\tlearn: 2.0870102\ttotal: 1.91s\tremaining: 52.8s\n",
      "7:\tlearn: 2.0612172\ttotal: 2.19s\tremaining: 52.6s\n",
      "8:\tlearn: 2.0345898\ttotal: 2.47s\tremaining: 52.5s\n",
      "9:\tlearn: 2.0107693\ttotal: 2.75s\tremaining: 52.2s\n",
      "10:\tlearn: 1.9885799\ttotal: 3.02s\tremaining: 52s\n",
      "11:\tlearn: 1.9672853\ttotal: 3.3s\tremaining: 51.7s\n",
      "12:\tlearn: 1.9465835\ttotal: 3.57s\tremaining: 51.3s\n",
      "13:\tlearn: 1.9267541\ttotal: 3.84s\tremaining: 51s\n",
      "14:\tlearn: 1.9073327\ttotal: 4.11s\tremaining: 50.7s\n",
      "15:\tlearn: 1.8879555\ttotal: 4.39s\tremaining: 50.5s\n",
      "16:\tlearn: 1.8698446\ttotal: 4.66s\tremaining: 50.2s\n",
      "17:\tlearn: 1.8524154\ttotal: 4.93s\tremaining: 49.8s\n",
      "18:\tlearn: 1.8348135\ttotal: 5.22s\tremaining: 49.7s\n",
      "19:\tlearn: 1.8167583\ttotal: 5.5s\tremaining: 49.6s\n",
      "20:\tlearn: 1.8005195\ttotal: 5.79s\tremaining: 49.3s\n",
      "21:\tlearn: 1.7830541\ttotal: 6.07s\tremaining: 49.1s\n",
      "22:\tlearn: 1.7660927\ttotal: 6.36s\tremaining: 48.9s\n",
      "23:\tlearn: 1.7505340\ttotal: 6.63s\tremaining: 48.6s\n",
      "24:\tlearn: 1.7350243\ttotal: 6.92s\tremaining: 48.4s\n",
      "25:\tlearn: 1.7204197\ttotal: 7.2s\tremaining: 48.2s\n",
      "26:\tlearn: 1.7061317\ttotal: 7.48s\tremaining: 48s\n",
      "27:\tlearn: 1.6930708\ttotal: 7.76s\tremaining: 47.7s\n",
      "28:\tlearn: 1.6789393\ttotal: 8.04s\tremaining: 47.4s\n",
      "29:\tlearn: 1.6655962\ttotal: 8.31s\tremaining: 47.1s\n",
      "30:\tlearn: 1.6530749\ttotal: 8.58s\tremaining: 46.8s\n",
      "31:\tlearn: 1.6399162\ttotal: 8.86s\tremaining: 46.5s\n",
      "32:\tlearn: 1.6271479\ttotal: 9.14s\tremaining: 46.3s\n",
      "33:\tlearn: 1.6142222\ttotal: 9.42s\tremaining: 46s\n",
      "34:\tlearn: 1.6019316\ttotal: 9.7s\tremaining: 45.7s\n",
      "35:\tlearn: 1.5899986\ttotal: 10s\tremaining: 45.6s\n",
      "36:\tlearn: 1.5791980\ttotal: 10.3s\tremaining: 45.3s\n",
      "37:\tlearn: 1.5670542\ttotal: 10.6s\tremaining: 45s\n",
      "38:\tlearn: 1.5558176\ttotal: 10.8s\tremaining: 44.8s\n",
      "39:\tlearn: 1.5452011\ttotal: 11.1s\tremaining: 44.5s\n",
      "40:\tlearn: 1.5348511\ttotal: 11.4s\tremaining: 44.3s\n",
      "41:\tlearn: 1.5240529\ttotal: 11.7s\tremaining: 44s\n",
      "42:\tlearn: 1.5140522\ttotal: 12s\tremaining: 43.7s\n",
      "43:\tlearn: 1.5042739\ttotal: 12.3s\tremaining: 43.5s\n",
      "44:\tlearn: 1.4947875\ttotal: 12.5s\tremaining: 43.2s\n",
      "45:\tlearn: 1.4850110\ttotal: 12.8s\tremaining: 42.9s\n",
      "46:\tlearn: 1.4754400\ttotal: 13.1s\tremaining: 42.6s\n",
      "47:\tlearn: 1.4653980\ttotal: 13.4s\tremaining: 42.4s\n",
      "48:\tlearn: 1.4557138\ttotal: 13.7s\tremaining: 42.1s\n",
      "49:\tlearn: 1.4463370\ttotal: 13.9s\tremaining: 41.8s\n",
      "50:\tlearn: 1.4380509\ttotal: 14.2s\tremaining: 41.5s\n",
      "51:\tlearn: 1.4287553\ttotal: 14.5s\tremaining: 41.3s\n",
      "52:\tlearn: 1.4201901\ttotal: 14.8s\tremaining: 41s\n",
      "53:\tlearn: 1.4115870\ttotal: 15s\tremaining: 40.7s\n",
      "54:\tlearn: 1.4029148\ttotal: 15.3s\tremaining: 40.4s\n",
      "55:\tlearn: 1.3943630\ttotal: 15.6s\tremaining: 40.1s\n",
      "56:\tlearn: 1.3866313\ttotal: 15.9s\tremaining: 39.8s\n",
      "57:\tlearn: 1.3788452\ttotal: 16.2s\tremaining: 39.6s\n",
      "58:\tlearn: 1.3713696\ttotal: 16.4s\tremaining: 39.3s\n",
      "59:\tlearn: 1.3635481\ttotal: 16.7s\tremaining: 39s\n",
      "60:\tlearn: 1.3559909\ttotal: 17s\tremaining: 38.7s\n",
      "61:\tlearn: 1.3483509\ttotal: 17.3s\tremaining: 38.5s\n",
      "62:\tlearn: 1.3408879\ttotal: 17.6s\tremaining: 38.2s\n",
      "63:\tlearn: 1.3343050\ttotal: 17.8s\tremaining: 37.9s\n",
      "64:\tlearn: 1.3266084\ttotal: 18.1s\tremaining: 37.6s\n",
      "65:\tlearn: 1.3192575\ttotal: 18.4s\tremaining: 37.4s\n",
      "66:\tlearn: 1.3118719\ttotal: 18.7s\tremaining: 37.1s\n",
      "67:\tlearn: 1.3054877\ttotal: 19s\tremaining: 36.8s\n",
      "68:\tlearn: 1.2989392\ttotal: 19.2s\tremaining: 36.5s\n",
      "69:\tlearn: 1.2925001\ttotal: 19.5s\tremaining: 36.3s\n",
      "70:\tlearn: 1.2857567\ttotal: 19.8s\tremaining: 36s\n",
      "71:\tlearn: 1.2791112\ttotal: 20.1s\tremaining: 35.7s\n",
      "72:\tlearn: 1.2726317\ttotal: 20.4s\tremaining: 35.4s\n",
      "73:\tlearn: 1.2656780\ttotal: 20.7s\tremaining: 35.2s\n",
      "74:\tlearn: 1.2592673\ttotal: 20.9s\tremaining: 34.9s\n",
      "75:\tlearn: 1.2529669\ttotal: 21.2s\tremaining: 34.6s\n",
      "76:\tlearn: 1.2463677\ttotal: 21.5s\tremaining: 34.4s\n",
      "77:\tlearn: 1.2400692\ttotal: 21.8s\tremaining: 34.1s\n",
      "78:\tlearn: 1.2344377\ttotal: 22.1s\tremaining: 33.8s\n",
      "79:\tlearn: 1.2289360\ttotal: 22.3s\tremaining: 33.5s\n",
      "80:\tlearn: 1.2226774\ttotal: 22.6s\tremaining: 33.2s\n",
      "81:\tlearn: 1.2172070\ttotal: 22.9s\tremaining: 32.9s\n",
      "82:\tlearn: 1.2117429\ttotal: 23.2s\tremaining: 32.7s\n",
      "83:\tlearn: 1.2064233\ttotal: 23.4s\tremaining: 32.4s\n",
      "84:\tlearn: 1.2010964\ttotal: 23.7s\tremaining: 32.1s\n",
      "85:\tlearn: 1.1953776\ttotal: 24s\tremaining: 31.8s\n",
      "86:\tlearn: 1.1901437\ttotal: 24.3s\tremaining: 31.5s\n",
      "87:\tlearn: 1.1853279\ttotal: 24.5s\tremaining: 31.2s\n",
      "88:\tlearn: 1.1802565\ttotal: 24.8s\tremaining: 30.9s\n",
      "89:\tlearn: 1.1745928\ttotal: 25.1s\tremaining: 30.7s\n",
      "90:\tlearn: 1.1695442\ttotal: 25.4s\tremaining: 30.4s\n",
      "91:\tlearn: 1.1642966\ttotal: 25.7s\tremaining: 30.2s\n",
      "92:\tlearn: 1.1590612\ttotal: 26.9s\tremaining: 31s\n",
      "93:\tlearn: 1.1536931\ttotal: 28.2s\tremaining: 31.8s\n",
      "94:\tlearn: 1.1491156\ttotal: 29.7s\tremaining: 32.9s\n",
      "95:\tlearn: 1.1440859\ttotal: 31.2s\tremaining: 33.8s\n",
      "96:\tlearn: 1.1391190\ttotal: 32.5s\tremaining: 34.5s\n",
      "97:\tlearn: 1.1343866\ttotal: 33s\tremaining: 34.4s\n",
      "98:\tlearn: 1.1300979\ttotal: 33.3s\tremaining: 34s\n",
      "99:\tlearn: 1.1253022\ttotal: 33.6s\tremaining: 33.6s\n",
      "100:\tlearn: 1.1207739\ttotal: 33.9s\tremaining: 33.2s\n",
      "101:\tlearn: 1.1169480\ttotal: 34.2s\tremaining: 32.8s\n",
      "102:\tlearn: 1.1124401\ttotal: 34.5s\tremaining: 32.4s\n",
      "103:\tlearn: 1.1080671\ttotal: 34.7s\tremaining: 32s\n",
      "104:\tlearn: 1.1032262\ttotal: 35s\tremaining: 31.7s\n",
      "105:\tlearn: 1.0992025\ttotal: 35.3s\tremaining: 31.3s\n",
      "106:\tlearn: 1.0949362\ttotal: 35.5s\tremaining: 30.9s\n",
      "107:\tlearn: 1.0908956\ttotal: 35.8s\tremaining: 30.5s\n",
      "108:\tlearn: 1.0867597\ttotal: 36.1s\tremaining: 30.1s\n",
      "109:\tlearn: 1.0829870\ttotal: 36.4s\tremaining: 29.8s\n",
      "110:\tlearn: 1.0786317\ttotal: 36.7s\tremaining: 29.4s\n",
      "111:\tlearn: 1.0742669\ttotal: 37s\tremaining: 29s\n",
      "112:\tlearn: 1.0701398\ttotal: 37.2s\tremaining: 28.7s\n",
      "113:\tlearn: 1.0662238\ttotal: 37.6s\tremaining: 28.3s\n",
      "114:\tlearn: 1.0622424\ttotal: 37.8s\tremaining: 28s\n",
      "115:\tlearn: 1.0584132\ttotal: 38.1s\tremaining: 27.6s\n",
      "116:\tlearn: 1.0545715\ttotal: 38.4s\tremaining: 27.2s\n",
      "117:\tlearn: 1.0507955\ttotal: 38.7s\tremaining: 26.9s\n",
      "118:\tlearn: 1.0474674\ttotal: 38.9s\tremaining: 26.5s\n",
      "119:\tlearn: 1.0439222\ttotal: 39.2s\tremaining: 26.1s\n",
      "120:\tlearn: 1.0405523\ttotal: 39.5s\tremaining: 25.8s\n",
      "121:\tlearn: 1.0372064\ttotal: 39.8s\tremaining: 25.4s\n",
      "122:\tlearn: 1.0334295\ttotal: 40s\tremaining: 25.1s\n",
      "123:\tlearn: 1.0300127\ttotal: 40.3s\tremaining: 24.7s\n",
      "124:\tlearn: 1.0263953\ttotal: 40.6s\tremaining: 24.4s\n",
      "125:\tlearn: 1.0227689\ttotal: 40.9s\tremaining: 24s\n",
      "126:\tlearn: 1.0192296\ttotal: 41.2s\tremaining: 23.7s\n",
      "127:\tlearn: 1.0161566\ttotal: 41.4s\tremaining: 23.3s\n",
      "128:\tlearn: 1.0128959\ttotal: 41.7s\tremaining: 23s\n",
      "129:\tlearn: 1.0091809\ttotal: 42s\tremaining: 22.6s\n",
      "130:\tlearn: 1.0058913\ttotal: 42.3s\tremaining: 22.3s\n",
      "131:\tlearn: 1.0024136\ttotal: 42.6s\tremaining: 21.9s\n",
      "132:\tlearn: 0.9989586\ttotal: 42.9s\tremaining: 21.6s\n",
      "133:\tlearn: 0.9960919\ttotal: 43.1s\tremaining: 21.2s\n",
      "134:\tlearn: 0.9926536\ttotal: 43.4s\tremaining: 20.9s\n",
      "135:\tlearn: 0.9899285\ttotal: 43.7s\tremaining: 20.6s\n",
      "136:\tlearn: 0.9865571\ttotal: 44s\tremaining: 20.2s\n",
      "137:\tlearn: 0.9833595\ttotal: 44.3s\tremaining: 19.9s\n",
      "138:\tlearn: 0.9800211\ttotal: 44.5s\tremaining: 19.6s\n",
      "139:\tlearn: 0.9766692\ttotal: 44.8s\tremaining: 19.2s\n",
      "140:\tlearn: 0.9733719\ttotal: 45.1s\tremaining: 18.9s\n",
      "141:\tlearn: 0.9705979\ttotal: 45.4s\tremaining: 18.5s\n",
      "142:\tlearn: 0.9672831\ttotal: 45.7s\tremaining: 18.2s\n",
      "143:\tlearn: 0.9645428\ttotal: 46s\tremaining: 17.9s\n",
      "144:\tlearn: 0.9614707\ttotal: 46.2s\tremaining: 17.5s\n",
      "145:\tlearn: 0.9588795\ttotal: 46.5s\tremaining: 17.2s\n",
      "146:\tlearn: 0.9557975\ttotal: 46.8s\tremaining: 16.9s\n",
      "147:\tlearn: 0.9528697\ttotal: 47.1s\tremaining: 16.5s\n",
      "148:\tlearn: 0.9502592\ttotal: 47.3s\tremaining: 16.2s\n",
      "149:\tlearn: 0.9474860\ttotal: 47.6s\tremaining: 15.9s\n",
      "150:\tlearn: 0.9452352\ttotal: 47.9s\tremaining: 15.5s\n",
      "151:\tlearn: 0.9425518\ttotal: 48.2s\tremaining: 15.2s\n",
      "152:\tlearn: 0.9399567\ttotal: 48.5s\tremaining: 14.9s\n",
      "153:\tlearn: 0.9373182\ttotal: 48.8s\tremaining: 14.6s\n",
      "154:\tlearn: 0.9348007\ttotal: 49s\tremaining: 14.2s\n",
      "155:\tlearn: 0.9323697\ttotal: 49.3s\tremaining: 13.9s\n",
      "156:\tlearn: 0.9296380\ttotal: 49.6s\tremaining: 13.6s\n",
      "157:\tlearn: 0.9269888\ttotal: 49.9s\tremaining: 13.3s\n",
      "158:\tlearn: 0.9247102\ttotal: 50.1s\tremaining: 12.9s\n",
      "159:\tlearn: 0.9221188\ttotal: 50.4s\tremaining: 12.6s\n",
      "160:\tlearn: 0.9196686\ttotal: 50.7s\tremaining: 12.3s\n",
      "161:\tlearn: 0.9170662\ttotal: 51s\tremaining: 12s\n",
      "162:\tlearn: 0.9145124\ttotal: 51.3s\tremaining: 11.6s\n",
      "163:\tlearn: 0.9121991\ttotal: 51.5s\tremaining: 11.3s\n",
      "164:\tlearn: 0.9099361\ttotal: 51.8s\tremaining: 11s\n",
      "165:\tlearn: 0.9078558\ttotal: 52s\tremaining: 10.7s\n",
      "166:\tlearn: 0.9054632\ttotal: 52.3s\tremaining: 10.3s\n",
      "167:\tlearn: 0.9029335\ttotal: 52.6s\tremaining: 10s\n",
      "168:\tlearn: 0.9005895\ttotal: 52.9s\tremaining: 9.7s\n",
      "169:\tlearn: 0.8983679\ttotal: 53.2s\tremaining: 9.38s\n",
      "170:\tlearn: 0.8961605\ttotal: 53.4s\tremaining: 9.06s\n",
      "171:\tlearn: 0.8941592\ttotal: 53.7s\tremaining: 8.74s\n",
      "172:\tlearn: 0.8920696\ttotal: 54s\tremaining: 8.42s\n",
      "173:\tlearn: 0.8897962\ttotal: 54.2s\tremaining: 8.1s\n",
      "174:\tlearn: 0.8876245\ttotal: 54.5s\tremaining: 7.78s\n",
      "175:\tlearn: 0.8851675\ttotal: 54.8s\tremaining: 7.47s\n",
      "176:\tlearn: 0.8828667\ttotal: 55s\tremaining: 7.15s\n",
      "177:\tlearn: 0.8805173\ttotal: 55.3s\tremaining: 6.84s\n",
      "178:\tlearn: 0.8784453\ttotal: 55.6s\tremaining: 6.52s\n",
      "179:\tlearn: 0.8759793\ttotal: 55.9s\tremaining: 6.21s\n",
      "180:\tlearn: 0.8739448\ttotal: 56.1s\tremaining: 5.89s\n",
      "181:\tlearn: 0.8719059\ttotal: 56.4s\tremaining: 5.58s\n",
      "182:\tlearn: 0.8696972\ttotal: 56.7s\tremaining: 5.27s\n",
      "183:\tlearn: 0.8678827\ttotal: 57s\tremaining: 4.95s\n",
      "184:\tlearn: 0.8660935\ttotal: 57.2s\tremaining: 4.64s\n",
      "185:\tlearn: 0.8638449\ttotal: 57.5s\tremaining: 4.33s\n",
      "186:\tlearn: 0.8617035\ttotal: 57.8s\tremaining: 4.02s\n",
      "187:\tlearn: 0.8594827\ttotal: 58.1s\tremaining: 3.71s\n",
      "188:\tlearn: 0.8573123\ttotal: 58.4s\tremaining: 3.4s\n",
      "189:\tlearn: 0.8553339\ttotal: 58.6s\tremaining: 3.09s\n",
      "190:\tlearn: 0.8534236\ttotal: 58.9s\tremaining: 2.77s\n",
      "191:\tlearn: 0.8512366\ttotal: 59.2s\tremaining: 2.47s\n",
      "192:\tlearn: 0.8492045\ttotal: 59.5s\tremaining: 2.16s\n",
      "193:\tlearn: 0.8473433\ttotal: 59.7s\tremaining: 1.85s\n",
      "194:\tlearn: 0.8455592\ttotal: 60s\tremaining: 1.54s\n",
      "195:\tlearn: 0.8434250\ttotal: 1m\tremaining: 1.23s\n",
      "196:\tlearn: 0.8415110\ttotal: 1m\tremaining: 922ms\n",
      "197:\tlearn: 0.8394639\ttotal: 1m\tremaining: 614ms\n",
      "198:\tlearn: 0.8374365\ttotal: 1m 1s\tremaining: 307ms\n",
      "199:\tlearn: 0.8352194\ttotal: 1m 1s\tremaining: 0us\n",
      "0:\tlearn: 2.2658662\ttotal: 268ms\tremaining: 53.3s\n",
      "1:\tlearn: 2.2321196\ttotal: 540ms\tremaining: 53.5s\n",
      "2:\tlearn: 2.2000769\ttotal: 808ms\tremaining: 53.1s\n",
      "3:\tlearn: 2.1700152\ttotal: 1.07s\tremaining: 52.7s\n",
      "4:\tlearn: 2.1397933\ttotal: 1.35s\tremaining: 52.8s\n",
      "5:\tlearn: 2.1124022\ttotal: 1.63s\tremaining: 52.6s\n",
      "6:\tlearn: 2.0870195\ttotal: 1.89s\tremaining: 52.2s\n",
      "7:\tlearn: 2.0610816\ttotal: 2.17s\tremaining: 52s\n",
      "8:\tlearn: 2.0346797\ttotal: 2.44s\tremaining: 51.9s\n",
      "9:\tlearn: 2.0112394\ttotal: 2.72s\tremaining: 51.6s\n",
      "10:\tlearn: 1.9891258\ttotal: 2.99s\tremaining: 51.4s\n",
      "11:\tlearn: 1.9665233\ttotal: 3.27s\tremaining: 51.2s\n",
      "12:\tlearn: 1.9459449\ttotal: 3.54s\tremaining: 50.9s\n",
      "13:\tlearn: 1.9262198\ttotal: 3.81s\tremaining: 50.6s\n",
      "14:\tlearn: 1.9072866\ttotal: 4.08s\tremaining: 50.4s\n",
      "15:\tlearn: 1.8882567\ttotal: 4.36s\tremaining: 50.2s\n",
      "16:\tlearn: 1.8700881\ttotal: 4.63s\tremaining: 49.9s\n",
      "17:\tlearn: 1.8518151\ttotal: 4.91s\tremaining: 49.6s\n",
      "18:\tlearn: 1.8338730\ttotal: 5.18s\tremaining: 49.3s\n",
      "19:\tlearn: 1.8169242\ttotal: 5.45s\tremaining: 49.1s\n",
      "20:\tlearn: 1.8007661\ttotal: 5.73s\tremaining: 48.8s\n",
      "21:\tlearn: 1.7840747\ttotal: 6s\tremaining: 48.6s\n",
      "22:\tlearn: 1.7674244\ttotal: 6.28s\tremaining: 48.4s\n",
      "23:\tlearn: 1.7525202\ttotal: 6.55s\tremaining: 48.1s\n",
      "24:\tlearn: 1.7367955\ttotal: 6.83s\tremaining: 47.8s\n",
      "25:\tlearn: 1.7220128\ttotal: 7.11s\tremaining: 47.6s\n",
      "26:\tlearn: 1.7070051\ttotal: 7.39s\tremaining: 47.3s\n",
      "27:\tlearn: 1.6936101\ttotal: 7.65s\tremaining: 47s\n",
      "28:\tlearn: 1.6795383\ttotal: 7.93s\tremaining: 46.8s\n",
      "29:\tlearn: 1.6664890\ttotal: 8.21s\tremaining: 46.5s\n",
      "30:\tlearn: 1.6540412\ttotal: 8.47s\tremaining: 46.2s\n",
      "31:\tlearn: 1.6420332\ttotal: 8.76s\tremaining: 46s\n",
      "32:\tlearn: 1.6293734\ttotal: 9.04s\tremaining: 45.7s\n",
      "33:\tlearn: 1.6165076\ttotal: 9.31s\tremaining: 45.5s\n",
      "34:\tlearn: 1.6048963\ttotal: 9.59s\tremaining: 45.2s\n",
      "35:\tlearn: 1.5930459\ttotal: 9.86s\tremaining: 44.9s\n",
      "36:\tlearn: 1.5823790\ttotal: 10.1s\tremaining: 44.7s\n",
      "37:\tlearn: 1.5704712\ttotal: 10.4s\tremaining: 44.4s\n",
      "38:\tlearn: 1.5594392\ttotal: 10.7s\tremaining: 44.1s\n",
      "39:\tlearn: 1.5488511\ttotal: 11s\tremaining: 43.8s\n",
      "40:\tlearn: 1.5383351\ttotal: 11.2s\tremaining: 43.6s\n",
      "41:\tlearn: 1.5277579\ttotal: 11.5s\tremaining: 43.4s\n",
      "42:\tlearn: 1.5174808\ttotal: 11.8s\tremaining: 43.1s\n",
      "43:\tlearn: 1.5077700\ttotal: 12.3s\tremaining: 43.7s\n",
      "44:\tlearn: 1.4981677\ttotal: 13.5s\tremaining: 46.4s\n",
      "45:\tlearn: 1.4882478\ttotal: 14.8s\tremaining: 49.5s\n",
      "46:\tlearn: 1.4786084\ttotal: 16.6s\tremaining: 54s\n",
      "47:\tlearn: 1.4697465\ttotal: 19s\tremaining: 1m\n",
      "48:\tlearn: 1.4600768\ttotal: 19.5s\tremaining: 60s\n",
      "49:\tlearn: 1.4508920\ttotal: 19.8s\tremaining: 59.4s\n",
      "50:\tlearn: 1.4420124\ttotal: 20.1s\tremaining: 58.7s\n",
      "51:\tlearn: 1.4325981\ttotal: 20.4s\tremaining: 58.1s\n",
      "52:\tlearn: 1.4239182\ttotal: 20.7s\tremaining: 57.4s\n",
      "53:\tlearn: 1.4152526\ttotal: 21s\tremaining: 56.7s\n",
      "54:\tlearn: 1.4067786\ttotal: 21.3s\tremaining: 56.1s\n",
      "55:\tlearn: 1.3986248\ttotal: 21.6s\tremaining: 55.5s\n",
      "56:\tlearn: 1.3905384\ttotal: 21.9s\tremaining: 54.9s\n",
      "57:\tlearn: 1.3825087\ttotal: 22.2s\tremaining: 54.3s\n",
      "58:\tlearn: 1.3750030\ttotal: 22.5s\tremaining: 53.7s\n",
      "59:\tlearn: 1.3668683\ttotal: 22.8s\tremaining: 53.1s\n",
      "60:\tlearn: 1.3594376\ttotal: 23.1s\tremaining: 52.5s\n",
      "61:\tlearn: 1.3518517\ttotal: 23.4s\tremaining: 52s\n",
      "62:\tlearn: 1.3440052\ttotal: 23.7s\tremaining: 51.4s\n",
      "63:\tlearn: 1.3374164\ttotal: 23.9s\tremaining: 50.9s\n",
      "64:\tlearn: 1.3300053\ttotal: 24.2s\tremaining: 50.3s\n",
      "65:\tlearn: 1.3226447\ttotal: 24.5s\tremaining: 49.8s\n",
      "66:\tlearn: 1.3153739\ttotal: 24.8s\tremaining: 49.3s\n",
      "67:\tlearn: 1.3090016\ttotal: 25.1s\tremaining: 48.7s\n",
      "68:\tlearn: 1.3022701\ttotal: 25.4s\tremaining: 48.2s\n",
      "69:\tlearn: 1.2957489\ttotal: 25.7s\tremaining: 47.7s\n",
      "70:\tlearn: 1.2885132\ttotal: 26s\tremaining: 47.2s\n",
      "71:\tlearn: 1.2824298\ttotal: 26.3s\tremaining: 46.7s\n",
      "72:\tlearn: 1.2762711\ttotal: 26.5s\tremaining: 46.2s\n",
      "73:\tlearn: 1.2694337\ttotal: 26.8s\tremaining: 45.7s\n",
      "74:\tlearn: 1.2628962\ttotal: 27.1s\tremaining: 45.2s\n",
      "75:\tlearn: 1.2571373\ttotal: 27.4s\tremaining: 44.7s\n",
      "76:\tlearn: 1.2507156\ttotal: 27.7s\tremaining: 44.3s\n",
      "77:\tlearn: 1.2444499\ttotal: 28s\tremaining: 43.8s\n",
      "78:\tlearn: 1.2388406\ttotal: 28.3s\tremaining: 43.4s\n",
      "79:\tlearn: 1.2334934\ttotal: 28.6s\tremaining: 43s\n",
      "80:\tlearn: 1.2271808\ttotal: 29s\tremaining: 42.6s\n",
      "81:\tlearn: 1.2217179\ttotal: 29.3s\tremaining: 42.2s\n",
      "82:\tlearn: 1.2162501\ttotal: 29.6s\tremaining: 41.8s\n",
      "83:\tlearn: 1.2103142\ttotal: 30s\tremaining: 41.4s\n",
      "84:\tlearn: 1.2042927\ttotal: 30.3s\tremaining: 41s\n",
      "85:\tlearn: 1.1985221\ttotal: 30.6s\tremaining: 40.6s\n",
      "86:\tlearn: 1.1933482\ttotal: 30.9s\tremaining: 40.2s\n",
      "87:\tlearn: 1.1885704\ttotal: 31.3s\tremaining: 39.8s\n",
      "88:\tlearn: 1.1829325\ttotal: 31.6s\tremaining: 39.4s\n",
      "89:\tlearn: 1.1773452\ttotal: 31.9s\tremaining: 39s\n",
      "90:\tlearn: 1.1724112\ttotal: 32.2s\tremaining: 38.6s\n",
      "91:\tlearn: 1.1671410\ttotal: 32.5s\tremaining: 38.2s\n",
      "92:\tlearn: 1.1617659\ttotal: 32.8s\tremaining: 37.8s\n",
      "93:\tlearn: 1.1568809\ttotal: 33.1s\tremaining: 37.4s\n",
      "94:\tlearn: 1.1519844\ttotal: 33.4s\tremaining: 36.9s\n",
      "95:\tlearn: 1.1469142\ttotal: 33.7s\tremaining: 36.5s\n",
      "96:\tlearn: 1.1419818\ttotal: 34s\tremaining: 36.1s\n",
      "97:\tlearn: 1.1372831\ttotal: 34.3s\tremaining: 35.7s\n",
      "98:\tlearn: 1.1326306\ttotal: 34.5s\tremaining: 35.2s\n",
      "99:\tlearn: 1.1277865\ttotal: 34.8s\tremaining: 34.8s\n",
      "100:\tlearn: 1.1236201\ttotal: 35.1s\tremaining: 34.4s\n",
      "101:\tlearn: 1.1190300\ttotal: 35.4s\tremaining: 34s\n",
      "102:\tlearn: 1.1144390\ttotal: 35.7s\tremaining: 33.6s\n",
      "103:\tlearn: 1.1102011\ttotal: 35.9s\tremaining: 33.2s\n",
      "104:\tlearn: 1.1055099\ttotal: 36.2s\tremaining: 32.8s\n",
      "105:\tlearn: 1.1011334\ttotal: 36.6s\tremaining: 32.4s\n",
      "106:\tlearn: 1.0964227\ttotal: 36.8s\tremaining: 32s\n",
      "107:\tlearn: 1.0922695\ttotal: 37.1s\tremaining: 31.6s\n",
      "108:\tlearn: 1.0879369\ttotal: 37.4s\tremaining: 31.3s\n",
      "109:\tlearn: 1.0839396\ttotal: 37.7s\tremaining: 30.9s\n",
      "110:\tlearn: 1.0795559\ttotal: 38.1s\tremaining: 30.5s\n",
      "111:\tlearn: 1.0754345\ttotal: 38.4s\tremaining: 30.2s\n",
      "112:\tlearn: 1.0715593\ttotal: 38.7s\tremaining: 29.8s\n",
      "113:\tlearn: 1.0676146\ttotal: 39s\tremaining: 29.4s\n",
      "114:\tlearn: 1.0635961\ttotal: 39.3s\tremaining: 29.1s\n",
      "115:\tlearn: 1.0596545\ttotal: 39.6s\tremaining: 28.7s\n",
      "116:\tlearn: 1.0557663\ttotal: 40s\tremaining: 28.3s\n",
      "117:\tlearn: 1.0519625\ttotal: 40.3s\tremaining: 28s\n",
      "118:\tlearn: 1.0487094\ttotal: 40.5s\tremaining: 27.6s\n",
      "119:\tlearn: 1.0453043\ttotal: 40.8s\tremaining: 27.2s\n",
      "120:\tlearn: 1.0417218\ttotal: 41.1s\tremaining: 26.8s\n",
      "121:\tlearn: 1.0383345\ttotal: 41.4s\tremaining: 26.4s\n",
      "122:\tlearn: 1.0343953\ttotal: 41.6s\tremaining: 26.1s\n",
      "123:\tlearn: 1.0309059\ttotal: 41.9s\tremaining: 25.7s\n",
      "124:\tlearn: 1.0276734\ttotal: 42.3s\tremaining: 25.4s\n",
      "125:\tlearn: 1.0239786\ttotal: 42.6s\tremaining: 25s\n",
      "126:\tlearn: 1.0203617\ttotal: 42.9s\tremaining: 24.6s\n",
      "127:\tlearn: 1.0172918\ttotal: 43.2s\tremaining: 24.3s\n",
      "128:\tlearn: 1.0140560\ttotal: 43.5s\tremaining: 23.9s\n",
      "129:\tlearn: 1.0101683\ttotal: 43.8s\tremaining: 23.6s\n",
      "130:\tlearn: 1.0068335\ttotal: 44.1s\tremaining: 23.2s\n",
      "131:\tlearn: 1.0034692\ttotal: 44.4s\tremaining: 22.9s\n",
      "132:\tlearn: 0.9997947\ttotal: 44.7s\tremaining: 22.5s\n",
      "133:\tlearn: 0.9967285\ttotal: 44.9s\tremaining: 22.1s\n",
      "134:\tlearn: 0.9934213\ttotal: 45.2s\tremaining: 21.8s\n",
      "135:\tlearn: 0.9900762\ttotal: 45.5s\tremaining: 21.4s\n",
      "136:\tlearn: 0.9865264\ttotal: 45.8s\tremaining: 21.1s\n",
      "137:\tlearn: 0.9833256\ttotal: 46.1s\tremaining: 20.7s\n",
      "138:\tlearn: 0.9799419\ttotal: 46.4s\tremaining: 20.3s\n",
      "139:\tlearn: 0.9770069\ttotal: 46.6s\tremaining: 20s\n",
      "140:\tlearn: 0.9737143\ttotal: 46.9s\tremaining: 19.6s\n",
      "141:\tlearn: 0.9713381\ttotal: 47.2s\tremaining: 19.3s\n",
      "142:\tlearn: 0.9680164\ttotal: 47.5s\tremaining: 18.9s\n",
      "143:\tlearn: 0.9650610\ttotal: 47.8s\tremaining: 18.6s\n",
      "144:\tlearn: 0.9625269\ttotal: 48s\tremaining: 18.2s\n",
      "145:\tlearn: 0.9599225\ttotal: 48.3s\tremaining: 17.9s\n",
      "146:\tlearn: 0.9568782\ttotal: 48.6s\tremaining: 17.5s\n",
      "147:\tlearn: 0.9539465\ttotal: 48.9s\tremaining: 17.2s\n",
      "148:\tlearn: 0.9510597\ttotal: 49.2s\tremaining: 16.8s\n",
      "149:\tlearn: 0.9482510\ttotal: 49.5s\tremaining: 16.5s\n",
      "150:\tlearn: 0.9454581\ttotal: 49.8s\tremaining: 16.1s\n",
      "151:\tlearn: 0.9427039\ttotal: 50.1s\tremaining: 15.8s\n",
      "152:\tlearn: 0.9403411\ttotal: 50.4s\tremaining: 15.5s\n",
      "153:\tlearn: 0.9375698\ttotal: 50.7s\tremaining: 15.1s\n",
      "154:\tlearn: 0.9351598\ttotal: 50.9s\tremaining: 14.8s\n",
      "155:\tlearn: 0.9325565\ttotal: 51.2s\tremaining: 14.4s\n",
      "156:\tlearn: 0.9298557\ttotal: 51.5s\tremaining: 14.1s\n",
      "157:\tlearn: 0.9273451\ttotal: 51.8s\tremaining: 13.8s\n",
      "158:\tlearn: 0.9247954\ttotal: 52.1s\tremaining: 13.4s\n",
      "159:\tlearn: 0.9220646\ttotal: 52.4s\tremaining: 13.1s\n",
      "160:\tlearn: 0.9192385\ttotal: 52.7s\tremaining: 12.8s\n",
      "161:\tlearn: 0.9164700\ttotal: 53s\tremaining: 12.4s\n",
      "162:\tlearn: 0.9138513\ttotal: 53.3s\tremaining: 12.1s\n",
      "163:\tlearn: 0.9115531\ttotal: 53.6s\tremaining: 11.8s\n",
      "164:\tlearn: 0.9093522\ttotal: 53.8s\tremaining: 11.4s\n",
      "165:\tlearn: 0.9067944\ttotal: 54.1s\tremaining: 11.1s\n",
      "166:\tlearn: 0.9044756\ttotal: 54.4s\tremaining: 10.8s\n",
      "167:\tlearn: 0.9019638\ttotal: 54.7s\tremaining: 10.4s\n",
      "168:\tlearn: 0.8996983\ttotal: 55s\tremaining: 10.1s\n",
      "169:\tlearn: 0.8974454\ttotal: 55.3s\tremaining: 9.76s\n",
      "170:\tlearn: 0.8954062\ttotal: 55.6s\tremaining: 9.43s\n",
      "171:\tlearn: 0.8931967\ttotal: 55.9s\tremaining: 9.1s\n",
      "172:\tlearn: 0.8908835\ttotal: 56.2s\tremaining: 8.77s\n",
      "173:\tlearn: 0.8885189\ttotal: 56.5s\tremaining: 8.44s\n",
      "174:\tlearn: 0.8862729\ttotal: 56.8s\tremaining: 8.11s\n",
      "175:\tlearn: 0.8844406\ttotal: 57s\tremaining: 7.78s\n",
      "176:\tlearn: 0.8825655\ttotal: 57.3s\tremaining: 7.45s\n",
      "177:\tlearn: 0.8807569\ttotal: 57.6s\tremaining: 7.12s\n",
      "178:\tlearn: 0.8787484\ttotal: 57.9s\tremaining: 6.79s\n",
      "179:\tlearn: 0.8762939\ttotal: 58.2s\tremaining: 6.46s\n",
      "180:\tlearn: 0.8741412\ttotal: 58.5s\tremaining: 6.14s\n",
      "181:\tlearn: 0.8718982\ttotal: 58.8s\tremaining: 5.81s\n",
      "182:\tlearn: 0.8697377\ttotal: 59.1s\tremaining: 5.49s\n",
      "183:\tlearn: 0.8675909\ttotal: 59.4s\tremaining: 5.16s\n",
      "184:\tlearn: 0.8653128\ttotal: 59.7s\tremaining: 4.84s\n",
      "185:\tlearn: 0.8630603\ttotal: 60s\tremaining: 4.51s\n",
      "186:\tlearn: 0.8609424\ttotal: 1m\tremaining: 4.19s\n",
      "187:\tlearn: 0.8587385\ttotal: 1m\tremaining: 3.87s\n",
      "188:\tlearn: 0.8568201\ttotal: 1m\tremaining: 3.54s\n",
      "189:\tlearn: 0.8547411\ttotal: 1m 1s\tremaining: 3.22s\n",
      "190:\tlearn: 0.8526178\ttotal: 1m 1s\tremaining: 2.89s\n",
      "191:\tlearn: 0.8504577\ttotal: 1m 1s\tremaining: 2.57s\n",
      "192:\tlearn: 0.8484150\ttotal: 1m 2s\tremaining: 2.25s\n",
      "193:\tlearn: 0.8464928\ttotal: 1m 2s\tremaining: 1.93s\n",
      "194:\tlearn: 0.8447685\ttotal: 1m 2s\tremaining: 1.6s\n",
      "195:\tlearn: 0.8426875\ttotal: 1m 2s\tremaining: 1.28s\n",
      "196:\tlearn: 0.8408220\ttotal: 1m 3s\tremaining: 962ms\n",
      "197:\tlearn: 0.8390075\ttotal: 1m 3s\tremaining: 641ms\n",
      "198:\tlearn: 0.8371618\ttotal: 1m 3s\tremaining: 320ms\n",
      "199:\tlearn: 0.8351044\ttotal: 1m 4s\tremaining: 0us\n",
      "0:\tlearn: 2.2658348\ttotal: 276ms\tremaining: 54.9s\n",
      "1:\tlearn: 2.2318670\ttotal: 557ms\tremaining: 55.2s\n",
      "2:\tlearn: 2.1995876\ttotal: 835ms\tremaining: 54.8s\n",
      "3:\tlearn: 2.1694404\ttotal: 1.11s\tremaining: 54.5s\n",
      "4:\tlearn: 2.1391886\ttotal: 1.41s\tremaining: 54.9s\n",
      "5:\tlearn: 2.1122518\ttotal: 1.68s\tremaining: 54.4s\n",
      "6:\tlearn: 2.0866065\ttotal: 1.96s\tremaining: 54.1s\n",
      "7:\tlearn: 2.0604940\ttotal: 2.24s\tremaining: 53.9s\n",
      "8:\tlearn: 2.0342440\ttotal: 2.53s\tremaining: 53.8s\n",
      "9:\tlearn: 2.0108247\ttotal: 2.81s\tremaining: 53.5s\n",
      "10:\tlearn: 1.9887644\ttotal: 3.1s\tremaining: 53.2s\n",
      "11:\tlearn: 1.9663554\ttotal: 3.39s\tremaining: 53.1s\n",
      "12:\tlearn: 1.9460161\ttotal: 3.67s\tremaining: 52.8s\n",
      "13:\tlearn: 1.9262526\ttotal: 3.95s\tremaining: 52.5s\n",
      "14:\tlearn: 1.9063746\ttotal: 4.24s\tremaining: 52.2s\n",
      "15:\tlearn: 1.8871857\ttotal: 4.52s\tremaining: 52s\n",
      "16:\tlearn: 1.8689453\ttotal: 4.81s\tremaining: 51.7s\n",
      "17:\tlearn: 1.8510906\ttotal: 5.09s\tremaining: 51.5s\n",
      "18:\tlearn: 1.8330862\ttotal: 5.38s\tremaining: 51.3s\n",
      "19:\tlearn: 1.8159929\ttotal: 5.67s\tremaining: 51.1s\n",
      "20:\tlearn: 1.7998444\ttotal: 5.95s\tremaining: 50.7s\n",
      "21:\tlearn: 1.7832012\ttotal: 6.25s\tremaining: 50.5s\n",
      "22:\tlearn: 1.7672822\ttotal: 6.54s\tremaining: 50.3s\n",
      "23:\tlearn: 1.7523322\ttotal: 6.84s\tremaining: 50.2s\n",
      "24:\tlearn: 1.7369720\ttotal: 7.15s\tremaining: 50.1s\n",
      "25:\tlearn: 1.7229644\ttotal: 7.44s\tremaining: 49.8s\n",
      "26:\tlearn: 1.7079435\ttotal: 7.74s\tremaining: 49.6s\n",
      "27:\tlearn: 1.6940111\ttotal: 8.03s\tremaining: 49.3s\n",
      "28:\tlearn: 1.6799941\ttotal: 8.33s\tremaining: 49.1s\n",
      "29:\tlearn: 1.6669424\ttotal: 8.62s\tremaining: 48.8s\n",
      "30:\tlearn: 1.6545551\ttotal: 8.91s\tremaining: 48.6s\n",
      "31:\tlearn: 1.6415428\ttotal: 9.2s\tremaining: 48.3s\n",
      "32:\tlearn: 1.6286692\ttotal: 9.5s\tremaining: 48.1s\n",
      "33:\tlearn: 1.6160027\ttotal: 9.79s\tremaining: 47.8s\n",
      "34:\tlearn: 1.6035782\ttotal: 10.1s\tremaining: 47.5s\n",
      "35:\tlearn: 1.5916527\ttotal: 10.4s\tremaining: 47.3s\n",
      "36:\tlearn: 1.5810683\ttotal: 10.7s\tremaining: 47s\n",
      "37:\tlearn: 1.5697625\ttotal: 11s\tremaining: 46.7s\n",
      "38:\tlearn: 1.5585202\ttotal: 11.3s\tremaining: 46.5s\n",
      "39:\tlearn: 1.5481518\ttotal: 11.6s\tremaining: 46.2s\n",
      "40:\tlearn: 1.5377913\ttotal: 11.8s\tremaining: 45.9s\n",
      "41:\tlearn: 1.5272234\ttotal: 12.1s\tremaining: 45.7s\n",
      "42:\tlearn: 1.5175372\ttotal: 12.4s\tremaining: 45.4s\n",
      "43:\tlearn: 1.5071924\ttotal: 12.7s\tremaining: 45.1s\n",
      "44:\tlearn: 1.4975511\ttotal: 13s\tremaining: 44.8s\n",
      "45:\tlearn: 1.4882345\ttotal: 13.3s\tremaining: 44.5s\n",
      "46:\tlearn: 1.4785427\ttotal: 13.6s\tremaining: 44.3s\n",
      "47:\tlearn: 1.4693593\ttotal: 13.9s\tremaining: 44s\n",
      "48:\tlearn: 1.4600600\ttotal: 14.2s\tremaining: 43.7s\n",
      "49:\tlearn: 1.4509252\ttotal: 14.5s\tremaining: 43.4s\n",
      "50:\tlearn: 1.4426465\ttotal: 14.7s\tremaining: 43.1s\n",
      "51:\tlearn: 1.4331327\ttotal: 15s\tremaining: 42.8s\n",
      "52:\tlearn: 1.4246175\ttotal: 15.3s\tremaining: 42.5s\n",
      "53:\tlearn: 1.4159833\ttotal: 15.6s\tremaining: 42.2s\n",
      "54:\tlearn: 1.4075353\ttotal: 15.9s\tremaining: 41.9s\n",
      "55:\tlearn: 1.3983680\ttotal: 16.2s\tremaining: 41.8s\n",
      "56:\tlearn: 1.3905548\ttotal: 16.6s\tremaining: 41.5s\n",
      "57:\tlearn: 1.3824593\ttotal: 16.9s\tremaining: 41.3s\n",
      "58:\tlearn: 1.3750512\ttotal: 17.2s\tremaining: 41s\n",
      "59:\tlearn: 1.3675995\ttotal: 17.5s\tremaining: 40.8s\n",
      "60:\tlearn: 1.3601802\ttotal: 17.8s\tremaining: 40.6s\n",
      "61:\tlearn: 1.3526767\ttotal: 18.1s\tremaining: 40.3s\n",
      "62:\tlearn: 1.3445280\ttotal: 18.4s\tremaining: 40.1s\n",
      "63:\tlearn: 1.3371855\ttotal: 18.7s\tremaining: 39.8s\n",
      "64:\tlearn: 1.3294855\ttotal: 19s\tremaining: 39.5s\n",
      "65:\tlearn: 1.3220691\ttotal: 19.3s\tremaining: 39.3s\n",
      "66:\tlearn: 1.3147716\ttotal: 19.7s\tremaining: 39s\n",
      "67:\tlearn: 1.3083777\ttotal: 19.9s\tremaining: 38.7s\n",
      "68:\tlearn: 1.3015194\ttotal: 20.3s\tremaining: 38.5s\n",
      "69:\tlearn: 1.2955230\ttotal: 20.6s\tremaining: 38.2s\n",
      "70:\tlearn: 1.2881869\ttotal: 20.9s\tremaining: 37.9s\n",
      "71:\tlearn: 1.2821119\ttotal: 21.2s\tremaining: 37.6s\n",
      "72:\tlearn: 1.2753178\ttotal: 21.5s\tremaining: 37.4s\n",
      "73:\tlearn: 1.2684737\ttotal: 21.8s\tremaining: 37.1s\n",
      "74:\tlearn: 1.2623719\ttotal: 22.1s\tremaining: 36.8s\n",
      "75:\tlearn: 1.2564955\ttotal: 22.4s\tremaining: 36.5s\n",
      "76:\tlearn: 1.2499109\ttotal: 22.7s\tremaining: 36.2s\n",
      "77:\tlearn: 1.2439606\ttotal: 23s\tremaining: 35.9s\n",
      "78:\tlearn: 1.2384212\ttotal: 23.3s\tremaining: 35.6s\n",
      "79:\tlearn: 1.2330370\ttotal: 23.5s\tremaining: 35.3s\n",
      "80:\tlearn: 1.2270309\ttotal: 23.9s\tremaining: 35.1s\n",
      "81:\tlearn: 1.2218386\ttotal: 24.2s\tremaining: 34.8s\n",
      "82:\tlearn: 1.2164314\ttotal: 24.5s\tremaining: 34.5s\n",
      "83:\tlearn: 1.2109682\ttotal: 24.8s\tremaining: 34.3s\n",
      "84:\tlearn: 1.2053451\ttotal: 25.1s\tremaining: 34s\n",
      "85:\tlearn: 1.1996161\ttotal: 25.4s\tremaining: 33.7s\n",
      "86:\tlearn: 1.1941879\ttotal: 25.7s\tremaining: 33.4s\n",
      "87:\tlearn: 1.1891235\ttotal: 26s\tremaining: 33.1s\n",
      "88:\tlearn: 1.1842241\ttotal: 26.3s\tremaining: 32.8s\n",
      "89:\tlearn: 1.1785432\ttotal: 26.6s\tremaining: 32.5s\n",
      "90:\tlearn: 1.1733837\ttotal: 26.9s\tremaining: 32.3s\n",
      "91:\tlearn: 1.1682235\ttotal: 27.3s\tremaining: 32s\n",
      "92:\tlearn: 1.1631448\ttotal: 27.6s\tremaining: 31.7s\n",
      "93:\tlearn: 1.1576167\ttotal: 27.9s\tremaining: 31.4s\n",
      "94:\tlearn: 1.1526028\ttotal: 28.2s\tremaining: 31.2s\n",
      "95:\tlearn: 1.1476650\ttotal: 28.5s\tremaining: 30.9s\n",
      "96:\tlearn: 1.1427013\ttotal: 28.8s\tremaining: 30.6s\n",
      "97:\tlearn: 1.1380165\ttotal: 29.1s\tremaining: 30.3s\n",
      "98:\tlearn: 1.1334592\ttotal: 29.4s\tremaining: 30s\n",
      "99:\tlearn: 1.1286791\ttotal: 29.7s\tremaining: 29.7s\n",
      "100:\tlearn: 1.1245727\ttotal: 30s\tremaining: 29.4s\n",
      "101:\tlearn: 1.1201861\ttotal: 30.2s\tremaining: 29.1s\n",
      "102:\tlearn: 1.1159003\ttotal: 30.6s\tremaining: 28.8s\n",
      "103:\tlearn: 1.1115832\ttotal: 30.8s\tremaining: 28.5s\n",
      "104:\tlearn: 1.1069663\ttotal: 31.1s\tremaining: 28.2s\n",
      "105:\tlearn: 1.1024959\ttotal: 31.4s\tremaining: 27.9s\n",
      "106:\tlearn: 1.0978701\ttotal: 31.7s\tremaining: 27.6s\n",
      "107:\tlearn: 1.0936303\ttotal: 32s\tremaining: 27.3s\n",
      "108:\tlearn: 1.0892387\ttotal: 32.3s\tremaining: 27s\n",
      "109:\tlearn: 1.0855275\ttotal: 32.6s\tremaining: 26.7s\n",
      "110:\tlearn: 1.0817792\ttotal: 32.9s\tremaining: 26.4s\n",
      "111:\tlearn: 1.0780755\ttotal: 33.2s\tremaining: 26s\n",
      "112:\tlearn: 1.0740418\ttotal: 33.5s\tremaining: 25.8s\n",
      "113:\tlearn: 1.0700557\ttotal: 33.8s\tremaining: 25.5s\n",
      "114:\tlearn: 1.0658713\ttotal: 34.2s\tremaining: 25.3s\n",
      "115:\tlearn: 1.0620511\ttotal: 34.5s\tremaining: 25s\n",
      "116:\tlearn: 1.0579525\ttotal: 34.8s\tremaining: 24.7s\n",
      "117:\tlearn: 1.0540068\ttotal: 35.1s\tremaining: 24.4s\n",
      "118:\tlearn: 1.0507681\ttotal: 35.4s\tremaining: 24.1s\n",
      "119:\tlearn: 1.0472551\ttotal: 35.8s\tremaining: 23.8s\n",
      "120:\tlearn: 1.0435683\ttotal: 36s\tremaining: 23.5s\n",
      "121:\tlearn: 1.0397653\ttotal: 36.3s\tremaining: 23.2s\n",
      "122:\tlearn: 1.0360055\ttotal: 36.7s\tremaining: 23s\n",
      "123:\tlearn: 1.0324991\ttotal: 37s\tremaining: 22.7s\n",
      "124:\tlearn: 1.0292904\ttotal: 37.3s\tremaining: 22.4s\n",
      "125:\tlearn: 1.0256036\ttotal: 37.6s\tremaining: 22.1s\n",
      "126:\tlearn: 1.0218350\ttotal: 37.9s\tremaining: 21.8s\n",
      "127:\tlearn: 1.0187902\ttotal: 38.2s\tremaining: 21.5s\n",
      "128:\tlearn: 1.0152852\ttotal: 38.5s\tremaining: 21.2s\n",
      "129:\tlearn: 1.0117422\ttotal: 38.8s\tremaining: 20.9s\n",
      "130:\tlearn: 1.0083954\ttotal: 39.1s\tremaining: 20.6s\n",
      "131:\tlearn: 1.0049125\ttotal: 39.4s\tremaining: 20.3s\n",
      "132:\tlearn: 1.0015740\ttotal: 39.7s\tremaining: 20s\n",
      "133:\tlearn: 0.9982863\ttotal: 40.1s\tremaining: 19.7s\n",
      "134:\tlearn: 0.9950189\ttotal: 40.4s\tremaining: 19.4s\n",
      "135:\tlearn: 0.9917129\ttotal: 40.7s\tremaining: 19.1s\n",
      "136:\tlearn: 0.9880284\ttotal: 41s\tremaining: 18.9s\n",
      "137:\tlearn: 0.9847904\ttotal: 41.4s\tremaining: 18.6s\n",
      "138:\tlearn: 0.9814738\ttotal: 41.7s\tremaining: 18.3s\n",
      "139:\tlearn: 0.9785453\ttotal: 42s\tremaining: 18s\n",
      "140:\tlearn: 0.9752393\ttotal: 42.3s\tremaining: 17.7s\n",
      "141:\tlearn: 0.9721586\ttotal: 42.6s\tremaining: 17.4s\n",
      "142:\tlearn: 0.9690923\ttotal: 42.9s\tremaining: 17.1s\n",
      "143:\tlearn: 0.9661988\ttotal: 43.2s\tremaining: 16.8s\n",
      "144:\tlearn: 0.9631584\ttotal: 43.5s\tremaining: 16.5s\n",
      "145:\tlearn: 0.9604785\ttotal: 43.8s\tremaining: 16.2s\n",
      "146:\tlearn: 0.9577522\ttotal: 44.1s\tremaining: 15.9s\n",
      "147:\tlearn: 0.9547728\ttotal: 44.4s\tremaining: 15.6s\n",
      "148:\tlearn: 0.9523177\ttotal: 44.7s\tremaining: 15.3s\n",
      "149:\tlearn: 0.9496189\ttotal: 44.9s\tremaining: 15s\n",
      "150:\tlearn: 0.9473134\ttotal: 45.2s\tremaining: 14.7s\n",
      "151:\tlearn: 0.9446354\ttotal: 45.5s\tremaining: 14.4s\n",
      "152:\tlearn: 0.9420343\ttotal: 45.8s\tremaining: 14.1s\n",
      "153:\tlearn: 0.9393126\ttotal: 46.1s\tremaining: 13.8s\n",
      "154:\tlearn: 0.9369892\ttotal: 46.4s\tremaining: 13.5s\n",
      "155:\tlearn: 0.9343516\ttotal: 46.7s\tremaining: 13.2s\n",
      "156:\tlearn: 0.9316448\ttotal: 47s\tremaining: 12.9s\n",
      "157:\tlearn: 0.9291463\ttotal: 47.4s\tremaining: 12.6s\n",
      "158:\tlearn: 0.9268741\ttotal: 47.7s\tremaining: 12.3s\n",
      "159:\tlearn: 0.9242923\ttotal: 48s\tremaining: 12s\n",
      "160:\tlearn: 0.9223102\ttotal: 48.3s\tremaining: 11.7s\n",
      "161:\tlearn: 0.9194901\ttotal: 48.6s\tremaining: 11.4s\n",
      "162:\tlearn: 0.9165889\ttotal: 48.9s\tremaining: 11.1s\n",
      "163:\tlearn: 0.9142227\ttotal: 49.2s\tremaining: 10.8s\n",
      "164:\tlearn: 0.9118820\ttotal: 49.5s\tremaining: 10.5s\n",
      "165:\tlearn: 0.9096216\ttotal: 49.8s\tremaining: 10.2s\n",
      "166:\tlearn: 0.9073388\ttotal: 50.1s\tremaining: 9.9s\n",
      "167:\tlearn: 0.9046295\ttotal: 50.4s\tremaining: 9.6s\n",
      "168:\tlearn: 0.9024372\ttotal: 50.7s\tremaining: 9.31s\n",
      "169:\tlearn: 0.9002618\ttotal: 51s\tremaining: 9.01s\n",
      "170:\tlearn: 0.8978514\ttotal: 51.3s\tremaining: 8.71s\n",
      "171:\tlearn: 0.8956333\ttotal: 51.7s\tremaining: 8.41s\n",
      "172:\tlearn: 0.8937627\ttotal: 52s\tremaining: 8.11s\n",
      "173:\tlearn: 0.8913831\ttotal: 52.2s\tremaining: 7.81s\n",
      "174:\tlearn: 0.8890348\ttotal: 52.6s\tremaining: 7.51s\n",
      "175:\tlearn: 0.8869089\ttotal: 52.9s\tremaining: 7.21s\n",
      "176:\tlearn: 0.8846493\ttotal: 53.2s\tremaining: 6.91s\n",
      "177:\tlearn: 0.8821954\ttotal: 53.5s\tremaining: 6.61s\n",
      "178:\tlearn: 0.8800460\ttotal: 53.8s\tremaining: 6.31s\n",
      "179:\tlearn: 0.8775913\ttotal: 54.1s\tremaining: 6.01s\n",
      "180:\tlearn: 0.8753926\ttotal: 54.3s\tremaining: 5.71s\n",
      "181:\tlearn: 0.8731405\ttotal: 54.6s\tremaining: 5.4s\n",
      "182:\tlearn: 0.8709763\ttotal: 55s\tremaining: 5.11s\n",
      "183:\tlearn: 0.8686203\ttotal: 55.3s\tremaining: 4.81s\n",
      "184:\tlearn: 0.8669564\ttotal: 55.6s\tremaining: 4.51s\n",
      "185:\tlearn: 0.8649422\ttotal: 55.9s\tremaining: 4.21s\n",
      "186:\tlearn: 0.8627164\ttotal: 56.3s\tremaining: 3.91s\n",
      "187:\tlearn: 0.8606822\ttotal: 56.6s\tremaining: 3.61s\n",
      "188:\tlearn: 0.8587732\ttotal: 56.9s\tremaining: 3.31s\n",
      "189:\tlearn: 0.8566007\ttotal: 57.2s\tremaining: 3.01s\n",
      "190:\tlearn: 0.8546600\ttotal: 57.5s\tremaining: 2.71s\n",
      "191:\tlearn: 0.8525136\ttotal: 57.8s\tremaining: 2.41s\n",
      "192:\tlearn: 0.8506812\ttotal: 58.1s\tremaining: 2.11s\n",
      "193:\tlearn: 0.8486242\ttotal: 58.4s\tremaining: 1.8s\n",
      "194:\tlearn: 0.8468393\ttotal: 58.7s\tremaining: 1.5s\n",
      "195:\tlearn: 0.8448103\ttotal: 59s\tremaining: 1.2s\n",
      "196:\tlearn: 0.8425465\ttotal: 59.4s\tremaining: 904ms\n",
      "197:\tlearn: 0.8405931\ttotal: 59.7s\tremaining: 603ms\n",
      "198:\tlearn: 0.8385729\ttotal: 60s\tremaining: 301ms\n",
      "199:\tlearn: 0.8366527\ttotal: 1m\tremaining: 0us\n",
      "0:\tlearn: 1.2891537\ttotal: 294ms\tremaining: 58.6s\n",
      "1:\tlearn: 1.0635618\ttotal: 591ms\tremaining: 58.5s\n",
      "2:\tlearn: 0.9281624\ttotal: 876ms\tremaining: 57.5s\n",
      "3:\tlearn: 0.8417570\ttotal: 1.16s\tremaining: 57.1s\n",
      "4:\tlearn: 0.7599713\ttotal: 1.48s\tremaining: 57.6s\n",
      "5:\tlearn: 0.7134519\ttotal: 1.78s\tremaining: 57.5s\n",
      "6:\tlearn: 0.6819323\ttotal: 2.07s\tremaining: 57.2s\n",
      "7:\tlearn: 0.6421344\ttotal: 2.38s\tremaining: 57s\n",
      "8:\tlearn: 0.6131799\ttotal: 2.66s\tremaining: 56.4s\n",
      "9:\tlearn: 0.5855527\ttotal: 2.94s\tremaining: 56s\n",
      "10:\tlearn: 0.5736969\ttotal: 3.21s\tremaining: 55.2s\n",
      "11:\tlearn: 0.5637071\ttotal: 3.49s\tremaining: 54.7s\n",
      "12:\tlearn: 0.5470339\ttotal: 3.78s\tremaining: 54.4s\n",
      "13:\tlearn: 0.5328172\ttotal: 4.06s\tremaining: 53.9s\n",
      "14:\tlearn: 0.5199291\ttotal: 4.34s\tremaining: 53.5s\n",
      "15:\tlearn: 0.5089275\ttotal: 4.61s\tremaining: 53.1s\n",
      "16:\tlearn: 0.5027604\ttotal: 4.89s\tremaining: 52.6s\n",
      "17:\tlearn: 0.4971283\ttotal: 5.19s\tremaining: 52.5s\n",
      "18:\tlearn: 0.4922164\ttotal: 5.46s\tremaining: 52.1s\n",
      "19:\tlearn: 0.4858211\ttotal: 5.75s\tremaining: 51.8s\n",
      "20:\tlearn: 0.4765633\ttotal: 6.03s\tremaining: 51.4s\n",
      "21:\tlearn: 0.4683197\ttotal: 6.32s\tremaining: 51.1s\n",
      "22:\tlearn: 0.4596810\ttotal: 6.6s\tremaining: 50.8s\n",
      "23:\tlearn: 0.4560721\ttotal: 6.87s\tremaining: 50.4s\n",
      "24:\tlearn: 0.4476011\ttotal: 7.15s\tremaining: 50s\n",
      "25:\tlearn: 0.4425884\ttotal: 7.44s\tremaining: 49.8s\n",
      "26:\tlearn: 0.4400161\ttotal: 7.7s\tremaining: 49.3s\n",
      "27:\tlearn: 0.4356819\ttotal: 7.98s\tremaining: 49s\n",
      "28:\tlearn: 0.4308022\ttotal: 8.25s\tremaining: 48.7s\n",
      "29:\tlearn: 0.4247129\ttotal: 8.54s\tremaining: 48.4s\n",
      "30:\tlearn: 0.4214119\ttotal: 8.83s\tremaining: 48.1s\n",
      "31:\tlearn: 0.4146935\ttotal: 9.13s\tremaining: 47.9s\n",
      "32:\tlearn: 0.4035699\ttotal: 9.41s\tremaining: 47.6s\n",
      "33:\tlearn: 0.3972906\ttotal: 9.69s\tremaining: 47.3s\n",
      "34:\tlearn: 0.3922274\ttotal: 9.98s\tremaining: 47s\n",
      "35:\tlearn: 0.3879774\ttotal: 10.3s\tremaining: 46.7s\n",
      "36:\tlearn: 0.3864630\ttotal: 10.5s\tremaining: 46.3s\n",
      "37:\tlearn: 0.3838449\ttotal: 10.8s\tremaining: 46s\n",
      "38:\tlearn: 0.3799694\ttotal: 11s\tremaining: 45.6s\n",
      "39:\tlearn: 0.3759426\ttotal: 11.3s\tremaining: 45.4s\n",
      "40:\tlearn: 0.3722526\ttotal: 11.7s\tremaining: 45.2s\n",
      "41:\tlearn: 0.3699576\ttotal: 11.9s\tremaining: 44.8s\n",
      "42:\tlearn: 0.3667690\ttotal: 12.2s\tremaining: 44.5s\n",
      "43:\tlearn: 0.3642207\ttotal: 12.5s\tremaining: 44.2s\n",
      "44:\tlearn: 0.3616298\ttotal: 12.7s\tremaining: 43.8s\n",
      "45:\tlearn: 0.3591593\ttotal: 13s\tremaining: 43.5s\n",
      "46:\tlearn: 0.3577433\ttotal: 13.3s\tremaining: 43.2s\n",
      "47:\tlearn: 0.3549495\ttotal: 13.5s\tremaining: 42.8s\n",
      "48:\tlearn: 0.3519899\ttotal: 13.8s\tremaining: 42.6s\n",
      "49:\tlearn: 0.3509037\ttotal: 14.1s\tremaining: 42.3s\n",
      "50:\tlearn: 0.3500819\ttotal: 14.4s\tremaining: 42s\n",
      "51:\tlearn: 0.3479737\ttotal: 14.6s\tremaining: 41.7s\n",
      "52:\tlearn: 0.3457946\ttotal: 14.9s\tremaining: 41.4s\n",
      "53:\tlearn: 0.3430581\ttotal: 15.2s\tremaining: 41.1s\n",
      "54:\tlearn: 0.3406439\ttotal: 15.5s\tremaining: 40.8s\n",
      "55:\tlearn: 0.3377603\ttotal: 15.7s\tremaining: 40.5s\n",
      "56:\tlearn: 0.3362619\ttotal: 16s\tremaining: 40.2s\n",
      "57:\tlearn: 0.3301957\ttotal: 16.3s\tremaining: 40s\n",
      "58:\tlearn: 0.3275173\ttotal: 16.6s\tremaining: 39.7s\n",
      "59:\tlearn: 0.3259710\ttotal: 16.9s\tremaining: 39.4s\n",
      "60:\tlearn: 0.3238108\ttotal: 17.2s\tremaining: 39.1s\n",
      "61:\tlearn: 0.3216094\ttotal: 17.4s\tremaining: 38.8s\n",
      "62:\tlearn: 0.3183372\ttotal: 17.7s\tremaining: 38.6s\n",
      "63:\tlearn: 0.3160793\ttotal: 18s\tremaining: 38.3s\n",
      "64:\tlearn: 0.3140282\ttotal: 18.3s\tremaining: 38s\n",
      "65:\tlearn: 0.3126501\ttotal: 18.6s\tremaining: 37.7s\n",
      "66:\tlearn: 0.3112348\ttotal: 18.8s\tremaining: 37.4s\n",
      "67:\tlearn: 0.3103329\ttotal: 19.1s\tremaining: 37.1s\n",
      "68:\tlearn: 0.3084596\ttotal: 19.4s\tremaining: 36.8s\n",
      "69:\tlearn: 0.3051045\ttotal: 19.7s\tremaining: 36.5s\n",
      "70:\tlearn: 0.3029219\ttotal: 19.9s\tremaining: 36.2s\n",
      "71:\tlearn: 0.3016418\ttotal: 20.2s\tremaining: 35.9s\n",
      "72:\tlearn: 0.2993073\ttotal: 20.5s\tremaining: 35.7s\n",
      "73:\tlearn: 0.2976537\ttotal: 20.8s\tremaining: 35.4s\n",
      "74:\tlearn: 0.2966458\ttotal: 21.1s\tremaining: 35.1s\n",
      "75:\tlearn: 0.2958733\ttotal: 21.3s\tremaining: 34.8s\n",
      "76:\tlearn: 0.2930826\ttotal: 21.6s\tremaining: 34.5s\n",
      "77:\tlearn: 0.2923063\ttotal: 21.8s\tremaining: 34.2s\n",
      "78:\tlearn: 0.2915689\ttotal: 22.1s\tremaining: 33.9s\n",
      "79:\tlearn: 0.2896730\ttotal: 22.4s\tremaining: 33.6s\n",
      "80:\tlearn: 0.2884715\ttotal: 22.6s\tremaining: 33.2s\n",
      "81:\tlearn: 0.2865178\ttotal: 22.9s\tremaining: 32.9s\n",
      "82:\tlearn: 0.2851551\ttotal: 23.2s\tremaining: 32.6s\n",
      "83:\tlearn: 0.2839602\ttotal: 23.4s\tremaining: 32.3s\n",
      "84:\tlearn: 0.2828179\ttotal: 23.7s\tremaining: 32s\n",
      "85:\tlearn: 0.2809309\ttotal: 23.9s\tremaining: 31.7s\n",
      "86:\tlearn: 0.2802643\ttotal: 24.2s\tremaining: 31.4s\n",
      "87:\tlearn: 0.2784397\ttotal: 24.5s\tremaining: 31.1s\n",
      "88:\tlearn: 0.2765641\ttotal: 24.7s\tremaining: 30.8s\n",
      "89:\tlearn: 0.2749822\ttotal: 25s\tremaining: 30.6s\n",
      "90:\tlearn: 0.2741946\ttotal: 25.3s\tremaining: 30.3s\n",
      "91:\tlearn: 0.2733344\ttotal: 25.5s\tremaining: 30s\n",
      "92:\tlearn: 0.2727329\ttotal: 25.8s\tremaining: 29.7s\n",
      "93:\tlearn: 0.2714400\ttotal: 26s\tremaining: 29.4s\n",
      "94:\tlearn: 0.2703430\ttotal: 26.3s\tremaining: 29.1s\n",
      "95:\tlearn: 0.2689044\ttotal: 26.6s\tremaining: 28.8s\n",
      "96:\tlearn: 0.2677602\ttotal: 26.8s\tremaining: 28.5s\n",
      "97:\tlearn: 0.2664236\ttotal: 27.1s\tremaining: 28.2s\n",
      "98:\tlearn: 0.2637656\ttotal: 27.4s\tremaining: 27.9s\n",
      "99:\tlearn: 0.2631655\ttotal: 27.6s\tremaining: 27.6s\n",
      "100:\tlearn: 0.2624830\ttotal: 27.9s\tremaining: 27.3s\n",
      "101:\tlearn: 0.2605960\ttotal: 28.2s\tremaining: 27.1s\n",
      "102:\tlearn: 0.2594955\ttotal: 28.4s\tremaining: 26.8s\n",
      "103:\tlearn: 0.2578519\ttotal: 28.7s\tremaining: 26.5s\n",
      "104:\tlearn: 0.2567853\ttotal: 29s\tremaining: 26.2s\n",
      "105:\tlearn: 0.2552605\ttotal: 29.2s\tremaining: 25.9s\n",
      "106:\tlearn: 0.2531618\ttotal: 29.5s\tremaining: 25.6s\n",
      "107:\tlearn: 0.2524189\ttotal: 29.8s\tremaining: 25.4s\n",
      "108:\tlearn: 0.2505725\ttotal: 30.1s\tremaining: 25.1s\n",
      "109:\tlearn: 0.2480013\ttotal: 30.4s\tremaining: 24.8s\n",
      "110:\tlearn: 0.2462312\ttotal: 30.6s\tremaining: 24.6s\n",
      "111:\tlearn: 0.2457437\ttotal: 30.9s\tremaining: 24.3s\n",
      "112:\tlearn: 0.2437057\ttotal: 31.2s\tremaining: 24s\n",
      "113:\tlearn: 0.2424523\ttotal: 31.5s\tremaining: 23.7s\n",
      "114:\tlearn: 0.2409848\ttotal: 31.7s\tremaining: 23.4s\n",
      "115:\tlearn: 0.2395115\ttotal: 32s\tremaining: 23.2s\n",
      "116:\tlearn: 0.2387866\ttotal: 32.2s\tremaining: 22.9s\n",
      "117:\tlearn: 0.2370170\ttotal: 32.5s\tremaining: 22.6s\n",
      "118:\tlearn: 0.2359378\ttotal: 32.8s\tremaining: 22.3s\n",
      "119:\tlearn: 0.2347937\ttotal: 33s\tremaining: 22s\n",
      "120:\tlearn: 0.2331752\ttotal: 33.3s\tremaining: 21.8s\n",
      "121:\tlearn: 0.2324707\ttotal: 33.6s\tremaining: 21.5s\n",
      "122:\tlearn: 0.2311465\ttotal: 33.8s\tremaining: 21.2s\n",
      "123:\tlearn: 0.2303303\ttotal: 34.1s\tremaining: 20.9s\n",
      "124:\tlearn: 0.2292249\ttotal: 34.4s\tremaining: 20.6s\n",
      "125:\tlearn: 0.2277541\ttotal: 34.7s\tremaining: 20.4s\n",
      "126:\tlearn: 0.2268305\ttotal: 34.9s\tremaining: 20.1s\n",
      "127:\tlearn: 0.2255411\ttotal: 35.2s\tremaining: 19.8s\n",
      "128:\tlearn: 0.2245780\ttotal: 35.5s\tremaining: 19.5s\n",
      "129:\tlearn: 0.2234145\ttotal: 35.7s\tremaining: 19.2s\n",
      "130:\tlearn: 0.2222450\ttotal: 36s\tremaining: 19s\n",
      "131:\tlearn: 0.2218584\ttotal: 36.3s\tremaining: 18.7s\n",
      "132:\tlearn: 0.2209509\ttotal: 36.5s\tremaining: 18.4s\n",
      "133:\tlearn: 0.2205362\ttotal: 36.8s\tremaining: 18.1s\n",
      "134:\tlearn: 0.2192840\ttotal: 37.1s\tremaining: 17.8s\n",
      "135:\tlearn: 0.2182744\ttotal: 37.3s\tremaining: 17.6s\n",
      "136:\tlearn: 0.2170782\ttotal: 37.6s\tremaining: 17.3s\n",
      "137:\tlearn: 0.2155071\ttotal: 37.9s\tremaining: 17s\n",
      "138:\tlearn: 0.2145519\ttotal: 38.1s\tremaining: 16.7s\n",
      "139:\tlearn: 0.2125470\ttotal: 38.4s\tremaining: 16.5s\n",
      "140:\tlearn: 0.2115853\ttotal: 38.7s\tremaining: 16.2s\n",
      "141:\tlearn: 0.2108960\ttotal: 38.9s\tremaining: 15.9s\n",
      "142:\tlearn: 0.2098848\ttotal: 39.2s\tremaining: 15.6s\n",
      "143:\tlearn: 0.2082387\ttotal: 39.5s\tremaining: 15.4s\n",
      "144:\tlearn: 0.2070196\ttotal: 39.8s\tremaining: 15.1s\n",
      "145:\tlearn: 0.2063206\ttotal: 40s\tremaining: 14.8s\n",
      "146:\tlearn: 0.2050467\ttotal: 40.3s\tremaining: 14.5s\n",
      "147:\tlearn: 0.2041047\ttotal: 40.6s\tremaining: 14.3s\n",
      "148:\tlearn: 0.2036053\ttotal: 40.8s\tremaining: 14s\n",
      "149:\tlearn: 0.2033887\ttotal: 41.1s\tremaining: 13.7s\n",
      "150:\tlearn: 0.2027689\ttotal: 41.4s\tremaining: 13.4s\n",
      "151:\tlearn: 0.2017775\ttotal: 41.6s\tremaining: 13.1s\n",
      "152:\tlearn: 0.2001718\ttotal: 41.9s\tremaining: 12.9s\n",
      "153:\tlearn: 0.1997070\ttotal: 42.2s\tremaining: 12.6s\n",
      "154:\tlearn: 0.1982801\ttotal: 42.4s\tremaining: 12.3s\n",
      "155:\tlearn: 0.1975444\ttotal: 42.7s\tremaining: 12s\n",
      "156:\tlearn: 0.1968193\ttotal: 43s\tremaining: 11.8s\n",
      "157:\tlearn: 0.1956449\ttotal: 43.3s\tremaining: 11.5s\n",
      "158:\tlearn: 0.1947611\ttotal: 43.6s\tremaining: 11.2s\n",
      "159:\tlearn: 0.1940501\ttotal: 43.8s\tremaining: 11s\n",
      "160:\tlearn: 0.1934557\ttotal: 44.1s\tremaining: 10.7s\n",
      "161:\tlearn: 0.1919756\ttotal: 44.4s\tremaining: 10.4s\n",
      "162:\tlearn: 0.1911397\ttotal: 44.7s\tremaining: 10.1s\n",
      "163:\tlearn: 0.1896136\ttotal: 44.9s\tremaining: 9.87s\n",
      "164:\tlearn: 0.1889296\ttotal: 45.2s\tremaining: 9.59s\n",
      "165:\tlearn: 0.1884214\ttotal: 45.5s\tremaining: 9.32s\n",
      "166:\tlearn: 0.1877182\ttotal: 45.8s\tremaining: 9.04s\n",
      "167:\tlearn: 0.1874386\ttotal: 46s\tremaining: 8.77s\n",
      "168:\tlearn: 0.1870128\ttotal: 46.3s\tremaining: 8.49s\n",
      "169:\tlearn: 0.1861041\ttotal: 46.6s\tremaining: 8.22s\n",
      "170:\tlearn: 0.1854943\ttotal: 46.9s\tremaining: 7.95s\n",
      "171:\tlearn: 0.1842248\ttotal: 47.2s\tremaining: 7.68s\n",
      "172:\tlearn: 0.1833938\ttotal: 47.5s\tremaining: 7.41s\n",
      "173:\tlearn: 0.1820638\ttotal: 47.8s\tremaining: 7.14s\n",
      "174:\tlearn: 0.1811203\ttotal: 48s\tremaining: 6.86s\n",
      "175:\tlearn: 0.1807268\ttotal: 48.3s\tremaining: 6.59s\n",
      "176:\tlearn: 0.1793365\ttotal: 48.6s\tremaining: 6.31s\n",
      "177:\tlearn: 0.1788179\ttotal: 48.9s\tremaining: 6.04s\n",
      "178:\tlearn: 0.1780108\ttotal: 49.1s\tremaining: 5.76s\n",
      "179:\tlearn: 0.1771819\ttotal: 49.4s\tremaining: 5.49s\n",
      "180:\tlearn: 0.1763419\ttotal: 49.7s\tremaining: 5.22s\n",
      "181:\tlearn: 0.1755748\ttotal: 50s\tremaining: 4.94s\n",
      "182:\tlearn: 0.1751420\ttotal: 50.2s\tremaining: 4.67s\n",
      "183:\tlearn: 0.1736710\ttotal: 50.5s\tremaining: 4.39s\n",
      "184:\tlearn: 0.1730181\ttotal: 50.8s\tremaining: 4.12s\n",
      "185:\tlearn: 0.1721544\ttotal: 51.1s\tremaining: 3.85s\n",
      "186:\tlearn: 0.1715249\ttotal: 51.4s\tremaining: 3.57s\n",
      "187:\tlearn: 0.1702928\ttotal: 51.7s\tremaining: 3.3s\n",
      "188:\tlearn: 0.1693972\ttotal: 52s\tremaining: 3.02s\n",
      "189:\tlearn: 0.1687394\ttotal: 52.3s\tremaining: 2.75s\n",
      "190:\tlearn: 0.1675111\ttotal: 52.6s\tremaining: 2.48s\n",
      "191:\tlearn: 0.1671341\ttotal: 53s\tremaining: 2.21s\n",
      "192:\tlearn: 0.1664863\ttotal: 53.4s\tremaining: 1.94s\n",
      "193:\tlearn: 0.1659432\ttotal: 53.7s\tremaining: 1.66s\n",
      "194:\tlearn: 0.1651508\ttotal: 54s\tremaining: 1.38s\n",
      "195:\tlearn: 0.1646249\ttotal: 54.3s\tremaining: 1.11s\n",
      "196:\tlearn: 0.1637523\ttotal: 54.7s\tremaining: 832ms\n",
      "197:\tlearn: 0.1630163\ttotal: 55s\tremaining: 556ms\n",
      "198:\tlearn: 0.1619507\ttotal: 55.3s\tremaining: 278ms\n",
      "199:\tlearn: 0.1609950\ttotal: 55.6s\tremaining: 0us\n",
      "0:\tlearn: 1.2453824\ttotal: 285ms\tremaining: 56.7s\n",
      "1:\tlearn: 1.0460857\ttotal: 597ms\tremaining: 59.1s\n",
      "2:\tlearn: 0.9075354\ttotal: 901ms\tremaining: 59.1s\n",
      "3:\tlearn: 0.8161234\ttotal: 1.21s\tremaining: 59.4s\n",
      "4:\tlearn: 0.7571292\ttotal: 1.5s\tremaining: 58.7s\n",
      "5:\tlearn: 0.7033798\ttotal: 1.8s\tremaining: 58.1s\n",
      "6:\tlearn: 0.6682388\ttotal: 2.11s\tremaining: 58.3s\n",
      "7:\tlearn: 0.6332849\ttotal: 2.4s\tremaining: 57.7s\n",
      "8:\tlearn: 0.6102045\ttotal: 2.69s\tremaining: 57s\n",
      "9:\tlearn: 0.5819260\ttotal: 2.98s\tremaining: 56.6s\n",
      "10:\tlearn: 0.5699302\ttotal: 3.25s\tremaining: 55.9s\n",
      "11:\tlearn: 0.5590179\ttotal: 3.54s\tremaining: 55.4s\n",
      "12:\tlearn: 0.5426648\ttotal: 3.83s\tremaining: 55.1s\n",
      "13:\tlearn: 0.5358060\ttotal: 4.1s\tremaining: 54.5s\n",
      "14:\tlearn: 0.5237043\ttotal: 4.4s\tremaining: 54.3s\n",
      "15:\tlearn: 0.5109553\ttotal: 4.7s\tremaining: 54s\n",
      "16:\tlearn: 0.5051187\ttotal: 4.98s\tremaining: 53.6s\n",
      "17:\tlearn: 0.4983362\ttotal: 5.26s\tremaining: 53.2s\n",
      "18:\tlearn: 0.4877593\ttotal: 5.54s\tremaining: 52.8s\n",
      "19:\tlearn: 0.4773902\ttotal: 5.83s\tremaining: 52.5s\n",
      "20:\tlearn: 0.4714455\ttotal: 6.12s\tremaining: 52.2s\n",
      "21:\tlearn: 0.4626222\ttotal: 6.41s\tremaining: 51.9s\n",
      "22:\tlearn: 0.4575152\ttotal: 6.68s\tremaining: 51.4s\n",
      "23:\tlearn: 0.4518861\ttotal: 6.95s\tremaining: 51s\n",
      "24:\tlearn: 0.4489304\ttotal: 7.23s\tremaining: 50.6s\n",
      "25:\tlearn: 0.4419995\ttotal: 7.5s\tremaining: 50.2s\n",
      "26:\tlearn: 0.4358793\ttotal: 7.77s\tremaining: 49.8s\n",
      "27:\tlearn: 0.4318121\ttotal: 8.05s\tremaining: 49.4s\n",
      "28:\tlearn: 0.4281226\ttotal: 8.33s\tremaining: 49.1s\n",
      "29:\tlearn: 0.4235008\ttotal: 8.6s\tremaining: 48.7s\n",
      "30:\tlearn: 0.4211903\ttotal: 8.9s\tremaining: 48.5s\n",
      "31:\tlearn: 0.4141696\ttotal: 9.18s\tremaining: 48.2s\n",
      "32:\tlearn: 0.4108934\ttotal: 9.45s\tremaining: 47.8s\n",
      "33:\tlearn: 0.4080736\ttotal: 9.72s\tremaining: 47.4s\n",
      "34:\tlearn: 0.4023072\ttotal: 9.99s\tremaining: 47.1s\n",
      "35:\tlearn: 0.3991582\ttotal: 10.3s\tremaining: 46.7s\n",
      "36:\tlearn: 0.3924196\ttotal: 10.5s\tremaining: 46.4s\n",
      "37:\tlearn: 0.3909637\ttotal: 10.8s\tremaining: 46s\n",
      "38:\tlearn: 0.3856940\ttotal: 11.1s\tremaining: 45.7s\n",
      "39:\tlearn: 0.3838430\ttotal: 11.3s\tremaining: 45.3s\n",
      "40:\tlearn: 0.3800581\ttotal: 11.6s\tremaining: 45s\n",
      "41:\tlearn: 0.3765109\ttotal: 11.9s\tremaining: 44.8s\n",
      "42:\tlearn: 0.3738568\ttotal: 12.2s\tremaining: 44.4s\n",
      "43:\tlearn: 0.3700673\ttotal: 12.4s\tremaining: 44.1s\n",
      "44:\tlearn: 0.3657037\ttotal: 12.7s\tremaining: 43.8s\n",
      "45:\tlearn: 0.3639628\ttotal: 13s\tremaining: 43.5s\n",
      "46:\tlearn: 0.3599310\ttotal: 13.3s\tremaining: 43.2s\n",
      "47:\tlearn: 0.3582642\ttotal: 13.5s\tremaining: 42.8s\n",
      "48:\tlearn: 0.3555223\ttotal: 13.8s\tremaining: 42.5s\n",
      "49:\tlearn: 0.3515570\ttotal: 14.1s\tremaining: 42.2s\n",
      "50:\tlearn: 0.3501051\ttotal: 14.3s\tremaining: 41.9s\n",
      "51:\tlearn: 0.3464516\ttotal: 14.6s\tremaining: 41.6s\n",
      "52:\tlearn: 0.3443949\ttotal: 14.9s\tremaining: 41.3s\n",
      "53:\tlearn: 0.3431695\ttotal: 15.2s\tremaining: 41s\n",
      "54:\tlearn: 0.3405292\ttotal: 15.5s\tremaining: 40.8s\n",
      "55:\tlearn: 0.3382568\ttotal: 15.8s\tremaining: 40.5s\n",
      "56:\tlearn: 0.3369654\ttotal: 16s\tremaining: 40.2s\n",
      "57:\tlearn: 0.3349708\ttotal: 16.3s\tremaining: 40s\n",
      "58:\tlearn: 0.3310636\ttotal: 16.6s\tremaining: 39.7s\n",
      "59:\tlearn: 0.3292447\ttotal: 16.9s\tremaining: 39.4s\n",
      "60:\tlearn: 0.3264906\ttotal: 17.2s\tremaining: 39.1s\n",
      "61:\tlearn: 0.3244394\ttotal: 17.5s\tremaining: 38.9s\n",
      "62:\tlearn: 0.3225549\ttotal: 17.7s\tremaining: 38.6s\n",
      "63:\tlearn: 0.3198363\ttotal: 18s\tremaining: 38.3s\n",
      "64:\tlearn: 0.3193189\ttotal: 18.3s\tremaining: 38s\n",
      "65:\tlearn: 0.3160661\ttotal: 18.6s\tremaining: 37.8s\n",
      "66:\tlearn: 0.3148046\ttotal: 18.9s\tremaining: 37.5s\n",
      "67:\tlearn: 0.3105458\ttotal: 19.2s\tremaining: 37.2s\n",
      "68:\tlearn: 0.3080068\ttotal: 19.5s\tremaining: 37s\n",
      "69:\tlearn: 0.3054291\ttotal: 19.7s\tremaining: 36.7s\n",
      "70:\tlearn: 0.3036820\ttotal: 20s\tremaining: 36.4s\n",
      "71:\tlearn: 0.3028227\ttotal: 20.3s\tremaining: 36.1s\n",
      "72:\tlearn: 0.3013374\ttotal: 20.6s\tremaining: 35.8s\n",
      "73:\tlearn: 0.2993935\ttotal: 20.9s\tremaining: 35.5s\n",
      "74:\tlearn: 0.2977328\ttotal: 21.2s\tremaining: 35.3s\n",
      "75:\tlearn: 0.2963434\ttotal: 21.4s\tremaining: 35s\n",
      "76:\tlearn: 0.2934478\ttotal: 21.7s\tremaining: 34.7s\n",
      "77:\tlearn: 0.2915480\ttotal: 22s\tremaining: 34.4s\n",
      "78:\tlearn: 0.2895964\ttotal: 22.2s\tremaining: 34.1s\n",
      "79:\tlearn: 0.2876783\ttotal: 22.5s\tremaining: 33.8s\n",
      "80:\tlearn: 0.2864487\ttotal: 22.8s\tremaining: 33.5s\n",
      "81:\tlearn: 0.2849721\ttotal: 23s\tremaining: 33.2s\n",
      "82:\tlearn: 0.2838286\ttotal: 23.3s\tremaining: 32.8s\n",
      "83:\tlearn: 0.2832653\ttotal: 23.6s\tremaining: 32.5s\n",
      "84:\tlearn: 0.2812781\ttotal: 23.8s\tremaining: 32.3s\n",
      "85:\tlearn: 0.2802035\ttotal: 24.1s\tremaining: 32s\n",
      "86:\tlearn: 0.2791183\ttotal: 24.4s\tremaining: 31.7s\n",
      "87:\tlearn: 0.2776420\ttotal: 24.7s\tremaining: 31.4s\n",
      "88:\tlearn: 0.2760237\ttotal: 25s\tremaining: 31.2s\n",
      "89:\tlearn: 0.2749652\ttotal: 25.3s\tremaining: 30.9s\n",
      "90:\tlearn: 0.2736397\ttotal: 25.5s\tremaining: 30.6s\n",
      "91:\tlearn: 0.2726216\ttotal: 25.8s\tremaining: 30.3s\n",
      "92:\tlearn: 0.2719497\ttotal: 26.1s\tremaining: 30s\n",
      "93:\tlearn: 0.2710345\ttotal: 26.4s\tremaining: 29.7s\n",
      "94:\tlearn: 0.2698482\ttotal: 26.6s\tremaining: 29.5s\n",
      "95:\tlearn: 0.2681117\ttotal: 27s\tremaining: 29.2s\n",
      "96:\tlearn: 0.2670117\ttotal: 27.2s\tremaining: 28.9s\n",
      "97:\tlearn: 0.2661162\ttotal: 27.5s\tremaining: 28.6s\n",
      "98:\tlearn: 0.2650517\ttotal: 27.8s\tremaining: 28.3s\n",
      "99:\tlearn: 0.2641167\ttotal: 28s\tremaining: 28s\n",
      "100:\tlearn: 0.2623965\ttotal: 28.3s\tremaining: 27.7s\n",
      "101:\tlearn: 0.2605244\ttotal: 28.6s\tremaining: 27.5s\n",
      "102:\tlearn: 0.2594248\ttotal: 28.8s\tremaining: 27.1s\n",
      "103:\tlearn: 0.2579953\ttotal: 29.1s\tremaining: 26.9s\n",
      "104:\tlearn: 0.2553588\ttotal: 29.4s\tremaining: 26.6s\n",
      "105:\tlearn: 0.2542923\ttotal: 29.6s\tremaining: 26.3s\n",
      "106:\tlearn: 0.2535610\ttotal: 29.9s\tremaining: 26s\n",
      "107:\tlearn: 0.2524633\ttotal: 30.2s\tremaining: 25.7s\n",
      "108:\tlearn: 0.2514539\ttotal: 30.5s\tremaining: 25.5s\n",
      "109:\tlearn: 0.2498552\ttotal: 30.8s\tremaining: 25.2s\n",
      "110:\tlearn: 0.2476277\ttotal: 31s\tremaining: 24.9s\n",
      "111:\tlearn: 0.2464004\ttotal: 31.4s\tremaining: 24.6s\n",
      "112:\tlearn: 0.2450154\ttotal: 31.6s\tremaining: 24.4s\n",
      "113:\tlearn: 0.2440304\ttotal: 31.9s\tremaining: 24.1s\n",
      "114:\tlearn: 0.2432318\ttotal: 32.2s\tremaining: 23.8s\n",
      "115:\tlearn: 0.2422407\ttotal: 32.5s\tremaining: 23.5s\n",
      "116:\tlearn: 0.2412366\ttotal: 32.7s\tremaining: 23.2s\n",
      "117:\tlearn: 0.2399225\ttotal: 33s\tremaining: 22.9s\n",
      "118:\tlearn: 0.2390795\ttotal: 33.3s\tremaining: 22.6s\n",
      "119:\tlearn: 0.2372436\ttotal: 33.6s\tremaining: 22.4s\n",
      "120:\tlearn: 0.2350766\ttotal: 33.9s\tremaining: 22.1s\n",
      "121:\tlearn: 0.2336637\ttotal: 34.1s\tremaining: 21.8s\n",
      "122:\tlearn: 0.2329019\ttotal: 34.4s\tremaining: 21.5s\n",
      "123:\tlearn: 0.2315616\ttotal: 34.7s\tremaining: 21.2s\n",
      "124:\tlearn: 0.2302303\ttotal: 35s\tremaining: 21s\n",
      "125:\tlearn: 0.2285940\ttotal: 35.2s\tremaining: 20.7s\n",
      "126:\tlearn: 0.2272377\ttotal: 35.5s\tremaining: 20.4s\n",
      "127:\tlearn: 0.2264638\ttotal: 35.8s\tremaining: 20.1s\n",
      "128:\tlearn: 0.2255280\ttotal: 36s\tremaining: 19.8s\n",
      "129:\tlearn: 0.2246238\ttotal: 36.3s\tremaining: 19.5s\n",
      "130:\tlearn: 0.2238239\ttotal: 36.6s\tremaining: 19.3s\n",
      "131:\tlearn: 0.2224633\ttotal: 36.8s\tremaining: 19s\n",
      "132:\tlearn: 0.2217747\ttotal: 37.1s\tremaining: 18.7s\n",
      "133:\tlearn: 0.2208946\ttotal: 37.4s\tremaining: 18.4s\n",
      "134:\tlearn: 0.2204852\ttotal: 37.6s\tremaining: 18.1s\n",
      "135:\tlearn: 0.2197385\ttotal: 37.9s\tremaining: 17.8s\n",
      "136:\tlearn: 0.2189816\ttotal: 38.2s\tremaining: 17.5s\n",
      "137:\tlearn: 0.2184009\ttotal: 38.4s\tremaining: 17.3s\n",
      "138:\tlearn: 0.2175954\ttotal: 38.7s\tremaining: 17s\n",
      "139:\tlearn: 0.2168798\ttotal: 38.9s\tremaining: 16.7s\n",
      "140:\tlearn: 0.2158380\ttotal: 39.2s\tremaining: 16.4s\n",
      "141:\tlearn: 0.2151716\ttotal: 39.5s\tremaining: 16.1s\n",
      "142:\tlearn: 0.2145822\ttotal: 39.8s\tremaining: 15.9s\n",
      "143:\tlearn: 0.2136631\ttotal: 40.1s\tremaining: 15.6s\n",
      "144:\tlearn: 0.2132602\ttotal: 40.4s\tremaining: 15.3s\n",
      "145:\tlearn: 0.2115054\ttotal: 40.6s\tremaining: 15s\n",
      "146:\tlearn: 0.2106851\ttotal: 40.9s\tremaining: 14.8s\n",
      "147:\tlearn: 0.2097144\ttotal: 41.2s\tremaining: 14.5s\n",
      "148:\tlearn: 0.2088696\ttotal: 41.5s\tremaining: 14.2s\n",
      "149:\tlearn: 0.2081265\ttotal: 41.8s\tremaining: 13.9s\n",
      "150:\tlearn: 0.2072137\ttotal: 42s\tremaining: 13.6s\n",
      "151:\tlearn: 0.2057769\ttotal: 42.3s\tremaining: 13.4s\n",
      "152:\tlearn: 0.2049338\ttotal: 42.6s\tremaining: 13.1s\n",
      "153:\tlearn: 0.2045935\ttotal: 42.9s\tremaining: 12.8s\n",
      "154:\tlearn: 0.2041910\ttotal: 43.1s\tremaining: 12.5s\n",
      "155:\tlearn: 0.2015607\ttotal: 43.5s\tremaining: 12.3s\n",
      "156:\tlearn: 0.2012005\ttotal: 43.7s\tremaining: 12s\n",
      "157:\tlearn: 0.1999730\ttotal: 44s\tremaining: 11.7s\n",
      "158:\tlearn: 0.1994374\ttotal: 44.3s\tremaining: 11.4s\n",
      "159:\tlearn: 0.1990384\ttotal: 44.6s\tremaining: 11.1s\n",
      "160:\tlearn: 0.1986004\ttotal: 44.9s\tremaining: 10.9s\n",
      "161:\tlearn: 0.1973917\ttotal: 45.2s\tremaining: 10.6s\n",
      "162:\tlearn: 0.1965264\ttotal: 45.5s\tremaining: 10.3s\n",
      "163:\tlearn: 0.1955265\ttotal: 45.7s\tremaining: 10s\n",
      "164:\tlearn: 0.1946800\ttotal: 46s\tremaining: 9.77s\n",
      "165:\tlearn: 0.1940371\ttotal: 46.3s\tremaining: 9.49s\n",
      "166:\tlearn: 0.1927205\ttotal: 46.6s\tremaining: 9.21s\n",
      "167:\tlearn: 0.1920607\ttotal: 46.9s\tremaining: 8.93s\n",
      "168:\tlearn: 0.1915015\ttotal: 47.1s\tremaining: 8.65s\n",
      "169:\tlearn: 0.1902927\ttotal: 47.4s\tremaining: 8.37s\n",
      "170:\tlearn: 0.1900881\ttotal: 47.7s\tremaining: 8.09s\n",
      "171:\tlearn: 0.1889196\ttotal: 48s\tremaining: 7.82s\n",
      "172:\tlearn: 0.1883723\ttotal: 48.3s\tremaining: 7.54s\n",
      "173:\tlearn: 0.1876668\ttotal: 48.6s\tremaining: 7.26s\n",
      "174:\tlearn: 0.1867630\ttotal: 48.9s\tremaining: 6.98s\n",
      "175:\tlearn: 0.1853769\ttotal: 49.2s\tremaining: 6.71s\n",
      "176:\tlearn: 0.1847420\ttotal: 49.4s\tremaining: 6.42s\n",
      "177:\tlearn: 0.1844971\ttotal: 49.7s\tremaining: 6.14s\n",
      "178:\tlearn: 0.1833797\ttotal: 50s\tremaining: 5.87s\n",
      "179:\tlearn: 0.1823501\ttotal: 50.3s\tremaining: 5.59s\n",
      "180:\tlearn: 0.1816438\ttotal: 50.6s\tremaining: 5.31s\n",
      "181:\tlearn: 0.1805790\ttotal: 50.9s\tremaining: 5.03s\n",
      "182:\tlearn: 0.1802278\ttotal: 51.2s\tremaining: 4.75s\n",
      "183:\tlearn: 0.1796021\ttotal: 51.4s\tremaining: 4.47s\n",
      "184:\tlearn: 0.1785292\ttotal: 51.7s\tremaining: 4.19s\n",
      "185:\tlearn: 0.1779621\ttotal: 52s\tremaining: 3.91s\n",
      "186:\tlearn: 0.1774232\ttotal: 52.3s\tremaining: 3.63s\n",
      "187:\tlearn: 0.1761525\ttotal: 52.6s\tremaining: 3.36s\n",
      "188:\tlearn: 0.1755669\ttotal: 52.9s\tremaining: 3.08s\n",
      "189:\tlearn: 0.1749606\ttotal: 53.1s\tremaining: 2.8s\n",
      "190:\tlearn: 0.1737909\ttotal: 53.4s\tremaining: 2.52s\n",
      "191:\tlearn: 0.1736089\ttotal: 53.7s\tremaining: 2.24s\n",
      "192:\tlearn: 0.1729628\ttotal: 54s\tremaining: 1.96s\n",
      "193:\tlearn: 0.1723263\ttotal: 54.3s\tremaining: 1.68s\n",
      "194:\tlearn: 0.1712345\ttotal: 54.6s\tremaining: 1.4s\n",
      "195:\tlearn: 0.1704993\ttotal: 54.9s\tremaining: 1.12s\n",
      "196:\tlearn: 0.1700070\ttotal: 55.1s\tremaining: 840ms\n",
      "197:\tlearn: 0.1695612\ttotal: 55.4s\tremaining: 560ms\n",
      "198:\tlearn: 0.1689485\ttotal: 55.7s\tremaining: 280ms\n",
      "199:\tlearn: 0.1683463\ttotal: 56s\tremaining: 0us\n",
      "0:\tlearn: 1.2503068\ttotal: 301ms\tremaining: 59.9s\n",
      "1:\tlearn: 1.0477035\ttotal: 571ms\tremaining: 56.5s\n",
      "2:\tlearn: 0.9116336\ttotal: 861ms\tremaining: 56.5s\n",
      "3:\tlearn: 0.8324993\ttotal: 1.16s\tremaining: 56.8s\n",
      "4:\tlearn: 0.7706255\ttotal: 1.45s\tremaining: 56.5s\n",
      "5:\tlearn: 0.7187089\ttotal: 1.76s\tremaining: 56.9s\n",
      "6:\tlearn: 0.6785269\ttotal: 2.04s\tremaining: 56.4s\n",
      "7:\tlearn: 0.6421193\ttotal: 2.34s\tremaining: 56.1s\n",
      "8:\tlearn: 0.6068233\ttotal: 2.66s\tremaining: 56.5s\n",
      "9:\tlearn: 0.5786453\ttotal: 2.96s\tremaining: 56.3s\n",
      "10:\tlearn: 0.5635693\ttotal: 3.24s\tremaining: 55.7s\n",
      "11:\tlearn: 0.5501816\ttotal: 3.56s\tremaining: 55.7s\n",
      "12:\tlearn: 0.5345276\ttotal: 3.85s\tremaining: 55.5s\n",
      "13:\tlearn: 0.5252909\ttotal: 4.14s\tremaining: 55.1s\n",
      "14:\tlearn: 0.5117636\ttotal: 4.43s\tremaining: 54.6s\n",
      "15:\tlearn: 0.5053637\ttotal: 4.71s\tremaining: 54.1s\n",
      "16:\tlearn: 0.4991372\ttotal: 4.97s\tremaining: 53.6s\n",
      "17:\tlearn: 0.4899824\ttotal: 5.26s\tremaining: 53.2s\n",
      "18:\tlearn: 0.4817277\ttotal: 5.56s\tremaining: 53s\n",
      "19:\tlearn: 0.4712011\ttotal: 5.86s\tremaining: 52.7s\n",
      "20:\tlearn: 0.4663543\ttotal: 6.15s\tremaining: 52.4s\n",
      "21:\tlearn: 0.4620317\ttotal: 6.42s\tremaining: 51.9s\n",
      "22:\tlearn: 0.4566709\ttotal: 6.7s\tremaining: 51.6s\n",
      "23:\tlearn: 0.4469512\ttotal: 6.98s\tremaining: 51.2s\n",
      "24:\tlearn: 0.4431239\ttotal: 7.26s\tremaining: 50.9s\n",
      "25:\tlearn: 0.4396459\ttotal: 7.56s\tremaining: 50.6s\n",
      "26:\tlearn: 0.4343429\ttotal: 7.87s\tremaining: 50.4s\n",
      "27:\tlearn: 0.4263729\ttotal: 8.18s\tremaining: 50.2s\n",
      "28:\tlearn: 0.4216622\ttotal: 8.47s\tremaining: 49.9s\n",
      "29:\tlearn: 0.4165220\ttotal: 8.74s\tremaining: 49.5s\n",
      "30:\tlearn: 0.4131043\ttotal: 9s\tremaining: 49.1s\n",
      "31:\tlearn: 0.4041856\ttotal: 9.32s\tremaining: 48.9s\n",
      "32:\tlearn: 0.4010008\ttotal: 9.59s\tremaining: 48.5s\n",
      "33:\tlearn: 0.3975883\ttotal: 9.87s\tremaining: 48.2s\n",
      "34:\tlearn: 0.3938106\ttotal: 10.1s\tremaining: 47.8s\n",
      "35:\tlearn: 0.3895686\ttotal: 10.4s\tremaining: 47.5s\n",
      "36:\tlearn: 0.3846725\ttotal: 10.7s\tremaining: 47.2s\n",
      "37:\tlearn: 0.3829916\ttotal: 11s\tremaining: 46.8s\n",
      "38:\tlearn: 0.3794315\ttotal: 11.2s\tremaining: 46.4s\n",
      "39:\tlearn: 0.3749970\ttotal: 11.5s\tremaining: 46.1s\n",
      "40:\tlearn: 0.3733725\ttotal: 11.8s\tremaining: 45.7s\n",
      "41:\tlearn: 0.3698827\ttotal: 12.1s\tremaining: 45.4s\n",
      "42:\tlearn: 0.3683926\ttotal: 12.3s\tremaining: 45s\n",
      "43:\tlearn: 0.3659456\ttotal: 12.6s\tremaining: 44.7s\n",
      "44:\tlearn: 0.3637099\ttotal: 12.9s\tremaining: 44.3s\n",
      "45:\tlearn: 0.3621563\ttotal: 13.1s\tremaining: 43.9s\n",
      "46:\tlearn: 0.3588678\ttotal: 13.4s\tremaining: 43.7s\n",
      "47:\tlearn: 0.3566979\ttotal: 13.7s\tremaining: 43.3s\n",
      "48:\tlearn: 0.3543719\ttotal: 14s\tremaining: 43s\n",
      "49:\tlearn: 0.3523474\ttotal: 14.2s\tremaining: 42.7s\n",
      "50:\tlearn: 0.3504780\ttotal: 14.5s\tremaining: 42.4s\n",
      "51:\tlearn: 0.3485608\ttotal: 14.8s\tremaining: 42s\n",
      "52:\tlearn: 0.3459472\ttotal: 15s\tremaining: 41.7s\n",
      "53:\tlearn: 0.3423936\ttotal: 15.3s\tremaining: 41.5s\n",
      "54:\tlearn: 0.3408505\ttotal: 15.6s\tremaining: 41.1s\n",
      "55:\tlearn: 0.3387584\ttotal: 15.9s\tremaining: 40.8s\n",
      "56:\tlearn: 0.3375933\ttotal: 16.1s\tremaining: 40.5s\n",
      "57:\tlearn: 0.3360651\ttotal: 16.4s\tremaining: 40.1s\n",
      "58:\tlearn: 0.3339156\ttotal: 16.7s\tremaining: 39.8s\n",
      "59:\tlearn: 0.3304765\ttotal: 17s\tremaining: 39.6s\n",
      "60:\tlearn: 0.3286450\ttotal: 17.2s\tremaining: 39.3s\n",
      "61:\tlearn: 0.3265360\ttotal: 17.5s\tremaining: 38.9s\n",
      "62:\tlearn: 0.3255338\ttotal: 17.8s\tremaining: 38.6s\n",
      "63:\tlearn: 0.3227127\ttotal: 18s\tremaining: 38.3s\n",
      "64:\tlearn: 0.3198453\ttotal: 18.3s\tremaining: 38.1s\n",
      "65:\tlearn: 0.3192675\ttotal: 18.6s\tremaining: 37.7s\n",
      "66:\tlearn: 0.3179716\ttotal: 18.9s\tremaining: 37.4s\n",
      "67:\tlearn: 0.3159851\ttotal: 19.1s\tremaining: 37.1s\n",
      "68:\tlearn: 0.3149279\ttotal: 19.4s\tremaining: 36.8s\n",
      "69:\tlearn: 0.3140414\ttotal: 19.7s\tremaining: 36.5s\n",
      "70:\tlearn: 0.3133543\ttotal: 19.9s\tremaining: 36.2s\n",
      "71:\tlearn: 0.3120757\ttotal: 20.2s\tremaining: 35.9s\n",
      "72:\tlearn: 0.3109591\ttotal: 20.4s\tremaining: 35.6s\n",
      "73:\tlearn: 0.3081813\ttotal: 20.7s\tremaining: 35.3s\n",
      "74:\tlearn: 0.3065825\ttotal: 21s\tremaining: 35s\n",
      "75:\tlearn: 0.3042398\ttotal: 21.3s\tremaining: 34.7s\n",
      "76:\tlearn: 0.3021675\ttotal: 21.5s\tremaining: 34.4s\n",
      "77:\tlearn: 0.3006531\ttotal: 21.8s\tremaining: 34.1s\n",
      "78:\tlearn: 0.2968666\ttotal: 22.1s\tremaining: 33.9s\n",
      "79:\tlearn: 0.2946922\ttotal: 22.4s\tremaining: 33.6s\n",
      "80:\tlearn: 0.2936545\ttotal: 22.7s\tremaining: 33.3s\n",
      "81:\tlearn: 0.2926375\ttotal: 22.9s\tremaining: 33s\n",
      "82:\tlearn: 0.2900254\ttotal: 23.2s\tremaining: 32.7s\n",
      "83:\tlearn: 0.2876533\ttotal: 23.5s\tremaining: 32.5s\n",
      "84:\tlearn: 0.2861836\ttotal: 23.8s\tremaining: 32.2s\n",
      "85:\tlearn: 0.2849283\ttotal: 24.1s\tremaining: 31.9s\n",
      "86:\tlearn: 0.2831328\ttotal: 24.3s\tremaining: 31.6s\n",
      "87:\tlearn: 0.2826099\ttotal: 24.6s\tremaining: 31.3s\n",
      "88:\tlearn: 0.2811823\ttotal: 24.9s\tremaining: 31s\n",
      "89:\tlearn: 0.2801331\ttotal: 25.1s\tremaining: 30.7s\n",
      "90:\tlearn: 0.2794274\ttotal: 25.4s\tremaining: 30.4s\n",
      "91:\tlearn: 0.2786366\ttotal: 25.7s\tremaining: 30.1s\n",
      "92:\tlearn: 0.2780240\ttotal: 25.9s\tremaining: 29.8s\n",
      "93:\tlearn: 0.2768479\ttotal: 26.2s\tremaining: 29.5s\n",
      "94:\tlearn: 0.2760667\ttotal: 26.5s\tremaining: 29.2s\n",
      "95:\tlearn: 0.2748787\ttotal: 26.7s\tremaining: 29s\n",
      "96:\tlearn: 0.2734957\ttotal: 27s\tremaining: 28.7s\n",
      "97:\tlearn: 0.2728759\ttotal: 27.3s\tremaining: 28.4s\n",
      "98:\tlearn: 0.2711648\ttotal: 27.5s\tremaining: 28.1s\n",
      "99:\tlearn: 0.2689142\ttotal: 27.8s\tremaining: 27.8s\n",
      "100:\tlearn: 0.2681192\ttotal: 28.1s\tremaining: 27.5s\n",
      "101:\tlearn: 0.2667592\ttotal: 28.4s\tremaining: 27.3s\n",
      "102:\tlearn: 0.2658304\ttotal: 28.6s\tremaining: 27s\n",
      "103:\tlearn: 0.2651013\ttotal: 28.9s\tremaining: 26.7s\n",
      "104:\tlearn: 0.2634429\ttotal: 29.2s\tremaining: 26.4s\n",
      "105:\tlearn: 0.2616805\ttotal: 29.5s\tremaining: 26.1s\n",
      "106:\tlearn: 0.2609080\ttotal: 29.7s\tremaining: 25.8s\n",
      "107:\tlearn: 0.2597654\ttotal: 30s\tremaining: 25.6s\n",
      "108:\tlearn: 0.2588530\ttotal: 30.3s\tremaining: 25.3s\n",
      "109:\tlearn: 0.2568115\ttotal: 30.6s\tremaining: 25s\n",
      "110:\tlearn: 0.2552297\ttotal: 30.8s\tremaining: 24.7s\n",
      "111:\tlearn: 0.2532953\ttotal: 31.1s\tremaining: 24.5s\n",
      "112:\tlearn: 0.2517590\ttotal: 31.4s\tremaining: 24.2s\n",
      "113:\tlearn: 0.2506183\ttotal: 31.7s\tremaining: 23.9s\n",
      "114:\tlearn: 0.2496504\ttotal: 31.9s\tremaining: 23.6s\n",
      "115:\tlearn: 0.2484018\ttotal: 32.2s\tremaining: 23.3s\n",
      "116:\tlearn: 0.2476702\ttotal: 32.5s\tremaining: 23.1s\n",
      "117:\tlearn: 0.2460368\ttotal: 32.8s\tremaining: 22.8s\n",
      "118:\tlearn: 0.2445916\ttotal: 33s\tremaining: 22.5s\n",
      "119:\tlearn: 0.2441324\ttotal: 33.3s\tremaining: 22.2s\n",
      "120:\tlearn: 0.2430594\ttotal: 33.6s\tremaining: 21.9s\n",
      "121:\tlearn: 0.2420926\ttotal: 33.9s\tremaining: 21.6s\n",
      "122:\tlearn: 0.2409964\ttotal: 34.1s\tremaining: 21.4s\n",
      "123:\tlearn: 0.2399674\ttotal: 34.4s\tremaining: 21.1s\n",
      "124:\tlearn: 0.2388244\ttotal: 34.7s\tremaining: 20.8s\n",
      "125:\tlearn: 0.2373944\ttotal: 35s\tremaining: 20.5s\n",
      "126:\tlearn: 0.2365105\ttotal: 35.2s\tremaining: 20.3s\n",
      "127:\tlearn: 0.2361063\ttotal: 35.5s\tremaining: 20s\n",
      "128:\tlearn: 0.2344075\ttotal: 35.8s\tremaining: 19.7s\n",
      "129:\tlearn: 0.2327355\ttotal: 36.1s\tremaining: 19.4s\n",
      "130:\tlearn: 0.2316967\ttotal: 36.3s\tremaining: 19.1s\n",
      "131:\tlearn: 0.2310939\ttotal: 36.6s\tremaining: 18.9s\n",
      "132:\tlearn: 0.2304441\ttotal: 36.9s\tremaining: 18.6s\n",
      "133:\tlearn: 0.2288530\ttotal: 37.2s\tremaining: 18.3s\n",
      "134:\tlearn: 0.2283383\ttotal: 37.4s\tremaining: 18s\n",
      "135:\tlearn: 0.2264966\ttotal: 37.7s\tremaining: 17.7s\n",
      "136:\tlearn: 0.2254462\ttotal: 38s\tremaining: 17.5s\n",
      "137:\tlearn: 0.2249811\ttotal: 38.2s\tremaining: 17.2s\n",
      "138:\tlearn: 0.2228305\ttotal: 38.5s\tremaining: 16.9s\n",
      "139:\tlearn: 0.2212611\ttotal: 38.8s\tremaining: 16.6s\n",
      "140:\tlearn: 0.2202180\ttotal: 39.1s\tremaining: 16.4s\n",
      "141:\tlearn: 0.2188192\ttotal: 39.4s\tremaining: 16.1s\n",
      "142:\tlearn: 0.2177208\ttotal: 39.6s\tremaining: 15.8s\n",
      "143:\tlearn: 0.2165879\ttotal: 39.9s\tremaining: 15.5s\n",
      "144:\tlearn: 0.2152770\ttotal: 40.2s\tremaining: 15.2s\n",
      "145:\tlearn: 0.2147593\ttotal: 40.5s\tremaining: 15s\n",
      "146:\tlearn: 0.2138334\ttotal: 40.7s\tremaining: 14.7s\n",
      "147:\tlearn: 0.2122648\ttotal: 41s\tremaining: 14.4s\n",
      "148:\tlearn: 0.2116336\ttotal: 41.3s\tremaining: 14.1s\n",
      "149:\tlearn: 0.2104448\ttotal: 41.6s\tremaining: 13.9s\n",
      "150:\tlearn: 0.2099407\ttotal: 41.8s\tremaining: 13.6s\n",
      "151:\tlearn: 0.2093941\ttotal: 42.1s\tremaining: 13.3s\n",
      "152:\tlearn: 0.2086585\ttotal: 42.4s\tremaining: 13s\n",
      "153:\tlearn: 0.2070303\ttotal: 42.7s\tremaining: 12.7s\n",
      "154:\tlearn: 0.2067633\ttotal: 42.9s\tremaining: 12.5s\n",
      "155:\tlearn: 0.2062327\ttotal: 43.2s\tremaining: 12.2s\n",
      "156:\tlearn: 0.2049599\ttotal: 43.5s\tremaining: 11.9s\n",
      "157:\tlearn: 0.2046625\ttotal: 43.7s\tremaining: 11.6s\n",
      "158:\tlearn: 0.2035350\ttotal: 44s\tremaining: 11.4s\n",
      "159:\tlearn: 0.2023462\ttotal: 44.3s\tremaining: 11.1s\n",
      "160:\tlearn: 0.2018097\ttotal: 44.6s\tremaining: 10.8s\n",
      "161:\tlearn: 0.2001735\ttotal: 44.9s\tremaining: 10.5s\n",
      "162:\tlearn: 0.1988948\ttotal: 45.1s\tremaining: 10.2s\n",
      "163:\tlearn: 0.1980569\ttotal: 45.4s\tremaining: 9.97s\n",
      "164:\tlearn: 0.1970462\ttotal: 45.7s\tremaining: 9.69s\n",
      "165:\tlearn: 0.1958011\ttotal: 46s\tremaining: 9.42s\n",
      "166:\tlearn: 0.1952244\ttotal: 46.2s\tremaining: 9.14s\n",
      "167:\tlearn: 0.1945555\ttotal: 46.5s\tremaining: 8.86s\n",
      "168:\tlearn: 0.1941127\ttotal: 46.8s\tremaining: 8.58s\n",
      "169:\tlearn: 0.1927798\ttotal: 47.1s\tremaining: 8.31s\n",
      "170:\tlearn: 0.1921725\ttotal: 47.3s\tremaining: 8.03s\n",
      "171:\tlearn: 0.1913753\ttotal: 47.6s\tremaining: 7.75s\n",
      "172:\tlearn: 0.1907746\ttotal: 47.9s\tremaining: 7.47s\n",
      "173:\tlearn: 0.1898195\ttotal: 48.2s\tremaining: 7.2s\n",
      "174:\tlearn: 0.1893180\ttotal: 48.4s\tremaining: 6.92s\n",
      "175:\tlearn: 0.1887745\ttotal: 48.7s\tremaining: 6.64s\n",
      "176:\tlearn: 0.1876990\ttotal: 49s\tremaining: 6.37s\n",
      "177:\tlearn: 0.1867954\ttotal: 49.3s\tremaining: 6.09s\n",
      "178:\tlearn: 0.1862563\ttotal: 49.5s\tremaining: 5.81s\n",
      "179:\tlearn: 0.1857944\ttotal: 49.8s\tremaining: 5.53s\n",
      "180:\tlearn: 0.1844698\ttotal: 50.1s\tremaining: 5.26s\n",
      "181:\tlearn: 0.1839642\ttotal: 50.4s\tremaining: 4.98s\n",
      "182:\tlearn: 0.1830553\ttotal: 50.6s\tremaining: 4.7s\n",
      "183:\tlearn: 0.1826380\ttotal: 50.9s\tremaining: 4.43s\n",
      "184:\tlearn: 0.1823619\ttotal: 51.2s\tremaining: 4.15s\n",
      "185:\tlearn: 0.1820529\ttotal: 51.5s\tremaining: 3.87s\n",
      "186:\tlearn: 0.1811437\ttotal: 51.7s\tremaining: 3.6s\n",
      "187:\tlearn: 0.1804628\ttotal: 52s\tremaining: 3.32s\n",
      "188:\tlearn: 0.1800940\ttotal: 52.3s\tremaining: 3.04s\n",
      "189:\tlearn: 0.1792447\ttotal: 52.6s\tremaining: 2.77s\n",
      "190:\tlearn: 0.1785191\ttotal: 52.8s\tremaining: 2.49s\n",
      "191:\tlearn: 0.1776324\ttotal: 53.1s\tremaining: 2.21s\n",
      "192:\tlearn: 0.1766780\ttotal: 53.4s\tremaining: 1.94s\n",
      "193:\tlearn: 0.1751875\ttotal: 53.7s\tremaining: 1.66s\n",
      "194:\tlearn: 0.1742438\ttotal: 54s\tremaining: 1.38s\n",
      "195:\tlearn: 0.1739113\ttotal: 54.2s\tremaining: 1.11s\n",
      "196:\tlearn: 0.1732644\ttotal: 54.5s\tremaining: 830ms\n",
      "197:\tlearn: 0.1725872\ttotal: 54.8s\tremaining: 553ms\n",
      "198:\tlearn: 0.1711309\ttotal: 55.1s\tremaining: 277ms\n",
      "199:\tlearn: 0.1709686\ttotal: 55.3s\tremaining: 0us\n",
      "0:\tlearn: 1.5304652\ttotal: 270ms\tremaining: 53.7s\n",
      "1:\tlearn: 3.9594276\ttotal: 562ms\tremaining: 55.6s\n",
      "2:\tlearn: 22.8090832\ttotal: 845ms\tremaining: 55.5s\n",
      "3:\tlearn: 14.1684297\ttotal: 1.14s\tremaining: 55.7s\n",
      "4:\tlearn: 13.4715753\ttotal: 1.42s\tremaining: 55.4s\n",
      "5:\tlearn: 12.1525011\ttotal: 1.7s\tremaining: 54.9s\n",
      "6:\tlearn: 10.9711181\ttotal: 1.98s\tremaining: 54.7s\n",
      "7:\tlearn: 10.3372942\ttotal: 2.27s\tremaining: 54.6s\n",
      "8:\tlearn: 10.3191299\ttotal: 2.56s\tremaining: 54.4s\n",
      "9:\tlearn: 9.2994778\ttotal: 2.85s\tremaining: 54.2s\n",
      "10:\tlearn: 8.9432314\ttotal: 3.15s\tremaining: 54.1s\n",
      "11:\tlearn: 8.7004866\ttotal: 3.44s\tremaining: 53.9s\n",
      "12:\tlearn: 8.5347425\ttotal: 3.73s\tremaining: 53.6s\n",
      "13:\tlearn: 8.3822425\ttotal: 4s\tremaining: 53.1s\n",
      "14:\tlearn: 8.1667093\ttotal: 4.28s\tremaining: 52.8s\n",
      "15:\tlearn: 8.0273147\ttotal: 4.56s\tremaining: 52.4s\n",
      "16:\tlearn: 7.8583587\ttotal: 4.84s\tremaining: 52.1s\n",
      "17:\tlearn: 7.7132111\ttotal: 5.12s\tremaining: 51.8s\n",
      "18:\tlearn: 7.4960955\ttotal: 5.41s\tremaining: 51.6s\n",
      "19:\tlearn: 7.4246610\ttotal: 5.68s\tremaining: 51.1s\n",
      "20:\tlearn: 7.3578026\ttotal: 5.94s\tremaining: 50.7s\n",
      "21:\tlearn: 7.2548322\ttotal: 6.23s\tremaining: 50.4s\n",
      "22:\tlearn: 7.2118065\ttotal: 6.49s\tremaining: 50s\n",
      "23:\tlearn: 7.1460010\ttotal: 6.78s\tremaining: 49.7s\n",
      "24:\tlearn: 7.0230654\ttotal: 7.05s\tremaining: 49.3s\n",
      "25:\tlearn: 6.8799874\ttotal: 7.36s\tremaining: 49.2s\n",
      "26:\tlearn: 6.6813121\ttotal: 7.64s\tremaining: 48.9s\n",
      "27:\tlearn: 6.6127516\ttotal: 7.91s\tremaining: 48.6s\n",
      "28:\tlearn: 6.5803724\ttotal: 8.17s\tremaining: 48.2s\n",
      "29:\tlearn: 6.5439883\ttotal: 8.43s\tremaining: 47.8s\n",
      "30:\tlearn: 6.5023767\ttotal: 8.69s\tremaining: 47.4s\n",
      "31:\tlearn: 6.4776322\ttotal: 8.95s\tremaining: 47s\n",
      "32:\tlearn: 6.3814886\ttotal: 9.25s\tremaining: 46.8s\n",
      "33:\tlearn: 6.3518612\ttotal: 9.51s\tremaining: 46.4s\n",
      "34:\tlearn: 6.3091767\ttotal: 9.78s\tremaining: 46.1s\n",
      "35:\tlearn: 6.2630024\ttotal: 10.1s\tremaining: 45.8s\n",
      "36:\tlearn: 6.2341382\ttotal: 10.3s\tremaining: 45.6s\n",
      "37:\tlearn: 6.2085123\ttotal: 10.6s\tremaining: 45.3s\n",
      "38:\tlearn: 6.1937622\ttotal: 10.9s\tremaining: 44.9s\n",
      "39:\tlearn: 6.1714935\ttotal: 11.1s\tremaining: 44.6s\n",
      "40:\tlearn: 6.1236106\ttotal: 11.4s\tremaining: 44.3s\n",
      "41:\tlearn: 6.1085439\ttotal: 11.7s\tremaining: 44s\n",
      "42:\tlearn: 6.0758630\ttotal: 12s\tremaining: 43.7s\n",
      "43:\tlearn: 6.0639140\ttotal: 12.2s\tremaining: 43.4s\n",
      "44:\tlearn: 5.9118809\ttotal: 12.5s\tremaining: 43.1s\n",
      "45:\tlearn: 5.8778706\ttotal: 12.8s\tremaining: 42.8s\n",
      "46:\tlearn: 5.8616648\ttotal: 13.1s\tremaining: 42.6s\n",
      "47:\tlearn: 5.8408098\ttotal: 13.4s\tremaining: 42.3s\n",
      "48:\tlearn: 5.8146740\ttotal: 13.7s\tremaining: 42.3s\n",
      "49:\tlearn: 5.7920405\ttotal: 14s\tremaining: 42s\n",
      "50:\tlearn: 5.7650822\ttotal: 14.3s\tremaining: 41.7s\n",
      "51:\tlearn: 5.7270788\ttotal: 14.6s\tremaining: 41.5s\n",
      "52:\tlearn: 5.7032085\ttotal: 14.9s\tremaining: 41.2s\n",
      "53:\tlearn: 5.6944799\ttotal: 15.1s\tremaining: 40.9s\n",
      "54:\tlearn: 5.6786196\ttotal: 15.4s\tremaining: 40.7s\n",
      "55:\tlearn: 5.6582612\ttotal: 15.7s\tremaining: 40.4s\n",
      "56:\tlearn: 5.6442118\ttotal: 16s\tremaining: 40.1s\n",
      "57:\tlearn: 5.6212680\ttotal: 16.2s\tremaining: 39.8s\n",
      "58:\tlearn: 5.6027348\ttotal: 16.5s\tremaining: 39.5s\n",
      "59:\tlearn: 5.5937097\ttotal: 16.8s\tremaining: 39.1s\n",
      "60:\tlearn: 5.5385128\ttotal: 17.1s\tremaining: 38.9s\n",
      "61:\tlearn: 5.5326013\ttotal: 17.3s\tremaining: 38.6s\n",
      "62:\tlearn: 5.5131654\ttotal: 17.6s\tremaining: 38.3s\n",
      "63:\tlearn: 5.4495935\ttotal: 17.9s\tremaining: 38s\n",
      "64:\tlearn: 5.3717743\ttotal: 18.2s\tremaining: 37.8s\n",
      "65:\tlearn: 5.3473016\ttotal: 18.5s\tremaining: 37.5s\n",
      "66:\tlearn: 5.3402977\ttotal: 18.8s\tremaining: 37.3s\n",
      "67:\tlearn: 5.3338818\ttotal: 19.1s\tremaining: 37s\n",
      "68:\tlearn: 5.3229890\ttotal: 19.3s\tremaining: 36.7s\n",
      "69:\tlearn: 5.2994724\ttotal: 19.6s\tremaining: 36.4s\n",
      "70:\tlearn: 4.8953893\ttotal: 19.9s\tremaining: 36.2s\n",
      "71:\tlearn: 4.8475504\ttotal: 20.2s\tremaining: 35.9s\n",
      "72:\tlearn: 4.8417753\ttotal: 20.5s\tremaining: 35.6s\n",
      "73:\tlearn: 4.8135596\ttotal: 20.7s\tremaining: 35.3s\n",
      "74:\tlearn: 4.7704425\ttotal: 21s\tremaining: 35s\n",
      "75:\tlearn: 4.7533701\ttotal: 21.3s\tremaining: 34.7s\n",
      "76:\tlearn: 4.7056709\ttotal: 21.6s\tremaining: 34.5s\n",
      "77:\tlearn: 4.6941532\ttotal: 21.8s\tremaining: 34.2s\n",
      "78:\tlearn: 4.6899946\ttotal: 22.1s\tremaining: 33.8s\n",
      "79:\tlearn: 4.6733442\ttotal: 22.4s\tremaining: 33.5s\n",
      "80:\tlearn: 4.6557811\ttotal: 22.6s\tremaining: 33.2s\n",
      "81:\tlearn: 4.6368030\ttotal: 22.9s\tremaining: 32.9s\n",
      "82:\tlearn: 4.6306304\ttotal: 23.2s\tremaining: 32.8s\n",
      "83:\tlearn: 4.6196742\ttotal: 23.5s\tremaining: 32.5s\n",
      "84:\tlearn: 4.6019293\ttotal: 23.8s\tremaining: 32.2s\n",
      "85:\tlearn: 4.5959377\ttotal: 24s\tremaining: 31.9s\n",
      "86:\tlearn: 4.5534721\ttotal: 24.3s\tremaining: 31.6s\n",
      "87:\tlearn: 4.5445230\ttotal: 24.6s\tremaining: 31.3s\n",
      "88:\tlearn: 4.5210723\ttotal: 24.9s\tremaining: 31.1s\n",
      "89:\tlearn: 4.5031242\ttotal: 25.2s\tremaining: 30.8s\n",
      "90:\tlearn: 4.4889317\ttotal: 25.4s\tremaining: 30.5s\n",
      "91:\tlearn: 4.4821851\ttotal: 25.7s\tremaining: 30.2s\n",
      "92:\tlearn: 4.4708323\ttotal: 26s\tremaining: 29.9s\n",
      "93:\tlearn: 4.4446280\ttotal: 26.2s\tremaining: 29.6s\n",
      "94:\tlearn: 4.4387830\ttotal: 26.5s\tremaining: 29.3s\n",
      "95:\tlearn: 4.4325754\ttotal: 26.8s\tremaining: 29s\n",
      "96:\tlearn: 4.4099295\ttotal: 27s\tremaining: 28.7s\n",
      "97:\tlearn: 4.3996484\ttotal: 27.3s\tremaining: 28.4s\n",
      "98:\tlearn: 4.3804805\ttotal: 27.6s\tremaining: 28.1s\n",
      "99:\tlearn: 4.3686009\ttotal: 27.8s\tremaining: 27.8s\n",
      "100:\tlearn: 4.3628903\ttotal: 28.1s\tremaining: 27.6s\n",
      "101:\tlearn: 4.3555612\ttotal: 28.4s\tremaining: 27.3s\n",
      "102:\tlearn: 4.3351744\ttotal: 28.7s\tremaining: 27s\n",
      "103:\tlearn: 4.3183131\ttotal: 28.9s\tremaining: 26.7s\n",
      "104:\tlearn: 4.2902634\ttotal: 29.2s\tremaining: 26.4s\n",
      "105:\tlearn: 4.2797256\ttotal: 29.5s\tremaining: 26.1s\n",
      "106:\tlearn: 4.2663016\ttotal: 29.7s\tremaining: 25.8s\n",
      "107:\tlearn: 4.2506203\ttotal: 30s\tremaining: 25.5s\n",
      "108:\tlearn: 4.2442684\ttotal: 30.2s\tremaining: 25.2s\n",
      "109:\tlearn: 4.2397072\ttotal: 30.5s\tremaining: 25s\n",
      "110:\tlearn: 4.2290672\ttotal: 30.8s\tremaining: 24.7s\n",
      "111:\tlearn: 4.2145870\ttotal: 31s\tremaining: 24.4s\n",
      "112:\tlearn: 4.2092490\ttotal: 31.3s\tremaining: 24.1s\n",
      "113:\tlearn: 4.1820596\ttotal: 31.6s\tremaining: 23.8s\n",
      "114:\tlearn: 4.1786554\ttotal: 31.9s\tremaining: 23.5s\n",
      "115:\tlearn: 4.1644535\ttotal: 32.1s\tremaining: 23.3s\n",
      "116:\tlearn: 4.1569985\ttotal: 32.4s\tremaining: 23s\n",
      "117:\tlearn: 4.1486857\ttotal: 32.7s\tremaining: 22.7s\n",
      "118:\tlearn: 4.1423871\ttotal: 33s\tremaining: 22.4s\n",
      "119:\tlearn: 4.1115347\ttotal: 33.2s\tremaining: 22.2s\n",
      "120:\tlearn: 4.0882983\ttotal: 33.5s\tremaining: 21.9s\n",
      "121:\tlearn: 4.0783299\ttotal: 33.8s\tremaining: 21.6s\n",
      "122:\tlearn: 4.0670449\ttotal: 34.1s\tremaining: 21.3s\n",
      "123:\tlearn: 4.0548191\ttotal: 34.3s\tremaining: 21s\n",
      "124:\tlearn: 4.0491575\ttotal: 34.6s\tremaining: 20.8s\n",
      "125:\tlearn: 4.0454757\ttotal: 34.9s\tremaining: 20.5s\n",
      "126:\tlearn: 4.0328028\ttotal: 35.2s\tremaining: 20.2s\n",
      "127:\tlearn: 3.9945421\ttotal: 35.5s\tremaining: 19.9s\n",
      "128:\tlearn: 3.9787266\ttotal: 35.8s\tremaining: 19.7s\n",
      "129:\tlearn: 3.9689164\ttotal: 36s\tremaining: 19.4s\n",
      "130:\tlearn: 3.9486274\ttotal: 36.3s\tremaining: 19.1s\n",
      "131:\tlearn: 3.9424948\ttotal: 36.6s\tremaining: 18.9s\n",
      "132:\tlearn: 3.9133662\ttotal: 36.9s\tremaining: 18.6s\n",
      "133:\tlearn: 3.9069503\ttotal: 37.2s\tremaining: 18.3s\n",
      "134:\tlearn: 3.8697928\ttotal: 37.5s\tremaining: 18s\n",
      "135:\tlearn: 3.8463804\ttotal: 37.7s\tremaining: 17.8s\n",
      "136:\tlearn: 3.8299944\ttotal: 38s\tremaining: 17.5s\n",
      "137:\tlearn: 3.8222535\ttotal: 38.3s\tremaining: 17.2s\n",
      "138:\tlearn: 3.8030140\ttotal: 38.5s\tremaining: 16.9s\n",
      "139:\tlearn: 3.7985185\ttotal: 38.8s\tremaining: 16.6s\n",
      "140:\tlearn: 3.7951939\ttotal: 39s\tremaining: 16.3s\n",
      "141:\tlearn: 3.7822467\ttotal: 39.3s\tremaining: 16.1s\n",
      "142:\tlearn: 3.7753862\ttotal: 39.6s\tremaining: 15.8s\n",
      "143:\tlearn: 3.7560346\ttotal: 39.8s\tremaining: 15.5s\n",
      "144:\tlearn: 3.7053462\ttotal: 40.1s\tremaining: 15.2s\n",
      "145:\tlearn: 3.6967891\ttotal: 40.4s\tremaining: 14.9s\n",
      "146:\tlearn: 3.6877337\ttotal: 40.6s\tremaining: 14.6s\n",
      "147:\tlearn: 3.6556967\ttotal: 40.9s\tremaining: 14.4s\n",
      "148:\tlearn: 3.6508223\ttotal: 41.1s\tremaining: 14.1s\n",
      "149:\tlearn: 3.6478701\ttotal: 41.4s\tremaining: 13.8s\n",
      "150:\tlearn: 3.6212100\ttotal: 41.7s\tremaining: 13.5s\n",
      "151:\tlearn: 3.6144818\ttotal: 41.9s\tremaining: 13.2s\n",
      "152:\tlearn: 3.6048898\ttotal: 42.2s\tremaining: 13s\n",
      "153:\tlearn: 3.5952024\ttotal: 42.5s\tremaining: 12.7s\n",
      "154:\tlearn: 3.5872749\ttotal: 42.7s\tremaining: 12.4s\n",
      "155:\tlearn: 3.5787615\ttotal: 43s\tremaining: 12.1s\n",
      "156:\tlearn: 3.5648890\ttotal: 43.3s\tremaining: 11.8s\n",
      "157:\tlearn: 3.5589428\ttotal: 43.5s\tremaining: 11.6s\n",
      "158:\tlearn: 3.5433447\ttotal: 43.8s\tremaining: 11.3s\n",
      "159:\tlearn: 3.5330238\ttotal: 44s\tremaining: 11s\n",
      "160:\tlearn: 3.5290282\ttotal: 44.3s\tremaining: 10.7s\n",
      "161:\tlearn: 3.5231976\ttotal: 44.5s\tremaining: 10.4s\n",
      "162:\tlearn: 3.5094784\ttotal: 44.8s\tremaining: 10.2s\n",
      "163:\tlearn: 3.4816972\ttotal: 45.1s\tremaining: 9.9s\n",
      "164:\tlearn: 3.4666649\ttotal: 45.4s\tremaining: 9.63s\n",
      "165:\tlearn: 3.4364731\ttotal: 45.7s\tremaining: 9.36s\n",
      "166:\tlearn: 3.4107090\ttotal: 45.9s\tremaining: 9.08s\n",
      "167:\tlearn: 3.4049150\ttotal: 46.2s\tremaining: 8.8s\n",
      "168:\tlearn: 3.4001366\ttotal: 46.5s\tremaining: 8.53s\n",
      "169:\tlearn: 3.3747173\ttotal: 46.8s\tremaining: 8.26s\n",
      "170:\tlearn: 3.3694133\ttotal: 47.1s\tremaining: 7.98s\n",
      "171:\tlearn: 3.3550334\ttotal: 47.3s\tremaining: 7.71s\n",
      "172:\tlearn: 3.3498167\ttotal: 47.6s\tremaining: 7.43s\n",
      "173:\tlearn: 3.3394566\ttotal: 47.9s\tremaining: 7.16s\n",
      "174:\tlearn: 3.3360047\ttotal: 48.1s\tremaining: 6.88s\n",
      "175:\tlearn: 3.2480288\ttotal: 48.4s\tremaining: 6.61s\n",
      "176:\tlearn: 3.2453091\ttotal: 48.7s\tremaining: 6.33s\n",
      "177:\tlearn: 3.2387167\ttotal: 49s\tremaining: 6.05s\n",
      "178:\tlearn: 3.2304985\ttotal: 49.3s\tremaining: 5.78s\n",
      "179:\tlearn: 3.2278029\ttotal: 49.5s\tremaining: 5.5s\n",
      "180:\tlearn: 3.2230685\ttotal: 49.8s\tremaining: 5.23s\n",
      "181:\tlearn: 3.2160964\ttotal: 50.1s\tremaining: 4.95s\n",
      "182:\tlearn: 3.2131495\ttotal: 50.3s\tremaining: 4.67s\n",
      "183:\tlearn: 3.2056721\ttotal: 50.6s\tremaining: 4.4s\n",
      "184:\tlearn: 3.2023201\ttotal: 50.9s\tremaining: 4.12s\n",
      "185:\tlearn: 3.1988862\ttotal: 51.1s\tremaining: 3.85s\n",
      "186:\tlearn: 3.1929300\ttotal: 51.4s\tremaining: 3.57s\n",
      "187:\tlearn: 3.1908739\ttotal: 51.6s\tremaining: 3.29s\n",
      "188:\tlearn: 3.1573791\ttotal: 51.9s\tremaining: 3.02s\n",
      "189:\tlearn: 3.1513965\ttotal: 52.2s\tremaining: 2.75s\n",
      "190:\tlearn: 3.1154037\ttotal: 52.4s\tremaining: 2.47s\n",
      "191:\tlearn: 3.1126743\ttotal: 52.7s\tremaining: 2.19s\n",
      "192:\tlearn: 3.1069767\ttotal: 53s\tremaining: 1.92s\n",
      "193:\tlearn: 3.1057322\ttotal: 53.2s\tremaining: 1.65s\n",
      "194:\tlearn: 3.0982103\ttotal: 53.5s\tremaining: 1.37s\n",
      "195:\tlearn: 3.0854911\ttotal: 53.7s\tremaining: 1.1s\n",
      "196:\tlearn: 3.0771789\ttotal: 54s\tremaining: 822ms\n",
      "197:\tlearn: 3.0480870\ttotal: 54.3s\tremaining: 548ms\n",
      "198:\tlearn: 3.0426854\ttotal: 54.6s\tremaining: 274ms\n",
      "199:\tlearn: 3.0361029\ttotal: 54.8s\tremaining: 0us\n",
      "0:\tlearn: 1.4178636\ttotal: 275ms\tremaining: 54.7s\n",
      "1:\tlearn: 4.2154843\ttotal: 578ms\tremaining: 57.2s\n",
      "2:\tlearn: 13.1777011\ttotal: 874ms\tremaining: 57.4s\n",
      "3:\tlearn: 14.2806637\ttotal: 1.16s\tremaining: 57.1s\n",
      "4:\tlearn: 16.4422268\ttotal: 1.45s\tremaining: 56.4s\n",
      "5:\tlearn: 27.6912923\ttotal: 1.73s\tremaining: 55.8s\n",
      "6:\tlearn: 25.8154626\ttotal: 2.01s\tremaining: 55.5s\n",
      "7:\tlearn: 30.0826418\ttotal: 2.31s\tremaining: 55.4s\n",
      "8:\tlearn: 27.7295839\ttotal: 2.59s\tremaining: 55s\n",
      "9:\tlearn: 26.5603629\ttotal: 2.86s\tremaining: 54.4s\n",
      "10:\tlearn: 25.4710872\ttotal: 3.13s\tremaining: 53.8s\n",
      "11:\tlearn: 24.5573572\ttotal: 3.42s\tremaining: 53.6s\n",
      "12:\tlearn: 23.3305677\ttotal: 3.7s\tremaining: 53.3s\n",
      "13:\tlearn: 22.3812545\ttotal: 3.98s\tremaining: 52.9s\n",
      "14:\tlearn: 21.7156230\ttotal: 4.26s\tremaining: 52.6s\n",
      "15:\tlearn: 21.2362963\ttotal: 4.55s\tremaining: 52.3s\n",
      "16:\tlearn: 20.9976871\ttotal: 4.82s\tremaining: 51.9s\n",
      "17:\tlearn: 20.5050044\ttotal: 5.07s\tremaining: 51.3s\n",
      "18:\tlearn: 20.2809683\ttotal: 5.36s\tremaining: 51.1s\n",
      "19:\tlearn: 19.4951735\ttotal: 5.62s\tremaining: 50.6s\n",
      "20:\tlearn: 19.2542500\ttotal: 5.9s\tremaining: 50.3s\n",
      "21:\tlearn: 18.8277794\ttotal: 6.19s\tremaining: 50.1s\n",
      "22:\tlearn: 18.6695371\ttotal: 6.46s\tremaining: 49.7s\n",
      "23:\tlearn: 18.5222050\ttotal: 6.74s\tremaining: 49.4s\n",
      "24:\tlearn: 18.2660869\ttotal: 7.01s\tremaining: 49.1s\n",
      "25:\tlearn: 17.9608755\ttotal: 7.28s\tremaining: 48.7s\n",
      "26:\tlearn: 17.8494076\ttotal: 7.55s\tremaining: 48.4s\n",
      "27:\tlearn: 17.7754424\ttotal: 7.8s\tremaining: 47.9s\n",
      "28:\tlearn: 17.5455198\ttotal: 8.09s\tremaining: 47.7s\n",
      "29:\tlearn: 17.5035272\ttotal: 8.36s\tremaining: 47.3s\n",
      "30:\tlearn: 17.4060362\ttotal: 8.61s\tremaining: 47s\n",
      "31:\tlearn: 17.3391421\ttotal: 8.87s\tremaining: 46.6s\n",
      "32:\tlearn: 16.6237532\ttotal: 9.16s\tremaining: 46.4s\n",
      "33:\tlearn: 16.4854877\ttotal: 9.43s\tremaining: 46s\n",
      "34:\tlearn: 15.9928585\ttotal: 9.71s\tremaining: 45.8s\n",
      "35:\tlearn: 15.7140192\ttotal: 9.98s\tremaining: 45.5s\n",
      "36:\tlearn: 15.6522244\ttotal: 10.3s\tremaining: 45.2s\n",
      "37:\tlearn: 15.2758985\ttotal: 10.5s\tremaining: 44.8s\n",
      "38:\tlearn: 15.1149175\ttotal: 10.8s\tremaining: 44.6s\n",
      "39:\tlearn: 14.9202555\ttotal: 11.1s\tremaining: 44.3s\n",
      "40:\tlearn: 14.3822511\ttotal: 11.3s\tremaining: 44s\n",
      "41:\tlearn: 14.2305127\ttotal: 11.6s\tremaining: 43.7s\n",
      "42:\tlearn: 13.9377907\ttotal: 11.9s\tremaining: 43.5s\n",
      "43:\tlearn: 13.4553489\ttotal: 12.2s\tremaining: 43.2s\n",
      "44:\tlearn: 13.4055203\ttotal: 12.4s\tremaining: 42.9s\n",
      "45:\tlearn: 13.3244871\ttotal: 12.7s\tremaining: 42.5s\n",
      "46:\tlearn: 13.0807672\ttotal: 13s\tremaining: 42.3s\n",
      "47:\tlearn: 12.9843008\ttotal: 13.3s\tremaining: 42s\n",
      "48:\tlearn: 12.9570908\ttotal: 13.5s\tremaining: 41.6s\n",
      "49:\tlearn: 12.7634920\ttotal: 13.8s\tremaining: 41.4s\n",
      "50:\tlearn: 12.7360000\ttotal: 14s\tremaining: 41s\n",
      "51:\tlearn: 12.7028716\ttotal: 14.3s\tremaining: 40.7s\n",
      "52:\tlearn: 12.5823648\ttotal: 14.6s\tremaining: 40.4s\n",
      "53:\tlearn: 12.4886243\ttotal: 14.8s\tremaining: 40.1s\n",
      "54:\tlearn: 12.4677147\ttotal: 15.1s\tremaining: 39.8s\n",
      "55:\tlearn: 12.4020083\ttotal: 15.3s\tremaining: 39.4s\n",
      "56:\tlearn: 12.3602515\ttotal: 15.6s\tremaining: 39.2s\n",
      "57:\tlearn: 12.2757289\ttotal: 15.9s\tremaining: 38.9s\n",
      "58:\tlearn: 12.2385269\ttotal: 16.2s\tremaining: 38.6s\n",
      "59:\tlearn: 12.2104304\ttotal: 16.4s\tremaining: 38.3s\n",
      "60:\tlearn: 12.1923221\ttotal: 16.7s\tremaining: 38s\n",
      "61:\tlearn: 12.0051930\ttotal: 17s\tremaining: 37.8s\n",
      "62:\tlearn: 11.9225527\ttotal: 17.3s\tremaining: 37.5s\n",
      "63:\tlearn: 11.6560542\ttotal: 17.5s\tremaining: 37.3s\n",
      "64:\tlearn: 11.6188536\ttotal: 17.8s\tremaining: 37s\n",
      "65:\tlearn: 11.5909186\ttotal: 18.1s\tremaining: 36.8s\n",
      "66:\tlearn: 11.5499733\ttotal: 18.4s\tremaining: 36.5s\n",
      "67:\tlearn: 11.4047646\ttotal: 18.7s\tremaining: 36.2s\n",
      "68:\tlearn: 11.3666829\ttotal: 18.9s\tremaining: 36s\n",
      "69:\tlearn: 11.3245062\ttotal: 19.3s\tremaining: 35.8s\n",
      "70:\tlearn: 11.2673403\ttotal: 19.5s\tremaining: 35.5s\n",
      "71:\tlearn: 11.2544220\ttotal: 19.8s\tremaining: 35.3s\n",
      "72:\tlearn: 11.2318657\ttotal: 20.1s\tremaining: 35s\n",
      "73:\tlearn: 11.2182228\ttotal: 20.4s\tremaining: 34.7s\n",
      "74:\tlearn: 11.1511017\ttotal: 20.6s\tremaining: 34.4s\n",
      "75:\tlearn: 11.1197278\ttotal: 20.9s\tremaining: 34.1s\n",
      "76:\tlearn: 11.0983356\ttotal: 21.2s\tremaining: 33.8s\n",
      "77:\tlearn: 11.0537191\ttotal: 21.5s\tremaining: 33.7s\n",
      "78:\tlearn: 11.0237432\ttotal: 21.8s\tremaining: 33.4s\n",
      "79:\tlearn: 10.9730851\ttotal: 22.1s\tremaining: 33.1s\n",
      "80:\tlearn: 10.9180190\ttotal: 22.4s\tremaining: 32.9s\n",
      "81:\tlearn: 10.8988039\ttotal: 22.6s\tremaining: 32.6s\n",
      "82:\tlearn: 10.8534819\ttotal: 22.9s\tremaining: 32.3s\n",
      "83:\tlearn: 10.8468038\ttotal: 23.2s\tremaining: 32s\n",
      "84:\tlearn: 10.8315166\ttotal: 23.5s\tremaining: 31.8s\n",
      "85:\tlearn: 10.7792392\ttotal: 23.8s\tremaining: 31.6s\n",
      "86:\tlearn: 10.7324589\ttotal: 24.1s\tremaining: 31.3s\n",
      "87:\tlearn: 10.6985781\ttotal: 24.4s\tremaining: 31.1s\n",
      "88:\tlearn: 10.6869101\ttotal: 24.7s\tremaining: 30.8s\n",
      "89:\tlearn: 10.6405182\ttotal: 24.9s\tremaining: 30.5s\n",
      "90:\tlearn: 10.6060612\ttotal: 25.2s\tremaining: 30.2s\n",
      "91:\tlearn: 10.5796016\ttotal: 25.5s\tremaining: 29.9s\n",
      "92:\tlearn: 10.5570703\ttotal: 25.7s\tremaining: 29.6s\n",
      "93:\tlearn: 10.5004194\ttotal: 26s\tremaining: 29.3s\n",
      "94:\tlearn: 10.1794712\ttotal: 26.3s\tremaining: 29.1s\n",
      "95:\tlearn: 10.1560820\ttotal: 26.6s\tremaining: 28.8s\n",
      "96:\tlearn: 10.1489982\ttotal: 26.9s\tremaining: 28.5s\n",
      "97:\tlearn: 10.0888890\ttotal: 27.1s\tremaining: 28.3s\n",
      "98:\tlearn: 10.0776293\ttotal: 27.4s\tremaining: 28s\n",
      "99:\tlearn: 10.0650861\ttotal: 27.7s\tremaining: 27.7s\n",
      "100:\tlearn: 10.0326626\ttotal: 28s\tremaining: 27.4s\n",
      "101:\tlearn: 9.9862006\ttotal: 28.3s\tremaining: 27.1s\n",
      "102:\tlearn: 9.9760300\ttotal: 28.5s\tremaining: 26.9s\n",
      "103:\tlearn: 9.9329609\ttotal: 28.8s\tremaining: 26.6s\n",
      "104:\tlearn: 9.8084104\ttotal: 29.1s\tremaining: 26.3s\n",
      "105:\tlearn: 9.7955062\ttotal: 29.4s\tremaining: 26s\n",
      "106:\tlearn: 9.7828800\ttotal: 29.6s\tremaining: 25.7s\n",
      "107:\tlearn: 9.7605389\ttotal: 29.9s\tremaining: 25.5s\n",
      "108:\tlearn: 9.7332223\ttotal: 30.2s\tremaining: 25.2s\n",
      "109:\tlearn: 9.7087045\ttotal: 30.4s\tremaining: 24.9s\n",
      "110:\tlearn: 9.6984895\ttotal: 30.7s\tremaining: 24.6s\n",
      "111:\tlearn: 9.6684017\ttotal: 31s\tremaining: 24.3s\n",
      "112:\tlearn: 9.6460159\ttotal: 31.3s\tremaining: 24.1s\n",
      "113:\tlearn: 9.6201477\ttotal: 31.5s\tremaining: 23.8s\n",
      "114:\tlearn: 9.6053275\ttotal: 31.8s\tremaining: 23.5s\n",
      "115:\tlearn: 9.5804259\ttotal: 32s\tremaining: 23.2s\n",
      "116:\tlearn: 9.5528357\ttotal: 32.3s\tremaining: 22.9s\n",
      "117:\tlearn: 9.5449823\ttotal: 32.6s\tremaining: 22.6s\n",
      "118:\tlearn: 9.5239612\ttotal: 32.8s\tremaining: 22.3s\n",
      "119:\tlearn: 9.5036282\ttotal: 33.1s\tremaining: 22.1s\n",
      "120:\tlearn: 9.4786559\ttotal: 33.4s\tremaining: 21.8s\n",
      "121:\tlearn: 9.4658746\ttotal: 33.7s\tremaining: 21.5s\n",
      "122:\tlearn: 9.4409500\ttotal: 33.9s\tremaining: 21.2s\n",
      "123:\tlearn: 9.4102740\ttotal: 34.2s\tremaining: 21s\n",
      "124:\tlearn: 9.3910397\ttotal: 34.5s\tremaining: 20.7s\n",
      "125:\tlearn: 9.3440120\ttotal: 34.8s\tremaining: 20.4s\n",
      "126:\tlearn: 9.3324884\ttotal: 35s\tremaining: 20.1s\n",
      "127:\tlearn: 9.3084783\ttotal: 35.3s\tremaining: 19.9s\n",
      "128:\tlearn: 9.2990279\ttotal: 35.6s\tremaining: 19.6s\n",
      "129:\tlearn: 9.2906285\ttotal: 35.8s\tremaining: 19.3s\n",
      "130:\tlearn: 9.2127682\ttotal: 36.1s\tremaining: 19s\n",
      "131:\tlearn: 9.1665774\ttotal: 36.4s\tremaining: 18.7s\n",
      "132:\tlearn: 9.1523098\ttotal: 36.6s\tremaining: 18.5s\n",
      "133:\tlearn: 9.1439209\ttotal: 36.9s\tremaining: 18.2s\n",
      "134:\tlearn: 9.1368048\ttotal: 37.2s\tremaining: 17.9s\n",
      "135:\tlearn: 9.1060872\ttotal: 37.5s\tremaining: 17.6s\n",
      "136:\tlearn: 9.0780091\ttotal: 37.7s\tremaining: 17.3s\n",
      "137:\tlearn: 9.0624251\ttotal: 38s\tremaining: 17.1s\n",
      "138:\tlearn: 9.0486490\ttotal: 38.3s\tremaining: 16.8s\n",
      "139:\tlearn: 9.0064245\ttotal: 38.6s\tremaining: 16.5s\n",
      "140:\tlearn: 8.9886234\ttotal: 38.8s\tremaining: 16.3s\n",
      "141:\tlearn: 8.9680169\ttotal: 39.1s\tremaining: 16s\n",
      "142:\tlearn: 8.9528606\ttotal: 39.4s\tremaining: 15.7s\n",
      "143:\tlearn: 8.9369553\ttotal: 39.6s\tremaining: 15.4s\n",
      "144:\tlearn: 8.9145096\ttotal: 39.9s\tremaining: 15.1s\n",
      "145:\tlearn: 8.8935566\ttotal: 40.2s\tremaining: 14.9s\n",
      "146:\tlearn: 8.8564446\ttotal: 40.5s\tremaining: 14.6s\n",
      "147:\tlearn: 8.8096005\ttotal: 40.7s\tremaining: 14.3s\n",
      "148:\tlearn: 8.7920518\ttotal: 41s\tremaining: 14s\n",
      "149:\tlearn: 8.7624290\ttotal: 41.3s\tremaining: 13.8s\n",
      "150:\tlearn: 8.7561679\ttotal: 41.5s\tremaining: 13.5s\n",
      "151:\tlearn: 8.7420781\ttotal: 41.8s\tremaining: 13.2s\n",
      "152:\tlearn: 8.7142800\ttotal: 42.1s\tremaining: 12.9s\n",
      "153:\tlearn: 8.7071265\ttotal: 42.3s\tremaining: 12.6s\n",
      "154:\tlearn: 8.6915354\ttotal: 42.6s\tremaining: 12.4s\n",
      "155:\tlearn: 8.6686363\ttotal: 42.9s\tremaining: 12.1s\n",
      "156:\tlearn: 8.6647515\ttotal: 43.1s\tremaining: 11.8s\n",
      "157:\tlearn: 8.6582269\ttotal: 43.4s\tremaining: 11.5s\n",
      "158:\tlearn: 8.6439140\ttotal: 43.6s\tremaining: 11.3s\n",
      "159:\tlearn: 8.6356742\ttotal: 43.9s\tremaining: 11s\n",
      "160:\tlearn: 8.6249404\ttotal: 44.2s\tremaining: 10.7s\n",
      "161:\tlearn: 8.6194396\ttotal: 44.4s\tremaining: 10.4s\n",
      "162:\tlearn: 8.6074395\ttotal: 44.7s\tremaining: 10.1s\n",
      "163:\tlearn: 8.5937542\ttotal: 45s\tremaining: 9.87s\n",
      "164:\tlearn: 8.5691115\ttotal: 45.2s\tremaining: 9.6s\n",
      "165:\tlearn: 8.5578068\ttotal: 45.5s\tremaining: 9.32s\n",
      "166:\tlearn: 8.5456847\ttotal: 45.8s\tremaining: 9.04s\n",
      "167:\tlearn: 8.5382007\ttotal: 46s\tremaining: 8.77s\n",
      "168:\tlearn: 8.5165244\ttotal: 46.3s\tremaining: 8.49s\n",
      "169:\tlearn: 8.5148009\ttotal: 46.6s\tremaining: 8.21s\n",
      "170:\tlearn: 8.4943799\ttotal: 46.8s\tremaining: 7.94s\n",
      "171:\tlearn: 8.4797658\ttotal: 47.1s\tremaining: 7.66s\n",
      "172:\tlearn: 8.4710163\ttotal: 47.3s\tremaining: 7.39s\n",
      "173:\tlearn: 8.4641986\ttotal: 47.6s\tremaining: 7.11s\n",
      "174:\tlearn: 8.4521562\ttotal: 47.9s\tremaining: 6.84s\n",
      "175:\tlearn: 8.4405592\ttotal: 48.1s\tremaining: 6.57s\n",
      "176:\tlearn: 8.4242658\ttotal: 48.4s\tremaining: 6.29s\n",
      "177:\tlearn: 8.3924217\ttotal: 48.7s\tremaining: 6.02s\n",
      "178:\tlearn: 8.3829363\ttotal: 49s\tremaining: 5.75s\n",
      "179:\tlearn: 8.3768437\ttotal: 49.3s\tremaining: 5.47s\n",
      "180:\tlearn: 8.3504727\ttotal: 49.5s\tremaining: 5.2s\n",
      "181:\tlearn: 8.3387697\ttotal: 49.8s\tremaining: 4.92s\n",
      "182:\tlearn: 8.3310641\ttotal: 50.1s\tremaining: 4.65s\n",
      "183:\tlearn: 8.2699409\ttotal: 50.3s\tremaining: 4.38s\n",
      "184:\tlearn: 8.2428285\ttotal: 50.6s\tremaining: 4.1s\n",
      "185:\tlearn: 8.2339419\ttotal: 50.8s\tremaining: 3.83s\n",
      "186:\tlearn: 8.1918459\ttotal: 51.1s\tremaining: 3.55s\n",
      "187:\tlearn: 8.1402234\ttotal: 51.4s\tremaining: 3.28s\n",
      "188:\tlearn: 8.1317047\ttotal: 51.7s\tremaining: 3.01s\n",
      "189:\tlearn: 8.0661153\ttotal: 51.9s\tremaining: 2.73s\n",
      "190:\tlearn: 8.0628008\ttotal: 52.2s\tremaining: 2.46s\n",
      "191:\tlearn: 8.0378511\ttotal: 52.5s\tremaining: 2.19s\n",
      "192:\tlearn: 8.0214194\ttotal: 52.8s\tremaining: 1.91s\n",
      "193:\tlearn: 8.0096790\ttotal: 53s\tremaining: 1.64s\n",
      "194:\tlearn: 8.0051456\ttotal: 53.3s\tremaining: 1.37s\n",
      "195:\tlearn: 7.9846512\ttotal: 53.6s\tremaining: 1.09s\n",
      "196:\tlearn: 7.9728746\ttotal: 53.8s\tremaining: 820ms\n",
      "197:\tlearn: 7.9338021\ttotal: 54.1s\tremaining: 547ms\n",
      "198:\tlearn: 7.9140857\ttotal: 54.4s\tremaining: 273ms\n",
      "199:\tlearn: 7.9040970\ttotal: 54.7s\tremaining: 0us\n",
      "0:\tlearn: 1.4243817\ttotal: 268ms\tremaining: 53.3s\n",
      "1:\tlearn: 2.4462211\ttotal: 538ms\tremaining: 53.2s\n",
      "2:\tlearn: 12.7209456\ttotal: 823ms\tremaining: 54s\n",
      "3:\tlearn: 10.8348138\ttotal: 1.09s\tremaining: 53.6s\n",
      "4:\tlearn: 10.3888988\ttotal: 1.37s\tremaining: 53.4s\n",
      "5:\tlearn: 10.1636458\ttotal: 1.67s\tremaining: 54s\n",
      "6:\tlearn: 8.8300284\ttotal: 1.95s\tremaining: 53.7s\n",
      "7:\tlearn: 10.4688496\ttotal: 2.24s\tremaining: 53.7s\n",
      "8:\tlearn: 9.4708793\ttotal: 2.52s\tremaining: 53.5s\n",
      "9:\tlearn: 8.9756507\ttotal: 2.8s\tremaining: 53.3s\n",
      "10:\tlearn: 9.1636987\ttotal: 3.09s\tremaining: 53.1s\n",
      "11:\tlearn: 8.5103581\ttotal: 3.37s\tremaining: 52.8s\n",
      "12:\tlearn: 7.7510597\ttotal: 3.65s\tremaining: 52.6s\n",
      "13:\tlearn: 7.3143430\ttotal: 3.93s\tremaining: 52.2s\n",
      "14:\tlearn: 6.7871872\ttotal: 4.22s\tremaining: 52.1s\n",
      "15:\tlearn: 6.6276053\ttotal: 4.49s\tremaining: 51.7s\n",
      "16:\tlearn: 6.4796052\ttotal: 4.79s\tremaining: 51.5s\n",
      "17:\tlearn: 6.1936373\ttotal: 5.09s\tremaining: 51.5s\n",
      "18:\tlearn: 6.0568934\ttotal: 5.37s\tremaining: 51.2s\n",
      "19:\tlearn: 5.9583625\ttotal: 5.64s\tremaining: 50.8s\n",
      "20:\tlearn: 5.8727198\ttotal: 5.91s\tremaining: 50.4s\n",
      "21:\tlearn: 5.7843573\ttotal: 6.19s\tremaining: 50.1s\n",
      "22:\tlearn: 5.7522106\ttotal: 6.46s\tremaining: 49.7s\n",
      "23:\tlearn: 5.7154066\ttotal: 6.72s\tremaining: 49.3s\n",
      "24:\tlearn: 5.6507107\ttotal: 6.98s\tremaining: 48.9s\n",
      "25:\tlearn: 5.5841829\ttotal: 7.26s\tremaining: 48.6s\n",
      "26:\tlearn: 5.5350633\ttotal: 7.53s\tremaining: 48.3s\n",
      "27:\tlearn: 5.3846441\ttotal: 7.8s\tremaining: 47.9s\n",
      "28:\tlearn: 5.3446222\ttotal: 8.06s\tremaining: 47.5s\n",
      "29:\tlearn: 5.3197164\ttotal: 8.32s\tremaining: 47.1s\n",
      "30:\tlearn: 5.2526150\ttotal: 8.59s\tremaining: 46.8s\n",
      "31:\tlearn: 5.2068206\ttotal: 8.86s\tremaining: 46.5s\n",
      "32:\tlearn: 5.1773428\ttotal: 9.12s\tremaining: 46.2s\n",
      "33:\tlearn: 5.1502752\ttotal: 9.38s\tremaining: 45.8s\n",
      "34:\tlearn: 5.1246120\ttotal: 9.64s\tremaining: 45.4s\n",
      "35:\tlearn: 5.0870947\ttotal: 9.91s\tremaining: 45.2s\n",
      "36:\tlearn: 5.0647698\ttotal: 10.2s\tremaining: 44.8s\n",
      "37:\tlearn: 4.9455085\ttotal: 10.5s\tremaining: 44.6s\n",
      "38:\tlearn: 4.9205463\ttotal: 10.7s\tremaining: 44.3s\n",
      "39:\tlearn: 4.9045241\ttotal: 11s\tremaining: 44s\n",
      "40:\tlearn: 4.8897192\ttotal: 11.2s\tremaining: 43.6s\n",
      "41:\tlearn: 4.8760849\ttotal: 11.5s\tremaining: 43.3s\n",
      "42:\tlearn: 4.8639433\ttotal: 11.8s\tremaining: 43s\n",
      "43:\tlearn: 4.8491512\ttotal: 12s\tremaining: 42.7s\n",
      "44:\tlearn: 4.8157987\ttotal: 12.3s\tremaining: 42.4s\n",
      "45:\tlearn: 4.8060961\ttotal: 12.6s\tremaining: 42s\n",
      "46:\tlearn: 4.7729003\ttotal: 12.8s\tremaining: 41.8s\n",
      "47:\tlearn: 4.6833486\ttotal: 13.1s\tremaining: 41.5s\n",
      "48:\tlearn: 4.6691795\ttotal: 13.4s\tremaining: 41.2s\n",
      "49:\tlearn: 4.6634250\ttotal: 13.6s\tremaining: 40.9s\n",
      "50:\tlearn: 4.6417253\ttotal: 13.9s\tremaining: 40.6s\n",
      "51:\tlearn: 4.6261750\ttotal: 14.2s\tremaining: 40.3s\n",
      "52:\tlearn: 4.5131466\ttotal: 14.4s\tremaining: 40s\n",
      "53:\tlearn: 4.4997845\ttotal: 14.7s\tremaining: 39.7s\n",
      "54:\tlearn: 4.4872186\ttotal: 14.9s\tremaining: 39.4s\n",
      "55:\tlearn: 4.4308898\ttotal: 15.2s\tremaining: 39.2s\n",
      "56:\tlearn: 4.4214065\ttotal: 15.5s\tremaining: 38.9s\n",
      "57:\tlearn: 4.4150389\ttotal: 15.8s\tremaining: 38.6s\n",
      "58:\tlearn: 4.3861125\ttotal: 16s\tremaining: 38.3s\n",
      "59:\tlearn: 4.3172777\ttotal: 16.3s\tremaining: 38.1s\n",
      "60:\tlearn: 4.3072157\ttotal: 16.6s\tremaining: 37.8s\n",
      "61:\tlearn: 4.2919476\ttotal: 16.8s\tremaining: 37.5s\n",
      "62:\tlearn: 4.2113676\ttotal: 17.1s\tremaining: 37.2s\n",
      "63:\tlearn: 4.2035736\ttotal: 17.4s\tremaining: 36.9s\n",
      "64:\tlearn: 4.1949746\ttotal: 17.6s\tremaining: 36.6s\n",
      "65:\tlearn: 4.1879964\ttotal: 17.9s\tremaining: 36.3s\n",
      "66:\tlearn: 4.1759917\ttotal: 18.1s\tremaining: 36s\n",
      "67:\tlearn: 4.1634577\ttotal: 18.4s\tremaining: 35.7s\n",
      "68:\tlearn: 4.1501686\ttotal: 18.7s\tremaining: 35.5s\n",
      "69:\tlearn: 4.1409193\ttotal: 18.9s\tremaining: 35.2s\n",
      "70:\tlearn: 4.1309885\ttotal: 19.2s\tremaining: 34.9s\n",
      "71:\tlearn: 4.1167685\ttotal: 19.5s\tremaining: 34.6s\n",
      "72:\tlearn: 4.0962029\ttotal: 19.8s\tremaining: 34.4s\n",
      "73:\tlearn: 4.0880206\ttotal: 20s\tremaining: 34.1s\n",
      "74:\tlearn: 4.0797600\ttotal: 20.3s\tremaining: 33.8s\n",
      "75:\tlearn: 4.0650321\ttotal: 20.5s\tremaining: 33.5s\n",
      "76:\tlearn: 4.0553120\ttotal: 20.8s\tremaining: 33.2s\n",
      "77:\tlearn: 4.0453034\ttotal: 21.1s\tremaining: 33s\n",
      "78:\tlearn: 3.9845717\ttotal: 21.4s\tremaining: 32.7s\n",
      "79:\tlearn: 3.9782503\ttotal: 21.6s\tremaining: 32.4s\n",
      "80:\tlearn: 3.9661066\ttotal: 21.9s\tremaining: 32.1s\n",
      "81:\tlearn: 3.9561458\ttotal: 22.1s\tremaining: 31.8s\n",
      "82:\tlearn: 3.9429443\ttotal: 22.4s\tremaining: 31.6s\n",
      "83:\tlearn: 3.9333858\ttotal: 22.7s\tremaining: 31.3s\n",
      "84:\tlearn: 3.9168024\ttotal: 22.9s\tremaining: 31s\n",
      "85:\tlearn: 3.9111828\ttotal: 23.2s\tremaining: 30.7s\n",
      "86:\tlearn: 3.8993808\ttotal: 23.4s\tremaining: 30.4s\n",
      "87:\tlearn: 3.8903944\ttotal: 23.7s\tremaining: 30.2s\n",
      "88:\tlearn: 3.8809635\ttotal: 24s\tremaining: 29.9s\n",
      "89:\tlearn: 3.8672668\ttotal: 24.2s\tremaining: 29.6s\n",
      "90:\tlearn: 3.8616449\ttotal: 24.5s\tremaining: 29.3s\n",
      "91:\tlearn: 3.8455175\ttotal: 24.7s\tremaining: 29s\n",
      "92:\tlearn: 3.8375240\ttotal: 25s\tremaining: 28.8s\n",
      "93:\tlearn: 3.8253003\ttotal: 25.3s\tremaining: 28.5s\n",
      "94:\tlearn: 3.8203217\ttotal: 25.5s\tremaining: 28.2s\n",
      "95:\tlearn: 3.8173699\ttotal: 25.8s\tremaining: 27.9s\n",
      "96:\tlearn: 3.8084090\ttotal: 26.1s\tremaining: 27.7s\n",
      "97:\tlearn: 3.8001314\ttotal: 26.3s\tremaining: 27.4s\n",
      "98:\tlearn: 3.7883326\ttotal: 26.6s\tremaining: 27.1s\n",
      "99:\tlearn: 3.7819997\ttotal: 26.8s\tremaining: 26.8s\n",
      "100:\tlearn: 3.7701800\ttotal: 27.1s\tremaining: 26.6s\n",
      "101:\tlearn: 3.7609046\ttotal: 27.4s\tremaining: 26.3s\n",
      "102:\tlearn: 3.7512315\ttotal: 27.6s\tremaining: 26s\n",
      "103:\tlearn: 3.7473223\ttotal: 27.9s\tremaining: 25.8s\n",
      "104:\tlearn: 3.7384523\ttotal: 28.2s\tremaining: 25.5s\n",
      "105:\tlearn: 3.7331951\ttotal: 28.4s\tremaining: 25.2s\n",
      "106:\tlearn: 3.7268316\ttotal: 28.7s\tremaining: 24.9s\n",
      "107:\tlearn: 3.7205743\ttotal: 29s\tremaining: 24.7s\n",
      "108:\tlearn: 3.7164805\ttotal: 29.2s\tremaining: 24.4s\n",
      "109:\tlearn: 3.6871525\ttotal: 29.5s\tremaining: 24.1s\n",
      "110:\tlearn: 3.6806842\ttotal: 29.8s\tremaining: 23.9s\n",
      "111:\tlearn: 3.6064138\ttotal: 30.1s\tremaining: 23.6s\n",
      "112:\tlearn: 3.5982769\ttotal: 30.3s\tremaining: 23.4s\n",
      "113:\tlearn: 3.5922783\ttotal: 30.6s\tremaining: 23.1s\n",
      "114:\tlearn: 3.5816754\ttotal: 30.9s\tremaining: 22.8s\n",
      "115:\tlearn: 3.5787952\ttotal: 31.1s\tremaining: 22.5s\n",
      "116:\tlearn: 3.5680387\ttotal: 31.4s\tremaining: 22.3s\n",
      "117:\tlearn: 3.5516779\ttotal: 31.7s\tremaining: 22s\n",
      "118:\tlearn: 3.5447507\ttotal: 31.9s\tremaining: 21.7s\n",
      "119:\tlearn: 3.5391869\ttotal: 32.2s\tremaining: 21.5s\n",
      "120:\tlearn: 3.5336241\ttotal: 32.5s\tremaining: 21.2s\n",
      "121:\tlearn: 3.5315310\ttotal: 32.7s\tremaining: 20.9s\n",
      "122:\tlearn: 3.5142856\ttotal: 33s\tremaining: 20.7s\n",
      "123:\tlearn: 3.5010286\ttotal: 33.3s\tremaining: 20.4s\n",
      "124:\tlearn: 3.4522511\ttotal: 33.5s\tremaining: 20.1s\n",
      "125:\tlearn: 3.4367161\ttotal: 33.8s\tremaining: 19.9s\n",
      "126:\tlearn: 3.4335884\ttotal: 34.1s\tremaining: 19.6s\n",
      "127:\tlearn: 3.4273423\ttotal: 34.3s\tremaining: 19.3s\n",
      "128:\tlearn: 3.4174591\ttotal: 34.6s\tremaining: 19s\n",
      "129:\tlearn: 3.4031394\ttotal: 34.9s\tremaining: 18.8s\n",
      "130:\tlearn: 3.3918129\ttotal: 35.1s\tremaining: 18.5s\n",
      "131:\tlearn: 3.3764165\ttotal: 35.4s\tremaining: 18.2s\n",
      "132:\tlearn: 3.3741713\ttotal: 35.6s\tremaining: 18s\n",
      "133:\tlearn: 3.3659159\ttotal: 35.9s\tremaining: 17.7s\n",
      "134:\tlearn: 3.3576911\ttotal: 36.2s\tremaining: 17.4s\n",
      "135:\tlearn: 3.3487047\ttotal: 36.4s\tremaining: 17.1s\n",
      "136:\tlearn: 3.3434736\ttotal: 36.7s\tremaining: 16.9s\n",
      "137:\tlearn: 3.3328536\ttotal: 37s\tremaining: 16.6s\n",
      "138:\tlearn: 3.3269784\ttotal: 37.3s\tremaining: 16.4s\n",
      "139:\tlearn: 3.3158853\ttotal: 37.6s\tremaining: 16.1s\n",
      "140:\tlearn: 3.3111257\ttotal: 37.9s\tremaining: 15.8s\n",
      "141:\tlearn: 3.3028820\ttotal: 38.2s\tremaining: 15.6s\n",
      "142:\tlearn: 3.3001695\ttotal: 38.5s\tremaining: 15.3s\n",
      "143:\tlearn: 3.2919647\ttotal: 38.8s\tremaining: 15.1s\n",
      "144:\tlearn: 3.2862559\ttotal: 39s\tremaining: 14.8s\n",
      "145:\tlearn: 3.2813785\ttotal: 39.3s\tremaining: 14.5s\n",
      "146:\tlearn: 3.2737001\ttotal: 39.6s\tremaining: 14.3s\n",
      "147:\tlearn: 3.2595954\ttotal: 39.9s\tremaining: 14s\n",
      "148:\tlearn: 3.2551215\ttotal: 40.1s\tremaining: 13.7s\n",
      "149:\tlearn: 3.2473308\ttotal: 40.4s\tremaining: 13.5s\n",
      "150:\tlearn: 3.2289759\ttotal: 40.7s\tremaining: 13.2s\n",
      "151:\tlearn: 3.2208029\ttotal: 41s\tremaining: 12.9s\n",
      "152:\tlearn: 3.2158782\ttotal: 41.3s\tremaining: 12.7s\n",
      "153:\tlearn: 3.2114638\ttotal: 41.5s\tremaining: 12.4s\n",
      "154:\tlearn: 3.2016382\ttotal: 41.8s\tremaining: 12.1s\n",
      "155:\tlearn: 3.1929843\ttotal: 42.1s\tremaining: 11.9s\n",
      "156:\tlearn: 3.1784421\ttotal: 42.4s\tremaining: 11.6s\n",
      "157:\tlearn: 3.1731126\ttotal: 42.6s\tremaining: 11.3s\n",
      "158:\tlearn: 3.1698405\ttotal: 42.9s\tremaining: 11.1s\n",
      "159:\tlearn: 3.1638593\ttotal: 43.2s\tremaining: 10.8s\n",
      "160:\tlearn: 3.1602795\ttotal: 43.5s\tremaining: 10.5s\n",
      "161:\tlearn: 3.1508377\ttotal: 43.7s\tremaining: 10.3s\n",
      "162:\tlearn: 3.1065140\ttotal: 44s\tremaining: 9.99s\n",
      "163:\tlearn: 3.0923945\ttotal: 44.3s\tremaining: 9.73s\n",
      "164:\tlearn: 3.0581192\ttotal: 44.6s\tremaining: 9.47s\n",
      "165:\tlearn: 3.0492031\ttotal: 44.9s\tremaining: 9.21s\n",
      "166:\tlearn: 3.0449734\ttotal: 45.2s\tremaining: 8.94s\n",
      "167:\tlearn: 3.0398534\ttotal: 45.5s\tremaining: 8.66s\n",
      "168:\tlearn: 3.0348269\ttotal: 45.8s\tremaining: 8.39s\n",
      "169:\tlearn: 3.0273617\ttotal: 46s\tremaining: 8.12s\n",
      "170:\tlearn: 3.0218938\ttotal: 46.3s\tremaining: 7.86s\n",
      "171:\tlearn: 3.0140667\ttotal: 46.6s\tremaining: 7.59s\n",
      "172:\tlearn: 3.0029301\ttotal: 46.9s\tremaining: 7.32s\n",
      "173:\tlearn: 2.9979408\ttotal: 47.2s\tremaining: 7.05s\n",
      "174:\tlearn: 2.9932799\ttotal: 47.4s\tremaining: 6.78s\n",
      "175:\tlearn: 2.9850821\ttotal: 47.8s\tremaining: 6.51s\n",
      "176:\tlearn: 2.9788673\ttotal: 48s\tremaining: 6.24s\n",
      "177:\tlearn: 2.9713527\ttotal: 48.3s\tremaining: 5.97s\n",
      "178:\tlearn: 2.9645347\ttotal: 48.6s\tremaining: 5.7s\n",
      "179:\tlearn: 2.9560215\ttotal: 48.9s\tremaining: 5.43s\n",
      "180:\tlearn: 2.9511364\ttotal: 49.2s\tremaining: 5.16s\n",
      "181:\tlearn: 2.9476728\ttotal: 49.4s\tremaining: 4.89s\n",
      "182:\tlearn: 2.9420503\ttotal: 49.7s\tremaining: 4.62s\n",
      "183:\tlearn: 2.9394097\ttotal: 50s\tremaining: 4.34s\n",
      "184:\tlearn: 2.9330055\ttotal: 50.3s\tremaining: 4.08s\n",
      "185:\tlearn: 2.9310386\ttotal: 50.5s\tremaining: 3.8s\n",
      "186:\tlearn: 2.9249415\ttotal: 50.8s\tremaining: 3.53s\n",
      "187:\tlearn: 2.9231839\ttotal: 51s\tremaining: 3.26s\n",
      "188:\tlearn: 2.9179072\ttotal: 51.3s\tremaining: 2.99s\n",
      "189:\tlearn: 2.9083208\ttotal: 51.6s\tremaining: 2.71s\n",
      "190:\tlearn: 2.9040202\ttotal: 51.9s\tremaining: 2.44s\n",
      "191:\tlearn: 2.8983654\ttotal: 52.1s\tremaining: 2.17s\n",
      "192:\tlearn: 2.8924040\ttotal: 52.4s\tremaining: 1.9s\n",
      "193:\tlearn: 2.8886991\ttotal: 52.7s\tremaining: 1.63s\n",
      "194:\tlearn: 2.8724261\ttotal: 53s\tremaining: 1.36s\n",
      "195:\tlearn: 2.8657033\ttotal: 53.2s\tremaining: 1.09s\n",
      "196:\tlearn: 2.8607129\ttotal: 53.5s\tremaining: 815ms\n",
      "197:\tlearn: 2.8542980\ttotal: 53.8s\tremaining: 543ms\n",
      "198:\tlearn: 2.8477663\ttotal: 54.1s\tremaining: 272ms\n",
      "199:\tlearn: 2.8447452\ttotal: 54.3s\tremaining: 0us\n",
      "0:\tlearn: 1.2501526\ttotal: 365ms\tremaining: 1m 12s\n",
      "1:\tlearn: 1.0437243\ttotal: 736ms\tremaining: 1m 12s\n",
      "2:\tlearn: 0.9157887\ttotal: 1.12s\tremaining: 1m 13s\n",
      "3:\tlearn: 0.8189890\ttotal: 1.49s\tremaining: 1m 13s\n",
      "4:\tlearn: 0.7700410\ttotal: 1.85s\tremaining: 1m 12s\n",
      "5:\tlearn: 0.7151465\ttotal: 2.24s\tremaining: 1m 12s\n",
      "6:\tlearn: 0.6740440\ttotal: 2.63s\tremaining: 1m 12s\n",
      "7:\tlearn: 0.6433195\ttotal: 3.02s\tremaining: 1m 12s\n",
      "8:\tlearn: 0.6159315\ttotal: 3.41s\tremaining: 1m 12s\n",
      "9:\tlearn: 0.5943072\ttotal: 3.8s\tremaining: 1m 12s\n",
      "10:\tlearn: 0.5746886\ttotal: 4.18s\tremaining: 1m 11s\n",
      "11:\tlearn: 0.5631371\ttotal: 4.56s\tremaining: 1m 11s\n",
      "12:\tlearn: 0.5473808\ttotal: 4.96s\tremaining: 1m 11s\n",
      "13:\tlearn: 0.5350832\ttotal: 5.34s\tremaining: 1m 10s\n",
      "14:\tlearn: 0.5248467\ttotal: 5.7s\tremaining: 1m 10s\n",
      "15:\tlearn: 0.5163305\ttotal: 6.08s\tremaining: 1m 9s\n",
      "16:\tlearn: 0.5073104\ttotal: 6.46s\tremaining: 1m 9s\n",
      "17:\tlearn: 0.4999289\ttotal: 6.88s\tremaining: 1m 9s\n",
      "18:\tlearn: 0.4903411\ttotal: 7.29s\tremaining: 1m 9s\n",
      "19:\tlearn: 0.4807575\ttotal: 7.68s\tremaining: 1m 9s\n",
      "20:\tlearn: 0.4768007\ttotal: 8.04s\tremaining: 1m 8s\n",
      "21:\tlearn: 0.4680320\ttotal: 8.47s\tremaining: 1m 8s\n",
      "22:\tlearn: 0.4616912\ttotal: 8.85s\tremaining: 1m 8s\n",
      "23:\tlearn: 0.4546634\ttotal: 9.23s\tremaining: 1m 7s\n",
      "24:\tlearn: 0.4437827\ttotal: 9.62s\tremaining: 1m 7s\n",
      "25:\tlearn: 0.4384722\ttotal: 9.99s\tremaining: 1m 6s\n",
      "26:\tlearn: 0.4332146\ttotal: 10.4s\tremaining: 1m 6s\n",
      "27:\tlearn: 0.4281582\ttotal: 10.8s\tremaining: 1m 6s\n",
      "28:\tlearn: 0.4244182\ttotal: 11.1s\tremaining: 1m 5s\n",
      "29:\tlearn: 0.4175412\ttotal: 11.5s\tremaining: 1m 5s\n",
      "30:\tlearn: 0.4148354\ttotal: 11.9s\tremaining: 1m 4s\n",
      "31:\tlearn: 0.4053273\ttotal: 12.3s\tremaining: 1m 4s\n",
      "32:\tlearn: 0.4004595\ttotal: 12.7s\tremaining: 1m 4s\n",
      "33:\tlearn: 0.3958459\ttotal: 13.1s\tremaining: 1m 3s\n",
      "34:\tlearn: 0.3931801\ttotal: 13.4s\tremaining: 1m 3s\n",
      "35:\tlearn: 0.3910425\ttotal: 13.8s\tremaining: 1m 2s\n",
      "36:\tlearn: 0.3870816\ttotal: 14.2s\tremaining: 1m 2s\n",
      "37:\tlearn: 0.3845264\ttotal: 14.5s\tremaining: 1m 1s\n",
      "38:\tlearn: 0.3820561\ttotal: 14.9s\tremaining: 1m 1s\n",
      "39:\tlearn: 0.3806955\ttotal: 15.3s\tremaining: 1m 1s\n",
      "40:\tlearn: 0.3787183\ttotal: 15.7s\tremaining: 1m\n",
      "41:\tlearn: 0.3748893\ttotal: 16s\tremaining: 1m\n",
      "42:\tlearn: 0.3720629\ttotal: 16.4s\tremaining: 1m\n",
      "43:\tlearn: 0.3681802\ttotal: 16.8s\tremaining: 59.7s\n",
      "44:\tlearn: 0.3641012\ttotal: 17.2s\tremaining: 59.3s\n",
      "45:\tlearn: 0.3627081\ttotal: 17.6s\tremaining: 58.9s\n",
      "46:\tlearn: 0.3609312\ttotal: 18s\tremaining: 58.5s\n",
      "47:\tlearn: 0.3587507\ttotal: 18.3s\tremaining: 58.1s\n",
      "48:\tlearn: 0.3565172\ttotal: 18.7s\tremaining: 57.7s\n",
      "49:\tlearn: 0.3556492\ttotal: 19.1s\tremaining: 57.3s\n",
      "50:\tlearn: 0.3539154\ttotal: 19.5s\tremaining: 57s\n",
      "51:\tlearn: 0.3510747\ttotal: 19.9s\tremaining: 56.7s\n",
      "52:\tlearn: 0.3478875\ttotal: 20.3s\tremaining: 56.3s\n",
      "53:\tlearn: 0.3455009\ttotal: 20.7s\tremaining: 55.8s\n",
      "54:\tlearn: 0.3440143\ttotal: 21s\tremaining: 55.5s\n",
      "55:\tlearn: 0.3420151\ttotal: 21.4s\tremaining: 55.1s\n",
      "56:\tlearn: 0.3381701\ttotal: 21.8s\tremaining: 54.8s\n",
      "57:\tlearn: 0.3365183\ttotal: 22.2s\tremaining: 54.3s\n",
      "58:\tlearn: 0.3351205\ttotal: 22.5s\tremaining: 53.9s\n",
      "59:\tlearn: 0.3332311\ttotal: 22.9s\tremaining: 53.4s\n",
      "60:\tlearn: 0.3314060\ttotal: 23.3s\tremaining: 53s\n",
      "61:\tlearn: 0.3287474\ttotal: 23.6s\tremaining: 52.6s\n",
      "62:\tlearn: 0.3263804\ttotal: 24s\tremaining: 52.2s\n",
      "63:\tlearn: 0.3252337\ttotal: 24.3s\tremaining: 51.7s\n",
      "64:\tlearn: 0.3234869\ttotal: 24.7s\tremaining: 51.4s\n",
      "65:\tlearn: 0.3218798\ttotal: 25.1s\tremaining: 51s\n",
      "66:\tlearn: 0.3201103\ttotal: 25.5s\tremaining: 50.6s\n",
      "67:\tlearn: 0.3190896\ttotal: 25.8s\tremaining: 50.1s\n",
      "68:\tlearn: 0.3178072\ttotal: 26.2s\tremaining: 49.7s\n",
      "69:\tlearn: 0.3157844\ttotal: 26.6s\tremaining: 49.3s\n",
      "70:\tlearn: 0.3136680\ttotal: 26.9s\tremaining: 48.9s\n",
      "71:\tlearn: 0.3121128\ttotal: 27.3s\tremaining: 48.5s\n",
      "72:\tlearn: 0.3114769\ttotal: 27.7s\tremaining: 48.1s\n",
      "73:\tlearn: 0.3084732\ttotal: 28s\tremaining: 47.8s\n",
      "74:\tlearn: 0.3074747\ttotal: 28.4s\tremaining: 47.3s\n",
      "75:\tlearn: 0.3060468\ttotal: 28.8s\tremaining: 46.9s\n",
      "76:\tlearn: 0.3042839\ttotal: 29.1s\tremaining: 46.5s\n",
      "77:\tlearn: 0.3031694\ttotal: 29.5s\tremaining: 46.1s\n",
      "78:\tlearn: 0.3018441\ttotal: 29.8s\tremaining: 45.7s\n",
      "79:\tlearn: 0.3001026\ttotal: 30.2s\tremaining: 45.3s\n",
      "80:\tlearn: 0.2979043\ttotal: 30.6s\tremaining: 44.9s\n",
      "81:\tlearn: 0.2962984\ttotal: 30.9s\tremaining: 44.5s\n",
      "82:\tlearn: 0.2953328\ttotal: 31.3s\tremaining: 44.1s\n",
      "83:\tlearn: 0.2938054\ttotal: 31.6s\tremaining: 43.7s\n",
      "84:\tlearn: 0.2927094\ttotal: 32s\tremaining: 43.3s\n",
      "85:\tlearn: 0.2906773\ttotal: 32.3s\tremaining: 42.9s\n",
      "86:\tlearn: 0.2896826\ttotal: 32.7s\tremaining: 42.5s\n",
      "87:\tlearn: 0.2884050\ttotal: 33s\tremaining: 42.1s\n",
      "88:\tlearn: 0.2874075\ttotal: 33.4s\tremaining: 41.7s\n",
      "89:\tlearn: 0.2859219\ttotal: 33.8s\tremaining: 41.3s\n",
      "90:\tlearn: 0.2832685\ttotal: 34.1s\tremaining: 40.9s\n",
      "91:\tlearn: 0.2818496\ttotal: 34.5s\tremaining: 40.5s\n",
      "92:\tlearn: 0.2804558\ttotal: 34.9s\tremaining: 40.1s\n",
      "93:\tlearn: 0.2792650\ttotal: 35.2s\tremaining: 39.7s\n",
      "94:\tlearn: 0.2782216\ttotal: 35.6s\tremaining: 39.3s\n",
      "95:\tlearn: 0.2771835\ttotal: 35.9s\tremaining: 38.9s\n",
      "96:\tlearn: 0.2758108\ttotal: 36.3s\tremaining: 38.5s\n",
      "97:\tlearn: 0.2751490\ttotal: 36.6s\tremaining: 38.1s\n",
      "98:\tlearn: 0.2746384\ttotal: 36.9s\tremaining: 37.7s\n",
      "99:\tlearn: 0.2728109\ttotal: 37.3s\tremaining: 37.3s\n",
      "100:\tlearn: 0.2718850\ttotal: 37.7s\tremaining: 36.9s\n",
      "101:\tlearn: 0.2713576\ttotal: 38s\tremaining: 36.5s\n",
      "102:\tlearn: 0.2708240\ttotal: 38.4s\tremaining: 36.1s\n",
      "103:\tlearn: 0.2690222\ttotal: 38.7s\tremaining: 35.7s\n",
      "104:\tlearn: 0.2683441\ttotal: 39.1s\tremaining: 35.3s\n",
      "105:\tlearn: 0.2666080\ttotal: 39.4s\tremaining: 35s\n",
      "106:\tlearn: 0.2661789\ttotal: 39.8s\tremaining: 34.6s\n",
      "107:\tlearn: 0.2652172\ttotal: 40.1s\tremaining: 34.2s\n",
      "108:\tlearn: 0.2642980\ttotal: 40.5s\tremaining: 33.8s\n",
      "109:\tlearn: 0.2629135\ttotal: 40.8s\tremaining: 33.4s\n",
      "110:\tlearn: 0.2624078\ttotal: 41.2s\tremaining: 33s\n",
      "111:\tlearn: 0.2615069\ttotal: 41.5s\tremaining: 32.6s\n",
      "112:\tlearn: 0.2604121\ttotal: 41.9s\tremaining: 32.3s\n",
      "113:\tlearn: 0.2588483\ttotal: 42.3s\tremaining: 31.9s\n",
      "114:\tlearn: 0.2570856\ttotal: 42.6s\tremaining: 31.5s\n",
      "115:\tlearn: 0.2564363\ttotal: 43s\tremaining: 31.1s\n",
      "116:\tlearn: 0.2557467\ttotal: 43.3s\tremaining: 30.7s\n",
      "117:\tlearn: 0.2545257\ttotal: 43.7s\tremaining: 30.3s\n",
      "118:\tlearn: 0.2530485\ttotal: 44s\tremaining: 30s\n",
      "119:\tlearn: 0.2516683\ttotal: 44.4s\tremaining: 29.6s\n",
      "120:\tlearn: 0.2507785\ttotal: 44.8s\tremaining: 29.2s\n",
      "121:\tlearn: 0.2500174\ttotal: 45.1s\tremaining: 28.8s\n",
      "122:\tlearn: 0.2490742\ttotal: 45.5s\tremaining: 28.5s\n",
      "123:\tlearn: 0.2480975\ttotal: 45.8s\tremaining: 28.1s\n",
      "124:\tlearn: 0.2475471\ttotal: 46.2s\tremaining: 27.7s\n",
      "125:\tlearn: 0.2469361\ttotal: 46.5s\tremaining: 27.3s\n",
      "126:\tlearn: 0.2464961\ttotal: 46.9s\tremaining: 26.9s\n",
      "127:\tlearn: 0.2451389\ttotal: 47.2s\tremaining: 26.6s\n",
      "128:\tlearn: 0.2443671\ttotal: 47.6s\tremaining: 26.2s\n",
      "129:\tlearn: 0.2424789\ttotal: 47.9s\tremaining: 25.8s\n",
      "130:\tlearn: 0.2413304\ttotal: 48.3s\tremaining: 25.4s\n",
      "131:\tlearn: 0.2404116\ttotal: 48.7s\tremaining: 25.1s\n",
      "132:\tlearn: 0.2388876\ttotal: 49.1s\tremaining: 24.7s\n",
      "133:\tlearn: 0.2377239\ttotal: 49.4s\tremaining: 24.3s\n",
      "134:\tlearn: 0.2367307\ttotal: 49.8s\tremaining: 24s\n",
      "135:\tlearn: 0.2362401\ttotal: 50.1s\tremaining: 23.6s\n",
      "136:\tlearn: 0.2354190\ttotal: 50.5s\tremaining: 23.2s\n",
      "137:\tlearn: 0.2344737\ttotal: 50.9s\tremaining: 22.9s\n",
      "138:\tlearn: 0.2334256\ttotal: 51.2s\tremaining: 22.5s\n",
      "139:\tlearn: 0.2327306\ttotal: 51.6s\tremaining: 22.1s\n",
      "140:\tlearn: 0.2323643\ttotal: 52s\tremaining: 21.7s\n",
      "141:\tlearn: 0.2315047\ttotal: 52.3s\tremaining: 21.4s\n",
      "142:\tlearn: 0.2306202\ttotal: 52.7s\tremaining: 21s\n",
      "143:\tlearn: 0.2299307\ttotal: 53.1s\tremaining: 20.6s\n",
      "144:\tlearn: 0.2291695\ttotal: 53.5s\tremaining: 20.3s\n",
      "145:\tlearn: 0.2281608\ttotal: 53.8s\tremaining: 19.9s\n",
      "146:\tlearn: 0.2268082\ttotal: 54.2s\tremaining: 19.5s\n",
      "147:\tlearn: 0.2264889\ttotal: 54.5s\tremaining: 19.2s\n",
      "148:\tlearn: 0.2255511\ttotal: 54.9s\tremaining: 18.8s\n",
      "149:\tlearn: 0.2252380\ttotal: 55.2s\tremaining: 18.4s\n",
      "150:\tlearn: 0.2243908\ttotal: 55.6s\tremaining: 18s\n",
      "151:\tlearn: 0.2235083\ttotal: 55.9s\tremaining: 17.7s\n",
      "152:\tlearn: 0.2230944\ttotal: 56.3s\tremaining: 17.3s\n",
      "153:\tlearn: 0.2223048\ttotal: 56.6s\tremaining: 16.9s\n",
      "154:\tlearn: 0.2218995\ttotal: 57s\tremaining: 16.5s\n",
      "155:\tlearn: 0.2213945\ttotal: 57.3s\tremaining: 16.2s\n",
      "156:\tlearn: 0.2199259\ttotal: 57.7s\tremaining: 15.8s\n",
      "157:\tlearn: 0.2195200\ttotal: 58s\tremaining: 15.4s\n",
      "158:\tlearn: 0.2185050\ttotal: 58.4s\tremaining: 15.1s\n",
      "159:\tlearn: 0.2172882\ttotal: 58.8s\tremaining: 14.7s\n",
      "160:\tlearn: 0.2162614\ttotal: 59.1s\tremaining: 14.3s\n",
      "161:\tlearn: 0.2153781\ttotal: 59.5s\tremaining: 14s\n",
      "162:\tlearn: 0.2144033\ttotal: 59.9s\tremaining: 13.6s\n",
      "163:\tlearn: 0.2137630\ttotal: 1m\tremaining: 13.2s\n",
      "164:\tlearn: 0.2132899\ttotal: 1m\tremaining: 12.8s\n",
      "165:\tlearn: 0.2125965\ttotal: 1m\tremaining: 12.5s\n",
      "166:\tlearn: 0.2112378\ttotal: 1m 1s\tremaining: 12.1s\n",
      "167:\tlearn: 0.2106362\ttotal: 1m 1s\tremaining: 11.7s\n",
      "168:\tlearn: 0.2099201\ttotal: 1m 1s\tremaining: 11.4s\n",
      "169:\tlearn: 0.2095844\ttotal: 1m 2s\tremaining: 11s\n",
      "170:\tlearn: 0.2090287\ttotal: 1m 2s\tremaining: 10.6s\n",
      "171:\tlearn: 0.2082719\ttotal: 1m 3s\tremaining: 10.3s\n",
      "172:\tlearn: 0.2077148\ttotal: 1m 3s\tremaining: 9.89s\n",
      "173:\tlearn: 0.2070876\ttotal: 1m 3s\tremaining: 9.52s\n",
      "174:\tlearn: 0.2064333\ttotal: 1m 4s\tremaining: 9.15s\n",
      "175:\tlearn: 0.2055592\ttotal: 1m 4s\tremaining: 8.79s\n",
      "176:\tlearn: 0.2045715\ttotal: 1m 4s\tremaining: 8.42s\n",
      "177:\tlearn: 0.2038506\ttotal: 1m 5s\tremaining: 8.05s\n",
      "178:\tlearn: 0.2029211\ttotal: 1m 5s\tremaining: 7.69s\n",
      "179:\tlearn: 0.2013669\ttotal: 1m 5s\tremaining: 7.33s\n",
      "180:\tlearn: 0.1999284\ttotal: 1m 6s\tremaining: 6.96s\n",
      "181:\tlearn: 0.1992491\ttotal: 1m 6s\tremaining: 6.59s\n",
      "182:\tlearn: 0.1986857\ttotal: 1m 7s\tremaining: 6.23s\n",
      "183:\tlearn: 0.1984182\ttotal: 1m 7s\tremaining: 5.86s\n",
      "184:\tlearn: 0.1973178\ttotal: 1m 7s\tremaining: 5.5s\n",
      "185:\tlearn: 0.1970259\ttotal: 1m 8s\tremaining: 5.13s\n",
      "186:\tlearn: 0.1961855\ttotal: 1m 8s\tremaining: 4.76s\n",
      "187:\tlearn: 0.1956485\ttotal: 1m 8s\tremaining: 4.39s\n",
      "188:\tlearn: 0.1949655\ttotal: 1m 9s\tremaining: 4.03s\n",
      "189:\tlearn: 0.1942580\ttotal: 1m 9s\tremaining: 3.66s\n",
      "190:\tlearn: 0.1937865\ttotal: 1m 9s\tremaining: 3.29s\n",
      "191:\tlearn: 0.1931781\ttotal: 1m 10s\tremaining: 2.93s\n",
      "192:\tlearn: 0.1923575\ttotal: 1m 10s\tremaining: 2.56s\n",
      "193:\tlearn: 0.1917097\ttotal: 1m 11s\tremaining: 2.2s\n",
      "194:\tlearn: 0.1911151\ttotal: 1m 11s\tremaining: 1.83s\n",
      "195:\tlearn: 0.1904127\ttotal: 1m 11s\tremaining: 1.47s\n",
      "196:\tlearn: 0.1902370\ttotal: 1m 12s\tremaining: 1.1s\n",
      "197:\tlearn: 0.1895805\ttotal: 1m 12s\tremaining: 733ms\n",
      "198:\tlearn: 0.1884970\ttotal: 1m 12s\tremaining: 367ms\n",
      "199:\tlearn: 0.1881539\ttotal: 1m 13s\tremaining: 0us\n",
      "0:\tlearn: 1.2501526\ttotal: 373ms\tremaining: 1m 14s\n",
      "1:\tlearn: 1.0437243\ttotal: 748ms\tremaining: 1m 14s\n",
      "2:\tlearn: 0.9157887\ttotal: 1.13s\tremaining: 1m 14s\n",
      "3:\tlearn: 0.8189890\ttotal: 1.51s\tremaining: 1m 14s\n",
      "4:\tlearn: 0.7700410\ttotal: 1.89s\tremaining: 1m 13s\n",
      "5:\tlearn: 0.7151465\ttotal: 2.29s\tremaining: 1m 14s\n",
      "6:\tlearn: 0.6740440\ttotal: 2.69s\tremaining: 1m 14s\n",
      "7:\tlearn: 0.6433195\ttotal: 3.08s\tremaining: 1m 13s\n",
      "8:\tlearn: 0.6159315\ttotal: 3.5s\tremaining: 1m 14s\n",
      "9:\tlearn: 0.5943072\ttotal: 3.89s\tremaining: 1m 13s\n",
      "10:\tlearn: 0.5746886\ttotal: 4.32s\tremaining: 1m 14s\n",
      "11:\tlearn: 0.5631371\ttotal: 4.71s\tremaining: 1m 13s\n",
      "12:\tlearn: 0.5473808\ttotal: 5.12s\tremaining: 1m 13s\n",
      "13:\tlearn: 0.5350832\ttotal: 5.51s\tremaining: 1m 13s\n",
      "14:\tlearn: 0.5248467\ttotal: 5.88s\tremaining: 1m 12s\n",
      "15:\tlearn: 0.5163305\ttotal: 6.27s\tremaining: 1m 12s\n",
      "16:\tlearn: 0.5073104\ttotal: 6.66s\tremaining: 1m 11s\n",
      "17:\tlearn: 0.4999289\ttotal: 7.06s\tremaining: 1m 11s\n",
      "18:\tlearn: 0.4903411\ttotal: 7.45s\tremaining: 1m 11s\n",
      "19:\tlearn: 0.4807575\ttotal: 7.85s\tremaining: 1m 10s\n",
      "20:\tlearn: 0.4768007\ttotal: 8.22s\tremaining: 1m 10s\n",
      "21:\tlearn: 0.4680320\ttotal: 8.66s\tremaining: 1m 10s\n",
      "22:\tlearn: 0.4616912\ttotal: 9.05s\tremaining: 1m 9s\n",
      "23:\tlearn: 0.4546634\ttotal: 9.44s\tremaining: 1m 9s\n",
      "24:\tlearn: 0.4437827\ttotal: 9.83s\tremaining: 1m 8s\n",
      "25:\tlearn: 0.4384722\ttotal: 10.2s\tremaining: 1m 8s\n",
      "26:\tlearn: 0.4332146\ttotal: 10.6s\tremaining: 1m 7s\n",
      "27:\tlearn: 0.4281582\ttotal: 11s\tremaining: 1m 7s\n",
      "28:\tlearn: 0.4244182\ttotal: 11.4s\tremaining: 1m 7s\n",
      "29:\tlearn: 0.4175412\ttotal: 11.8s\tremaining: 1m 6s\n",
      "30:\tlearn: 0.4148354\ttotal: 12.1s\tremaining: 1m 5s\n",
      "31:\tlearn: 0.4053273\ttotal: 12.5s\tremaining: 1m 5s\n",
      "32:\tlearn: 0.4004595\ttotal: 12.9s\tremaining: 1m 5s\n",
      "33:\tlearn: 0.3958459\ttotal: 13.2s\tremaining: 1m 4s\n",
      "34:\tlearn: 0.3931801\ttotal: 13.6s\tremaining: 1m 4s\n",
      "35:\tlearn: 0.3910425\ttotal: 14s\tremaining: 1m 3s\n",
      "36:\tlearn: 0.3870816\ttotal: 14.4s\tremaining: 1m 3s\n",
      "37:\tlearn: 0.3845264\ttotal: 14.8s\tremaining: 1m 2s\n",
      "38:\tlearn: 0.3820561\ttotal: 15.1s\tremaining: 1m 2s\n",
      "39:\tlearn: 0.3806955\ttotal: 15.5s\tremaining: 1m 1s\n",
      "40:\tlearn: 0.3787183\ttotal: 15.9s\tremaining: 1m 1s\n",
      "41:\tlearn: 0.3748893\ttotal: 16.2s\tremaining: 1m 1s\n",
      "42:\tlearn: 0.3720629\ttotal: 16.6s\tremaining: 1m\n",
      "43:\tlearn: 0.3681802\ttotal: 17s\tremaining: 1m\n",
      "44:\tlearn: 0.3641012\ttotal: 17.4s\tremaining: 60s\n",
      "45:\tlearn: 0.3627081\ttotal: 17.8s\tremaining: 59.5s\n",
      "46:\tlearn: 0.3609312\ttotal: 18.1s\tremaining: 59s\n",
      "47:\tlearn: 0.3587507\ttotal: 18.5s\tremaining: 58.7s\n",
      "48:\tlearn: 0.3565172\ttotal: 19s\tremaining: 58.5s\n",
      "49:\tlearn: 0.3556492\ttotal: 19.4s\tremaining: 58.1s\n",
      "50:\tlearn: 0.3539154\ttotal: 19.8s\tremaining: 57.8s\n",
      "51:\tlearn: 0.3510747\ttotal: 20.2s\tremaining: 57.4s\n",
      "52:\tlearn: 0.3478875\ttotal: 20.6s\tremaining: 57s\n",
      "53:\tlearn: 0.3455009\ttotal: 20.9s\tremaining: 56.6s\n",
      "54:\tlearn: 0.3440143\ttotal: 21.3s\tremaining: 56.2s\n",
      "55:\tlearn: 0.3420151\ttotal: 21.7s\tremaining: 55.8s\n",
      "56:\tlearn: 0.3381701\ttotal: 22.1s\tremaining: 55.4s\n",
      "57:\tlearn: 0.3365183\ttotal: 22.5s\tremaining: 55s\n",
      "58:\tlearn: 0.3351205\ttotal: 22.8s\tremaining: 54.6s\n",
      "59:\tlearn: 0.3332311\ttotal: 23.2s\tremaining: 54.1s\n",
      "60:\tlearn: 0.3314060\ttotal: 23.5s\tremaining: 53.7s\n",
      "61:\tlearn: 0.3287474\ttotal: 23.9s\tremaining: 53.3s\n",
      "62:\tlearn: 0.3263804\ttotal: 24.3s\tremaining: 52.9s\n",
      "63:\tlearn: 0.3252337\ttotal: 24.7s\tremaining: 52.4s\n",
      "64:\tlearn: 0.3234869\ttotal: 25.1s\tremaining: 52.1s\n",
      "65:\tlearn: 0.3218798\ttotal: 25.4s\tremaining: 51.6s\n",
      "66:\tlearn: 0.3201103\ttotal: 25.9s\tremaining: 51.3s\n",
      "67:\tlearn: 0.3190896\ttotal: 26.2s\tremaining: 51s\n",
      "68:\tlearn: 0.3178072\ttotal: 26.6s\tremaining: 50.6s\n",
      "69:\tlearn: 0.3157844\ttotal: 27.1s\tremaining: 50.3s\n",
      "70:\tlearn: 0.3136680\ttotal: 27.5s\tremaining: 49.9s\n",
      "71:\tlearn: 0.3121128\ttotal: 27.9s\tremaining: 49.5s\n",
      "72:\tlearn: 0.3114769\ttotal: 28.2s\tremaining: 49.1s\n",
      "73:\tlearn: 0.3084732\ttotal: 28.6s\tremaining: 48.7s\n",
      "74:\tlearn: 0.3074747\ttotal: 28.9s\tremaining: 48.2s\n",
      "75:\tlearn: 0.3060468\ttotal: 29.3s\tremaining: 47.8s\n",
      "76:\tlearn: 0.3042839\ttotal: 29.7s\tremaining: 47.4s\n",
      "77:\tlearn: 0.3031694\ttotal: 30s\tremaining: 46.9s\n",
      "78:\tlearn: 0.3018441\ttotal: 30.4s\tremaining: 46.5s\n",
      "79:\tlearn: 0.3001026\ttotal: 30.8s\tremaining: 46.1s\n",
      "80:\tlearn: 0.2979043\ttotal: 31.2s\tremaining: 45.8s\n",
      "81:\tlearn: 0.2962984\ttotal: 31.6s\tremaining: 45.4s\n",
      "82:\tlearn: 0.2953328\ttotal: 31.9s\tremaining: 45s\n",
      "83:\tlearn: 0.2938054\ttotal: 32.3s\tremaining: 44.7s\n",
      "84:\tlearn: 0.2927094\ttotal: 32.7s\tremaining: 44.3s\n",
      "85:\tlearn: 0.2906773\ttotal: 33.1s\tremaining: 43.9s\n",
      "86:\tlearn: 0.2896826\ttotal: 33.5s\tremaining: 43.5s\n",
      "87:\tlearn: 0.2884050\ttotal: 33.9s\tremaining: 43.2s\n",
      "88:\tlearn: 0.2874075\ttotal: 34.3s\tremaining: 42.7s\n",
      "89:\tlearn: 0.2859219\ttotal: 34.7s\tremaining: 42.4s\n",
      "90:\tlearn: 0.2832685\ttotal: 35.1s\tremaining: 42s\n",
      "91:\tlearn: 0.2818496\ttotal: 35.5s\tremaining: 41.7s\n",
      "92:\tlearn: 0.2804558\ttotal: 35.9s\tremaining: 41.3s\n",
      "93:\tlearn: 0.2792650\ttotal: 36.3s\tremaining: 40.9s\n",
      "94:\tlearn: 0.2782216\ttotal: 36.7s\tremaining: 40.5s\n",
      "95:\tlearn: 0.2771835\ttotal: 37.1s\tremaining: 40.2s\n",
      "96:\tlearn: 0.2758108\ttotal: 37.5s\tremaining: 39.8s\n",
      "97:\tlearn: 0.2751490\ttotal: 37.8s\tremaining: 39.4s\n",
      "98:\tlearn: 0.2746384\ttotal: 38.2s\tremaining: 39s\n",
      "99:\tlearn: 0.2728109\ttotal: 38.7s\tremaining: 38.7s\n",
      "100:\tlearn: 0.2718850\ttotal: 39s\tremaining: 38.3s\n",
      "101:\tlearn: 0.2713576\ttotal: 39.4s\tremaining: 37.8s\n",
      "102:\tlearn: 0.2708240\ttotal: 39.8s\tremaining: 37.4s\n",
      "103:\tlearn: 0.2690222\ttotal: 40.1s\tremaining: 37s\n",
      "104:\tlearn: 0.2683441\ttotal: 40.5s\tremaining: 36.6s\n",
      "105:\tlearn: 0.2666080\ttotal: 40.9s\tremaining: 36.3s\n",
      "106:\tlearn: 0.2661789\ttotal: 41.3s\tremaining: 35.9s\n",
      "107:\tlearn: 0.2652172\ttotal: 41.6s\tremaining: 35.5s\n",
      "108:\tlearn: 0.2642980\ttotal: 42s\tremaining: 35.1s\n",
      "109:\tlearn: 0.2629135\ttotal: 42.4s\tremaining: 34.7s\n",
      "110:\tlearn: 0.2624078\ttotal: 42.7s\tremaining: 34.3s\n",
      "111:\tlearn: 0.2615069\ttotal: 43.1s\tremaining: 33.9s\n",
      "112:\tlearn: 0.2604121\ttotal: 43.5s\tremaining: 33.5s\n",
      "113:\tlearn: 0.2588483\ttotal: 43.9s\tremaining: 33.1s\n",
      "114:\tlearn: 0.2570856\ttotal: 44.2s\tremaining: 32.7s\n",
      "115:\tlearn: 0.2564363\ttotal: 44.6s\tremaining: 32.3s\n",
      "116:\tlearn: 0.2557467\ttotal: 45s\tremaining: 31.9s\n",
      "117:\tlearn: 0.2545257\ttotal: 45.4s\tremaining: 31.5s\n",
      "118:\tlearn: 0.2530485\ttotal: 45.8s\tremaining: 31.1s\n",
      "119:\tlearn: 0.2516683\ttotal: 46.1s\tremaining: 30.7s\n",
      "120:\tlearn: 0.2507785\ttotal: 46.5s\tremaining: 30.3s\n",
      "121:\tlearn: 0.2500174\ttotal: 46.9s\tremaining: 30s\n",
      "122:\tlearn: 0.2490742\ttotal: 47.2s\tremaining: 29.6s\n",
      "123:\tlearn: 0.2480975\ttotal: 47.6s\tremaining: 29.2s\n",
      "124:\tlearn: 0.2475471\ttotal: 48s\tremaining: 28.8s\n",
      "125:\tlearn: 0.2469361\ttotal: 48.3s\tremaining: 28.4s\n",
      "126:\tlearn: 0.2464961\ttotal: 48.7s\tremaining: 28s\n",
      "127:\tlearn: 0.2451389\ttotal: 49.1s\tremaining: 27.6s\n",
      "128:\tlearn: 0.2443671\ttotal: 49.4s\tremaining: 27.2s\n",
      "129:\tlearn: 0.2424789\ttotal: 49.8s\tremaining: 26.8s\n",
      "130:\tlearn: 0.2413304\ttotal: 50.2s\tremaining: 26.4s\n",
      "131:\tlearn: 0.2404116\ttotal: 50.6s\tremaining: 26.1s\n",
      "132:\tlearn: 0.2388876\ttotal: 51s\tremaining: 25.7s\n",
      "133:\tlearn: 0.2377239\ttotal: 51.4s\tremaining: 25.3s\n",
      "134:\tlearn: 0.2367307\ttotal: 51.7s\tremaining: 24.9s\n",
      "135:\tlearn: 0.2362401\ttotal: 52.1s\tremaining: 24.5s\n",
      "136:\tlearn: 0.2354190\ttotal: 52.5s\tremaining: 24.2s\n",
      "137:\tlearn: 0.2344737\ttotal: 52.9s\tremaining: 23.8s\n",
      "138:\tlearn: 0.2334256\ttotal: 53.3s\tremaining: 23.4s\n",
      "139:\tlearn: 0.2327306\ttotal: 53.6s\tremaining: 23s\n",
      "140:\tlearn: 0.2323643\ttotal: 54s\tremaining: 22.6s\n",
      "141:\tlearn: 0.2315047\ttotal: 54.3s\tremaining: 22.2s\n",
      "142:\tlearn: 0.2306202\ttotal: 54.7s\tremaining: 21.8s\n",
      "143:\tlearn: 0.2299307\ttotal: 55.1s\tremaining: 21.4s\n",
      "144:\tlearn: 0.2291695\ttotal: 55.5s\tremaining: 21s\n",
      "145:\tlearn: 0.2281608\ttotal: 55.9s\tremaining: 20.7s\n",
      "146:\tlearn: 0.2268082\ttotal: 56.2s\tremaining: 20.3s\n",
      "147:\tlearn: 0.2264889\ttotal: 56.6s\tremaining: 19.9s\n",
      "148:\tlearn: 0.2255511\ttotal: 57s\tremaining: 19.5s\n",
      "149:\tlearn: 0.2252380\ttotal: 57.3s\tremaining: 19.1s\n",
      "150:\tlearn: 0.2243908\ttotal: 57.7s\tremaining: 18.7s\n",
      "151:\tlearn: 0.2235083\ttotal: 58.1s\tremaining: 18.3s\n",
      "152:\tlearn: 0.2230944\ttotal: 58.4s\tremaining: 18s\n",
      "153:\tlearn: 0.2223048\ttotal: 58.8s\tremaining: 17.6s\n",
      "154:\tlearn: 0.2218995\ttotal: 59.2s\tremaining: 17.2s\n",
      "155:\tlearn: 0.2213945\ttotal: 59.6s\tremaining: 16.8s\n",
      "156:\tlearn: 0.2199259\ttotal: 59.9s\tremaining: 16.4s\n",
      "157:\tlearn: 0.2195200\ttotal: 1m\tremaining: 16s\n",
      "158:\tlearn: 0.2185050\ttotal: 1m\tremaining: 15.7s\n",
      "159:\tlearn: 0.2172882\ttotal: 1m 1s\tremaining: 15.3s\n",
      "160:\tlearn: 0.2162614\ttotal: 1m 1s\tremaining: 14.9s\n",
      "161:\tlearn: 0.2153781\ttotal: 1m 1s\tremaining: 14.5s\n",
      "162:\tlearn: 0.2144033\ttotal: 1m 2s\tremaining: 14.1s\n",
      "163:\tlearn: 0.2137630\ttotal: 1m 2s\tremaining: 13.8s\n",
      "164:\tlearn: 0.2132899\ttotal: 1m 3s\tremaining: 13.4s\n",
      "165:\tlearn: 0.2125965\ttotal: 1m 3s\tremaining: 13s\n",
      "166:\tlearn: 0.2112378\ttotal: 1m 3s\tremaining: 12.6s\n",
      "167:\tlearn: 0.2106362\ttotal: 1m 4s\tremaining: 12.2s\n",
      "168:\tlearn: 0.2099201\ttotal: 1m 4s\tremaining: 11.8s\n",
      "169:\tlearn: 0.2095844\ttotal: 1m 4s\tremaining: 11.5s\n",
      "170:\tlearn: 0.2090287\ttotal: 1m 5s\tremaining: 11.1s\n",
      "171:\tlearn: 0.2082719\ttotal: 1m 5s\tremaining: 10.7s\n",
      "172:\tlearn: 0.2077148\ttotal: 1m 6s\tremaining: 10.3s\n",
      "173:\tlearn: 0.2070876\ttotal: 1m 6s\tremaining: 9.92s\n",
      "174:\tlearn: 0.2064333\ttotal: 1m 6s\tremaining: 9.54s\n",
      "175:\tlearn: 0.2055592\ttotal: 1m 7s\tremaining: 9.16s\n",
      "176:\tlearn: 0.2045715\ttotal: 1m 7s\tremaining: 8.78s\n",
      "177:\tlearn: 0.2038506\ttotal: 1m 7s\tremaining: 8.4s\n",
      "178:\tlearn: 0.2029211\ttotal: 1m 8s\tremaining: 8.02s\n",
      "179:\tlearn: 0.2013669\ttotal: 1m 8s\tremaining: 7.64s\n",
      "180:\tlearn: 0.1999284\ttotal: 1m 9s\tremaining: 7.25s\n",
      "181:\tlearn: 0.1992491\ttotal: 1m 9s\tremaining: 6.87s\n",
      "182:\tlearn: 0.1986857\ttotal: 1m 9s\tremaining: 6.49s\n",
      "183:\tlearn: 0.1984182\ttotal: 1m 10s\tremaining: 6.11s\n",
      "184:\tlearn: 0.1973178\ttotal: 1m 10s\tremaining: 5.73s\n",
      "185:\tlearn: 0.1970259\ttotal: 1m 10s\tremaining: 5.34s\n",
      "186:\tlearn: 0.1961855\ttotal: 1m 11s\tremaining: 4.96s\n",
      "187:\tlearn: 0.1956485\ttotal: 1m 11s\tremaining: 4.58s\n",
      "188:\tlearn: 0.1949655\ttotal: 1m 12s\tremaining: 4.2s\n",
      "189:\tlearn: 0.1942580\ttotal: 1m 12s\tremaining: 3.81s\n",
      "190:\tlearn: 0.1937865\ttotal: 1m 12s\tremaining: 3.43s\n",
      "191:\tlearn: 0.1931781\ttotal: 1m 13s\tremaining: 3.05s\n",
      "192:\tlearn: 0.1923575\ttotal: 1m 13s\tremaining: 2.67s\n",
      "193:\tlearn: 0.1917097\ttotal: 1m 13s\tremaining: 2.29s\n",
      "194:\tlearn: 0.1911151\ttotal: 1m 14s\tremaining: 1.9s\n",
      "195:\tlearn: 0.1904127\ttotal: 1m 14s\tremaining: 1.52s\n",
      "196:\tlearn: 0.1902370\ttotal: 1m 14s\tremaining: 1.14s\n",
      "197:\tlearn: 0.1895805\ttotal: 1m 15s\tremaining: 761ms\n",
      "198:\tlearn: 0.1884970\ttotal: 1m 15s\tremaining: 381ms\n",
      "199:\tlearn: 0.1881539\ttotal: 1m 16s\tremaining: 0us\n",
      "accuracy: 0.849\n",
      "CPU times: user 4h 4min 25s, sys: 2min 4s, total: 4h 6min 29s\n",
      "Wall time: 1h 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "сb = CatBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.5, 1],\n",
    "    'depth': [2, 4, 6],\n",
    "    'iterations': [50, 100, 200]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=cb, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(x_train_pca, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "cb_best = CatBoostClassifier(**best_params)\n",
    "\n",
    "cb_best.fit(x_train_pca, y_train)\n",
    "y_pred = cb_best.predict(x_test_pca)\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Попробуем XgBoost с оптимально подобранными параметрами с помощью optuna*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 16:20:57,020] A new study created in memory with name: no-name-77297bd2-b813-4f72-8510-70dbbf3b7450\n",
      "[I 2024-02-12 16:21:57,740] Trial 0 finished with value: 0.8985 and parameters: {'subsample': 0.683884607422591, 'eta': 0.17249979045952676, 'gamma': 9.165951123080077, 'max_depth': 2, 'n_estimators': 34}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:22:57,270] Trial 1 finished with value: 0.8985 and parameters: {'subsample': 0.8140450186244641, 'eta': 0.4020605114835208, 'gamma': 1.8778004686875094, 'max_depth': 8, 'n_estimators': 32}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:23:57,043] Trial 2 finished with value: 0.8985 and parameters: {'subsample': 0.25706553284648953, 'eta': 0.7817640900847245, 'gamma': 2.17689464115832, 'max_depth': 10, 'n_estimators': 97}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:24:57,599] Trial 3 finished with value: 0.8985 and parameters: {'subsample': 0.3250814678053049, 'eta': 0.17798719262938653, 'gamma': 6.063315741799978, 'max_depth': 4, 'n_estimators': 192}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:25:57,829] Trial 4 finished with value: 0.8985 and parameters: {'subsample': 0.30517617608666775, 'eta': 0.2172133619223766, 'gamma': 0.5541469757128936, 'max_depth': 5, 'n_estimators': 132}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:26:58,540] Trial 5 finished with value: 0.8985 and parameters: {'subsample': 0.7849992321203595, 'eta': 0.2689750541777007, 'gamma': 5.4719318420745475, 'max_depth': 4, 'n_estimators': 65}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:27:59,910] Trial 6 finished with value: 0.8985 and parameters: {'subsample': 0.5196558626010788, 'eta': 0.615192004580122, 'gamma': 4.284933649739239, 'max_depth': 9, 'n_estimators': 194}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:29:00,700] Trial 7 finished with value: 0.8985 and parameters: {'subsample': 0.1943061495422986, 'eta': 0.7965892079426903, 'gamma': 6.11624225413138, 'max_depth': 3, 'n_estimators': 31}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:30:01,311] Trial 8 finished with value: 0.8985 and parameters: {'subsample': 0.9667364647765485, 'eta': 0.22271635061799147, 'gamma': 5.920931387982064, 'max_depth': 2, 'n_estimators': 124}. Best is trial 0 with value: 0.8985.\n",
      "[I 2024-02-12 16:31:01,180] Trial 9 finished with value: 0.8985 and parameters: {'subsample': 0.6191126092628839, 'eta': 0.4900108089698132, 'gamma': 2.4857385134704457, 'max_depth': 4, 'n_estimators': 189}. Best is trial 0 with value: 0.8985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8985\n"
     ]
    }
   ],
   "source": [
    "def obj(trial):\n",
    "    params = {\n",
    "        'subsample' : trial.suggest_float('subsample', 0.001, 1),\n",
    "        'learning_rate' : trial.suggest_float('eta', 0.001, 1),\n",
    "        'gamma' : trial.suggest_float('gamma', 0, 10),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 1, 10),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 1, 200)}\n",
    "    model = xgb.XGBClassifier(params, objective='multi:softprob')\n",
    "\n",
    "    model.fit(x_train_pca, y_train)\n",
    "    return accuracy_score(y_test, model.predict(x_tes_pca))\n",
    "\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(obj, n_trials=10)\n",
    "\n",
    "score = study_xgb.best_value\n",
    "print(\"accuracy:\", study_xgb.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ XgBoost с оптуной дал лучший результат, нежели RFF (случаные признаки) и работал сравнительно быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.1131\n"
     ]
    }
   ],
   "source": [
    "rff = RFFPipeline(classifier='logreg', use_PCA=False)\n",
    "rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train -  np.mean(x_train, axis = 0)) / np.max(x_train, axis = 0)\n",
    "x_test_scaled = (x_test -  np.mean(x_test, axis = 0)) / np.max(x_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "rff = RFFPipeline(classifier='logreg', use_PCA=False)\n",
    "rff.fit(x_train_scaled, y_train)\n",
    "y_pred = rff.predict(x_test_scaled)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без PCA качество такое же как у случайного классификатора, но нормализация и стандартизация все чинит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_буду обучать logreg - оно близко по качеству к svm и обучается сильно быстрее_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:15:18<00:00, 451.83s/it] \n"
     ]
    }
   ],
   "source": [
    "n_features_list = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "score_list = []\n",
    "for n_features in tqdm(n_features_list):\n",
    "    rff = RFFPipeline(classifier='logreg', use_PCA=True, n_features=n_features)\n",
    "    rff.fit(x_train, y_train)\n",
    "    y_pred = rff.predict(x_test)\n",
    "    score_list.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX9ElEQVR4nO3dd3gUVdsG8Ht3k930BEgPIaHXBDBI3lAVoqGIgEgXQhQQhJcSsSBVEKKIFAHhQ0WRIk1EXmliAFGIIC0Y6R1CCsV00nbP90fYSZZsQrKEnZT7d117kZ195uyZSdmbM2dmFEIIASIiIqIqRCl3B4iIiIjMjQGIiIiIqhwGICIiIqpyGICIiIioymEAIiIioiqHAYiIiIiqHAYgIiIiqnIYgIiIiKjKYQAiIiKiKocBiKicuHbtGhQKBb799lu5u0JkkosXL+LFF1+Eo6MjFAoFtm3bJneXiIrEAETl1rfffguFQiE9rKys4OnpiZCQEHz++edITU2Vu4v0GGfPnpW+d0lJSXJ3h56y0NBQ/P3335gzZw7WrFmDVq1alfl7ZGRkYObMmThw4ECZt01Vi4XcHSB6nFmzZqF27drIyclBfHw8Dhw4gAkTJmDBggXYvn07/P395e4iFWHt2rVwd3fHv//+iy1btmD48OFyd4mekgcPHiAqKgpTpkzB2LFjn9r7ZGRk4MMPPwQAPPfcc0/tfajyYwCicq9r164G/5OcPHky9u3bh5deegkvv/wyzp49C2traxl7SMYIIbB+/XoMGjQIV69exbp168ptAEpPT4etra3c3ajQ7ty5AwBwcnKStyMmys3NhU6ng1qtlrsrZCY8BEYVUqdOnTBt2jRcv34da9euNXjt3LlzePXVV1G9enVYWVmhVatW2L59u0GN/vDawYMH8eabb6JGjRpwcHDA0KFD8e+//xZ6v127dqF9+/awtbWFvb09unfvjn/++cegZtiwYbCzs0NsbCx69eoFOzs7uLi4YNKkSdBqtQa1SUlJGDZsGBwdHeHk5ITQ0NAiDxGVZnsOHTqE8PBwuLi4wNbWFr1795Y+mB7dno4dO8Le3h4ODg549tlnsX79eoOaI0eOoEuXLnB0dISNjQ06duyIQ4cOGe2jMYcOHcK1a9cwYMAADBgwAAcPHsStW7cK1el0OixevBh+fn6wsrKCi4sLunTpgmPHjhnUrV27Fq1bt4aNjQ2qVauGDh064JdffpFeVygUmDlzZqH2fX19MWzYsEL76rfffsNbb70FV1dX1KxZEwBw/fp1vPXWW2jYsCGsra1Ro0YN9O3bF9euXSvUblJSEiZOnAhfX19oNBrUrFkTQ4cOxd27d5GWlgZbW1uMHz++0Hq3bt2CSqVCREREsfsvPT0db7/9Nry9vaHRaNCwYUPMnz8fQgiDOoVCgbFjx2Lbtm1o1qwZNBoNmjZtit27dxfbPgAcOHAACoUCmzZtwpw5c1CzZk1YWVmhc+fOuHTp0mPX15s5cyZ8fHwAAO+88w4UCgV8fX2l12NjY/H666/Dzc1N6t+qVasM2sjOzsb06dMREBAAR0dH2Nraon379ti/f79Uc+3aNbi4uAAAPvzwQ+nwuP77/txzzxkdFRo2bJhBf/Tz7ebPn49Fixahbt260Gg0OHPmDICS/c7l5OTgww8/RP369WFlZYUaNWqgXbt22Lt3b4n3G8lMEJVT33zzjQAg/vrrL6Ov37x5UwAQr776qrQsJiZGODo6iiZNmohPPvlELF26VHTo0EEoFAqxdevWQm37+fmJ9u3bi88//1yMGTNGKJVK0aFDB6HT6aTa7777TigUCtGlSxexZMkS8cknnwhfX1/h5OQkrl69KtWFhoYKKysr0bRpU/H666+L5cuXiz59+ggA4osvvpDqdDqd6NChg1AqleKtt94SS5YsEZ06dRL+/v4CgPjmm29M3p6WLVuKTp06iSVLloi3335bqFQq0a9fv0L7VaFQiGbNmok5c+aIZcuWieHDh4shQ4ZINZGRkUKtVougoCDx2WefiYULFwp/f3+hVqvFkSNHSvT9GzVqlKhbt64QQoiMjAxhZ2cn5s2bV6hu2LBhAoDo2rWrWLRokZg/f77o2bOnWLJkiVQzc+ZMAUC0adNGfPrpp2Lx4sVi0KBB4r333pNqAIgZM2YUat/Hx0eEhoYW2ldNmjQRHTt2FEuWLBEff/yxEEKIzZs3i+bNm4vp06eLlStXig8++EBUq1ZN+Pj4iPT0dKmN1NRU0axZM6FSqcSIESPE8uXLxezZs8Wzzz4rTp48KYQQYvDgwcLNzU3k5uYa9GfevHlCoVCI69evF7nvdDqd6NSpk1AoFGL48OFi6dKlokePHgKAmDBhgkEtANG8eXPh4eEhZs+eLRYtWiTq1KkjbGxsxN27d4t8DyGE2L9/v/RzExAQIBYuXChmzpwpbGxsROvWrYtdt6Do6GixcOFCAUAMHDhQrFmzRvz4449CCCHi4+NFzZo1hbe3t5g1a5ZYvny5ePnllwUAsXDhQqmNO3fuCA8PDxEeHi6WL18u5s2bJxo2bCgsLS2lfZqWliaWL18uAIjevXuLNWvWiDVr1ojo6GghhBAdO3YUHTt2LNS/0NBQ4ePjIz2/evWq9DNQp04d8fHHH4uFCxeK69evl/h37oMPPhAKhUKMGDFCfPnll+Kzzz4TAwcOlH6WqPxjAKJy63EBSAghHB0dRcuWLaXnnTt3Fn5+fiIzM1NaptPpRJs2bUT9+vULtR0QECCys7Ol5fPmzRMAxE8//SSEyPugc3JyEiNGjDB43/j4eOHo6GiwPDQ0VAAQs2bNMqjVf7jobdu2TQAwCAO5ubmiffv2hQJQabcnODjYILxNnDhRqFQqkZSUJIQQIikpSdjb24vAwEDx4MEDg37q19PpdKJ+/foiJCTEoK2MjAxRu3Zt8cILL4jHyc7OFjVq1BBTpkyRlg0aNEg0b97coG7fvn0CgBg3blyhNvTvffHiRaFUKkXv3r2FVqs1WiNE6QNQu3btCoWTjIyMQutHRUUJAOK7776Tlk2fPl0AMPhAfLRPe/bsEQDErl27DF739/c3+iFdkP5n5KOPPjJY/uqrrwqFQiEuXbokLQMg1Gq1wbLo6GgBwCBEGqMPQI0bNxZZWVnS8sWLFwsA4u+//y52/YL0oeLTTz81WP7GG28IDw+PQmFswIABwtHRUdrnubm5Bn0QQoh///1XuLm5iddff11adufOnSK/16UNQA4ODiIxMdGgtqS/c82bNxfdu3c3vjOoQuAhMKrQ7OzspLPB7t+/j3379qFfv35ITU3F3bt3cffuXdy7dw8hISG4ePEiYmNjDdYfOXIkLC0tpeejR4+GhYUFdu7cCQDYu3cvkpKSMHDgQKm9u3fvQqVSITAw0GB4Xm/UqFEGz9u3b48rV65Iz3fu3AkLCwuMHj1aWqZSqfDf//7XYD1Tt0ehUBi8t1arxfXr16XtSU1Nxfvvvw8rKyuDdfXrnTp1ChcvXsSgQYNw79496X3T09PRuXNnHDx4EDqdzti3Q7Jr1y7cu3cPAwcOlJYNHDgQ0dHRBocOf/jhBygUCsyYMaNQG/r+bNu2DTqdDtOnT4dSqTRaY4oRI0ZApVIZLCs4lywnJwf37t1DvXr14OTkhBMnThj0u3nz5ujdu3eR/Q4ODoanpyfWrVsnvRYTE4PTp0/jtddeK7ZvO3fuhEqlwrhx4wyWv/322xBCYNeuXQbLg4ODUbduXem5v78/HBwcDH7uihMWFmYw96V9+/YAUOL1iyKEwA8//IAePXpACGHwOxQSEoLk5GRpv6pUKqkPOp0O9+/fR25uLlq1amWw78tSnz59pENqQOl+55ycnPDPP//g4sWLT6Vv9PRxEjRVaGlpaXB1dQUAXLp0CUIITJs2DdOmTTNan5iYCC8vL+l5/fr1DV63s7ODh4eHNOdD/8etU6dORttzcHAweK6fw1JQtWrVDOYVXb9+HR4eHrCzszOoa9iwocFzU7anVq1ahd4bgPT+ly9fBgA0a9bMaHtA/jaHhoYWWZOcnCy1bczatWtRu3ZtaDQaaS5J3bp1YWNjg3Xr1mHu3LlSfzw9PVG9evUi27p8+TKUSiWaNGlSZI0pateuXWjZgwcPEBERgW+++QaxsbEG822Sk5MN+tSnT59i21cqlRg8eDCWL1+OjIwMadutrKzQt2/fYte9fv06PD09YW9vb7C8cePG0usFPfp9Bwr/3BXncT83prpz5w6SkpKwcuVKrFy50mhNYmKi9PXq1avx2Wef4dy5c8jJyZGWG/telYVH2y3N79ysWbPQs2dPNGjQAM2aNUOXLl0wZMgQnpVagTAAUYV169YtJCcno169egAgjUpMmjQJISEhRtfR15aUvs01a9bA3d290OsWFoa/Qo+OKDwJU7anqPcXj0ycLcn7fvrpp2jRooXRmkfDW0EpKSn43//+h8zMzEIBEwDWr1+POXPmPNHoTWk8OgFdz9iZg//973/xzTffYMKECQgKCpIu6DdgwIDHjnoZM3ToUHz66afYtm0bBg4ciPXr1+Oll16Co6NjqdsqzpN+38vi58YY/T577bXXigzU+sCwdu1aDBs2DL169cI777wDV1dXabK4Prg/jkKhMNrnkv4MlOZ3rkOHDrh8+TJ++ukn/PLLL/jqq6+wcOFCrFixotye7UiGGICowlqzZg0ASH+o6tSpAwCwtLREcHBwidq4ePEinn/+eel5Wloa4uLi0K1bNwCQDiu4urqWuM3H8fHxQWRkJNLS0gyCxPnz5w3qTNmex9FvT0xMTJFhUF/j4OBg0vtu3boVmZmZWL58OZydnQ1eO3/+PKZOnYpDhw6hXbt2qFu3Lvbs2YP79+8XOQpUt25d6HQ6nDlzpshABuSNWjx6Jl12djbi4uJK3PctW7YgNDQUn332mbQsMzOzULt169ZFTEzMY9tr1qwZWrZsiXXr1qFmzZq4ceMGlixZ8tj1fHx88OuvvyI1NdVgFOjcuXPS6xWBi4sL7O3todVqH/uztGXLFtSpUwdbt241CMePHh4tLjhXq1bN6GG7R0fMilLa37nq1asjLCwMYWFhSEtLQ4cOHTBz5kwGoAqCc4CoQtq3bx9mz56N2rVrY/DgwQDyQspzzz2H//u//zP6oWfsdPCVK1caDLUvX74cubm56Nq1K4C8cOXg4IC5c+ca1BXX5uN069YNubm5WL58ubRMq9UW+mA0ZXse58UXX4S9vT0iIiKQmZlp8Jr+f84BAQGoW7cu5s+fj7S0tFK/79q1a1GnTh2MGjUKr776qsFj0qRJsLOzk+bF9OnTB0II6cJ2xvrTq1cvKJVKzJo1q9AoTMH/7detWxcHDx40eH3lypVF/u/fGJVKVWgEYcmSJYXa6NOnD6Kjo/Hjjz8W2W+9IUOG4JdffsGiRYtQo0YN6WerON26dYNWq8XSpUsNli9cuBAKhaJEbZQHKpUKffr0wQ8//GA0MBb8WdKPQhXcf0eOHEFUVJTBOjY2NgBg9LIRdevWxblz5wzajY6OLvHlG0rzO3fv3j2D1+zs7FCvXj1kZWWV6L1IfhwBonJv165dOHfuHHJzc5GQkIB9+/Zh79698PHxwfbt2w0m8y5btgzt2rWDn58fRowYgTp16iAhIQFRUVG4desWoqOjDdrOzs5G586d0a9fP5w/fx5ffPEF2rVrh5dffhlA3ijI8uXLMWTIEDzzzDMYMGAAXFxccOPGDezYsQNt27Yt9CH1OD169EDbtm3x/vvv49q1a2jSpAm2bt1qMMfE1O15HAcHByxcuBDDhw/Hs88+i0GDBqFatWqIjo5GRkYGVq9eDaVSia+++gpdu3ZF06ZNERYWBi8vL8TGxmL//v1wcHDA//73P6Pt3759G/v37y80eVdPo9EgJCQEmzdvxueff47nn38eQ4YMweeff46LFy+iS5cu0Ol0+P333/H8889j7NixqFevHqZMmYLZs2ejffv2eOWVV6DRaPDXX3/B09NTup7O8OHDMWrUKPTp0wcvvPACoqOjsWfPnkKjUMV56aWXsGbNGjg6OqJJkyaIiorCr7/+iho1ahjUvfPOO9iyZQv69u2L119/HQEBAbh//z62b9+OFStWoHnz5lLtoEGD8O677+LHH3/E6NGjDSbdF6VHjx54/vnnMWXKFFy7dg3NmzfHL7/8gp9++gkTJkwwmPBc3n388cfYv38/AgMDMWLECDRp0gT379/HiRMn8Ouvv+L+/fsA8vb91q1b0bt3b3Tv3h1Xr17FihUr0KRJE4Mgbm1tjSZNmmDjxo1o0KABqlevjmbNmqFZs2Z4/fXXsWDBAoSEhOCNN95AYmIiVqxYgaZNmyIlJaVE/S3p71yTJk3w3HPPISAgANWrV8exY8ewZcuWp3oVbCpj5j7tjKik9Kcr6x9qtVq4u7uLF154QSxevFikpKQYXe/y5cti6NChwt3dXVhaWgovLy/x0ksviS1bthRq+7fffhMjR44U1apVE3Z2dmLw4MHi3r17hdrcv3+/CAkJEY6OjsLKykrUrVtXDBs2TBw7dkyqCQ0NFba2toXWnTFjhnj0V+3evXtiyJAhwsHBQTg6OoohQ4aIkydPFjoNvrTb8+glA/SnOe/fv99g+fbt20WbNm2EtbW1cHBwEK1btxbff/+9Qc3JkyfFK6+8ImrUqCE0Go3w8fER/fr1E5GRkUb3uxBCfPbZZwJAsTXffvutwaUGcnNzxaeffioaNWok1Gq1cHFxEV27dhXHjx83WG/VqlWiZcuWQqPRiGrVqomOHTuKvXv3Sq9rtVrx3nvvCWdnZ2FjYyNCQkLEpUuXijwN3tjlFf79918RFhYmnJ2dhZ2dnQgJCRHnzp0r1IYQed/DsWPHCi8vL6FWq0XNmjVFaGio0WvvdOvWTQAQhw8fLnK/PCo1NVVMnDhReHp6CktLS1G/fn3x6aefGpz6L0TeafBjxowptL6xPj9K//OxefNmg+X608Qf/VksTlGnwQshREJCghgzZozw9vYWlpaWwt3dXXTu3FmsXLlSqtHpdGLu3LnCx8dHaDQa0bJlS/Hzzz8XOoVdCCEOHz4sAgIChFqtLnRK/Nq1a0WdOnWEWq0WLVq0EHv27CnyNHhjfRWiZL9zH330kWjdurVwcnIS1tbWolGjRmLOnDkGl9Wg8k0hxBPOciOqgL799luEhYXhr7/+eio3bCQqqHfv3vj7779LdXVlInq6OAeIiOgpiouLw44dOzBkyBC5u0JEBXAOEBHRU3D16lUcOnQIX331FSwtLfHmm2/K3SWTPHjwwOj8tIKqV6/Om4hShcMARET0FPz2228ICwtDrVq1sHr1aqPXkaoINm7ciLCwsGJr9u/fb/QmpETlGecAERFRkeLi4gxuX2JMQEBAsVcGJyqPGICIiIioyuEkaCIiIqpyOAfICJ1Oh9u3b8Pe3t5s9ysiIiKiJyOEQGpqKjw9PaFUPmaMR8ZrEAkhhFi6dKl04avWrVuLI0eOFFmbnZ0tPvzwQ1GnTh2h0WiEv7+/2LVr1xO1aczNmzcNLsDHBx988MEHH3xUnMfNmzcf+1kv6wjQxo0bER4ejhUrViAwMBCLFi1CSEgIzp8/D1dX10L1U6dOxdq1a/Hll1+iUaNG2LNnD3r37o3Dhw+jZcuWJrVpjP7mgzdv3oSDg0PZbTARERE9NSkpKfD29ja4iXBRZJ0EHRgYiGeffVa6l5JOp4O3tzf++9//4v333y9U7+npiSlTpmDMmDHSsj59+sDa2hpr1641qU1jUlJS4OjoiOTkZAYgIiKiCqI0n9+yTYLOzs7G8ePHERwcnN8ZpRLBwcGF7v6rl5WVZXDjSyDvxnh//PGHyW0SERFR1SNbALp79y60Wi3c3NwMlru5uSE+Pt7oOiEhIViwYAEuXrwInU6HvXv3YuvWrYiLizO5TSAvWKWkpBg8iIiIqPKqUKfBL168GPXr10ejRo2gVqsxduxYhIWFPX6m92NERETA0dFRenh7e5dRj4mIiKg8ki0AOTs7Q6VSISEhwWB5QkJCkZeMd3FxwbZt25Ceno7r16/j3LlzsLOzQ506dUxuEwAmT56M5ORk6XHz5s0n3DoiIiIqz2QLQGq1GgEBAYiMjJSW6XQ6REZGIigoqNh1rays4OXlhdzcXPzwww/o2bPnE7Wp0Wjg4OBg8CAiIqLKS9bT4MPDwxEaGopWrVqhdevWWLRoEdLT06Ub7w0dOhReXl6IiIgAABw5cgSxsbFo0aIFYmNjMXPmTOh0Orz77rslbpOIiIhI1gDUv39/3LlzB9OnT0d8fDxatGiB3bt3S5OYb9y4YTC/JzMzE1OnTsWVK1dgZ2eHbt26Yc2aNXBycipxm0RERES8GaoRvA4QERFRxVMhrgNEREREJBcGICIiIqpyGICIiIioymEAIiIioipH1rPAyr30dEClKrxcpQIK3pMsPb3oNpRKwNratNqMDKCoOeoKBWBjY1rtgweATld0P2xtTavNzAS02rKptbHJ6zcAZGUBubllU2ttnbefASA7G8jJKZtaK6v8n5XS1Obk5NUXRaMBLCxKX5ubm7cviqJWA5aWpa/VavO+d0WxtMyrL22tTpf3s1YWtRYWefsCyPudyMgom9rS/N7zb4TxWv6NKH1tOfobIYSAVieg1f+rf1hYQquygFYI5GbnQjx4gFydYa1OJ/KWqSyQo7KETgh42avha2fkM1bP1L8RJSWokOTkZAFAJOf9uSj86NbNcAUbG+N1gBAdOxrWOjsXXduqlWGtj0/RtU2aGNY2aVJ0rY+PYW2rVkXXOjsb1nbsWHStjY1hbbduRdc++qP26qvF16al5deGhhZfm5iYX/vWW8XXXr2aXztpUvG1MTH5tTNmFF979Gh+7bx5xdfu359fu3Rp8bU//5xf+803xddu2pRfu2lT8bXffJNf+/PPxdcuXZpfu39/8bXz5uXXHj1afO2MGfm1MTHF106alF979WrxtW+9lV+bmFh8bWhofm1aWvG1r74qDBRXy78ReY8K+Dci6+JlkZGVK1Izc0Tm+PBiay8f+FPExCaJ6Jv/itsT3i229o/1O8X2U7HixxO3xOlxU4qt3bpgrVi094L47JfzYu9bU4utXfne52Lc9yfEmHXHxbcjZhRb+8nrs0SPJb+LrosOio9CZxZbO6VnuGg6fbdoOHWnGNGv+NqpL4wSPu/9LHze+1n0Hzi32No5z4VJtd8tfszfKRP+Rkif38nJ4nE4AkREVAUIAIoiXtMKgYSkB9L/6N1zdbAqojZHK3Dk4l3k6nTQCYEW6dmoXkRtrk5gfdQ1qd0X7mfAp5g+ztz+D7QPRwoG3kqGfzG1w787hgeWGuRqBUafT8RzxdS+9PnvuGfjCK1OYNKxm+hXTG2nzw7glmPedeMmR13Dm8XUvvndcVx0uQsAmPDXTUwopvaT3edwOjpvpGzk6dvwK6Z241838GeCEwBgyMW7CC6m9vDle9iP2wAAq9jkYiqBa/cycPpWXo1vUjGjswAyc3RIy8obKcvRiWJrAUCpACyUSqhVxc+sqWGrRj1XO1goFXC0LmYUzAx4HSAjpOsI3L5t/DoCHN42Xsvh7dLXlqPh7RLVVqBDYEII5Gp1yE5JQ45Wh+xcnfSvVieQKwS0ChVyLdV5w/RaHUR6usHQfq5OQKdD3tdKBXIs1dDqAK1OB6RnQKfT5dcJfb1AjkKJHAt13pC/EFCmp0uHAvQ1Wh3yagFkWmqg1ebVqh5kSIcMtAUOI+S1pUCGhfrh4QQdLLMyodVppXW1D9vVr5Om0kj90mRnQlHEnwihADIt8/+maXKyoCzmo+GB2sTa3Gwoi/l7UqpaS430e6/OzYFKV/Tfk9LUZlqqIRR5v/eW2hxYaLVQKAALpQJKhSLvX6UCKqUCuWoNlBYqqBQKaEQuNEILlSLvNaVSCZUSUCmVUCkAncYKCgtVXkjQ5UIttFApFVK9qkDbQqOBwtICFkoFLLS50Ohy82r07614+FApALUGSrVlXq0uF5Zabf776v9F3roKKw1UaksolQpY6LSwyMmGharwdlko8motNOq814QWquxsqQ8GD4UCKisNFKb83j+FvxGluQ4QA5ARvBAiUcnodALZWl2BgCGQnatDdsHAodUhJ1eHrIf/FqzPflj/aEDJfuR5jlYg69G6ArVFvT+VTMEPM/0HocG/CgUsVArDD+wiavQfpoYflHkhoOCHcuEaw7YN3uORtvXv+eh6+TVKKJV5IxL5IaSItgu+RxFtK5VFjZ1ReVOaz28eAiMq53K1j3ywFwgSUgAoQbAoFCCKCiAlCBb65bklGBovL5QKQG2hhKUq72H8g9r4h7AUDoyEAGM1j36YSh+qCoXh/8wLhAHDmiL6pSpBSNGHgQIhQAoDBdqQRhQUgELBD3iqehiAqMoTQiBHK4yHBa0OObkC2VotsnNFobBR4lBhdFREGB8VeaS2AmUMWCgVUshQW+TNB8h7XmB5gdcspdf1yx5Z36CNh+tIyxRQq1QGbWssjLWZ96+K/4snogIYgKhCEEIgI1uLlMwcpDzIRWpmziNf5yLlwcNlmblIy8wtNIph7LCKfnlFUtpgoXm07tFQUVQAeRg2NAVCx+OCDQ8VEFFFwQBEZqHVCaRlFQgpRoJL6qNfP6zTP9eaaSik4KGSQiMKBqFAUUQoKH5Uw6BdIyMaBYPFo21aKBU8XEFEVAYYgKhEsnN1UmBJLRBMUh4UDCvGg0vKgxykZhVzZlYpWCgVcLC2hL2VBRysLOFgnfdv/nNLOFhZwFZjAY2liodKiIjIKAYgMkqrEzhwPhFr/ryOI1fu40FOMaesl4LGQimFlLwgU/BrwxBTMODoX7e2VHEEhIiInhgDEBn4Nz0bG4/dxNo/r+PWv4WvuWCnsTA++mJtWehrB2uLQgFHY1HMZc+JiIjMhAGIAADRN5PwXdR1/O/0ben6KY7WlujXqib6BNSEu4MV7DQWsHjMVT6JiIgqAgagKiwzR4ufT8dhTdQ1RN/Kv4R6My8HDP2PL3o094S1miM2RERU+TAAVUE372dg7ZHr2PTXTfybkXfLBrVKie7+HhgS5IOW3k6cZ0NERJUaA1AVodMJHLx4B2uirmPf+UTptmFeTtYYFFgL/Z/1hrOdRt5OEhERmQkDUCWXnJGDzcfzJjVfu5chLW9f3xlD/uODTo1cOa+HiIiqHAagSiomNhlroq7jp+hYZObkTWq2t7LAqwE18dp/fFDXxU7mHhIREcmHAagSycrVYtff8fgu6hpO3EiSljdyt8fQIF/0aukJGzW/5URERPw0rASycrVYtv8y1h+5jrtp2QDyrpjc1c8DQ4N80MqnGic1ExERFcAAVMEJIfDeltPYduo2AMDdwQqDAmthQGtvuNpbydw7IiKi8okBqIL74sBlbDt1GyqlAvP6+OPlFp6w5KRmIiKiYjEAVWC7Y+Lw6Z7zAIBZPZuiT0BNmXtERERUMXCooIKKiU3GxI3RAIBhbXwxONBH5h4RERFVHAxAFVBiSiaGrz6GBzladGjggqndG8vdJSIiogqFAaiCyczRYsR3xxCfkol6rnZYOqglL2RIRERUSvzkrECEEJi0ORrRt5LhZGOJr0NbwcHKUu5uERERVTgMQBXI55GX8PPpOFgoFVjxWgB8atjK3SUiIqIKiQGogvj59G0s/PUCAGBO72b4T50aMveIiIio4mIAqgCibybh7U15Z3wNb1cb/Z+tJXOPiIiIKjYGoHIuPjkTI747hqxcHZ5v6ILJ3XjGFxER0ZNiACrHHmTnnfGVmJqFBm52+HxgS6iUvKcXERHRk2IAKqd0OoG3N5/C37HJqG6rxldDn4U9z/giIiIqEwxA5dSiyIvY+Xc8LFV5Z3zVqmEjd5eIiIgqDQagcuinU7H4PPIiAGBubz+0rl1d5h4RERFVLgxA5czJG//inS2nAQBvdqiDvq28Ze4RERFR5cMAVM6898NpZOfqENzYFe92aSR3d4iIiColBqBy5F5aFi4kpAEAPn21Oc/4IiIiekoYgMqR07HJAIA6zraoZquWuTdERESVFwNQOXL6Zl4A8q/pKHNPiIiIKjcGoHLk9K0kAIB/TSdZ+0FERFTZyR6Ali1bBl9fX1hZWSEwMBBHjx4ttn7RokVo2LAhrK2t4e3tjYkTJyIzM1N6febMmVAoFAaPRo3K/2RiIQSib+WNADX3dpK3M0RERJWchZxvvnHjRoSHh2PFihUIDAzEokWLEBISgvPnz8PV1bVQ/fr16/H+++9j1apVaNOmDS5cuIBhw4ZBoVBgwYIFUl3Tpk3x66+/Ss8tLGTdzBKJS87E3bQsWCgVaOrpIHd3iIiIKjVZR4AWLFiAESNGICwsDE2aNMGKFStgY2ODVatWGa0/fPgw2rZti0GDBsHX1xcvvvgiBg4cWGjUyMLCAu7u7tLD2dnZHJvzRPSHvxq42cPKUiVvZ4iIiCo52QJQdnY2jh8/juDg4PzOKJUIDg5GVFSU0XXatGmD48ePS4HnypUr2LlzJ7p162ZQd/HiRXh6eqJOnToYPHgwbty4UWxfsrKykJKSYvAwt1M39Ye/OAGaiIjoaZPt2NDdu3eh1Wrh5uZmsNzNzQ3nzp0zus6gQYNw9+5dtGvXDkII5ObmYtSoUfjggw+kmsDAQHz77bdo2LAh4uLi8OGHH6J9+/aIiYmBvb290XYjIiLw4Ycflt3GmYAToImIiMxH9knQpXHgwAHMnTsXX3zxBU6cOIGtW7dix44dmD17tlTTtWtX9O3bF/7+/ggJCcHOnTuRlJSETZs2Fdnu5MmTkZycLD1u3rxpjs2R6HQCf9/iKfBERETmItsIkLOzM1QqFRISEgyWJyQkwN3d3eg606ZNw5AhQzB8+HAAgJ+fH9LT0zFy5EhMmTIFSmXhPOfk5IQGDRrg0qVLRfZFo9FAo9E8wdY8mav30pGalQuNhRIN3IyPUhEREVHZkW0ESK1WIyAgAJGRkdIynU6HyMhIBAUFGV0nIyOjUMhRqfImDAshjK6TlpaGy5cvw8PDo4x6Xvb0h7+aeTnCUlWhBuWIiIgqJFnPDw8PD0doaChatWqF1q1bY9GiRUhPT0dYWBgAYOjQofDy8kJERAQAoEePHliwYAFatmyJwMBAXLp0CdOmTUOPHj2kIDRp0iT06NEDPj4+uH37NmbMmAGVSoWBAwfKtp2PE80rQBMREZmVrAGof//+uHPnDqZPn474+Hi0aNECu3fvliZG37hxw2DEZ+rUqVAoFJg6dSpiY2Ph4uKCHj16YM6cOVLNrVu3MHDgQNy7dw8uLi5o164d/vzzT7i4uJh9+0pKPwLUnBOgiYiIzEIhijp2VIWlpKTA0dERycnJcHB4uhclzNHq0GzGHmTl6rDv7Y6o42L3VN+PiIiosirN5zcnnMjsQkIqsnJ1sLeygG8NW7m7Q0REVCUwAMnsdIHT35VKhcy9ISIiqhoYgGQWfTMJAOf/EBERmRMDkMyipREgJ3k7QkREVIUwAMnoQbYWFxJSAfAeYERERObEACSjM3HJ0OoEXOw1cHewkrs7REREVQYDkIzOxeeN/vh5OUKh4ARoIiIic2EAktG9tGwAgJuDfPchIyIiqooYgGSUlJEDAHC0VsvcEyIioqqFAUhGSRl5I0DVbCxl7gkREVHVwgAko3+lAMQRICIiInNiAJLRvw8PgTlxBIiIiMisGIBkJB0Cs+UIEBERkTkxAMlIPwLEOUBERETmxQAkE61OICVTfwiMI0BERETmxAAkk+QHORAi72tHa44AERERmRMDkEz0Z4DZayxgqeK3gYiIyJz4ySsT/UUQnWw5+kNERGRuDEAySeI1gIiIiGTDACST/GsAMQARERGZGwOQTHgbDCIiIvkwAMmEt8EgIiKSDwOQTHgbDCIiIvkwAMlEfwjMidcAIiIiMjsGIJn8m/7wNhi8DxgREZHZMQDJRD8HiGeBERERmR8DkEySH/BGqERERHJhAJIJzwIjIiKSDwOQDDJztMjM0QHgWWBERERyYACSgX70x0KpgJ3GQubeEBERVT0MQDLQnwHmZGMJhUIhc2+IiIiqHgYgGSTxDDAiIiJZMQDJQH8VaJ4BRkREJA8GIBnwGkBERETyYgCSAe8ET0REJC8GIBkkSYfAOAJEREQkBwYgGeTfCZ4BiIiISA4MQDLIyM4FANhpVDL3hIiIqGpiAJJBrk4AACxU3P1ERERy4CewDLQPA5CKF0EkIiKSBQOQDPQjQColAxAREZEcGIBkoJMOgTEAERERyYEBSAa5urw7wXMEiIiISB4MQDLQzwGyYAAiIiKShewBaNmyZfD19YWVlRUCAwNx9OjRYusXLVqEhg0bwtraGt7e3pg4cSIyMzOfqE1z088BUnISNBERkSxkDUAbN25EeHg4ZsyYgRMnTqB58+YICQlBYmKi0fr169fj/fffx4wZM3D27Fl8/fXX2LhxIz744AOT25SDlnOAiIiIZCVrAFqwYAFGjBiBsLAwNGnSBCtWrICNjQ1WrVpltP7w4cNo27YtBg0aBF9fX7z44osYOHCgwQhPaduUQ65WfxaY7ANwREREVZJsn8DZ2dk4fvw4goOD8zujVCI4OBhRUVFG12nTpg2OHz8uBZ4rV65g586d6Natm8ltykEnOAeIiIhIThZyvfHdu3eh1Wrh5uZmsNzNzQ3nzp0zus6gQYNw9+5dtGvXDkII5ObmYtSoUdIhMFPaBICsrCxkZWVJz1NSUkzdrBLhdYCIiIjkVaGOwRw4cABz587FF198gRMnTmDr1q3YsWMHZs+e/UTtRkREwNHRUXp4e3uXUY+N0zIAERERyUq2ESBnZ2eoVCokJCQYLE9ISIC7u7vRdaZNm4YhQ4Zg+PDhAAA/Pz+kp6dj5MiRmDJlikltAsDkyZMRHh4uPU9JSXmqIYjXASIiIpKXbCNAarUaAQEBiIyMlJbpdDpERkYiKCjI6DoZGRlQPjJxWKXKu6O6EMKkNgFAo9HAwcHB4PE0abWcA0RERCQn2UaAACA8PByhoaFo1aoVWrdujUWLFiE9PR1hYWEAgKFDh8LLywsREREAgB49emDBggVo2bIlAgMDcenSJUybNg09evSQgtDj2iwPtIKHwIiIiOQkawDq378/7ty5g+nTpyM+Ph4tWrTA7t27pUnMN27cMBjxmTp1KhQKBaZOnYrY2Fi4uLigR48emDNnTonbLA/yrwRdoaZgERERVRoKIR4OR5AkJSUFjo6OSE5OfiqHw1rM+gVJGTn4NbwD6rnal3n7REREVVFpPr85BCEDLS+ESEREJCt+AssglzdDJSIikhUDkAw4CZqIiEheDEAy0HIEiIiISFYMQGYmhOCVoImIiGTGAGRm+vADMAARERHJhQHIzHIZgIiIiGTHAGRmugKXXeKFEImIiOTBT2Az4wgQERGR/BiAzEx/EUSAZ4ERERHJhQHIzAqOACkZgIiIiGTBAGRmvAYQERGR/BiAzIxXgSYiIpIfA5CZ6ecAcQSIiIhIPgxAZpar0wHgCBAREZGcGIDMjLfBICIikh8DkJnlSgGIu56IiEgu/BQ2M54FRkREJD8GIDPjITAiIiL5MQCZmf4QmIWKAYiIiEguDEBmJo0AKRiAiIiI5MIAZGY8DZ6IiEh+DEBm9jD/MAARERHJiAHIzPQjQJwDREREJB8GIDPT8jpAREREsuOnsJlJF0LkABAREZFsGIDMLP9CiNz1REREcuGnsJnl8kKIREREsmMAMjMdL4RIREQkOwYgM+MIEBERkfwYgMxMqz8NngGIiIhINgxAZqYfAVLyVhhERESyYQAyMy3nABEREcmOAcjMeCFEIiIi+Zn0Kbx///6y7keVkX8dII4AERERycWkANSlSxfUrVsXH330EW7evFnWfarUeBYYERGR/EwKQLGxsRg7diy2bNmCOnXqICQkBJs2bUJ2dnZZ96/SkQ6BcRI0ERGRbEwKQM7Ozpg4cSJOnTqFI0eOoEGDBnjrrbfg6emJcePGITo6uqz7WWnkah8GIE6CJiIiks0Tz8R95plnMHnyZIwdOxZpaWlYtWoVAgIC0L59e/zzzz9l0cdKRSs4B4iIiEhuJgegnJwcbNmyBd26dYOPjw/27NmDpUuXIiEhAZcuXYKPjw/69u1bln2tFPQXQuQcICIiIvlYmLLSf//7X3z//fcQQmDIkCGYN28emjVrJr1ua2uL+fPnw9PTs8w6Wlnk8iwwIiIi2ZkUgM6cOYMlS5bglVdegUajMVrj7OzM0+WN0D6cA6RkACIiIpKNSQEoMjLy8Q1bWKBjx46mNF+pcQSIiIhIfibNAYqIiMCqVasKLV+1ahU++eSTJ+5UZaYTvBI0ERGR3Ez6FP6///s/NGrUqNDypk2bYsWKFU/cqcqMI0BERETyMykAxcfHw8PDo9ByFxcXxMXFlbq9ZcuWwdfXF1ZWVggMDMTRo0eLrH3uueegUCgKPbp37y7VDBs2rNDrXbp0KXW/ngb9HCCeBUZERCQfkwKQt7c3Dh06VGj5oUOHSn3m18aNGxEeHo4ZM2bgxIkTaN68OUJCQpCYmGi0fuvWrYiLi5MeMTExUKlUhU6579Kli0Hd999/X6p+PS28FQYREZH8TJoEPWLECEyYMAE5OTno1KkTgLyJ0e+++y7efvvtUrW1YMECjBgxAmFhYQCAFStWYMeOHVi1ahXef//9QvXVq1c3eL5hwwbY2NgUCkAajQbu7u6l6os56K8DxENgRERE8jEpAL3zzju4d+8e3nrrLen+X1ZWVnjvvfcwefLkEreTnZ2N48ePG6yjVCoRHByMqKioErXx9ddfY8CAAbC1tTVYfuDAAbi6uqJatWro1KkTPvroI9SoUcNoG1lZWcjKypKep6SklHgbSuvhETCOABEREcnIpENgCoUCn3zyCe7cuYM///wT0dHRuH//PqZPn16qdu7evQutVgs3NzeD5W5uboiPj3/s+kePHkVMTAyGDx9usLxLly747rvvEBkZiU8++QS//fYbunbtCq1Wa7SdiIgIODo6Sg9vb+9SbUdpcASIiIhIfiaNAOnZ2dnh2WefLau+lNrXX38NPz8/tG7d2mD5gAEDpK/9/Pzg7++PunXr4sCBA+jcuXOhdiZPnozw8HDpeUpKylMLQdLNUHkaPBERkWxMDkDHjh3Dpk2bcOPGDekwmN7WrVtL1IazszNUKhUSEhIMlickJDx2/k56ejo2bNiAWbNmPfZ96tSpA2dnZ1y6dMloANJoNEVe0bqsaXkaPBERkexMGobYsGED2rRpg7Nnz+LHH39ETk4O/vnnH+zbtw+Ojo4lbketViMgIMDgytI6nQ6RkZEICgoqdt3NmzcjKysLr7322mPf59atW7h3757RU/fNTX8WGG+FQUREJB+TAtDcuXOxcOFC/O9//4NarcbixYtx7tw59OvXD7Vq1SpVW+Hh4fjyyy+xevVqnD17FqNHj0Z6erp0VtjQoUONTqz++uuv0atXr0ITm9PS0vDOO+/gzz//xLVr1xAZGYmePXuiXr16CAkJMWVzy5T+StAcASIiIpKPSYfALl++LF14UK1WIz09HQqFAhMnTkSnTp3w4Ycflrit/v37486dO5g+fTri4+PRokUL7N69W5oYfePGDSgfmS9z/vx5/PHHH/jll18KtadSqXD69GmsXr0aSUlJ8PT0xIsvvojZs2eb7TBXcXJ5IUQiIiLZmRSAqlWrhtTUVACAl5cXYmJi4Ofnh6SkJGRkZJS6vbFjx2Ls2LFGXztw4EChZQ0bNoR4OJLyKGtra+zZs6fUfTAXzgEiIiKSn0kBqEOHDti7dy/8/PzQt29fjB8/Hvv27cPevXuNTjKmfLkPT4PnCBAREZF8TApAS5cuRWZmJgBgypQpsLS0xOHDh9GnTx9MnTq1TDtY2Wh5KwwiIiLZlToA5ebm4ueff5YmFCuVSqO3rCDjtIIBiIiISG6lPgvMwsICo0aNkkaAqHT0k6AteCFEIiIi2Zj0Kdy6dWucOnWqjLtSNfAQGBERkfxMmgP01ltvITw8HDdv3kRAQEChG5H6+/uXSecqI+ksMBUDEBERkVxMCkD6e22NGzdOWqZQKCCEgEKhKPKmo1TgStAKBiAiIiK5mBSArl69Wtb9qDJ4HSAiIiL5mRSAfHx8yrofVQbnABEREcnPpAD03XffFfv60KFDTepMVZDLOUBERESyMykAjR8/3uB5Tk4OMjIyoFarYWNjwwBUDO3DK0HzEBgREZF8TDoN/t9//zV4pKWl4fz582jXrh2+//77su5jpcJJ0ERERPIrs6vx1a9fHx9//HGh0SEylD8JmhdCJCIikkuZfgpbWFjg9u3bZdlkpSNNguYcICIiItmYNAdo+/btBs+FEIiLi8PSpUvRtm3bMulYZcXT4ImIiORnUgDq1auXwXOFQgEXFxd06tQJn332WVn0q1ISQkhzgHgaPBERkXxMCkC6h2cyUek8zD4AABUnQRMREcmGM3HNSCfyExDPAiMiIpKPSQGoT58++OSTTwotnzdvHvr27fvEnaqsCuQfgPmHiIhINiYFoIMHD6Jbt26Flnft2hUHDx584k5VVgL5CYgDQERERPIxKQClpaVBrVYXWm5paYmUlJQn7lRVwPxDREQkH5MCkJ+fHzZu3Fho+YYNG9CkSZMn7lRlZXAIjIiIiGRj0llg06ZNwyuvvILLly+jU6dOAIDIyEh8//332Lx5c5l2sLJS8BgYERGRbEwKQD169MC2bdswd+5cbNmyBdbW1vD398evv/6Kjh07lnUfK42CI0CMP0RERPIxKQABQPfu3dG9e/ey7EuVwgEgIiIi+Zg0B+ivv/7CkSNHCi0/cuQIjh079sSdqqwKngVGRERE8jEpAI0ZMwY3b94stDw2NhZjxox54k5VVoaHwDgEREREJBeTAtCZM2fwzDPPFFresmVLnDlz5ok7VVkZXAeR+YeIiEg2JgUgjUaDhISEQsvj4uJgYWHytCIiIiIiszApAL344ouYPHkykpOTpWVJSUn44IMP8MILL5RZ5yobwQsBERERlQsmDdfMnz8fHTp0gI+PD1q2bAkAOHXqFNzc3LBmzZoy7WBlwkNgRERE5YNJAcjLywunT5/GunXrEB0dDWtra4SFhWHgwIGwtLQs6z5WGpwETUREVD6YPGHH1tYW7dq1Q61atZCdnQ0A2LVrFwDg5ZdfLpveERERET0FJgWgK1euoHfv3vj777+hUCgghDC4tYNWqy2zDlYqBUeAOABEREQkG5MmQY8fPx61a9dGYmIibGxsEBMTg99++w2tWrXCgQMHyriLlUfBCyEy/xAREcnHpBGgqKgo7Nu3D87OzlAqlVCpVGjXrh0iIiIwbtw4nDx5sqz7WSkYzAHiEBAREZFsTBoB0mq1sLe3BwA4Ozvj9u3bAAAfHx+cP3++7HpHRERE9BSYNALUrFkzREdHo3bt2ggMDMS8efOgVquxcuVK1KlTp6z7WGkYnAYvWy+IiIjIpAA0depUpKenAwBmzZqFl156Ce3bt0eNGjWwcePGMu1gZVLwQog8AkZERCQfkwJQSEiI9HW9evVw7tw53L9/H9WqVePclhLifiIiIpJPmd24q3r16mXVVKXFG2EQERGVDyZNgibT8FZgRERE5QMDkBnprwPEo19ERETyYgAiIiKiKqdcBKBly5bB19cXVlZWCAwMxNGjR4usfe6556BQKAo9unfvLtUIITB9+nR4eHjA2toawcHBuHjxojk2pXgPD4FxAIiIiEhesgegjRs3Ijw8HDNmzMCJEyfQvHlzhISEIDEx0Wj91q1bERcXJz1iYmKgUqnQt29fqWbevHn4/PPPsWLFChw5cgS2trYICQlBZmamuTbLKP0UIJ4BRkREJC/ZA9CCBQswYsQIhIWFoUmTJlixYgVsbGywatUqo/XVq1eHu7u79Ni7dy9sbGykACSEwKJFizB16lT07NkT/v7++O6773D79m1s27bNjFtWmOAIEBERUbkgawDKzs7G8ePHERwcLC1TKpUIDg5GVFRUidr4+uuvMWDAANja2gIArl69ivj4eIM2HR0dERgYWOI2iYiIqHIrs+sAmeLu3bvQarVwc3MzWO7m5oZz5849dv2jR48iJiYGX3/9tbQsPj5eauPRNvWvPSorKwtZWVnS85SUlBJvQ2nwLDAiIqLyQfZDYE/i66+/hp+fH1q3bv1E7URERMDR0VF6eHt7l1EPDeUfAmMCIiIikpOsAcjZ2RkqlQoJCQkGyxMSEuDu7l7suunp6diwYQPeeOMNg+X69UrT5uTJk5GcnCw9bt68WdpNKRHpOojMP0RERLKSNQCp1WoEBAQgMjJSWqbT6RAZGYmgoKBi1928eTOysrLw2muvGSyvXbs23N3dDdpMSUnBkSNHimxTo9HAwcHB4EFERESVl6xzgAAgPDwcoaGhaNWqFVq3bo1FixYhPT0dYWFhAIChQ4fCy8sLERERBut9/fXX6NWrF2rUqGGwXKFQYMKECfjoo49Qv3591K5dG9OmTYOnpyd69eplrs0ySn83eA4AERERyUv2ANS/f3/cuXMH06dPR3x8PFq0aIHdu3dLk5hv3LgBpdJwoOr8+fP4448/8Msvvxht891330V6ejpGjhyJpKQktGvXDrt374aVldVT357iSHOAmICIiIhkpRCCt+h8VEpKChwdHZGcnFymh8Nu3s9A+3n7YW2pwtnZXcqsXSIiIird53eFPguMiIiIyBQMQGbEQ2BERETlAwOQGUkXQpS5H0RERFUdAxARERFVOQxAZpR/CIxjQERERHJiADIj/el2jD9ERETyYgAyI5F/MzAiIiKSEQMQERERVTkMQGbEQ2BERETlAwOQGXESNBERUfnAAGRWD68DxPxDREQkKwYgIiIiqnIYgMyIJ4ERERGVDwxAZiRNguYxMCIiIlkxAJmRfgSIiIiI5MUAJAOO/xAREcmLAciMBM8CIyIiKhcYgMwo/xAYExAREZGcGIDMiHOAiIiIygcGIBnwEBgREZG8GIDMSJoDJHM/iIiIqjoGIDPKvxeYvP0gIiKq6hiAiIiIqMphAJKBggfBiIiIZMUAZEY8BEZERFQ+MACZESdBExERlQ8MQERERFTlMACZUf4hMI4BERERyYkByIx4IWgiIqLygQHIjATvhUFERFQuMADJgEfAiIiI5MUAZEb68R8GICIiInkxAJmRNAmaJ8ITERHJigHIrDgHiIiIqDxgAJIBD4ERERHJiwHIjPIPgREREZGcGIDMKH8SNCMQERGRnBiAiIiIqMphADIjHgIjIiIqHxiAzEgwAREREZULDEBmxJPgiYiIygcGIBlwAIiIiEheDEBmJB0B41lgREREsmIAMiPx8CAY4w8REZG8GIDMiZOAiIiIygXZA9CyZcvg6+sLKysrBAYG4ujRo8XWJyUlYcyYMfDw8IBGo0GDBg2wc+dO6fWZM2dCoVAYPBo1avS0N6NUeASMiIhIXhZyvvnGjRsRHh6OFStWIDAwEIsWLUJISAjOnz8PV1fXQvXZ2dl44YUX4Orqii1btsDLywvXr1+Hk5OTQV3Tpk3x66+/Ss8tLGTdTIl0JWgeBCMiIpKVrMlgwYIFGDFiBMLCwgAAK1aswI4dO7Bq1Sq8//77hepXrVqF+/fv4/Dhw7C0tAQA+Pr6FqqzsLCAu7v7U+27KfInQcvbDyIioqpOtkNg2dnZOH78OIKDg/M7o1QiODgYUVFRRtfZvn07goKCMGbMGLi5uaFZs2aYO3cutFqtQd3Fixfh6emJOnXqYPDgwbhx40axfcnKykJKSorB42kQnARERERULsgWgO7evQutVgs3NzeD5W5uboiPjze6zpUrV7BlyxZotVrs3LkT06ZNw2effYaPPvpIqgkMDMS3336L3bt3Y/ny5bh69Srat2+P1NTUIvsSEREBR0dH6eHt7V02G0lERETlUvmYHFNCOp0Orq6uWLlyJVQqFQICAhAbG4tPP/0UM2bMAAB07dpVqvf390dgYCB8fHywadMmvPHGG0bbnTx5MsLDw6XnKSkpTyUE8TpARERE5YNsAcjZ2RkqlQoJCQkGyxMSEoqcv+Ph4QFLS0uoVCppWePGjREfH4/s7Gyo1epC6zg5OaFBgwa4dOlSkX3RaDTQaDQmbknJ5U+CJiIiIjnJdghMrVYjICAAkZGR0jKdTofIyEgEBQUZXadt27a4dOkSdDqdtOzChQvw8PAwGn4AIC0tDZcvX4aHh0fZboAJpJuhEhERkaxkvQ5QeHg4vvzyS6xevRpnz57F6NGjkZ6eLp0VNnToUEyePFmqHz16NO7fv4/x48fjwoUL2LFjB+bOnYsxY8ZINZMmTcJvv/2Ga9eu4fDhw+jduzdUKhUGDhxo9u0rCo+AERERyUvWOUD9+/fHnTt3MH36dMTHx6NFixbYvXu3NDH6xo0bUCrzM5q3tzf27NmDiRMnwt/fH15eXhg/fjzee+89qebWrVsYOHAg7t27BxcXF7Rr1w5//vknXFxczL59j5IOgTEAERERyUoheFymkJSUFDg6OiI5ORkODg5l1u7+c4kI+/YvNPNywM//bV9m7RIREVHpPr9lvxVGVcQrQRMREcmLAciMpLvBM/8QERHJigHIjKTrAMnbDSIioiqPAciMONuKiIiofGAAkgOPgREREcmKAciMeCVoIiKi8oEByIz0VxzgABAREZG8GIDMiFOAiIiIygcGIBlwAIiIiEheDEBmJJ0Gz2NgREREsmIAMiseBCMiIioPGIDMiBdCJCIiKh8YgGTAI2BERETyYgAyo/zrADEBERERyYkByIx4KwwiIqLygQHIjPR3g+cAEBERkbwYgGTA/ENERCQvBiAzyr8OkLz9ICIiquoYgMyIU4CIiIjKBwYgGfAsMCIiInkxAJkR7wZPRERUPjAAERERUZXDAGRGnARNRERUPjAAyYBzgIiIiOTFAGRG+gshcgSIiIhIXgxAZsRbYRAREZUPDEBmxABERERUPjAAyUDBY2BERESyYgAyI/0AEOMPERGRvBiAzEjwGBgREVG5wABkRtIIEIeAiIiIZMUAJAPmHyIiInkxAJmTdCVoRiAiIiI5MQCZkQDnABEREZUHDEBmJN0LTN5uEBERVXkMQDLgETAiIiJ5MQCZEQ+AERERlQ8MQGaUfxkgDgERERHJiQFIBjwERkREJC8GIDPSnwXG/ENERCQvBiAz4p0wiIiIygcGIDPirTCIiIjKBwYgGSh4EIyIiEhWDEDm9PAYGEeAiIiI5CV7AFq2bBl8fX1hZWWFwMBAHD16tNj6pKQkjBkzBh4eHtBoNGjQoAF27tz5RG2aC6cAERERlQ+yBqCNGzciPDwcM2bMwIkTJ9C8eXOEhIQgMTHRaH12djZeeOEFXLt2DVu2bMH58+fx5ZdfwsvLy+Q2zUm6FQZHgIiIiGQlawBasGABRowYgbCwMDRp0gQrVqyAjY0NVq1aZbR+1apVuH//PrZt24a2bdvC19cXHTt2RPPmzU1uUw6cA0RERCQv2QJQdnY2jh8/juDg4PzOKJUIDg5GVFSU0XW2b9+OoKAgjBkzBm5ubmjWrBnmzp0LrVZrcpsAkJWVhZSUFIPH0yB4HjwREVG5IFsAunv3LrRaLdzc3AyWu7m5IT4+3ug6V65cwZYtW6DVarFz505MmzYNn332GT766COT2wSAiIgIODo6Sg9vb+8n3DrjeCcMIiKi8kH2SdClodPp4OrqipUrVyIgIAD9+/fHlClTsGLFiidqd/LkyUhOTpYeN2/eLKMeG5LmAD2V1omIiKikLOR6Y2dnZ6hUKiQkJBgsT0hIgLu7u9F1PDw8YGlpCZVKJS1r3Lgx4uPjkZ2dbVKbAKDRaKDRaJ5ga0pHwVnQREREspJtBEitViMgIACRkZHSMp1Oh8jISAQFBRldp23btrh06RJ0Op207MKFC/Dw8IBarTapTXPiDCAiIqLyQdZDYOHh4fjyyy+xevVqnD17FqNHj0Z6ejrCwsIAAEOHDsXkyZOl+tGjR+P+/fsYP348Lly4gB07dmDu3LkYM2ZMiduUk34SNMd/iIiI5CXbITAA6N+/P+7cuYPp06cjPj4eLVq0wO7du6VJzDdu3IBSmZ/RvL29sWfPHkycOBH+/v7w8vLC+PHj8d5775W4zfKAR8CIiIjkpRA8N7uQlJQUODo6Ijk5GQ4ODmXW7le/X8FHO86iVwtPLBrQsszaJSIiotJ9fleos8AqOkZNIiKi8oEByIwE9DdD5TEwIiIiOTEAyYDxh4iISF4MQGYkHQJjAiIiIpIVA5AZcQoQERFR+cAAZEb5t8LgEBAREZGcGIBkwDnQRERE8mIAMiPBg2BERETlAgOQGfFu8EREROUDA5AZ1bBVo6GbPTwcreTuChERUZUm673AqpoBrWthQOtacneDiIioyuMIEBEREVU5DEBERERU5TAAERERUZXDAERERERVDgMQERERVTkMQERERFTlMAARERFRlcMARERERFUOAxARERFVOQxAREREVOUwABEREVGVwwBEREREVQ4DEBEREVU5DEBERERU5VjI3YHySAgBAEhJSZG5J0RERFRS+s9t/ed4cRiAjEhNTQUAeHt7y9wTIiIiKq3U1FQ4OjoWW6MQJYlJVYxOp8Pt27dhb28PhUJRZu2mpKTA29sbN2/ehIODQ5m1S4a4n82H+9o8uJ/Ng/vZPJ7mfhZCIDU1FZ6enlAqi5/lwxEgI5RKJWrWrPnU2ndwcOAvlxlwP5sP97V5cD+bB/ezeTyt/fy4kR89ToImIiKiKocBiIiIiKocBiAz0mg0mDFjBjQajdxdqdS4n82H+9o8uJ/Ng/vZPMrLfuYkaCIiIqpyOAJEREREVQ4DEBEREVU5DEBERERU5TAAERERUZXDAGRGy5Ytg6+vL6ysrBAYGIijR4/K3aVyKyIiAs8++yzs7e3h6uqKXr164fz58wY1mZmZGDNmDGrUqAE7Ozv06dMHCQkJBjU3btxA9+7dYWNjA1dXV7zzzjvIzc01qDlw4ACeeeYZaDQa1KtXD99+++3T3rxy6+OPP4ZCocCECROkZdzPZSM2NhavvfYaatSoAWtra/j5+eHYsWPS60IITJ8+HR4eHrC2tkZwcDAuXrxo0Mb9+/cxePBgODg4wMnJCW+88QbS0tIMak6fPo327dvDysoK3t7emDdvnlm2r7zQarWYNm0aateuDWtra9StWxezZ882uDcU93XpHTx4ED169ICnpycUCgW2bdtm8Lo59+nmzZvRqFEjWFlZwc/PDzt37jRtowSZxYYNG4RarRarVq0S//zzjxgxYoRwcnISCQkJcnetXAoJCRHffPONiImJEadOnRLdunUTtWrVEmlpaVLNqFGjhLe3t4iMjBTHjh0T//nPf0SbNm2k13Nzc0WzZs1EcHCwOHnypNi5c6dwdnYWkydPlmquXLkibGxsRHh4uDhz5oxYsmSJUKlUYvfu3Wbd3vLg6NGjwtfXV/j7+4vx48dLy7mfn9z9+/eFj4+PGDZsmDhy5Ii4cuWK2LNnj7h06ZJU8/HHHwtHR0exbds2ER0dLV5++WVRu3Zt8eDBA6mmS5cuonnz5uLPP/8Uv//+u6hXr54YOHCg9HpycrJwc3MTgwcPFjExMeL7778X1tbW4v/+7//Mur1ymjNnjqhRo4b4+eefxdWrV8XmzZuFnZ2dWLx4sVTDfV16O3fuFFOmTBFbt24VAMSPP/5o8Lq59umhQ4eESqUS8+bNE2fOnBFTp04VlpaW4u+//y71NjEAmUnr1q3FmDFjpOdarVZ4enqKiIgIGXtVcSQmJgoA4rfffhNCCJGUlCQsLS3F5s2bpZqzZ88KACIqKkoIkfcLq1QqRXx8vFSzfPly4eDgILKysoQQQrz77ruiadOmBu/Vv39/ERIS8rQ3qVxJTU0V9evXF3v37hUdO3aUAhD3c9l47733RLt27Yp8XafTCXd3d/Hpp59Ky5KSkoRGoxHff/+9EEKIM2fOCADir7/+kmp27dolFAqFiI2NFUII8cUXX4hq1apJ+13/3g0bNizrTSq3unfvLl5//XWDZa+88ooYPHiwEIL7uiw8GoDMuU/79esnunfvbtCfwMBA8eabb5Z6O3gIzAyys7Nx/PhxBAcHS8uUSiWCg4MRFRUlY88qjuTkZABA9erVAQDHjx9HTk6OwT5t1KgRatWqJe3TqKgo+Pn5wc3NTaoJCQlBSkoK/vnnH6mmYBv6mqr2fRkzZgy6d+9eaF9wP5eN7du3o1WrVujbty9cXV3RsmVLfPnll9LrV69eRXx8vME+cnR0RGBgoMF+dnJyQqtWraSa4OBgKJVKHDlyRKrp0KED1Gq1VBMSEoLz58/j33//fdqbWS60adMGkZGRuHDhAgAgOjoaf/zxB7p27QqA+/ppMOc+Lcu/JQxAZnD37l1otVqDDwgAcHNzQ3x8vEy9qjh0Oh0mTJiAtm3bolmzZgCA+Ph4qNVqODk5GdQW3Kfx8fFG97n+teJqUlJS8ODBg6exOeXOhg0bcOLECURERBR6jfu5bFy5cgXLly9H/fr1sWfPHowePRrjxo3D6tWrAeTvp+L+RsTHx8PV1dXgdQsLC1SvXr1U34vK7v3338eAAQPQqFEjWFpaomXLlpgwYQIGDx4MgPv6aTDnPi2qxpR9zrvBU7k3ZswYxMTE4I8//pC7K5XOzZs3MX78eOzduxdWVlZyd6fS0ul0aNWqFebOnQsAaNmyJWJiYrBixQqEhobK3LvKZdOmTVi3bh3Wr1+Ppk2b4tSpU5gwYQI8PT25r8kAR4DMwNnZGSqVqtCZMwkJCXB3d5epVxXD2LFj8fPPP2P//v2oWbOmtNzd3R3Z2dlISkoyqC+4T93d3Y3uc/1rxdU4ODjA2tq6rDen3Dl+/DgSExPxzDPPwMLCAhYWFvjtt9/w+eefw8LCAm5ubtzPZcDDwwNNmjQxWNa4cWPcuHEDQP5+Ku5vhLu7OxITEw1ez83Nxf3790v1vajs3nnnHWkUyM/PD0OGDMHEiROlEU7u67Jnzn1aVI0p+5wByAzUajUCAgIQGRkpLdPpdIiMjERQUJCMPSu/hBAYO3YsfvzxR+zbtw+1a9c2eD0gIACWlpYG+/T8+fO4ceOGtE+DgoLw999/G/zS7d27Fw4ODtKHUVBQkEEb+pqq8n3p3Lkz/v77b5w6dUp6tGrVCoMHD5a+5n5+cm3bti10GYcLFy7Ax8cHAFC7dm24u7sb7KOUlBQcOXLEYD8nJSXh+PHjUs2+ffug0+kQGBgo1Rw8eBA5OTlSzd69e9GwYUNUq1btqW1feZKRkQGl0vCjTaVSQafTAeC+fhrMuU/L9G9JqadNk0k2bNggNBqN+Pbbb8WZM2fEyJEjhZOTk8GZM5Rv9OjRwtHRURw4cEDExcVJj4yMDKlm1KhRolatWmLfvn3i2LFjIigoSAQFBUmv60/PfvHFF8WpU6fE7t27hYuLi9HTs9955x1x9uxZsWzZsip1erYxBc8CE4L7uSwcPXpUWFhYiDlz5oiLFy+KdevWCRsbG7F27Vqp5uOPPxZOTk7ip59+EqdPnxY9e/Y0ehpxy5YtxZEjR8Qff/wh6tevb3AacVJSknBzcxNDhgwRMTExYsOGDcLGxqbSnpptTGhoqPDy8pJOg9+6datwdnYW7777rlTDfV16qamp4uTJk+LkyZMCgFiwYIE4efKkuH79uhDCfPv00KFDwsLCQsyfP1+cPXtWzJgxg6fBVwRLliwRtWrVEmq1WrRu3Vr8+eefcnep3AJg9PHNN99INQ8ePBBvvfWWqFatmrCxsRG9e/cWcXFxBu1cu3ZNdO3aVVhbWwtnZ2fx9ttvi5ycHIOa/fv3ixYtWgi1Wi3q1Klj8B5V0aMBiPu5bPzvf/8TzZo1ExqNRjRq1EisXLnS4HWdTiemTZsm3NzchEajEZ07dxbnz583qLl3754YOHCgsLOzEw4ODiIsLEykpqYa1ERHR4t27doJjUYjvLy8xMcff/zUt608SUlJEePHjxe1atUSVlZWok6dOmLKlCkGp1ZzX5fe/v37jf5NDg0NFUKYd59u2rRJNGjQQKjVatG0aVOxY8cOk7ZJIUSBy2MSERERVQGcA0RERERVDgMQERERVTkMQERERFTlMAARERFRlcMARERERFUOAxARERFVOQxAREREVOUwABFRuRcfH48XXngBtra2he5MT0RkCgYgIir3Fi5ciLi4OJw6dQoXLlwos3Z9fX2xaNGiMmuPiCoOC7k7QET0OJcvX0ZAQADq168vd1eMys7OhlqtlrsbRFQKHAEiIrN47rnnMG7cOLz77ruoXr063N3dMXPmzMeu5+vrix9++AHfffcdFAoFhg0bBgBISkrC8OHD4eLiAgcHB3Tq1AnR0dHSepcvX0bPnj3h5uYGOzs7PPvss/j1118N+nP9+nVMnDgRCoUCCoUCADBz5ky0aNHCoA+LFi2Cr6+v9HzYsGHo1asX5syZA09PTzRs2BAAcPPmTfTr1w9OTk6oXr06evbsiWvXrknrHThwAK1bt5YO5bVt2xbXr18v3Y4kojLBAEREZrN69WrY2triyJEjmDdvHmbNmoW9e/cWu85ff/2FLl26oF+/foiLi8PixYsBAH379kViYiJ27dqF48eP45lnnkHnzp1x//59AEBaWhq6deuGyMhInDx5El26dEGPHj1w48YNAMDWrVtRs2ZNzJo1C3FxcYiLiyvVtkRGRuL8+fPYu3cvfv75Z+Tk5CAkJAT29vb4/fffcejQIdjZ2aFLly7Izs5Gbm4uevXqhY4dO+L06dOIiorCyJEjpeBFRObFQ2BEZDb+/v6YMWMGAKB+/fpYunQpIiMj8cILLxS5jouLCzQaDaytreHu7g4A+OOPP3D06FEkJiZCo9EAAObPn49t27Zhy5YtGDlyJJo3b47mzZtL7cyePRs//vgjtm/fjrFjx6J69epQqVSwt7eX2i0NW1tbfPXVV9Khr7Vr10Kn0+Grr76SQs0333wDJycnHDhwAK1atUJycjJeeukl1K1bFwDQuHHjUr8vEZUNjgARkdn4+/sbPPfw8EBiYmKp24mOjkZaWhpq1KgBOzs76XH16lVcvnwZQN4I0KRJk9C4cWM4OTnBzs4OZ8+elUaAnpSfn5/BvJ/o6GhcunQJ9vb2Un+qV6+OzMxMXL58GdWrV8ewYcMQEhKCHj16YPHixaUedSKissMRICIyG0tLS4PnCoUCOp2u1O2kpaXBw8MDBw4cKPSa/jT5SZMmYe/evZg/fz7q1asHa2trvPrqq8jOzi62baVSCSGEwbKcnJxCdba2toX6FBAQgHXr1hWqdXFxAZA3IjRu3Djs3r0bGzduxNSpU7F371785z//KbZPRFT2GICIqMJ55plnEB8fDwsLC4PJyQUdOnQIw4YNQ+/evQHkBZSCE5IBQK1WQ6vVGixzcXFBfHw8hBDSoaxTp06VqE8bN26Eq6srHBwciqxr2bIlWrZsicmTJyMoKAjr169nACKSAQ+BEVGFExwcjKCgIPTq1Qu//PILrl27hsOHD2PKlCk4duwYgLw5Rlu3bsWpU6cQHR2NQYMGFRpt8vX1xcGDBxEbG4u7d+8CyDs77M6dO5g3bx4uX76MZcuWYdeuXY/t0+DBg+Hs7IyePXvi999/x9WrV3HgwAGMGzcOt27dwtWrVzF58mRERUXh+vXr+OWXX3Dx4kXOAyKSCQMQEVU4CoUCO3fuRIcOHRAWFoYGDRpgwIABuH79Otzc3AAACxYsQLVq1dCmTRv06NEDISEheOaZZwzamTVrFq5du4a6detKh6kaN26ML774AsuWLUPz5s1x9OhRTJo06bF9srGxwcGDB1GrVi288soraNy4Md544w1kZmbCwcEBNjY2OHfuHPr06YMGDRpg5MiRGDNmDN58882y30FE9FgK8ejBbiIiIqJKjiNAREREVOUwABGRrNatW2dwKnvBR9OmTeXuHhFVUjwERkSySk1NRUJCgtHXLC0t4ePjY+YeEVFVwABEREREVQ4PgREREVGVwwBEREREVQ4DEBEREVU5DEBERERU5TAAERERUZXDAERERERVDgMQERERVTkMQERERFTl/D+NKyy6QYAG6QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_features_list, score_list)\n",
    "plt.axhline(score_list[-1], color = 'red', linestyle = '--')\n",
    "plt.title('Dependence Accuracy on n_features')\n",
    "plt.xlabel('n_features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество довольно быстро выходит на плато, значит совсем необязательно большое количество n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ в целом по качеству довольно хорошо и у logrega и svm, у svm чуть получше, но обучается дольше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1000\n",
    "X = x_train\n",
    "d = X.shape[1]\n",
    "m = math.ceil(n_features / d)\n",
    "intercept_ = []\n",
    "weights_ = []\n",
    "for i in range(m):\n",
    "    G = np.random.normal(0,1, (d, d))    # Gaussian matrix\n",
    "    intercept_ += [np.random.uniform(-np.pi, np.pi, d)]\n",
    "    Q, _ = np.linalg.qr(G)    # Q from QR-decomposition of G\n",
    "    S = np.diagflat(np.sqrt(np.random.chisquare(d, d)))    # diag values from chi with dof = d\n",
    "    weights_ += [S @ Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "class OFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', kernel = 'rbf'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        X_fit = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            self.dec = PCA(self.new_dim)\n",
    "            X_fit = self.dec.fit_transform(X_fit)\n",
    "        \n",
    "        indices = np.random.randint(0, X_fit.shape[0], size=(1000000, 2))\n",
    "        X_pairs = X_fit[indices]\n",
    "        sigma = np.sqrt(np.median(np.sum(np.square(X_pairs[:, 0] - X_pairs[:, 1]), axis = 1)))\n",
    "\n",
    "        d = self.n_features // X_fit.shape[1]\n",
    "\n",
    "        self.w = []\n",
    "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        for _ in range(d):\n",
    "            G = np.random.normal(0, 1, size=(X_fit.shape[1], X_fit.shape[1]))\n",
    "            Q, R = np.linalg.qr(G)\n",
    "            S = np.diag(np.sqrt(np.random.chisquare(X_fit.shape[1], X_fit.shape[1])))\n",
    "            W = (1 / sigma) * S @ Q\n",
    "            self.w.append(W)\n",
    "        \n",
    "        self.w = np.vstack(self.w)\n",
    "        X_fit = X_fit[:, :self.n_features]\n",
    "        self.phi = np.cos(X_fit @ self.w.T + self.b)\n",
    "        \n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(max_iter = 100000)\n",
    "        if self.classifier == 'svm':\n",
    "            self.model = SVC(kernel = self.kernel, max_iter = 100000)\n",
    "        self.model.fit(self.phi, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        X_pred = X_pred[:, :self.n_features]\n",
    "        phi = np.cos(X_pred @ self.w.T + self.b)\n",
    "\n",
    "        return self.model.predict_proba(phi)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        X_pred = X_pred[:, :self.n_features]    \n",
    "        phi = np.cos(X_pred @ self.w.T + self.b)\n",
    "        \n",
    "        return self.model.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "off = OFFPipeline()\n",
    "X_fit = off.fit(x_train, y_train)\n",
    "y_pred = off.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ASUS/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "off = OFFPipeline(classifier='svm', kernel = 'linear')\n",
    "X_fit = off.fit(x_train, y_train)\n",
    "y_pred = off.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8675\n"
     ]
    }
   ],
   "source": [
    "off = OFFPipeline(classifier='svm', kernel = 'rbf')\n",
    "X_fit = off.fit(x_train, y_train)\n",
    "y_pred = off.predict(x_test)\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:___ качество получилось лучше, чем у rff, считается приблизительно столько же"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 1 балл)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class RFFPipelineCustomFunc(RFFPipeline):\n",
    "    def __init__(self, function = np.cos, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.function = function\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        X_fit = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            self.dec = PCA(self.new_dim)\n",
    "            X_fit = self.dec.fit_transform(X_fit)\n",
    "        \n",
    "        indices = np.random.randint(0, X_fit.shape[0], size=(1000000, 2))\n",
    "        X_pairs = X_fit[indices]\n",
    "        sigma = np.sqrt(np.median(np.sum(np.square(X_pairs[:, 0] - X_pairs[:, 1]), axis = 1)))\n",
    "\n",
    "        self.w = np.random.normal(0, (1 / sigma), [X_fit.shape[1], self.n_features])\n",
    "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        phi = self.function(X_fit @ self.w + self.b)\n",
    "\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(max_iter = 100000)\n",
    "        if self.classifier == 'svm':\n",
    "            self.model = SVC(kernel = self.kernel, max_iter = 100000)\n",
    "        self.model.fit(phi, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        phi = self.function(X_pred @ self.w + self.b)\n",
    "\n",
    "        return self.model.predict_proba(phi)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        X_pred = X.copy()\n",
    "\n",
    "        if self.use_PCA == True:\n",
    "            X_pred = self.dec.transform(X_pred)\n",
    "\n",
    "        phi = self.function(X_pred @ self.w + self.b)\n",
    "        return self.model.predict(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8692\n"
     ]
    }
   ],
   "source": [
    "rff_abs = RFFPipelineCustomFunc(np.abs)\n",
    "rff_abs.fit(x_train, y_train)\n",
    "y_pred = rff_abs.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8732\n"
     ]
    }
   ],
   "source": [
    "rff_tanh = RFFPipelineCustomFunc(np.tanh)\n",
    "rff_tanh.fit(x_train, y_train)\n",
    "y_pred = rff_tanh.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ASUS/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "rff_exp = RFFPipelineCustomFunc(np.exp)\n",
    "rff_exp.fit(x_train, y_train)\n",
    "y_pred = rff_exp.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ в целом результаты довольно близки к тому, что у косинуса были, если увеличить max_iter у np.exp, то качество может станет еще лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (Максимум 1 балл)__\n",
    "\n",
    "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск, а не аналитическую формулу. Также подумайте о том, как в формулах правильно учесть свободный коэффициент. Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь: \n",
    "$$\n",
    "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w + b - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
    "$$\n",
    "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
    "\n",
    "Предсказание: \n",
    "$\n",
    "y(x) = k(x)^T w,\n",
    "$\n",
    "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
    "\n",
    "Вы можете изменять представленный ниже шаблон по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KernelRidgeRegression(RegressorMixin):\n",
    "    \"\"\"\n",
    "    Kernel Ridge regression class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,         \n",
    "        lr=0.01,\n",
    "        regularization=0.1,\n",
    "        tolerance=1e-3,\n",
    "        max_iter=1000,\n",
    "        batch_size=64,\n",
    "        kernel_scale=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param lr: learning rate\n",
    "        :param regularization: regularization coefficient\n",
    "        :param tolerance: stopping criterion for square of euclidean norm of weight difference\n",
    "        :param max_iter: stopping criterion for iterations\n",
    "        :param batch_size: size of the batches used in gradient descent steps\n",
    "        :parame kernel_scale: length scale in RBF kernel formula\n",
    "        \"\"\"\n",
    "\n",
    "        self.lr: float = lr\n",
    "        self.regularization: float = regularization\n",
    "        self.w: np.ndarray | None = None\n",
    "        self.tolerance: float = tolerance\n",
    "        self.max_iter: int = max_iter\n",
    "        self.batch_size: int = batch_size\n",
    "        self.loss_history: list[float] = []\n",
    "        self.kernel = RBF(kernel_scale)\n",
    "\n",
    "    def calc_loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculating loss for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        \"\"\"\n",
    "        return 0.5 * np.linalg.norm(self.kernel_ @ self.w + self.b - y) + 0.5 * self.regularization * self.w.T @ self.kernel_ @ self.w \n",
    "\n",
    "    def calc_grad(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculating gradient for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        \"\"\"\n",
    "        batch_indices = np.random.randint(0, x.shape[0], self.batch_size)\n",
    "        \n",
    "        kernel_batch = self.kernel(x[batch_indices], x)\n",
    "        return kernel_batch.T @ kernel_batch @ self.w - + kernel_batch.T @ np.ones((self.batch_size, 1)) * 1 +  kernel_batch.T @ y[batch_indices] + self.regularization * self.kernel_ @ self.w, np.mean(self.b + kernel_batch @ self.w - y[batch_indices])\n",
    "    \n",
    "    def step(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return self.update_weights(self.calc_grad(x, y))\n",
    "    \n",
    "    def update_weights(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        :return: weight difference (w_{k + 1} - w_k): np.ndarray\n",
    "        \"\"\"\n",
    "        weight_difference = -self.lr * gradient[0]\n",
    "        self.w = self.w + weight_difference[0]\n",
    "        self.b = self.b - self.lr * gradient[1]\n",
    "        return weight_difference\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> \"KernelRidgeRegression\":\n",
    "        \"\"\"\n",
    "        Fitting weights for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.w = np.random.rand(x.shape[0]).reshape(x.shape[0], 1)\n",
    "        self.b = np.random.rand(1).reshape(-1, 1)\n",
    "        self.kernel_ = self.kernel(x)\n",
    "        for _ in tqdm(range(self.max_iter)):\n",
    "            self.loss_history.append(self.calc_loss(x, y).item())\n",
    "            delta = self.step(x, y)\n",
    "            if np.linalg.norm(delta)**2  < self.tolerance:\n",
    "                break\n",
    "\n",
    "        self.loss_history.append(self.calc_loss(x, y).item())\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_train, x_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicting targets for x dataset\n",
    "        :param x: features array\n",
    "        :return: prediction: np.ndarray\n",
    "        \"\"\"\n",
    "        return self.kernel(x_train, x_test).T @ self.w + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые пять строк матрицы корреляций:\n",
      "[[1.         0.90338652 0.89297273 0.89196328 0.8907343 ]\n",
      " [0.90338652 1.         0.81643574 0.79689683 0.81229991]\n",
      " [0.89297273 0.81643574 1.         0.78855243 0.7960388 ]\n",
      " [0.89196328 0.79689683 0.78855243 1.         0.80647691]\n",
      " [0.8907343  0.81229991 0.7960388  0.80647691 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n",
      "/var/folders/mr/q050g7h96kl_k_qkx4dkzjl00000gn/T/ipykernel_11935/912548847.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f'feature_{i}'] = X_base * correlation + noise\n"
     ]
    }
   ],
   "source": [
    "def generate_correlated_data(correlation, n_samples, n_features, taska):\n",
    "    np.random.seed(322)\n",
    "    \n",
    "    X_base = np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "    \n",
    "    df_features = pd.DataFrame(X_base, columns=['base_feature'])\n",
    "    for i in range(1, n_features + 1):\n",
    "        noise = np.random.normal(loc=0, scale=(1 - correlation ** 2)  ** 0.5, size=n_samples)\n",
    "        df_features[f'feature_{i}'] = X_base * correlation + noise\n",
    "    \n",
    "    if taska == 'classification':\n",
    "\n",
    "        y = pd.qcut(X_base, q=10, labels=False)\n",
    "    elif taska == 'regression':\n",
    "        y = X_base + np.random.normal(loc=0, scale=0.5, size=n_samples)\n",
    "        \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features.values, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    correlation_matrix = np.corrcoef(X_train.T)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, correlation_matrix\n",
    "\n",
    "\n",
    "\n",
    "correlation = 0.9 #тут вставляем корреляцию\n",
    "n_observations = 1000\n",
    "n_feat = 1000\n",
    "taska = 'classification'\n",
    "\n",
    "X_train_corr, X_test_corr, y_train_corr, y_test_corr, correlation_matrix = generate_correlated_data(correlation, n_observations, n_feat, taska)\n",
    "\n",
    "print(\"Первые пять строк матрицы корреляций:\")\n",
    "print(correlation_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.10529733420764575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# Assuming X_train_corr, X_test_corr, y_train_corr, y_test_corr are provided\n",
    "\n",
    "# Initialize KRR model\n",
    "krr_model = KernelRidge(kernel='rbf')  # You can choose other kernels as well\n",
    "\n",
    "# Fit the model\n",
    "krr_model.fit(X_train_corr, y_train_corr)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_corr = krr_model.predict(X_test_corr)\n",
    "\n",
    "# Evaluate the model if needed\n",
    "# For example, you can use mean squared error for regression tasks\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test_corr, y_pred_corr)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.773312277915771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_corr = y_train_corr.reshape(-1, 1)\n",
    "y_test_corr = y_test_corr.reshape(-1, 1)\n",
    "krr = KernelRidgeRegression()\n",
    "krr.fit(X_train_corr, y_train_corr)\n",
    "y_pred_corr = krr.predict(X_train_corr, X_test_corr)\n",
    "print('MSE:', mean_squared_error(y_pred_corr, y_test_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(krr.loss_history, label = 'krr')\n",
    "plt.xlabel('Iter')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss history on x_train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:09<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0191065972192404\n"
     ]
    }
   ],
   "source": [
    "X = sts.norm.rvs(size=[10000, 20])\n",
    "y = sts.norm.rvs(size=[10000, 1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "krr = KernelRidgeRegression()\n",
    "krr.fit(x_train, y_train)\n",
    "y_pred = krr.predict(x_train, x_test)\n",
    "print('MSE:', mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1534297739055308\n"
     ]
    }
   ],
   "source": [
    "rff = RFFPipeline(classifier = 'linreg', use_PCA=False)\n",
    "rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "print('MSE:', mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg+ElEQVR4nO3deVhU5d8G8HsWZlhnEGRVNlfEBXFD3C1zN9cWNUOzzMLKNCvrZ7tpZmaaZqtaaZa97pWK+4bghgsqbigoAirCsMg287x/IJMTqKAwZxjuz3XNdcU5z5zznaMyd+c8i0wIIUBERERkpeRSF0BERERUlRh2iIiIyKox7BAREZFVY9ghIiIiq8awQ0RERFaNYYeIiIisGsMOERERWTWGHSIiIrJqDDtERERk1Rh2iKhMo0ePhqOjY7naymQyfPDBB1VbEEliyZIlkMlkuHjxotSlED0whh0iMyv58jh48KDUpUhq+fLlmDt3rtRlWIVPP/0Ua9askboMIovFsENED+3WrVv43//+V6H3MOxUnqoMO6NGjcKtW7fg5+dXJccnMgeGHSJ6aLa2tlAqlVKXgaKiIhQUFEhdhkXLycmpUHuFQgFbW1vIZLIqqoio6jHsEFmoI0eOoE+fPtBoNHB0dMSjjz6K/fv3m7QpLCzEhx9+iIYNG8LW1haurq7o1KkTIiMjjW1SUlIwZswY1K1bF2q1Gl5eXhg4cGC5+2BcuXIFgwYNgqOjI9zc3PDGG29Ar9ebtPlvn52srCxMnDgR/v7+UKvVcHd3x2OPPYbDhw8DALp164a//voLly5dgkwmg0wmg7+/v/H9aWlpGDt2LDw8PGBra4vg4GAsXbrU5JwXL16ETCbD7NmzMXfuXNSvXx9qtRoxMTFwcHDAa6+9VuqzXL58GQqFAjNmzLjnZ87JycHkyZPh4+MDtVqNxo0bY/bs2RBClPrcEyZMwJo1a9CsWTOo1Wo0bdoUGzduvO91DQ8Ph62tLU6dOmWyvVevXqhVqxaSk5Pve4ySGnJycrB06VLjtRw9ejQA4IMPPoBMJsPJkycxYsQI1KpVC506dQIAHDt2DKNHj0a9evVga2sLT09PPPfcc7hx44bJ8cvqs+Pv74/+/ftjz549aNeuHWxtbVGvXj38/PPP5aqZyNyk/18xIiolLi4OnTt3hkajwZtvvgkbGxt8++236NatG3bu3InQ0FAAxV9mM2bMwPPPP4927dpBp9Ph4MGDOHz4MB577DEAwNChQxEXF4dXXnkF/v7+SEtLQ2RkJBITE00CRln0ej169eqF0NBQzJ49G1u2bMEXX3yB+vXr46WXXrrr+8aPH48///wTEyZMQFBQEG7cuIE9e/bg1KlTaNWqFd59911kZmbi8uXL+PLLLwHA2Bn61q1b6NatG86dO4cJEyYgICAAK1euxOjRo5GRkVEqxCxevBh5eXkYN24c1Go1fH19MXjwYPz++++YM2cOFAqFse1vv/0GIQRGjhx519qFEHj88cexfft2jB07Fi1btsSmTZswZcoUXLlyxVhviT179mDVqlV4+eWX4eTkhHnz5mHo0KFITEyEq6vrXc/z1VdfYdu2bQgPD0dUVBQUCgW+/fZbbN68Gb/88gu8vb3v/gdzh19++cX45z9u3DgAQP369U3aPPHEE2jYsCE+/fRTY2CLjIzEhQsXMGbMGHh6eiIuLg7fffcd4uLisH///vveyTl37hyGDRuGsWPHIjw8HD/99BNGjx6N1q1bo2nTpuWqnchsBBGZ1eLFiwUAceDAgbu2GTRokFCpVOL8+fPGbcnJycLJyUl06dLFuC04OFj069fvrse5efOmACA+//zzCtcZHh4uAIiPPvrIZHtISIho3bq1yTYA4v333zf+rNVqRURExD2P369fP+Hn51dq+9y5cwUA8euvvxq3FRQUiLCwMOHo6Ch0Op0QQoiEhAQBQGg0GpGWlmZyjE2bNgkA4p9//jHZ3qJFC9G1a9d71rVmzRoBQHzyyScm24cNGyZkMpk4d+6ccRsAoVKpTLYdPXpUABDz58+/53nurPOTTz4RFy5cEI6OjmLQoEH3fd9/OTg4iPDw8FLb33//fQFADB8+vNS+3NzcUtt+++03AUDs2rXLuK3k72tCQoJxm5+fX6l2aWlpQq1Wi8mTJ1e4fqKqxsdYRBZGr9dj8+bNGDRoEOrVq2fc7uXlhREjRmDPnj3Q6XQAAGdnZ8TFxeHs2bNlHsvOzg4qlQo7duzAzZs3H6ie8ePHm/zcuXNnXLhw4Z7vcXZ2RnR0dLkfxdzp77//hqenJ4YPH27cZmNjg1dffRXZ2dnYuXOnSfuhQ4fCzc3NZFuPHj3g7e2NZcuWGbedOHECx44dwzPPPHPf8ysUCrz66qsm2ydPngwhBP75559S57rzTkqLFi2g0Wjue40AoGfPnnjxxRfx0UcfYciQIbC1tcW333573/dV1H//DIHivxsl8vLycP36dbRv3x4AjI8b7yUoKAidO3c2/uzm5obGjRuX63MTmRvDDpGFuXbtGnJzc9G4ceNS+5o0aQKDwYCkpCQAwEcffYSMjAw0atQIzZs3x5QpU3Ds2DFje7Vajc8++wz//PMPPDw80KVLF8yaNQspKSnlqsXW1rZUkKhVq9Z9g9OsWbNw4sQJ+Pj4oF27dvjggw/K/SV46dIlNGzYEHK56a+nJk2aGPffKSAgoNQx5HI5Ro4ciTVr1iA3NxcAsGzZMtja2uKJJ5647/m9vb3h5ORUrvP7+vqWOkZ5rlGJ2bNnw8XFBbGxsZg3bx7c3d3L9b6KKOsapaen47XXXoOHhwfs7Ozg5uZmbJeZmXnfYz7s5yYyJ4YdomqsS5cuOH/+PH766Sc0a9YMP/zwA1q1aoUffvjB2GbixIk4c+YMZsyYAVtbW0ybNg1NmjTBkSNH7nv8O/u7VMSTTz6JCxcuYP78+fD29sbnn3+Opk2blrorUhnuvENxp2effRbZ2dlYs2YNhBBYvnw5+vfvD61WW6nnv9s1Ev/pzHw3R44cQVpaGgDg+PHjlVbXncq6Rk8++SS+//57jB8/HqtWrcLmzZuNHasNBsN9j/mwn5vInBh2iCyMm5sb7O3tER8fX2rf6dOnIZfL4ePjY9zm4uKCMWPG4LfffkNSUhJatGhRajbj+vXrY/Lkydi8eTNOnDiBgoICfPHFF1X6Oby8vPDyyy9jzZo1SEhIgKurK6ZPn27cf7cOsH5+fjh79mypL9zTp08b95dHs2bNEBISgmXLlmH37t1ITEzEqFGj7vs+Pz8/JCcnIysr66HOXx45OTkYM2YMgoKCMG7cOMyaNQsHDhyo8HEqOiz85s2b2Lp1K95++218+OGHGDx4MB577DGTx6ZE1oRhh8jCKBQK9OzZE2vXrjUZ7puamorly5ejU6dO0Gg0AFBqmLCjoyMaNGiA/Px8AEBubi7y8vJM2tSvXx9OTk7GNpVNr9eXegzi7u4Ob29vk3M6ODiU+bikb9++SElJwe+//27cVlRUhPnz58PR0RFdu3Ytdy2jRo3C5s2bMXfuXLi6uqJPnz73fU/fvn2h1+vx9ddfm2z/8ssvIZPJynWM8nrrrbeQmJiIpUuXYs6cOfD390d4eHiF/2wcHByQkZFR7vYld2X+exeGkzySteLQcyKJ/PTTT2XOx/Laa6/hk08+QWRkJDp16oSXX34ZSqUS3377LfLz8zFr1ixj26CgIHTr1g2tW7eGi4sLDh48aBzyDQBnzpzBo48+iieffBJBQUFQKpVYvXo1UlNT8fTTT1fJ58rKykLdunUxbNgwBAcHw9HREVu2bMGBAwdM7ia1bt0av//+OyZNmoS2bdvC0dERAwYMwLhx4/Dtt99i9OjROHToEPz9/fHnn39i7969mDt3bqm+NPcyYsQIvPnmm1i9ejVeeukl2NjY3Pc9AwYMQPfu3fHuu+/i4sWLCA4OxubNm7F27VpMnDix1LDuB7Vt2zYsXLgQ77//Plq1agWgeBh9t27dMG3aNJM/5/tp3bo1tmzZgjlz5sDb2xsBAQHG6QnKotFojP23CgsLUadOHWzevBkJCQkP/bmILJKkY8GIaqCSobx3eyUlJQkhhDh8+LDo1auXcHR0FPb29qJ79+5i3759Jsf65JNPRLt27YSzs7Ows7MTgYGBYvr06aKgoEAIIcT169dFRESECAwMFA4ODkKr1YrQ0FDxxx9/3LfO8PBw4eDgUGp7yXDmO+GOoef5+fliypQpIjg4WDg5OQkHBwcRHBwsFi5caPKe7OxsMWLECOHs7CwAmAxDT01NFWPGjBG1a9cWKpVKNG/eXCxevNjk/SVDz+83rL5v374CQKlrdy9ZWVni9ddfF97e3sLGxkY0bNhQfP7558JgMJT63GUNsffz8ytzKHgJnU4n/Pz8RKtWrURhYaHJvtdff13I5XIRFRVV7npPnz4tunTpIuzs7AQA47lL/qyuXbtW6j2XL18WgwcPFs7OzkKr1YonnnhCJCcnl5pG4G5Dz8ua8qBr1673HdpPJAWZEOxNRkTWa/DgwTh+/DjOnTsndSlEJBH22SEiq3X16lX89ddf5eqYTETWi312iMjqJCQkYO/evfjhhx9gY2ODF198UeqSHsj95kOys7Or9KH0RNaIYYeIrM7OnTsxZswY+Pr6YunSpfD09JS6pAfi5eV1z/3h4eFYsmSJeYohqsbYZ4eIyEJt2bLlnvu9vb0RFBRkpmqIqi+GHSIiIrJq7KBMREREVo19dlC8DkxycjKcnJwqPO06ERERSUMIgaysLHh7e5daPPi/DSXz6aefijZt2ghHR0fh5uYmBg4cKE6fPm3cf+PGDTFhwgTRqFEjYWtrK3x8fMQrr7wiMjIyTI5z6dIl0bdvX2FnZyfc3NzEG2+8UWqirntJSkq65yRvfPHFF1988cWX5b5KJmO9G0nv7OzcuRMRERFo27YtioqK8M4776Bnz544efIkHBwckJycjOTkZMyePRtBQUG4dOkSxo8fj+TkZPz5558Aitfh6devHzw9PbFv3z5cvXoVzz77LGxsbPDpp5+Wq46S6eeTkpKMaw4RERGRZdPpdPDx8bnvMjIW1UH52rVrcHd3x86dO9GlS5cy26xcuRLPPPMMcnJyoFQq8c8//6B///5ITk6Gh4cHAGDRokV46623cO3aNahUqvueV6fTQavVIjMzk2GHiIiomijv97dFdVAuWQHZxcXlnm00Gg2UyuKbUlFRUWjevLkx6ABAr169oNPpEBcXV+Yx8vPzodPpTF5ERERknSwm7BgMBkycOBEdO3ZEs2bNymxz/fp1fPzxxxg3bpxxW0pKiknQAWD8+W6zj86YMQNardb48vHxqaRPQURERJbGYsJOREQETpw4gRUrVpS5X6fToV+/fggKCsIHH3zwUOeaOnUqMjMzja+kpKSHOh4RERFZLosYej5hwgRs2LABu3btQt26dUvtz8rKQu/eveHk5ITVq1fDxsbGuM/T0xMxMTEm7VNTU437yqJWq6FWqyvxExAREZGlkvTOjhACEyZMwOrVq7Ft2zYEBASUaqPT6dCzZ0+oVCqsW7cOtra2JvvDwsJw/PhxpKWlGbdFRkZCo9FwGnUiIiKS9s5OREQEli9fjrVr18LJycnYx0ar1cLOzs4YdHJzc/Hrr7+adCZ2c3ODQqFAz549ERQUhFGjRmHWrFlISUnB//73P0RERPDuDREREUk79PxusxUvXrwYo0ePxo4dO9C9e/cy2yQkJMDf3x8AcOnSJbz00kvYsWMHHBwcEB4ejpkzZxpHbN0Ph54TERFVP+X9/raoeXakwrBDRERU/VTLeXaIiIiIKhvDDhEREVk1hh0iIiKyagw7REREZNUYdqqQ3iBw4komcguKpC6FiIioxmLYqUIDF+xB//l7EH0hXepSiIiIaiyGnSrU1EsLAIhOYNghIiKSCsNOFWob4AIAiEm4IXElRERENRfDThUKvR12jl3OxK0CvcTVEBER1UwMO1Wobi07eGltUWQQOJJ4U+pyiIiIaiSGnSokk8nQ7vbdHfbbISIikgbDThUrCTsHLjLsEBERSYFhp4qV9Ns5nHgTBUUGiashIiKqeRh2qlh9N0e4OKiQV2jA8SuZUpdDRERU4zDsVDGZTIZ2/iVD0Pkoi4iIyNwYdsyA8+0QERFJh2HHDEr67Ry8eBN6g5C4GiIiopqFYccMmnhp4KhWIiu/CKeu6qQuh4iIqEZh2DEDhVyGNv61ALDfDhERkbkx7JgJ59shIiKSBsOOmYQG/DsiSwj22yEiIjIXhh0zaV7HGWqlHDdyCnD+Wo7U5RAREdUYDDtmolLK0cqX/XaIiIjMjWHHjNpxvh0iIiKzY9gxo5J+O/svsN8OERGRuTDsmFErv1pQKeVI0eXh/LVsqcshIiKqERh2zMjWRmFcJ2v32esSV0NERFQzMOyYWeeGtQEw7BAREZkLw46ZdboddvZfuIGCIoPE1RAREVk/hh0za+KpQW1HFXIL9DiSeFPqcoiIiKwew46ZyeUyhNUvvruz9zyHoBMREVU1hh0JdKzvCgDYd479doiIiKoaw44EOjYovrMTm5SBnPwiiashIiKybgw7EvBxsYePix2KDIJLRxAREVUxhh2JdKhXfHdnDx9lERERVSmGHYl0blQy3841iSshIiKybgw7EunUoDbkMuBMajaSM25JXQ4REZHVYtiRiLO9CsE+zgCAXWd4d4eIiKiqMOxIqGsjNwDALj7KIiIiqjIMOxLqcjvs7D57HUV6Lh1BRERUFSQNOzNmzEDbtm3h5OQEd3d3DBo0CPHx8SZt8vLyEBERAVdXVzg6OmLo0KFITU01aZOYmIh+/frB3t4e7u7umDJlCoqKLH/+muC6ztDa2SArrwhHL2dIXQ4REZFVkjTs7Ny5ExEREdi/fz8iIyNRWFiInj17Iicnx9jm9ddfx/r167Fy5Urs3LkTycnJGDJkiHG/Xq9Hv379UFBQgH379mHp0qVYsmQJ3nvvPSk+UoUo5DLjKug74/koi4iIqCrIhBBC6iJKXLt2De7u7ti5cye6dOmCzMxMuLm5Yfny5Rg2bBgA4PTp02jSpAmioqLQvn17/PPPP+jfvz+Sk5Ph4eEBAFi0aBHeeustXLt2DSqV6r7n1el00Gq1yMzMhEajqdLP+F9/HEzCm38eQ3BdLdZO6GTWcxMREVVn5f3+tqg+O5mZmQAAFxcXAMChQ4dQWFiIHj16GNsEBgbC19cXUVFRAICoqCg0b97cGHQAoFevXtDpdIiLiyvzPPn5+dDpdCYvqZR0Uj52JRPpOQWS1UFERGStLCbsGAwGTJw4ER07dkSzZs0AACkpKVCpVHB2djZp6+HhgZSUFGObO4NOyf6SfWWZMWMGtFqt8eXj41PJn6b8PDS2aOzhBCE4mzIREVFVsJiwExERgRMnTmDFihVVfq6pU6ciMzPT+EpKSqryc95Ll9uzKXO+HSIiospnEWFnwoQJ2LBhA7Zv3466desat3t6eqKgoAAZGRkm7VNTU+Hp6Wls89/RWSU/l7T5L7VaDY1GY/KS0r9D0K/BgrpQERERWQVJw44QAhMmTMDq1auxbds2BAQEmOxv3bo1bGxssHXrVuO2+Ph4JCYmIiwsDAAQFhaG48ePIy0tzdgmMjISGo0GQUFB5vkgD6mtvwtsbeRI1eXjTGq21OUQERFZFaWUJ4+IiMDy5cuxdu1aODk5GfvYaLVa2NnZQavVYuzYsZg0aRJcXFyg0WjwyiuvICwsDO3btwcA9OzZE0FBQRg1ahRmzZqFlJQU/O9//0NERATUarWUH6/cbG0UCA1wxc4z17DrzDU09nSSuiQiIiKrIemdnW+++QaZmZno1q0bvLy8jK/ff//d2ObLL79E//79MXToUHTp0gWenp5YtWqVcb9CocCGDRugUCgQFhaGZ555Bs8++yw++ugjKT7SAysZlbX1dOp9WhIREVFFWNQ8O1KRcp6dEknpueg8azvkMuDQ/x5DLYf7zw9ERERUk1XLeXZqMh8XezTx0sAggC2neHeHiIiosjDsWJBeTYvnB9p8kmGHiIiosjDsWJBeTYuHyu86cw25BZa/kCkREVF1wLBjQQI9neDjYof8IgMnGCQiIqokDDsWRCaToWdQ8d0dPsoiIiKqHAw7FqZnUHG/na2n0lCkN0hcDRERUfXHsGNhWvvVgouDCpm3ChFzMV3qcoiIiKo9hh0Lo1TI8UigOwAgko+yiIiIHhrDjgUqeZS1OS6VC4MSERE9JIYdC9S5oRtsbeS4knELp65mSV0OERFRtcawY4HsVAp0bli8VtbmkykSV0NERFS9MexYqMfueJRFRERED45hx0L1aOIBhVyGk1d1SLyRK3U5RERE1RbDjoVycVAhNMAFALApjo+yiIiIHhTDjgUrWStrI8MOERHRA2PYsWA9b6+CfjjxJtJ0eRJXQ0REVD0x7FgwL60dWvo4QwiulUVERPSgGHYsXO9mxY+y2G+HiIjowTDsWLjet/vt7Dt/A9ez8yWuhoiIqPph2LFw/rUdEFxXC71BYP3RZKnLISIiqnYYdqqBwSF1AACrDl+RuBIiIqLqh2GnGhgQ7A2lXIbjVzJxLo1rZREREVUEw0414OqoRrfGxWtl8e4OERFRxTDsVBODQ+oCANbGJsNgEBJXQ0REVH0w7FQTjzZxh5OtElcybiE6IV3qcoiIiKoNhp1qwtZGgX7NvQAAq49clrgaIiKi6oNhpxopGZX19/EU3CrQS1wNERFR9cCwU4209XdBHWc7ZOcXIfIUl48gIiIqD4adakQul2FIq+K7O6sP81EWERFReTDsVDMlj7J2nb2Oa1lcPoKIiOh+GHaqmXpujgj2cebyEUREROXEsFMNDbl9d2f1EU4wSEREdD8MO9XQnctHnE3l8hFERET3wrBTDbk4qP5dPoJ3d4iIiO6JYaeaGtLq9vIRR65w+QgiIqJ7YNipph4JLF4+IjkzD/sTbkhdDhERkcVi2KmmbG0U6N/i9vIRXAmdiIjorhh2qrGSldD/OcHlI4iIiO6GYacaa+NXC3VrFS8fsflkitTlEBERWSSGnWpMLpcZZ1TmnDtERERlkzTs7Nq1CwMGDIC3tzdkMhnWrFljsj87OxsTJkxA3bp1YWdnh6CgICxatMikTV5eHiIiIuDq6gpHR0cMHToUqak1Z5HMkrCzm8tHEBERlUnSsJOTk4Pg4GAsWLCgzP2TJk3Cxo0b8euvv+LUqVOYOHEiJkyYgHXr1hnbvP7661i/fj1WrlyJnTt3Ijk5GUOGDDHXR5BcPTdHtLy9fMTaWN7dISIi+i9Jw06fPn3wySefYPDgwWXu37dvH8LDw9GtWzf4+/tj3LhxCA4ORkxMDAAgMzMTP/74I+bMmYNHHnkErVu3xuLFi7Fv3z7s37/fnB9FUsNaF3dU/i0mEUJwzh0iIqI7WXSfnQ4dOmDdunW4cuUKhBDYvn07zpw5g549ewIADh06hMLCQvTo0cP4nsDAQPj6+iIqKkqqss1uYEtv2KsUOH8tBzEJ6VKXQ0REZFEsOuzMnz8fQUFBqFu3LlQqFXr37o0FCxagS5cuAICUlBSoVCo4OzubvM/DwwMpKXcfnZSfnw+dTmfyqs6cbG3weLA3AGBZdKLE1RAREVkWiw87+/fvx7p163Do0CF88cUXiIiIwJYtWx7quDNmzIBWqzW+fHx8Kqli6YwM9QMAbDyRghvZ7KhMRERUwmLDzq1bt/DOO+9gzpw5GDBgAFq0aIEJEybgqaeewuzZswEAnp6eKCgoQEZGhsl7U1NT4enpeddjT506FZmZmcZXUlJSVX4Us2heV4vmdbQo0Bvwf4cvS10OERGRxbDYsFNYWIjCwkLI5aYlKhQKGAwGAEDr1q1hY2ODrVu3GvfHx8cjMTERYWFhdz22Wq2GRqMxeVmDEaG+AIDfYpLYUZmIiOg2pZQnz87Oxrlz54w/JyQkIDY2Fi4uLvD19UXXrl0xZcoU2NnZwc/PDzt37sTPP/+MOXPmAAC0Wi3Gjh2LSZMmwcXFBRqNBq+88grCwsLQvn17qT6WZB4P9sb0v04h4XoOos7fQIcGtaUuiYiISHKShp2DBw+ie/fuxp8nTZoEAAgPD8eSJUuwYsUKTJ06FSNHjkR6ejr8/Pwwffp0jB8/3vieL7/8EnK5HEOHDkV+fj569eqFhQsXmv2zWAIHtRIDW3pjWXQilsUkMuwQEREBkAk+74BOp4NWq0VmZma1f6QVl5yJfvP2wEYhQ9TUR1HbUS11SURERFWivN/fFttnhx5MU28tgn2cUagX+ONg9e94TURE9LAYdqzQqPbFw9B/ibqEQr1B4mqIiIikxbBjhQYEe6G2oxpXM/Pwz4m7T65IRERUEzDsWCG1UmG8u/PjngQOQyciohqNYcdKjWzvC5VSjqNJGTiceFPqcoiIiCTDsGOlajuqMahl8XpZP+5JkLgaIiIi6TDsWLHnOgUAKF4vKyk9V+JqiIiIpMGwY8UCPTXo1KA2DAJYuu+i1OUQERFJgmHHyo29fXfn9wNJyM4vkrgaIiIi82PYsXJdG7mhnpsDsvKL8McBTjJIREQ1D8OOlZPLZXiuY/HdncX7ElDESQaJiKiGYdipAYa2qgsXBxWS0m9hU1yq1OUQERGZFcNODWCn+neSwe92X+Akg0REVKMw7NQQo8L8jJMMHknKkLocIiIis2HYqSFqO6oxMLh4ksEley9KWwwREZEZMezUIOEd/AEAfx+/ilRdXrnew0deRERU3THs1CDN6mjRzt8FRQaBn8qxhERMQjqaf7AZy6IvmaE6IiKiqsGwU8OM71YPAPDr/kvIyC24Z9s/DhZPRPju6hP3bUtERGSpGHZqmO6N3dHES4OcAj2W3GcJCU+NrfG/v9t1oYorIyIiqhoMOzWMTCZDRPf6AIDFey/ecwmJIsO//XUW772I69n5VV4fERFRZWPYqYH6NPNCvdoOyLxViGX7794f587Zlm8V6nl3h4iIqiWGnRpIIZdhfLfiuzvf705AXqG+zHaFt8NOszoaAMDPUReRllW+UVxERESWgmGnhhocUgd1nO1wPTsfKw+WvUBo4e3HWD2aeCDE1xl5hQYs2sG7O0REVL0w7NRQNgo5xnUpHpm1aOcF412cOxUWGYxtJz3WCADwa/Slcs/RQ0REZAkYdmqwp9r6oLajGlcybmFtbHKp/SUdlFUKOTo1qI22/rVQUGTAwu3nzF0qERHRA2PYqcFsbRR4vnMAAGDhjnPQG0xnSy6526NUyCCTyfB6j+K7O7/FJOHyzVzzFktERPSAGHZquJGhvtDYKnHhWg42nkgx2VcSdmwUxX9Nwuq7IqyeKwr0BnwZedbstRIRET0Ihp0azsnWBqM7Ft/dmb/tLAx33N0p0hf/t41CBqB4jp63+gQCAFYduYz4lCwzV0tERFRxDDuE5zr6w1GtxOmULGw++e/dnYL/3NkBgJY+zujTzBNCAJ9vOm32WomIiCqKYYfgbK/CmI7+AIC5W/69u1NyZ0epMP1r8kavxlDIZdhyKg0HLqabtVYiIqKKYtghAMDznerB6fbdnX9u990p6bOjuv0Yq0R9N0c82cYHADDzn9MQwrRjMxERkSVh2CEAgNbeBs91Ku678+WWM9AbhHFSQaW89F+TiT0awtZGjkOXbmLLqTSz1kpERFQRDDtkNLZzALR2NjiXlo11R6/8O6mgsvRfEw+NLZ673bF51sbTpYatExERWQqGHTLS2NoYZ1Weu+Wscc0sG7mszPYvdq0PZ3sbnE3Lxv8dumy2OomIiCqCYYdMjO7gj9qOKly6kYsL13MAlH1nBwC0djaI6NYAADB7czxy8ovMVicREVF5MeyQCQe1Eq880tBkm/Iud3YA4NkOfvBztUdaVj6+2XG+qssjIiKqMIYdKmV4O1/4utgbf7ZR3P2viVqpwDt9mwAAvtt9AUnpXEaCiIgsC8MOlaJSyjG5ZyPjz/cKOwDQM8gDHeq7oqDIgJn/cKJBIiKyLAw7VKYBLbzRrbEb/F3t4edqf8+2MpkM7w0IglwG/HX8KqIv3DBTlURERPfHsENlkstl+Cm8Lba/0Q22Nor7tg/01GB4O18AwEcbTnIoOhERWQxJw86uXbswYMAAeHt7QyaTYc2aNaXanDp1Co8//ji0Wi0cHBzQtm1bJCYmGvfn5eUhIiICrq6ucHR0xNChQ5GammrGT2G95HIZZLK7d07+r0mPNYKTrRJxyToORSciIoshadjJyclBcHAwFixYUOb+8+fPo1OnTggMDMSOHTtw7NgxTJs2Dba2tsY2r7/+OtavX4+VK1di586dSE5OxpAhQ8z1EegOro5qvPZo8UiuWZvikZVXKHFFREREgExYyMJGMpkMq1evxqBBg4zbnn76adjY2OCXX34p8z2ZmZlwc3PD8uXLMWzYMADA6dOn0aRJE0RFRaF9+/blOrdOp4NWq0VmZiY0Gs1Df5aarKDIgN5zd+HC9RyM71ofb/cJlLokIiKyUuX9/rbYPjsGgwF//fUXGjVqhF69esHd3R2hoaEmj7oOHTqEwsJC9OjRw7gtMDAQvr6+iIqKkqBqUinleLdf8VD0n/Yk4NKNHIkrIiKims5iw05aWhqys7Mxc+ZM9O7dG5s3b8bgwYMxZMgQ7Ny5EwCQkpIClUoFZ2dnk/d6eHggJSXlrsfOz8+HTqczeVHleSTQHZ0b1kaB3oBP/z4ldTlERFTDWWzYMRiKF6EcOHAgXn/9dbRs2RJvv/02+vfvj0WLFj3UsWfMmAGtVmt8+fj4VEbJdJtMJsO0/kFQyGXYFJeKfeevS10SERHVYBYbdmrXrg2lUomgoCCT7U2aNDGOxvL09ERBQQEyMjJM2qSmpsLT0/Oux546dSoyMzONr6SkpEqvv6Zr5OGEkaHFQ9E/3nCKQ9GJiEgyFht2VCoV2rZti/j4eJPtZ86cgZ+fHwCgdevWsLGxwdatW4374+PjkZiYiLCwsLseW61WQ6PRmLyo8r3eoxE0tkqcuqrD7wcYKImISBpKKU+enZ2Nc+fOGX9OSEhAbGwsXFxc4OvriylTpuCpp55Cly5d0L17d2zcuBHr16/Hjh07AABarRZjx47FpEmT4OLiAo1Gg1deeQVhYWHlHolFVaeWgwoTezTCRxtO4ovN8egf7AWNrY3UZRERUQ0j6dDzHTt2oHv37qW2h4eHY8mSJQCAn376CTNmzMDly5fRuHFjfPjhhxg4cKCxbV5eHiZPnozffvsN+fn56NWrFxYuXHjPx1j/xaHnVadQXzwU/fy1HLzQOQDv9gu6/5uIiIjKobzf3xYzz46UGHaq1vb4NIxZfAA2Chn+frUzGno4SV0SERFZgWo/zw5Zj+6N3dGjiTsK9QLvrD4OAzsrExGRGTHskFl8OLAZ7FUKHLh4E78fZGdlIiIyH4YdMos6znaY9FgjAMCMv08hLStP4oqIiKimYNghsxndwR/N6migyyvCxxs4szIREZkHww6ZjVIhx8whLSCXAeuPJmNHfJrUJRERUQ3AsENm1ayOFmM6BgAA/rfmBHILiiSuiIiIrB3DDpndpMcaoY6zHS7fvIWvtpyVuhwiIrJyDDtkdg5qJT4a2BQA8MOeBMQlZ0pcERERWTOGHZLEo0080Le5J/QGgbf+7xiK9AapSyIiIiv1QGEnKSkJly9fNv4cExODiRMn4rvvvqu0wsj6ffB4U2jtbHDiig7f7b4gdTlERGSlHijsjBgxAtu3bwcApKSk4LHHHkNMTAzeffddfPTRR5VaIFkvdydbvNe/eK2suVvO4lxalsQVERGRNXqgsHPixAm0a9cOAPDHH3+gWbNm2LdvH5YtW2ZcwJOoPIa0qoNujd1QUGTAm38eg55LSRARUSV7oLBTWFgItVoNANiyZQsef/xxAEBgYCCuXr1aedWR1ZPJZPh0cHM4qpU4nJiBJfsuSl0SERFZmQcKO02bNsWiRYuwe/duREZGonfv3gCA5ORkuLq6VmqBZP28ne3wTt8mAIDPN51GwvUciSsiIiJr8kBh57PPPsO3336Lbt26Yfjw4QgODgYArFu3zvh4i6gihrfzQYf6rsgrNGDKyqN8nEVERJVGJoR4oG8VvV4PnU6HWrVqGbddvHgR9vb2cHd3r7QCzUGn00Gr1SIzMxMajUbqcmqspPRc9J67CzkFevyvXxM837me1CUREZEFK+/39wPd2bl16xby8/ONQefSpUuYO3cu4uPjq13QIcvh42KPd/sVj876fFM8zqVlS1wRERFZgwcKOwMHDsTPP/8MAMjIyEBoaCi++OILDBo0CN98802lFkg1y/B2PujcsDbyiwx4g4+ziIioEjxQ2Dl8+DA6d+4MAPjzzz/h4eGBS5cu4eeff8a8efMqtUCqWWQyGT4b2gJOaiVikzLwPScbJCKih/RAYSc3NxdOTk4AgM2bN2PIkCGQy+Vo3749Ll26VKkFUs3j7WyHaQOKH2fN2XwGZ1M52SARET24Bwo7DRo0wJo1a5CUlIRNmzahZ8+eAIC0tDR28KVK8UTruuje2A0FegMmrzzKtbOIiOiBPVDYee+99/DGG2/A398f7dq1Q1hYGIDiuzwhISGVWiDVTDKZDDOGtIDGVoljlzOxYPt5qUsiIqJq6oGHnqekpODq1asIDg6GXF6cmWJiYqDRaBAYGFipRVY1Dj23XKuPXMbrvx+FQi7DHy+GobVfrfu/iYiIaoTyfn8/cNgpUbL6ed26dR/mMJJi2LFcQgi8tiIW644mw8fFDn+/2hlOtjZSl0VERBagSufZMRgM+Oijj6DVauHn5wc/Pz84Ozvj448/hsHAvhVUeWQyGT4e1Ax1nO2QlH4L76+Lk7okIiKqZh4o7Lz77rv4+uuvMXPmTBw5cgRHjhzBp59+ivnz52PatGmVXSPVcFo7G8x9uiXkMmDV4StYdzRZ6pKIiKgaeaDHWN7e3li0aJFxtfMSa9euxcsvv4wrV65UWoHmwMdY1cOczfGYt+0cnGyV+Oe1zqhby17qkoiISEJV+hgrPT29zE7IgYGBSE9Pf5BDEt3Xq482RIivM7LyijDpd86uTERE5fNAYSc4OBhff/11qe1ff/01WrRo8dBFEZVFqZBj7lMt4aBSIOZiOr7ZcU7qkoiIqBpQPsibZs2ahX79+mHLli3GOXaioqKQlJSEv//+u1ILJLqTn6sDPhrYDJNXHsWXW86iY4PaCPHlcHQiIrq7B7qz07VrV5w5cwaDBw9GRkYGMjIyMGTIEMTFxeGXX36p7BqJTAxpVQcDgr2hNxQPS8/OL5K6JCIismAPPc/OnY4ePYpWrVpBr9dX1iHNgh2Uq5/MW4Xo+9VuXMm4hWGt62L2E8FSl0RERGZWpR2UiaSmtbPBl08VD0f/89BlbDjG4ehERFQ2hh2qttoFuCCiewMAwNRVx5F4I1fiioiIyBIx7FC19uqjDdHq9nD0l5YdQl5h9XqESkREVa9Co7GGDBlyz/0ZGRkPUwtRhdko5Ph6RCv0n78Hcck6fLAuDjOHcvoDIiL6V4XCjlarve/+Z5999qEKIqoob2c7zHs6BKN+isaKA0lo5VsLT7b1kbosIiKyEJU6Gqu64mgs6/D1trOYvfkM1Eo5Vr3cAU297x3OiYioeuNoLKpxXu7WAI8EuiO/yICXfj2MzFuFUpdEREQWgGGHrIZcLsOcJ4NRt5YdEtNzMfmPWBi4fhYRUY0nadjZtWsXBgwYAG9vb8hkMqxZs+aubcePHw+ZTIa5c+eabE9PT8fIkSOh0Wjg7OyMsWPHIjs7u2oLJ4vlbK/CNyNbQ6WUY8upNCzadV7qkoiISGKShp2cnBwEBwdjwYIF92y3evVq7N+/H97e3qX2jRw5EnFxcYiMjMSGDRuwa9cujBs3rqpKpmqgeV0tPnq8KQBg9qZ47Dt/XeKKiIhISpKGnT59+uCTTz7B4MGD79rmypUreOWVV7Bs2TLY2NiY7Dt16hQ2btyIH374AaGhoejUqRPmz5+PFStWIDmZM+rWZE+19cGw1nVhEMCrvx1BSmae1CUREZFELLrPjsFgwKhRozBlyhQ0bdq01P6oqCg4OzujTZs2xm09evSAXC5HdHS0OUslCyOTyfDxwGZo4qXB9ewCRCw/jEK9QeqyiIhIAhYddj777DMolUq8+uqrZe5PSUmBu7u7yTalUgkXFxekpKTc9bj5+fnQ6XQmL7I+dioFvhnZCk62Shy6dBMz/j4tdUlERCQBiw07hw4dwldffYUlS5ZAJpNV6rFnzJgBrVZrfPn4cAI6a+Vf2wFf3F4R/ae9CVh/lI83iYhqGosNO7t370ZaWhp8fX2hVCqhVCpx6dIlTJ48Gf7+/gAAT09PpKWlmbyvqKgI6enp8PT0vOuxp06diszMTOMrKSmpKj8KSaxnU0+M71ofAPDmn8cQl5wpcUVERGROFht2Ro0ahWPHjiE2Ntb48vb2xpQpU7Bp0yYAQFhYGDIyMnDo0CHj+7Zt2waDwYDQ0NC7HlutVkOj0Zi8yLpN6dUYnRvWxq1CPcb9fAg3svOlLomIiMykQmtjVbbs7GycO3fO+HNCQgJiY2Ph4uICX19fuLq6mrS3sbGBp6cnGjduDABo0qQJevfujRdeeAGLFi1CYWEhJkyYgKeffrrMYepUcynkMnw9vBUGLtiDizdy8fKyw/j1+VDYKCw27xMRUSWR9Df9wYMHERISgpCQEADApEmTEBISgvfee6/cx1i2bBkCAwPx6KOPom/fvujUqRO+++67qiqZqjGtvQ2+f7YNHNVKRCek46P1J6UuiYiIzIALgYILgdY0W06m4oVfDkII4NPBzTEi1FfqkoiI6AFwIVCiu+gR5IHJjzUCALy/7gQOXEyXuCIiIqpKDDtUI0V0b4B+zb1QqBd46ddDSM64ZfYaUnV5+GrLWVzNNP+5iYhqEoYdqpFkMhk+f6IFAj2dcD27AON+OYhbBXqz1vDr/kv4cssZjPwhGpm5hWY9NxFRTcKwQzWWvUqJ759tg1r2NjhxRYfJK2NhMJivC5vuVnHAuXAth8tZEBFVIYYdqtF8XOyx6JnWsFHI8PfxFHwRGW+2cxfcEW72nLuO99fFgeMFiIgqH8MO1Xih9VwxY0gLAMCC7efx56HLZjlvflFx2OlQ3xUyGbA8OhGL9140y7mJiGoShh0iAMNa18XL3YqXlJi66hiiL9yo8nMW3A47jwV54J0+TQAAn/x1EttPp93rbUREVEEMO0S3vdGzMfo290ShXuDFXw/h4vWcKj1fSdhRKeV4vnMAnm7rA4MAXvntCE6n6Kr03ERENQnDDtFtcrkMXzzREsF1tcjILcRzSw5U6Sipkg7JNgo5ZDIZPhrYDO3ruSA7vwhjlxzEtSyu30VEVBkYdojuYKdS4PvwNvDW2uLC9Ry8tOxQlY2SKumgrFYW/zNUKeVY9ExrBNR2wJWMW3jhZ/MPhyciskYMO0T/4e5kix9Ht4WDSoF9529g2poTVTJKyvgY647FSJ3tVfgxvA20djaITcrAK78dgd6Mw+GJiKwRww5RGZp4aTB/RAjkMmDFgSQs2H6u0s9REnb+u/J6PTdH/BjeBiqlHFtOpeL9dVUTtoiIagqGHaK7eCTQAx883hQAMHvzGaw8mFSpx8+/o4Pyf7Xxd8FXT7WETAb8uj8RC3ecr9RzExHVJAw7RPfwbJg/Xro9JP3tVcexI77yhoWX9NkpK+wAQJ/mXnivfxAA4PNN8Vh12Dzz/xARWRuGHaL7eLNXYwwOqQO9QeDlZYdx/HJmpRy38D5hBwDGdAzAuC71iuv48xh2n71WKecmIqpJGHaI7kMmk+GzoS3QqUFt5BboMWZJDBJv5D70ccvqoFyWt3sHYkCwN4oMAi/9ehhxyZUTtoiIagqGHaJyUCnl+OaZVgjy0uB6dgHCF8cgPafgoY5ZcI8+O3eSy2WY/UQL4xw8YxYfwOWbDx+2iIhqCoYdonJysrXBkjFtUcfZDgnXc/DckgMPNQ9OTn7xe+93ZwcA1EoFvh3VBo09nJCWlY9nf4zB9WxOOkhEVB4MO0QV4K6xxdLn2sHZvngenJeWHTLeoamI/Rdu3LeD8n9p7Wyw5Lm2xgkPw3+KgS6v6mZ4JiKyFgw7RBXUwL14HhxbGzl2xF/DpD9iKzzxX0xCuvG/nWyV5X6fl9YOvzwfClcHFeKSdXh+6UHkFXKWZSKie2HYIXoArf1c8O2oNrBRyLDh2FVMW1uxif9Kmvq52sPJ1qZC567v5oilz7WDk1qJmIR0TFh+uMqWtCAisgYMO0QPqGsjN3x5e+K/5dGJ+HxTfLnfW6AvvhvTvbH7A527WR0tfghvA7VSji2n0vDmn8dg4LISRERlYtghegj9W3hj+qDmAICFO87j253lm+k4v9B0EdAHEVrPFQtHtoJCLsPqI1fw0YaTXFaCiKgMDDtED2lEqC/e6h0IAJjxz2msiEm873sq2jn5bh5t4oEvnggGACzZdxFfbT37UMcjIrJGDDtEleClbvXxYtfimY7fWX0cfx+/es/2JSO4HubOTolBIXXw4e01vOZuOYsfdl946GMSEVkThh2iSvJ270A83dYHBgG8tuIItp+++zpa5Z1QsLzCO/hj8mONAACf/HUKP0ddrJTjEhFZA4Ydokoik8kwfXBz9GvhhUK9wIu/HrrrWlb5+vItFVEREx5pgJdvL1r63tq4cj1OIyKqCRh2iCqRQi7D3Kda4rEgDxQUGfDCzwcRdf5GqXb/3tlRVNq5ZTIZpvRqjOc7BQAApq4+zpXSiYjAsENU6WwUcnw9IgTdG7shr9CAsUsP4ODFdJM2+ZX8GKuETCbDu/2aYFR7PwgBvLHyKNYfTa7UcxARVTcMO0RVQK1U4JtnWqNzw+KV0kcvPoAjiTeN+wuKbq+LVclhBygOPB8+3tTYf2ji77HYeCKl0s9DRFRdMOwQVRFbGwW+G9XGuFr5sz/F4MSVTAB3PMaqxD47d5LLi/sPDQmpA71B4JXfDmPb6dQqORcRkaVj2CGqQnYqBX4Mb4s2frWQlVeEZ36MxqmrOuM8O2qbqvsnqJDLMGtYC2OH6fG/HsauM2V3mCYismYMO0RVzEGtxOIxbdHSxxkZuYUY+UM0UjLzAADqKrqzU0KpkGPuUy3R83aH6ed/Pojt8XcfEk9EZI0YdojMwMnWBkufa4fmdbRIzynA9ewCAFXTZ+e/ijtMtzKOEHvx50PYeoqPtIio5mDYITITrZ0Nfh0biuZ1tMZt5gg7JedZOLIV+jTzRIHegPG/HsLmOHZaJqKagWGHyIy09sWBp52/Czw1tqjn5mi2c9so5Jg3PMTYh+flZYex8cS9l7UgIrIGMsFlkqHT6aDVapGZmQmNRiN1OVQDCCGgNwgoq7jPTlmK9AZMXnkUa2OToZDLMO/p4gBERFTdlPf7m3d2iCQgk8kkCTpAcaflOU+2xJBWxcPSX11xBGtjr0hSCxGROTDsENVACrkMnw8LxpNt6kJvEHj991j8cSBJ6rKIiKoEww5RDaWQyzBzSAuMCPWFQQBv/t8x/LD7gtRlERFVOoYdohpMLpdh+qBmeLFLPQDAJ3+dwuxN8WBXPiKyJpKGnV27dmHAgAHw9vaGTCbDmjVrjPsKCwvx1ltvoXnz5nBwcIC3tzeeffZZJCebLmqYnp6OkSNHQqPRwNnZGWPHjkV2draZPwlR9SWTyTC1bxO82bsxAODr7efw3to4GAwMPERkHSQNOzk5OQgODsaCBQtK7cvNzcXhw4cxbdo0HD58GKtWrUJ8fDwef/xxk3YjR45EXFwcIiMjsWHDBuzatQvjxo0z10cgshovd2uA6YObQSYDftl/Ca//EYvC28taEBFVZxYz9Fwmk2H16tUYNGjQXdscOHAA7dq1w6VLl+Dr64tTp04hKCgIBw4cQJs2bQAAGzduRN++fXH58mV4e3uX69wcek70r/VHk/H677EoMgg8EuiOBSNawU6lkLosIqJSrHLoeWZmJmQyGZydnQEAUVFRcHZ2NgYdAOjRowfkcjmio6Pvepz8/HzodDqTFxEVGxDsje/D28DWRo5tp9MQ/lMMdHmFUpdFRPTAqk3YycvLw1tvvYXhw4cb01tKSgrc3d1N2imVSri4uCAl5e5T4c+YMQNardb48vHxqdLaiaqb7o3d8cvYUDjZKhFzMR3Dv9uP69n5UpdFRPRAqkXYKSwsxJNPPgkhBL755puHPt7UqVORmZlpfCUlcX4Rov9q6++CFePaw9VBhbhkHZ5cFIXLN3OlLouIqMIsPuyUBJ1Lly4hMjLS5Jmcp6cn0tLSTNoXFRUhPT0dnp6edz2mWq2GRqMxeRFRaU29tVg5Pgx1nO1w4XoOBi/chxNXMqUui4ioQiw67JQEnbNnz2LLli1wdXU12R8WFoaMjAwcOnTIuG3btm0wGAwIDQ01d7lEVqmemyP+fCkMgZ5OuJaVjye/jcL2+LT7v5GIyEJIGnays7MRGxuL2NhYAEBCQgJiY2ORmJiIwsJCDBs2DAcPHsSyZcug1+uRkpKClJQUFBQUAACaNGmC3r1744UXXkBMTAz27t2LCRMm4Omnny73SCwiuj8vrR3+GB+GTg1qI7dAj+eXHsSKmESpyyIiKhdJh57v2LED3bt3L7U9PDwcH3zwAQICAsp83/bt29GtWzcAxZMKTpgwAevXr4dcLsfQoUMxb948ODo6lrsODj0nKp+CIgPeXnUMqw4XLxz6yiMNMOmxRpDJZBJXRkQ1UXm/vy1mnh0pMewQlZ8QAl9uOYt5W88CAIaE1MHMoS2gUlr0U3EiskJWOc8OEUlPJpNh0mON8NnQ5lDIZVh15ArGLOFcPERkuRh2iOiBPNXWFz+Gt4GDSoG9527gyUVRSM64JXVZRESlMOwQ0QPr1tgdv78YBjcnNU6nZOHxr/fiSOJNqcsiIjLBsENED6VZHS1Wv9wBgZ5OuJ6dj6e+24+1sVekLouIyIhhh4geWt1a9vjzpQ7o0cQDBUUGvLYiFrM3xcNgqPHjH4jIAjDsEFGlcFQr8e2o1nixaz0AwNfbz+HlZYeRW1AkcWVEVNMx7BBRpVHIZZjapwlmPxEMlUKOjXEpeIIdl4lIYgw7RFTphrWui+UvhBoXER24oHI6LgshoOejMSKqIIYdIqoSbfxdsCaio3FNrcrouPzaili0m74F206nVlKVRFQTMOwQUZXxcSnpuOxu7Lg885/TKNIbHuh4e89dx42cAoxdehDztp5lB2giKheGHSKqUsUdl9sYOy4v2nkez/4Ug+vZ+RU+Vn5RcUgSApgTeQYv/noIWZy5mYjug2GHiKpcScflr0eEwF6lwL7zNzBg/p4K9+PJK9QDACY/1ggqpRyRJ1MxcMFenEvLroqyichKMOwQkdn0b+GNtREdUc/NAVcz8/Dkt1H4df8llGc94iK9AUW3H1uNbO+HlS+GwUtriwvXcjBowV5sikup6vKJqJpi2CEis2ro4YS1ER3Ru6knCvUC/1tzApNXHsWtAv0931fyCAsAbG3kCPZxxvpXOqFdgAuy84vw4i+HMP2vkyh8wP5ARGS9GHaIyOycbG3wzTOtMLVPIOQyYNXhKxjyzT5cupFz1/eUPMICALVSAQCo7ajGsudD8VzHAADA97sT8NS3nNeHiEwx7BCRJGQyGV7sWh+/Pl88H8+pqzr0n78HW0+VPay85M6OjUIGhVxm3G6jkOO9AUFY9EwrONkqcTgxA/3m7cb2+DSzfA4isnwMO0QkqQ71a2PDq50Q4uuMrLwijF16EDP+PlXqcVTJnR3b23d1/qt3My/89UpnNKujwc3cQoxZfACzNj74MHcish4MO0QkOS+tHX4fF4bRHfwBAN/uuoCnvo3ClTseR5Xc2VHblB12AMDX1R5/ju+AUe39AAALd5zHiB+ikarLq7riicjiMewQkUVQKeX44PGm+GZkKzip/30cVfJYq+TOjlp5719btjYKfDyoGeYPD4GjWomYhHT0/Wo39py9XuWfgYgsE8MOEVmUPs298NerndGirhYZuYUYu/Qgpv91Etn5xaun29qU79fWgGBvrJtQvFzFjZwCjPopGl9GnuHaWkQ1EMMOEVkcX1d7rBwfhjEd/QEUj7J6/fdYAMV3bsqrnpsj1kR0xPB2PhAC+GrrWQz/fr/J4zEisn4MO0RkkdRKBd4f0BSLnmkNrZ0NrmcX3N5esV9btjYKzBjSAl8+FQwHlQIxCenoPXfXQy9KSkTVB8MOEVm03s088c9rndHO3wUA4Km1faDjDA6pi79f62wc9fXailhMXHEEOq6tRWT1ZKI887RbOZ1OB61Wi8zMTGg0GqnLIaIy6A0CO8+koUVdZ9R2VD/wcYr0Bny9/VzxqukCqONshy+faol2AS6VWC0RmUN5v78ZdsCwQ1QTHbp0E6//HovE9FzIZcBL3epjYo9GsFHwhjdRdVHe72/+qyaiGqm1Xy38/VpnDGtdFwYBLNh+HkO/2Yfz17iCOpG1YdghohrLUa3E7CeCsWBEK2jtbHDscib6fLUbC3ec48zLRFaEYYeIarx+LbywcWJndGnkhoIiA2ZtjMeghXsRl5wpdWlEVAkYdoiIULxkxdIxbTH7iWBo7Wxw4ooOA7/ei9mb4pFfpL//AYjIYjHsEBHdJpPJMKx1XURO6oLeTT1RZBD4evs59Ju3B4cu3ZS6PCJ6QAw7RET/4e5ki0WjWuObka1Q21GNc2nZGLZoHz5cH4fcgiKpyyOiCmLYISK6iz7NvbBlUhcMaVUHQgCL915Er7m7sPccFxUlqk4YdoiI7sHZXoU5T7bE4jFt4a21RVL6LYz8IRpv/98xZN7i7MtE1QHDDhFROXRv7I7Nk7piVHs/AMCKA0no+eVORJ5MlbgyIrofhh0ionJyVCvx8aBm+H1cewTUdkCqLh8v/HwQr/x2BDey86Uuj4jugmGHiKiCQuu54p/XOuPFrvUglwHrjyajx5ydWHPkCrgCD5HlYdghInoAtjYKTO3TBGsiOiLQ0wk3cwsx8fdYPPXdfpxO0UldHhHdgWGHiOghtKjrjHUTOuGNno1gayNHTEI6+s3bgw/Xx7EDM5GFYNghInpIKqUcEx5piC2TuqJPM0/oDQKL917Eo1/swJ+HLsNgsMxHWwcvpmPYN/vwc9RFrgVGVk0m+IC53EvEExGVx+6z1/D+ujhcuJYDAGjl64yPBjZDszpaiSszNW3NCfyy/xIAoLGHE94fEIQODWpLXBVR+ZX3+1vSOzu7du3CgAED4O3tDZlMhjVr1pjsF0Lgvffeg5eXF+zs7NCjRw+cPXvWpE16ejpGjhwJjUYDZ2dnjB07FtnZ2Wb8FEREpjo3dMPG17pgap9A2KsUOJyYgQFf78G7q48jI7dA6vKMcu6YDTo+NQsjfojG+F8OISk9V8KqiCqfpGEnJycHwcHBWLBgQZn7Z82ahXnz5mHRokWIjo6Gg4MDevXqhby8PGObkSNHIi4uDpGRkdiwYQN27dqFcePGmesjEBGVSaWU48Wu9bFtcjc8HuwNIYBl0YnoPnsHlu67iEILeGyUV1i8wOmkxxohPMwPCrkMG+NS8OicnZi9KZ5LY5DVsJjHWDKZDKtXr8agQYMAFN/V8fb2xuTJk/HGG28AADIzM+Hh4YElS5bg6aefxqlTpxAUFIQDBw6gTZs2AICNGzeib9++uHz5Mry9vct1bj7GIqKqtv/CDby/Ng7xqVkAgIDaDnirdyB6NfWATCaTpKbRi2OwI/4aZg1rgSfb+CA+JQsfro/DvvM3AACeGltM6dUYg0PqQC6Xpkaie6kWj7HuJSEhASkpKejRo4dxm1arRWhoKKKiogAAUVFRcHZ2NgYdAOjRowfkcjmio6Pveuz8/HzodDqTFxFRVWpfzxV/vdoJnwxqhtqOKiRcz8H4Xw/hiUVROJJYuSuqF+oNyC/S37fdrYLiNvYqBQCgsacTlj0fikXPtIaPix1SdHmYvPIo+s3fg91nr1VqjUTmZLFhJyUlBQDg4eFhst3Dw8O4LyUlBe7u7ib7lUolXFxcjG3KMmPGDGi1WuPLx8enkqsnIipNqZDjmfZ+2DGlO155pAFsbeQ4eOkmBi/ch4jlh5F4o3L6yoz6MRohH0Xii83xyMq7+/D3W7cfY9nZKIzbZDIZejfzROTrXfFm78ZwUitx6qoOo36MwagfoxGXnFkpNRKZk8WGnao0depUZGZmGl9JSUlSl0RENYijWonJPRtj+xvd8ETrupDJgL+OXcWjc3bgo/UncTPn4ToxH07MQG6BHvO3nUOXWdvxw+4LZd7pKbmzY6dSlNpna6PAy90aYOeb3fFcxwDYKGTYffY6+s/fg0m/x+LyTXZipurDYsOOp6cnACA11XSRvdTUVOM+T09PpKWlmewvKipCenq6sU1Z1Go1NBqNyYuIyNy8tHb4/Ilg/PVKZ3RuWBuFeoGf9iagy6zt+DLyzANNSqg3CBQUFXd+9nGxw83cQnzy1yk8Mnsn/jx0Gfo75vzJLSh9Z+e/XBxUeG9AELZO+rej9aojV/DIFzsx4+9TyMzlxIlk+Sw27AQEBMDT0xNbt241btPpdIiOjkZYWBgAICwsDBkZGTh06JCxzbZt22AwGBAaGmr2momIHkSQtwa/jA3F0ufaIdDTCVn5Rfhq61l0/mwb5m09e89HUf915wiqja91wcwhzeGpscWVjFt4Y+VR9P1qN7acTIUQwjgay16lvO9xfV3tMW94CNZN6Iiweq4oKDLg210X0GnWNszfehbZ+Ry5RZZL0tFY2dnZOHfuHAAgJCQEc+bMQffu3eHi4gJfX1989tlnmDlzJpYuXYqAgABMmzYNx44dw8mTJ2FrawsA6NOnD1JTU7Fo0SIUFhZizJgxaNOmDZYvX17uOjgai4gshcEg8M+JFMzdcgZn04rnDNPa2eCFzgEY3TEAjup7B5M0XR7afboVchlw/tO+kMlkyCvUY8m+i1i4/Rx0ecWhpJWvM05c0aFAb8CuKd3h62pf7hqFENhx5ho+++c0TqcUjy5zcVDhpa71MSrMD7b3uFNEVJnK+/0tadjZsWMHunfvXmp7eHg4lixZAiEE3n//fXz33XfIyMhAp06dsHDhQjRq1MjYNj09HRMmTMD69eshl8sxdOhQzJs3D46OjuWug2GHiCyN3iDw1/Gr+GrLGZy/PRNzLXsbvNClHsLD/OFwl9CTcD0H3WfvgKNaiRMf9jLZl5lbiG92nsfivQnIL/p3np8D7/aAm5O6wjUaDAIbjl/F3MgzuHC9uEZ3JzVeeaQBnmzrA7WSoYeqVrUIO5aCYYeILJXeILDhWDK+2nLWGChcHFR4sUs9jArzK/UIKi45E/3m7YGbkxoH3u1R1iGRpsvDwh3nsTw6ERo7Jfa9/ShUygfv1VCkN2DVkSv4astZXMm4BQCo42yHiO4NMLR1HYYeqjIMOxXAsENElq5Ib8C6o8mYt/UsLt4eol7bUYXxXetjZKifcUTVwYvpGLYoCn6u9tg5pfSd8zvdzCmAQHF4qgwFRQb8fiAR87edQ1pWPgDAS2uLF7vUw9PtfPl4iyodw04FMOwQUXVRpDdg9ZErmL/tHBJvr2Hl5qTGS13rY0SoL2IS0vHsTzEI9HTCxoldJKkxr1CPZdGJ+G7XeaTqikNPbUcVXuhcDyPb+9233xFReTHsVADDDhFVN4V6A1YfvoJ5287i8s3iR0fuTmo0cHfEvvM30MrXGate7ihpjflFevx56DK+2XHeWKOzvQ2e6xiA8A7+0NrZSFofVX8MOxXAsENE1VVBkQH/d/gyvt52zthfBgA6NnDFsufbS1jZvwr1Bqw5cgULd5xHwu1+R05qJZ7t4IcxHQNQ27HinaOJAIadCmHYIaLqrqDIgD8OJuGzf04jK78IT7api1nDgqUuy0TJCLMF284ZF0RVKeUYElIHz3cOQAN3J4krpOqGYacCGHaIyFrkF+kRk5COEN9aFts3xmAQiDyVioU7zuNoUoZxe/fGbnihcz2E1XeVbCV4ql4YdiqAYYeIyPyEEDh46Sa+33UBkadSUfJtFOSlwQtdAtC/hTdsFBY70T9ZAIadCmDYISKSVsL1HPy0JwErDyUhr7B4wkNPjS1Gd/TH8Ha+7MxMZWLYqQCGHSIiy3AzpwDLoi9hadQlXLs9V4+DSoFBIXUwItQXTb21EldIloRhpwIYdoiILEt+kR5rY5Px4+4EY2dmAAj2ccbIdr7oH+xVrgVMybox7FQAww4RkWUSQiDq/A0si0nE5rgUFOqLv7KcbJUYElIHI0L90NiTo7hqKoadCmDYISKyfNez87Hy4GX8FpNonD0aANr41cKIUF/0be7FJSlqGIadCmDYISKqPgwGgT3nrmN5dCIiT6VCbyj+GtPa2WBoq7oYEeqLBu6OEldJ5sCwUwEMO0RE1VOaLg9/HEzCbzFJJjNItwtwwZNtfNC7mafFzjdED49hpwIYdoiIqje9QWDX2WtYHp2IradScftmD2xt5OgZ5InBreqgc4PaUHLeHqvCsFMBDDtERNbjauYt/HnwMlYfuYILt9fiAopXXh8Q7I0hIXXRrI6GszRbAYadCmDYISKyPkIIHLucidVHrmDd0WSk5xQY9zVwd8TgkDoY2NIbdWvZS1glPQyGnQpg2CEism6FegN2nbmG1UeuIPJkKvKLDMZ9oQEuGBxSB32ae3Gm5mqGYacCGHaIiGoOXV4hNh5PweojV7A/4YZxTS6VUo7Hmnjg8Zbe6NrIjcPYqwGGnQpg2CEiqpmSM25hTewVrD58BWfTso3b7VUKdG/sjl7NPNG9sRucbHnHxxIx7FQAww4RUc0mhEBcsg6rj1zBxhMpJsPYVQo5OjesjV7NPPFYEw/UclBJWCndiWGnAhh2iIiohBACx69kYuOJFGw8kWIyokshlyE0wAV9mnmiZ1NPeGhsJayUGHYqgGGHiIjKIoTA2bRsY/A5eVVnsr+VrzN6N/PEo008UK+2A4ezmxnDTgUw7BARUXkk3sjFxrir2HgiBYcTM0z2+bjYoVsjd3Rr7Iaw+q5cld0MGHYqgGGHiIgqKlWXh81xKdgUl4qYhHQU6P8dzq5SyhEa4IKujdzQPdCdd32qCMNOBTDsEBHRw8jJL8K+8zewIz4NO+KvmXRwBorv+nRt5IZujdzRoUHV3fURQmD32euwVykQ7OMMGytfHoNhpwIYdoiIqLIIIXD+Wo4x+JS666OQo12ACzo3rI2ODWojyEsDubxy7vrsO38dI76PBlA8fL5dgAs61HdFh/qVex5LwbBTAQw7RERUVXLyixB1/gZ2nCkOP5dvmt71qWVvg7D6rgirXxuhAS5o4Ob4wKFkWfQlvLv6RJn7nO1t0D7AFR0buCKsvivquzlW+0drDDsVwLBDRETmUHLXZ+eZa9h37jr2X7iBnAK9SZta9jZo4++Cdv4uaBfggqbemnKv1r5g+zl8vikew1rXxXMdA7Dv/HXsO38D0WWcx8VBhbb+tdAuwBWhAS5o4qWBoprd+WHYqQCGHSIikkKh3oBjlzOw5+wNRCfcwOHEm8grNJi0sVcp0Mq3FtoFuKCtvwtCfJ3vupTF9L9O4vvdCRjXpR7e6dvkP+fJxL5zxeHncOJNk/XBAMBRrURrv+LztPGrheZ1tRY/ooxhpwIYdoiIyBIUFBlwIjkTMQnpOJCQjgMX06HLKzJpY6OQoUVdZ7T1d0ErX2e09HWGu1Px5IZvrDyKPw9dxpu9G+Plbg3ueZ7jVzIQk3ATMQk3cPDiTWTlm55HIZehkYcTWvo4I8Sn+Dz13Rwt6u4Pw04FMOwQEZElMhgE4lOzcOBiOmISil9pWfml2tWtZYeWPs44eVWHC9dy8Ong5hgR6lvu8+gNAqeu6oznOZKYgRRdXql2jmolWtTVItjH2RiC3CWcRZphpwIYdoiIqDoQQiAxPRcxCek4ePEmYpMycCYtC//9Jl/0TCv0bub1UOdKycxDbNJNHEnKQGxiBo5fyUTuf/r9AIC31hYtfYvDT3BdZwR5a8y2cCrDTgUw7BARUXWVlVeIY5czcSTxJo4kZsAgBOaPaAVHdeX2t9EbBM6kZuFoUgZib7/OpGbBUEaK8He1R1NvLYK8NWjqrUFTby3cnNSVWg/AsFMhDDtEREQVl5NfhGOXM2+Hn5s4djkTVzNLP/4CgK+ebomBLetU6vnL+/1t2d2siYiIyGI5qJW35whyNW5LzylAXHIm4pJ1t1+ZSLieg0YeTpLVybBDRERElcbFQYXODd3QuaGbcVtOftFdh8ubA8MOERERVSmHSu4/VFHWvUIYERER1XgMO0RERGTVLDrs6PV6TJs2DQEBAbCzs0P9+vXx8ccf484BZEIIvPfee/Dy8oKdnR169OiBs2fPSlg1ERERWRKLDjufffYZvvnmG3z99dc4deoUPvvsM8yaNQvz5883tpk1axbmzZuHRYsWITo6Gg4ODujVqxfy8soe+kZEREQ1i0XPs9O/f394eHjgxx9/NG4bOnQo7Ozs8Ouvv0IIAW9vb0yePBlvvPEGACAzMxMeHh5YsmQJnn766XKdh/PsEBERVT/l/f626Ds7HTp0wNatW3HmzBkAwNGjR7Fnzx706dMHAJCQkICUlBT06NHD+B6tVovQ0FBERUXd9bj5+fnQ6XQmLyIiIrJOFj30/O2334ZOp0NgYCAUCgX0ej2mT5+OkSNHAgBSUlIAAB4eHibv8/DwMO4ry4wZM/Dhhx9WXeFERERkMSz6zs4ff/yBZcuWYfny5Th8+DCWLl2K2bNnY+nSpQ913KlTpyIzM9P4SkpKqqSKiYiIyNJY9J2dKVOm4O233zb2vWnevDkuXbqEGTNmIDw8HJ6engCA1NRUeHn9u7pramoqWrZsedfjqtVqqNWVvyAZERERWR6LvrOTm5sLudy0RIVCAYPBAAAICAiAp6cntm7datyv0+kQHR2NsLAws9ZKRERElsmi7+wMGDAA06dPh6+vL5o2bYojR45gzpw5eO655wAAMpkMEydOxCeffIKGDRsiICAA06ZNg7e3NwYNGiRt8URERGQRLDrszJ8/H9OmTcPLL7+MtLQ0eHt748UXX8R7771nbPPmm28iJycH48aNQ0ZGBjp16oSNGzfC1tZWwsqJiIjIUlj0PDvmwnl2iIiIqp/yfn9b9J0dcynJe5xvh4iIqPoo+d6+330bhh0AWVlZAAAfHx+JKyEiIqKKysrKglarvet+PsYCYDAYkJycDCcnJ8hksko7rk6ng4+PD5KSkvh4rIrxWpsHr7N58DqbB6+zeVTldRZCICsrC97e3qVGb9+Jd3YAyOVy1K1bt8qOr9Fo+A/JTHitzYPX2Tx4nc2D19k8quo63+uOTgmLnmeHiIiI6GEx7BAREZFVY9ipQmq1Gu+//z6XpjADXmvz4HU2D15n8+B1Ng9LuM7soExERERWjXd2iIiIyKox7BAREZFVY9ghIiIiq8awQ0RERFaNYacKLViwAP7+/rC1tUVoaChiYmKkLqnamDFjBtq2bQsnJye4u7tj0KBBiI+PN2mTl5eHiIgIuLq6wtHREUOHDkVqaqpJm8TERPTr1w/29vZwd3fHlClTUFRUZM6PUq3MnDkTMpkMEydONG7jda48V65cwTPPPANXV1fY2dmhefPmOHjwoHG/EALvvfcevLy8YGdnhx49euDs2bMmx0hPT8fIkSOh0Wjg7OyMsWPHIjs729wfxWLp9XpMmzYNAQEBsLOzQ/369fHxxx+brJ3E61xxu3btwoABA+Dt7Q2ZTIY1a9aY7K+sa3rs2DF07twZtra28PHxwaxZsyrnAwiqEitWrBAqlUr89NNPIi4uTrzwwgvC2dlZpKamSl1atdCrVy+xePFiceLECREbGyv69u0rfH19RXZ2trHN+PHjhY+Pj9i6das4ePCgaN++vejQoYNxf1FRkWjWrJno0aOHOHLkiPj7779F7dq1xdSpU6X4SBYvJiZG+Pv7ixYtWojXXnvNuJ3XuXKkp6cLPz8/MXr0aBEdHS0uXLggNm3aJM6dO2dsM3PmTKHVasWaNWvE0aNHxeOPPy4CAgLErVu3jG169+4tgoODxf79+8Xu3btFgwYNxPDhw6X4SBZp+vTpwtXVVWzYsEEkJCSIlStXCkdHR/HVV18Z2/A6V9zff/8t3n33XbFq1SoBQKxevdpkf2Vc08zMTOHh4SFGjhwpTpw4IX777TdhZ2cnvv3224eun2GnirRr105EREQYf9br9cLb21vMmDFDwqqqr7S0NAFA7Ny5UwghREZGhrCxsRErV640tjl16pQAIKKiooQQxf845XK5SElJMbb55ptvhEajEfn5+eb9ABYuKytLNGzYUERGRoquXbsaww6vc+V56623RKdOne6632AwCE9PT/H5558bt2VkZAi1Wi1+++03IYQQJ0+eFADEgQMHjG3++ecfIZPJxJUrV6qu+GqkX79+4rnnnjPZNmTIEDFy5EghBK9zZfhv2Kmsa7pw4UJRq1Ytk98bb731lmjcuPFD18zHWFWgoKAAhw4dQo8ePYzb5HI5evTogaioKAkrq74yMzMBAC4uLgCAQ4cOobCw0OQaBwYGwtfX13iNo6Ki0Lx5c3h4eBjb9OrVCzqdDnFxcWas3vJFRESgX79+JtcT4HWuTOvWrUObNm3wxBNPwN3dHSEhIfj++++N+xMSEpCSkmJyrbVaLUJDQ02utbOzM9q0aWNs06NHD8jlckRHR5vvw1iwDh06YOvWrThz5gwA4OjRo9izZw/69OkDgNe5KlTWNY2KikKXLl2gUqmMbXr16oX4+HjcvHnzoWrkQqBV4Pr169Dr9Sa//AHAw8MDp0+flqiq6stgMGDixIno2LEjmjVrBgBISUmBSqWCs7OzSVsPDw+kpKQY25T1Z1Cyj4qtWLEChw8fxoEDB0rt43WuPBcuXMA333yDSZMm4Z133sGBAwfw6quvQqVSITw83HityrqWd15rd3d3k/1KpRIuLi681re9/fbb0Ol0CAwMhEKhgF6vx/Tp0zFy5EgA4HWuApV1TVNSUhAQEFDqGCX7atWq9cA1MuyQxYuIiMCJEyewZ88eqUuxOklJSXjttdcQGRkJW1tbqcuxagaDAW3atMGnn34KAAgJCcGJEyewaNEihIeHS1yd9fjjjz+wbNkyLF++HE2bNkVsbCwmTpwIb29vXucajI+xqkDt2rWhUChKjVhJTU2Fp6enRFVVTxMmTMCGDRuwfft21K1b17jd09MTBQUFyMjIMGl/5zX29PQs88+gZB8VP6ZKS0tDq1atoFQqoVQqsXPnTsybNw9KpRIeHh68zpXEy8sLQUFBJtuaNGmCxMREAP9eq3v93vD09ERaWprJ/qKiIqSnp/Na3zZlyhS8/fbbePrpp9G8eXOMGjUKr7/+OmbMmAGA17kqVNY1rcrfJQw7VUClUqF169bYunWrcZvBYMDWrVsRFhYmYWXVhxACEyZMwOrVq7Ft27ZStzZbt24NGxsbk2scHx+PxMRE4zUOCwvD8ePHTf6BRUZGQqPRlPrSqakeffRRHD9+HLGxscZXmzZtMHLkSON/8zpXjo4dO5aaPuHMmTPw8/MDAAQEBMDT09PkWut0OkRHR5tc64yMDBw6dMjYZtu2bTAYDAgNDTXDp7B8ubm5kMtNv9oUCgUMBgMAXueqUFnXNCwsDLt27UJhYaGxTWRkJBo3bvxQj7AAcOh5VVmxYoVQq9ViyZIl4uTJk2LcuHHC2dnZZMQK3d1LL70ktFqt2LFjh7h69arxlZuba2wzfvx44evrK7Zt2yYOHjwowsLCRFhYmHF/yZDonj17itjYWLFx40bh5ubGIdH3cedoLCF4nStLTEyMUCqVYvr06eLs2bNi2bJlwt7eXvz666/GNjNnzhTOzs5i7dq14tixY2LgwIFlDt8NCQkR0dHRYs+ePaJhw4Y1ekj0f4WHh4s6deoYh56vWrVK1K5dW7z55pvGNrzOFZeVlSWOHDkijhw5IgCIOXPmiCNHjohLly4JISrnmmZkZAgPDw8xatQoceLECbFixQphb2/PoeeWbv78+cLX11eoVCrRrl07sX//fqlLqjYAlPlavHixsc2tW7fEyy+/LGrVqiXs7e3F4MGDxdWrV02Oc/HiRdGnTx9hZ2cnateuLSZPniwKCwvN/Gmql/+GHV7nyrN+/XrRrFkzoVarRWBgoPjuu+9M9hsMBjFt2jTh4eEh1Gq1ePTRR0V8fLxJmxs3bojhw4cLR0dHodFoxJgxY0RWVpY5P4ZF0+l04rXXXhO+vr7C1tZW1KtXT7z77rsmw5l5nStu+/btZf5ODg8PF0JU3jU9evSo6NSpk1Cr1aJOnTpi5syZlVK/TIg7ppUkIiIisjLss0NERERWjWGHiIiIrBrDDhEREVk1hh0iIiKyagw7REREZNUYdoiIiMiqMewQERGRVWPYISIiIqvGsENE1dLo0aMxaNAgAEC3bt0wceJESeshIsvFsENEdFtBQYHUJRBRFWDYIaJqbfTo0di5cye++uoryGQyyGQyXLx4EQBw4sQJ9OnTB46OjvDw8MCoUaNw/fp143u7deuGCRMmYOLEiahduzZ69eol0acgoqrEsENE1dpXX32FsLAwvPDCC7h69SquXr0KHx8fZGRk4JFHHkFISAgOHjyIjRs3IjU1FU8++aTJ+5cuXQqVSoW9e/di0aJFEn0KIqpKSqkLICJ6GFqtFiqVCvb29vD09DRu//rrrxESEoJPP/3UuO2nn36Cj48Pzpw5g0aNGgEAGjZsiFmzZpm9biIyH4YdIrJKR48exfbt2+Ho6Fhq3/nz541hp3Xr1uYujYjMjGGHiKxSdnY2BgwYgM8++6zUPi8vL+N/Ozg4mLMsIpIAww4RVXsqlQp6vd5kW6tWrfB///d/8Pf3h1LJX3VENRk7KBNRtefv74/o6GhcvHgR169fh8FgQEREBNLT0zF8+HAcOHAA58+fx6ZNmzBmzJhSwYiIrBvDDhFVe2+88QYUCgWCgoLg5uaGxMREeHt7Y+/evdDr9ejZsyeaN2+OiRMnwtnZGXI5f/UR1SQyIYSQuggiIiKiqsL/vSEiIiKrxrBDREREVo1hh4iIiKwaww4RERFZNYYdIiIismoMO0RERGTVGHaIiIjIqjHsEBERkVVj2CEiIiKrxrBDREREVo1hh4iIiKwaww4RERFZtf8HTgTMtdBB/jQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(krr.loss_history, label = 'krr')\n",
    "plt.xlabel('Iter')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss history on x_train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ У krr качество оказалось лучше, чем у rff, но считает оно дольше"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
